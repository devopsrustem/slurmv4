2025-07-22 13:02:25,589 p=43730 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in 
version 2.18. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:02:25,590 p=43730 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in 
version 2.18. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:02:26,222 p=43730 u=master n=ansible | sm02 | CHANGED | rc=0 >>
sm02
Warning: Permanently added 'sm02' (ED25519) to the list of known hosts.
Shared connection to sm02 closed.


2025-07-22 13:02:26,616 p=43730 u=master n=ansible | sm01 | CHANGED | rc=0 >>
sm01
Warning: Permanently added 'sm01' (ED25519) to the list of known hosts.
Shared connection to sm01 closed.


2025-07-22 13:02:26,664 p=43730 u=master n=ansible | cn01 | CHANGED | rc=0 >>
cn01
Warning: Permanently added 'cn01' (ED25519) to the list of known hosts.
Shared connection to cn01 closed.


2025-07-22 13:02:26,706 p=43730 u=master n=ansible | cn02 | CHANGED | rc=0 >>
cn02
Warning: Permanently added 'cn02' (ED25519) to the list of known hosts.
Shared connection to cn02 closed.


2025-07-22 13:02:47,833 p=43754 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in 
version 2.18. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:02:47,834 p=43754 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in 
version 2.18. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:02:48,641 p=43754 u=master n=ansible | sm02 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
2025-07-22 13:02:48,720 p=43754 u=master n=ansible | cn01 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
2025-07-22 13:02:48,729 p=43754 u=master n=ansible | cn02 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
2025-07-22 13:02:48,733 p=43754 u=master n=ansible | sm01 | SUCCESS => {
    "changed": false,
    "ping": "pong"
}
2025-07-22 13:03:10,323 p=43767 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in 
version 2.18. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:03:10,323 p=43767 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in 
version 2.18. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:03:10,465 p=43767 u=master n=ansible | [WARNING]: Could not match supplied host pattern, ignoring: slurm-cluster

2025-07-22 13:03:10,465 p=43767 u=master n=ansible | [WARNING]: No hosts matched, nothing to do

2025-07-22 13:03:10,465 p=43767 u=master n=ansible |   hosts (0):
2025-07-22 13:18:35,313 p=44118 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:18:35,313 p=44118 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:18:35,751 p=44118 u=master n=ansible | ERROR! conflicting action statements: command, creates

The error appears to be in '/home/master/22Jul/slurm-hpc-cluster/roles/common/tasks/main.yml': line 68, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


- name: "[COMMON] Создание MUNGE ключа на master узле"
  ^ here

2025-07-22 13:21:19,812 p=44159 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:21:19,812 p=44159 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:21:20,253 p=44159 u=master n=ansible | PLAY [Тестирование роли common] ********************************************************************************************************************************************
2025-07-22 13:21:20,268 p=44159 u=master n=ansible | TASK [Gathering Facts] *****************************************************************************************************************************************************
2025-07-22 13:21:20,268 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:21:20 +0000 (0:00:00.017)       0:00:00.017 ********** 
2025-07-22 13:21:22,069 p=44159 u=master n=ansible | ok: [sm01]
2025-07-22 13:21:22,083 p=44159 u=master n=ansible | ok: [sm02]
2025-07-22 13:21:22,107 p=44159 u=master n=ansible | ok: [cn02]
2025-07-22 13:21:22,162 p=44159 u=master n=ansible | ok: [cn01]
2025-07-22 13:21:22,166 p=44159 u=master n=ansible | TASK [Информация о тестировании] *******************************************************************************************************************************************
2025-07-22 13:21:22,166 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:21:22 +0000 (0:00:01.897)       0:00:01.915 ********** 
2025-07-22 13:21:22,216 p=44159 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 13:21:22,224 p=44159 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 13:21:22,232 p=44159 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 13:21:22,242 p=44159 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 13:21:22,258 p=44159 u=master n=ansible | TASK [common : [COMMON] Начало выполнения роли common] *********************************************************************************************************************
2025-07-22 13:21:22,258 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:21:22 +0000 (0:00:00.091)       0:00:02.007 ********** 
2025-07-22 13:21:22,291 p=44159 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm01"
2025-07-22 13:21:22,292 p=44159 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm02"
2025-07-22 13:21:22,296 p=44159 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn01"
2025-07-22 13:21:22,306 p=44159 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn02"
2025-07-22 13:21:22,310 p=44159 u=master n=ansible | TASK [common : [COMMON] Обновление apt cache] ******************************************************************************************************************************
2025-07-22 13:21:22,310 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:21:22 +0000 (0:00:00.051)       0:00:02.059 ********** 
2025-07-22 13:21:23,251 p=44159 u=master n=ansible | ok: [sm02]
2025-07-22 13:21:28,303 p=44159 u=master n=ansible | changed: [sm01]
2025-07-22 13:21:29,660 p=44159 u=master n=ansible | changed: [cn02]
2025-07-22 13:21:30,156 p=44159 u=master n=ansible | changed: [cn01]
2025-07-22 13:21:30,160 p=44159 u=master n=ansible | TASK [common : [COMMON] Установка базовых пакетов] *************************************************************************************************************************
2025-07-22 13:21:30,160 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:21:30 +0000 (0:00:07.850)       0:00:09.909 ********** 
2025-07-22 13:23:51,321 p=44159 u=master n=ansible | changed: [sm02]
2025-07-22 13:24:11,202 p=44159 u=master n=ansible | changed: [sm01]
2025-07-22 13:24:15,822 p=44159 u=master n=ansible | changed: [cn01]
2025-07-22 13:24:25,519 p=44159 u=master n=ansible | changed: [cn02]
2025-07-22 13:24:25,524 p=44159 u=master n=ansible | TASK [common : [COMMON] Настройка timezone] ********************************************************************************************************************************
2025-07-22 13:24:25,524 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:24:25 +0000 (0:02:55.363)       0:03:05.273 ********** 
2025-07-22 13:24:26,087 p=44159 u=master n=ansible | changed: [sm02]
2025-07-22 13:24:26,105 p=44159 u=master n=ansible | changed: [cn01]
2025-07-22 13:24:26,146 p=44159 u=master n=ansible | changed: [cn02]
2025-07-22 13:24:26,185 p=44159 u=master n=ansible | changed: [sm01]
2025-07-22 13:24:26,189 p=44159 u=master n=ansible | TASK [common : [COMMON] Создание пользователя slurm] ***********************************************************************************************************************
2025-07-22 13:24:26,190 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:24:26 +0000 (0:00:00.665)       0:03:05.938 ********** 
2025-07-22 13:24:26,956 p=44159 u=master n=ansible | changed: [sm02]
2025-07-22 13:24:27,427 p=44159 u=master n=ansible | changed: [sm01]
2025-07-22 13:24:27,632 p=44159 u=master n=ansible | changed: [cn02]
2025-07-22 13:24:27,659 p=44159 u=master n=ansible | changed: [cn01]
2025-07-22 13:24:27,663 p=44159 u=master n=ansible | TASK [common : [COMMON] Установка MUNGE] ***********************************************************************************************************************************
2025-07-22 13:24:27,663 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:24:27 +0000 (0:00:01.473)       0:03:07.412 ********** 
2025-07-22 13:24:42,309 p=44159 u=master n=ansible | changed: [cn02]
2025-07-22 13:24:42,435 p=44159 u=master n=ansible | changed: [sm01]
2025-07-22 13:24:43,472 p=44159 u=master n=ansible | changed: [cn01]
2025-07-22 13:24:43,743 p=44159 u=master n=ansible | changed: [sm02]
2025-07-22 13:24:43,747 p=44159 u=master n=ansible | TASK [common : [COMMON] Остановка MUNGE перед настройкой] ******************************************************************************************************************
2025-07-22 13:24:43,747 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:24:43 +0000 (0:00:16.084)       0:03:23.496 ********** 
2025-07-22 13:24:45,559 p=44159 u=master n=ansible | changed: [sm01]
2025-07-22 13:24:45,616 p=44159 u=master n=ansible | changed: [cn02]
2025-07-22 13:24:45,626 p=44159 u=master n=ansible | changed: [sm02]
2025-07-22 13:24:45,649 p=44159 u=master n=ansible | changed: [cn01]
2025-07-22 13:24:45,654 p=44159 u=master n=ansible | TASK [common : [COMMON] Создание MUNGE ключа на master узле] ***************************************************************************************************************
2025-07-22 13:24:45,654 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:24:45 +0000 (0:00:01.906)       0:03:25.403 ********** 
2025-07-22 13:24:45,686 p=44159 u=master n=ansible | skipping: [sm02]
2025-07-22 13:24:45,688 p=44159 u=master n=ansible | skipping: [cn01]
2025-07-22 13:24:45,696 p=44159 u=master n=ansible | skipping: [cn02]
2025-07-22 13:24:46,039 p=44159 u=master n=ansible | ok: [sm01]
2025-07-22 13:24:46,043 p=44159 u=master n=ansible | TASK [common : [COMMON] Получение MUNGE ключа с master узла] ***************************************************************************************************************
2025-07-22 13:24:46,043 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:24:46 +0000 (0:00:00.389)       0:03:25.792 ********** 
2025-07-22 13:24:46,075 p=44159 u=master n=ansible | skipping: [sm02]
2025-07-22 13:24:46,078 p=44159 u=master n=ansible | skipping: [cn01]
2025-07-22 13:24:46,086 p=44159 u=master n=ansible | skipping: [cn02]
2025-07-22 13:24:46,422 p=44159 u=master n=ansible | ok: [sm01]
2025-07-22 13:24:46,426 p=44159 u=master n=ansible | TASK [common : [COMMON] Распространение MUNGE ключа на все узлы] ***********************************************************************************************************
2025-07-22 13:24:46,427 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:24:46 +0000 (0:00:00.383)       0:03:26.176 ********** 
2025-07-22 13:24:46,449 p=44159 u=master n=ansible | skipping: [sm01]
2025-07-22 13:24:47,429 p=44159 u=master n=ansible | changed: [cn01]
2025-07-22 13:24:47,443 p=44159 u=master n=ansible | changed: [cn02]
2025-07-22 13:24:47,467 p=44159 u=master n=ansible | changed: [sm02]
2025-07-22 13:24:47,471 p=44159 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа MUNGE] **********************************************************************************************************************
2025-07-22 13:24:47,471 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:24:47 +0000 (0:00:01.044)       0:03:27.220 ********** 
2025-07-22 13:24:47,884 p=44159 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:24:47,886 p=44159 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:24:47,888 p=44159 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:24:47,896 p=44159 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:24:48,142 p=44159 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:24:48,146 p=44159 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:24:48,146 p=44159 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:24:48,160 p=44159 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:24:48,402 p=44159 u=master n=ansible | changed: [sm02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:24:48,403 p=44159 u=master n=ansible | changed: [cn01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:24:48,404 p=44159 u=master n=ansible | changed: [sm01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:24:48,438 p=44159 u=master n=ansible | changed: [cn02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:24:48,656 p=44159 u=master n=ansible | changed: [sm02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 13:24:48,661 p=44159 u=master n=ansible | changed: [sm01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 13:24:48,669 p=44159 u=master n=ansible | changed: [cn01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 13:24:48,707 p=44159 u=master n=ansible | changed: [cn02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 13:24:48,712 p=44159 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа на ключ MUNGE] **************************************************************************************************************
2025-07-22 13:24:48,713 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:24:48 +0000 (0:00:01.241)       0:03:28.462 ********** 
2025-07-22 13:24:48,987 p=44159 u=master n=ansible | ok: [sm02]
2025-07-22 13:24:48,988 p=44159 u=master n=ansible | changed: [sm01]
2025-07-22 13:24:49,003 p=44159 u=master n=ansible | ok: [cn01]
2025-07-22 13:24:49,008 p=44159 u=master n=ansible | ok: [cn02]
2025-07-22 13:24:49,012 p=44159 u=master n=ansible | TASK [common : [COMMON] Запуск и включение MUNGE] **************************************************************************************************************************
2025-07-22 13:24:49,012 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:24:49 +0000 (0:00:00.299)       0:03:28.761 ********** 
2025-07-22 13:24:50,825 p=44159 u=master n=ansible | changed: [sm01]
2025-07-22 13:24:50,940 p=44159 u=master n=ansible | changed: [sm02]
2025-07-22 13:24:51,015 p=44159 u=master n=ansible | changed: [cn02]
2025-07-22 13:24:51,034 p=44159 u=master n=ansible | changed: [cn01]
2025-07-22 13:24:51,038 p=44159 u=master n=ansible | TASK [common : [COMMON] Проверка работы MUNGE] *****************************************************************************************************************************
2025-07-22 13:24:51,038 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:24:51 +0000 (0:00:02.025)       0:03:30.787 ********** 
2025-07-22 13:24:51,316 p=44159 u=master n=ansible | ok: [sm02]
2025-07-22 13:24:51,335 p=44159 u=master n=ansible | ok: [cn01]
2025-07-22 13:24:51,342 p=44159 u=master n=ansible | ok: [sm01]
2025-07-22 13:24:51,364 p=44159 u=master n=ansible | ok: [cn02]
2025-07-22 13:24:51,368 p=44159 u=master n=ansible | TASK [common : [COMMON] Результат проверки MUNGE] **************************************************************************************************************************
2025-07-22 13:24:51,368 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:24:51 +0000 (0:00:00.330)       0:03:31.117 ********** 
2025-07-22 13:24:51,403 p=44159 u=master n=ansible | ok: [sm01] => 
  msg: MUNGE работает корректно на sm01
2025-07-22 13:24:51,404 p=44159 u=master n=ansible | ok: [sm02] => 
  msg: MUNGE работает корректно на sm02
2025-07-22 13:24:51,411 p=44159 u=master n=ansible | ok: [cn01] => 
  msg: MUNGE работает корректно на cn01
2025-07-22 13:24:51,420 p=44159 u=master n=ansible | ok: [cn02] => 
  msg: MUNGE работает корректно на cn02
2025-07-22 13:24:51,423 p=44159 u=master n=ansible | TASK [common : [COMMON] Установка HWLOC] ***********************************************************************************************************************************
2025-07-22 13:24:51,424 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:24:51 +0000 (0:00:00.055)       0:03:31.172 ********** 
2025-07-22 13:25:19,764 p=44159 u=master n=ansible | changed: [sm02]
2025-07-22 13:25:20,369 p=44159 u=master n=ansible | changed: [cn02]
2025-07-22 13:25:20,491 p=44159 u=master n=ansible | changed: [sm01]
2025-07-22 13:25:20,611 p=44159 u=master n=ansible | changed: [cn01]
2025-07-22 13:25:20,615 p=44159 u=master n=ansible | TASK [common : [COMMON] Проверка HWLOC] ************************************************************************************************************************************
2025-07-22 13:25:20,615 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:25:20 +0000 (0:00:29.191)       0:04:00.364 ********** 
2025-07-22 13:25:21,103 p=44159 u=master n=ansible | ok: [cn01]
2025-07-22 13:25:21,107 p=44159 u=master n=ansible | ok: [sm01]
2025-07-22 13:25:21,120 p=44159 u=master n=ansible | ok: [cn02]
2025-07-22 13:25:21,134 p=44159 u=master n=ansible | ok: [sm02]
2025-07-22 13:25:21,138 p=44159 u=master n=ansible | TASK [common : [COMMON] Версия HWLOC] **************************************************************************************************************************************
2025-07-22 13:25:21,138 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:25:21 +0000 (0:00:00.522)       0:04:00.887 ********** 
2025-07-22 13:25:21,165 p=44159 u=master n=ansible | ok: [sm01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 13:25:21,176 p=44159 u=master n=ansible | ok: [sm02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 13:25:21,181 p=44159 u=master n=ansible | ok: [cn01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 13:25:21,192 p=44159 u=master n=ansible | ok: [cn02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 13:25:21,196 p=44159 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-22 13:25:21,196 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:25:21 +0000 (0:00:00.058)       0:04:00.945 ********** 
2025-07-22 13:25:21,229 p=44159 u=master n=ansible | skipping: [sm02]
2025-07-22 13:25:21,231 p=44159 u=master n=ansible | skipping: [cn01]
2025-07-22 13:25:21,242 p=44159 u=master n=ansible | skipping: [cn02]
2025-07-22 13:25:40,340 p=44159 u=master n=ansible | changed: [sm01]
2025-07-22 13:25:40,344 p=44159 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-22 13:25:40,345 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:25:40 +0000 (0:00:19.148)       0:04:20.093 ********** 
2025-07-22 13:25:40,382 p=44159 u=master n=ansible | skipping: [sm02] => (item=/shared) 
2025-07-22 13:25:40,384 p=44159 u=master n=ansible | skipping: [sm02] => (item=/home/shared) 
2025-07-22 13:25:40,385 p=44159 u=master n=ansible | skipping: [sm02]
2025-07-22 13:25:40,389 p=44159 u=master n=ansible | skipping: [cn01] => (item=/shared) 
2025-07-22 13:25:40,393 p=44159 u=master n=ansible | skipping: [cn01] => (item=/home/shared) 
2025-07-22 13:25:40,394 p=44159 u=master n=ansible | skipping: [cn02] => (item=/shared) 
2025-07-22 13:25:40,395 p=44159 u=master n=ansible | skipping: [cn01]
2025-07-22 13:25:40,397 p=44159 u=master n=ansible | skipping: [cn02] => (item=/home/shared) 
2025-07-22 13:25:40,397 p=44159 u=master n=ansible | skipping: [cn02]
2025-07-22 13:25:40,615 p=44159 u=master n=ansible | changed: [sm01] => (item=/shared)
2025-07-22 13:25:40,861 p=44159 u=master n=ansible | changed: [sm01] => (item=/home/shared)
2025-07-22 13:25:40,866 p=44159 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS] ****************************************************************************************************************************
2025-07-22 13:25:40,866 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:25:40 +0000 (0:00:00.521)       0:04:20.615 ********** 
2025-07-22 13:25:40,919 p=44159 u=master n=ansible | fatal: [sm01]: FAILED! => 
  msg: '''ansible.vars.hostvars.HostVarsVars object'' has no attribute ''ansible_default_ipv4''. ''ansible.vars.hostvars.HostVarsVars object'' has no attribute ''ansible_default_ipv4'''
2025-07-22 13:25:40,924 p=44159 u=master n=ansible | skipping: [sm02]
2025-07-22 13:25:40,934 p=44159 u=master n=ansible | skipping: [cn01]
2025-07-22 13:25:40,948 p=44159 u=master n=ansible | skipping: [cn02]
2025-07-22 13:25:40,952 p=44159 u=master n=ansible | TASK [common : [COMMON] Запуск и включение NFS server] *********************************************************************************************************************
2025-07-22 13:25:40,952 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:25:40 +0000 (0:00:00.085)       0:04:20.701 ********** 
2025-07-22 13:25:40,976 p=44159 u=master n=ansible | skipping: [sm02]
2025-07-22 13:25:40,978 p=44159 u=master n=ansible | skipping: [cn01]
2025-07-22 13:25:40,987 p=44159 u=master n=ansible | skipping: [cn02]
2025-07-22 13:25:40,990 p=44159 u=master n=ansible | TASK [common : [COMMON] Установка NFS client] ******************************************************************************************************************************
2025-07-22 13:25:40,991 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:25:40 +0000 (0:00:00.038)       0:04:20.740 ********** 
2025-07-22 13:25:56,732 p=44159 u=master n=ansible | changed: [cn02]
2025-07-22 13:26:00,910 p=44159 u=master n=ansible | changed: [cn01]
2025-07-22 13:26:18,812 p=44159 u=master n=ansible | changed: [sm02]
2025-07-22 13:26:18,816 p=44159 u=master n=ansible | TASK [common : [COMMON] Создание точек монтирования NFS] *******************************************************************************************************************
2025-07-22 13:26:18,816 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:26:18 +0000 (0:00:37.825)       0:04:58.565 ********** 
2025-07-22 13:26:19,090 p=44159 u=master n=ansible | changed: [sm02] => (item=/shared)
2025-07-22 13:26:19,115 p=44159 u=master n=ansible | changed: [cn02] => (item=/shared)
2025-07-22 13:26:19,129 p=44159 u=master n=ansible | changed: [cn01] => (item=/shared)
2025-07-22 13:26:19,343 p=44159 u=master n=ansible | changed: [sm02] => (item=/home/shared)
2025-07-22 13:26:19,370 p=44159 u=master n=ansible | changed: [cn02] => (item=/home/shared)
2025-07-22 13:26:19,393 p=44159 u=master n=ansible | changed: [cn01] => (item=/home/shared)
2025-07-22 13:26:19,398 p=44159 u=master n=ansible | TASK [common : [COMMON] Монтирование NFS shares] ***************************************************************************************************************************
2025-07-22 13:26:19,398 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:26:19 +0000 (0:00:00.581)       0:04:59.147 ********** 
2025-07-22 13:26:19,426 p=44159 u=master n=ansible | fatal: [sm02]: FAILED! => 
  msg: |-
    The task includes an option with an undefined variable. The error was: 'ansible.vars.hostvars.HostVarsVars object' has no attribute 'ansible_default_ipv4'. 'ansible.vars.hostvars.HostVarsVars object' has no attribute 'ansible_default_ipv4'
  
    The error appears to be in '/home/master/22Jul/slurm-hpc-cluster/roles/common/tasks/main.yml': line 255, column 3, but may
    be elsewhere in the file depending on the exact syntax problem.
  
    The offending line appears to be:
  
  
    - name: "[COMMON] Монтирование NFS shares"
      ^ here
2025-07-22 13:26:19,430 p=44159 u=master n=ansible | fatal: [cn01]: FAILED! => 
  msg: |-
    The task includes an option with an undefined variable. The error was: 'ansible.vars.hostvars.HostVarsVars object' has no attribute 'ansible_default_ipv4'. 'ansible.vars.hostvars.HostVarsVars object' has no attribute 'ansible_default_ipv4'
  
    The error appears to be in '/home/master/22Jul/slurm-hpc-cluster/roles/common/tasks/main.yml': line 255, column 3, but may
    be elsewhere in the file depending on the exact syntax problem.
  
    The offending line appears to be:
  
  
    - name: "[COMMON] Монтирование NFS shares"
      ^ here
2025-07-22 13:26:19,444 p=44159 u=master n=ansible | fatal: [cn02]: FAILED! => 
  msg: |-
    The task includes an option with an undefined variable. The error was: 'ansible.vars.hostvars.HostVarsVars object' has no attribute 'ansible_default_ipv4'. 'ansible.vars.hostvars.HostVarsVars object' has no attribute 'ansible_default_ipv4'
  
    The error appears to be in '/home/master/22Jul/slurm-hpc-cluster/roles/common/tasks/main.yml': line 255, column 3, but may
    be elsewhere in the file depending on the exact syntax problem.
  
    The offending line appears to be:
  
  
    - name: "[COMMON] Монтирование NFS shares"
      ^ here
2025-07-22 13:26:19,446 p=44159 u=master n=ansible | PLAY RECAP *****************************************************************************************************************************************************************
2025-07-22 13:26:19,446 p=44159 u=master n=ansible | cn01                       : ok=20   changed=12   unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-22 13:26:19,446 p=44159 u=master n=ansible | cn02                       : ok=20   changed=12   unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-22 13:26:19,446 p=44159 u=master n=ansible | sm01                       : ok=21   changed=12   unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
2025-07-22 13:26:19,446 p=44159 u=master n=ansible | sm02                       : ok=20   changed=11   unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-22 13:26:19,447 p=44159 u=master n=ansible | Playbook run took 0 days, 0 hours, 4 minutes, 59 seconds
2025-07-22 13:26:19,447 p=44159 u=master n=ansible | Tuesday 22 July 2025  13:26:19 +0000 (0:00:00.048)       0:04:59.196 ********** 
2025-07-22 13:26:19,447 p=44159 u=master n=ansible | =============================================================================== 
2025-07-22 13:26:19,447 p=44159 u=master n=ansible | common : [COMMON] Установка базовых пакетов ----------------------------------------------------------------------------------------------------------------------- 175.36s
2025-07-22 13:26:19,447 p=44159 u=master n=ansible | common : [COMMON] Установка NFS client ----------------------------------------------------------------------------------------------------------------------------- 37.83s
2025-07-22 13:26:19,447 p=44159 u=master n=ansible | common : [COMMON] Установка HWLOC ---------------------------------------------------------------------------------------------------------------------------------- 29.19s
2025-07-22 13:26:19,447 p=44159 u=master n=ansible | common : [COMMON] Установка NFS server на master ------------------------------------------------------------------------------------------------------------------- 19.15s
2025-07-22 13:26:19,447 p=44159 u=master n=ansible | common : [COMMON] Установка MUNGE ---------------------------------------------------------------------------------------------------------------------------------- 16.08s
2025-07-22 13:26:19,447 p=44159 u=master n=ansible | common : [COMMON] Обновление apt cache ------------------------------------------------------------------------------------------------------------------------------ 7.85s
2025-07-22 13:26:19,448 p=44159 u=master n=ansible | common : [COMMON] Запуск и включение MUNGE -------------------------------------------------------------------------------------------------------------------------- 2.03s
2025-07-22 13:26:19,448 p=44159 u=master n=ansible | common : [COMMON] Остановка MUNGE перед настройкой ------------------------------------------------------------------------------------------------------------------ 1.91s
2025-07-22 13:26:19,448 p=44159 u=master n=ansible | Gathering Facts ----------------------------------------------------------------------------------------------------------------------------------------------------- 1.90s
2025-07-22 13:26:19,448 p=44159 u=master n=ansible | common : [COMMON] Создание пользователя slurm ----------------------------------------------------------------------------------------------------------------------- 1.47s
2025-07-22 13:26:19,448 p=44159 u=master n=ansible | common : [COMMON] Настройка прав доступа MUNGE ---------------------------------------------------------------------------------------------------------------------- 1.24s
2025-07-22 13:26:19,448 p=44159 u=master n=ansible | common : [COMMON] Распространение MUNGE ключа на все узлы ----------------------------------------------------------------------------------------------------------- 1.04s
2025-07-22 13:26:19,448 p=44159 u=master n=ansible | common : [COMMON] Настройка timezone -------------------------------------------------------------------------------------------------------------------------------- 0.67s
2025-07-22 13:26:19,448 p=44159 u=master n=ansible | common : [COMMON] Создание точек монтирования NFS ------------------------------------------------------------------------------------------------------------------- 0.58s
2025-07-22 13:26:19,448 p=44159 u=master n=ansible | common : [COMMON] Проверка HWLOC ------------------------------------------------------------------------------------------------------------------------------------ 0.52s
2025-07-22 13:26:19,448 p=44159 u=master n=ansible | common : [COMMON] Создание директорий для экспорта NFS -------------------------------------------------------------------------------------------------------------- 0.52s
2025-07-22 13:26:19,448 p=44159 u=master n=ansible | common : [COMMON] Создание MUNGE ключа на master узле --------------------------------------------------------------------------------------------------------------- 0.39s
2025-07-22 13:26:19,448 p=44159 u=master n=ansible | common : [COMMON] Получение MUNGE ключа с master узла --------------------------------------------------------------------------------------------------------------- 0.38s
2025-07-22 13:26:19,449 p=44159 u=master n=ansible | common : [COMMON] Проверка работы MUNGE ----------------------------------------------------------------------------------------------------------------------------- 0.33s
2025-07-22 13:26:19,449 p=44159 u=master n=ansible | common : [COMMON] Настройка прав доступа на ключ MUNGE -------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-22 13:31:06,725 p=44974 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:31:06,725 p=44974 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:31:07,163 p=44974 u=master n=ansible | PLAY [Тестирование роли common] ********************************************************************************************************************************************
2025-07-22 13:31:07,179 p=44974 u=master n=ansible | TASK [Информация о тестировании] *******************************************************************************************************************************************
2025-07-22 13:31:07,179 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:07 +0000 (0:00:00.018)       0:00:00.018 ********** 
2025-07-22 13:31:07,230 p=44974 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 13:31:07,237 p=44974 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 13:31:07,245 p=44974 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 13:31:07,264 p=44974 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 13:31:07,283 p=44974 u=master n=ansible | TASK [common : [COMMON] Начало выполнения роли common] *********************************************************************************************************************
2025-07-22 13:31:07,284 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:07 +0000 (0:00:00.104)       0:00:00.123 ********** 
2025-07-22 13:31:07,317 p=44974 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm01"
2025-07-22 13:31:07,318 p=44974 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm02"
2025-07-22 13:31:07,320 p=44974 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn01"
2025-07-22 13:31:07,331 p=44974 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn02"
2025-07-22 13:31:07,336 p=44974 u=master n=ansible | TASK [common : [COMMON] Обновление apt cache] ******************************************************************************************************************************
2025-07-22 13:31:07,336 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:07 +0000 (0:00:00.052)       0:00:00.175 ********** 
2025-07-22 13:31:08,963 p=44974 u=master n=ansible | ok: [sm02]
2025-07-22 13:31:09,007 p=44974 u=master n=ansible | ok: [sm01]
2025-07-22 13:31:09,030 p=44974 u=master n=ansible | ok: [cn02]
2025-07-22 13:31:09,131 p=44974 u=master n=ansible | ok: [cn01]
2025-07-22 13:31:09,135 p=44974 u=master n=ansible | TASK [common : [COMMON] Установка базовых пакетов] *************************************************************************************************************************
2025-07-22 13:31:09,135 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:09 +0000 (0:00:01.798)       0:00:01.974 ********** 
2025-07-22 13:31:10,232 p=44974 u=master n=ansible | ok: [sm02]
2025-07-22 13:31:10,260 p=44974 u=master n=ansible | ok: [sm01]
2025-07-22 13:31:10,314 p=44974 u=master n=ansible | ok: [cn02]
2025-07-22 13:31:10,372 p=44974 u=master n=ansible | ok: [cn01]
2025-07-22 13:31:10,376 p=44974 u=master n=ansible | TASK [common : [COMMON] Настройка timezone] ********************************************************************************************************************************
2025-07-22 13:31:10,376 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:10 +0000 (0:00:01.241)       0:00:03.215 ********** 
2025-07-22 13:31:10,877 p=44974 u=master n=ansible | ok: [sm01]
2025-07-22 13:31:10,889 p=44974 u=master n=ansible | ok: [cn02]
2025-07-22 13:31:10,908 p=44974 u=master n=ansible | ok: [sm02]
2025-07-22 13:31:10,925 p=44974 u=master n=ansible | ok: [cn01]
2025-07-22 13:31:10,928 p=44974 u=master n=ansible | TASK [common : [COMMON] Создание пользователя slurm] ***********************************************************************************************************************
2025-07-22 13:31:10,928 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:10 +0000 (0:00:00.552)       0:00:03.767 ********** 
2025-07-22 13:31:11,441 p=44974 u=master n=ansible | ok: [sm02]
2025-07-22 13:31:11,448 p=44974 u=master n=ansible | ok: [cn02]
2025-07-22 13:31:11,449 p=44974 u=master n=ansible | ok: [cn01]
2025-07-22 13:31:11,453 p=44974 u=master n=ansible | ok: [sm01]
2025-07-22 13:31:11,457 p=44974 u=master n=ansible | TASK [common : [COMMON] Установка MUNGE] ***********************************************************************************************************************************
2025-07-22 13:31:11,458 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:11 +0000 (0:00:00.529)       0:00:04.296 ********** 
2025-07-22 13:31:12,512 p=44974 u=master n=ansible | ok: [sm01]
2025-07-22 13:31:12,513 p=44974 u=master n=ansible | ok: [sm02]
2025-07-22 13:31:12,582 p=44974 u=master n=ansible | ok: [cn02]
2025-07-22 13:31:12,612 p=44974 u=master n=ansible | ok: [cn01]
2025-07-22 13:31:12,616 p=44974 u=master n=ansible | TASK [common : [COMMON] Остановка MUNGE перед настройкой] ******************************************************************************************************************
2025-07-22 13:31:12,617 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:12 +0000 (0:00:01.159)       0:00:05.455 ********** 
2025-07-22 13:31:14,478 p=44974 u=master n=ansible | changed: [sm02]
2025-07-22 13:31:14,501 p=44974 u=master n=ansible | changed: [cn02]
2025-07-22 13:31:14,571 p=44974 u=master n=ansible | changed: [cn01]
2025-07-22 13:31:14,699 p=44974 u=master n=ansible | changed: [sm01]
2025-07-22 13:31:14,705 p=44974 u=master n=ansible | TASK [common : [COMMON] Создание MUNGE ключа на master узле] ***************************************************************************************************************
2025-07-22 13:31:14,705 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:14 +0000 (0:00:02.088)       0:00:07.544 ********** 
2025-07-22 13:31:14,740 p=44974 u=master n=ansible | skipping: [sm02]
2025-07-22 13:31:14,743 p=44974 u=master n=ansible | skipping: [cn01]
2025-07-22 13:31:14,750 p=44974 u=master n=ansible | skipping: [cn02]
2025-07-22 13:31:15,091 p=44974 u=master n=ansible | ok: [sm01]
2025-07-22 13:31:15,096 p=44974 u=master n=ansible | TASK [common : [COMMON] Получение MUNGE ключа с master узла] ***************************************************************************************************************
2025-07-22 13:31:15,096 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:15 +0000 (0:00:00.390)       0:00:07.935 ********** 
2025-07-22 13:31:15,131 p=44974 u=master n=ansible | skipping: [sm02]
2025-07-22 13:31:15,132 p=44974 u=master n=ansible | skipping: [cn01]
2025-07-22 13:31:15,141 p=44974 u=master n=ansible | skipping: [cn02]
2025-07-22 13:31:15,490 p=44974 u=master n=ansible | ok: [sm01]
2025-07-22 13:31:15,496 p=44974 u=master n=ansible | TASK [common : [COMMON] Распространение MUNGE ключа на все узлы] ***********************************************************************************************************
2025-07-22 13:31:15,496 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:15 +0000 (0:00:00.400)       0:00:08.335 ********** 
2025-07-22 13:31:15,519 p=44974 u=master n=ansible | skipping: [sm01]
2025-07-22 13:31:16,347 p=44974 u=master n=ansible | ok: [sm02]
2025-07-22 13:31:16,360 p=44974 u=master n=ansible | ok: [cn02]
2025-07-22 13:31:16,367 p=44974 u=master n=ansible | ok: [cn01]
2025-07-22 13:31:16,370 p=44974 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа MUNGE] **********************************************************************************************************************
2025-07-22 13:31:16,371 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:16 +0000 (0:00:00.874)       0:00:09.209 ********** 
2025-07-22 13:31:16,656 p=44974 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:31:16,660 p=44974 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:31:16,674 p=44974 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:31:16,698 p=44974 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:31:16,902 p=44974 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:31:16,916 p=44974 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:31:16,936 p=44974 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:31:16,990 p=44974 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:31:17,156 p=44974 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:31:17,180 p=44974 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:31:17,198 p=44974 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:31:17,271 p=44974 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:31:17,408 p=44974 u=master n=ansible | changed: [sm02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 13:31:17,436 p=44974 u=master n=ansible | changed: [sm01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 13:31:17,455 p=44974 u=master n=ansible | changed: [cn02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 13:31:17,530 p=44974 u=master n=ansible | changed: [cn01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 13:31:17,537 p=44974 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа на ключ MUNGE] **************************************************************************************************************
2025-07-22 13:31:17,537 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:17 +0000 (0:00:01.166)       0:00:10.376 ********** 
2025-07-22 13:31:17,813 p=44974 u=master n=ansible | ok: [sm01]
2025-07-22 13:31:17,814 p=44974 u=master n=ansible | ok: [sm02]
2025-07-22 13:31:17,829 p=44974 u=master n=ansible | ok: [cn01]
2025-07-22 13:31:17,844 p=44974 u=master n=ansible | ok: [cn02]
2025-07-22 13:31:17,848 p=44974 u=master n=ansible | TASK [common : [COMMON] Запуск и включение MUNGE] **************************************************************************************************************************
2025-07-22 13:31:17,848 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:17 +0000 (0:00:00.311)       0:00:10.687 ********** 
2025-07-22 13:31:19,731 p=44974 u=master n=ansible | changed: [sm01]
2025-07-22 13:31:19,791 p=44974 u=master n=ansible | changed: [sm02]
2025-07-22 13:31:19,826 p=44974 u=master n=ansible | changed: [cn02]
2025-07-22 13:31:19,963 p=44974 u=master n=ansible | changed: [cn01]
2025-07-22 13:31:19,968 p=44974 u=master n=ansible | TASK [common : [COMMON] Проверка работы MUNGE] *****************************************************************************************************************************
2025-07-22 13:31:19,968 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:19 +0000 (0:00:02.119)       0:00:12.807 ********** 
2025-07-22 13:31:20,245 p=44974 u=master n=ansible | ok: [sm02]
2025-07-22 13:31:20,253 p=44974 u=master n=ansible | ok: [sm01]
2025-07-22 13:31:20,278 p=44974 u=master n=ansible | ok: [cn01]
2025-07-22 13:31:20,286 p=44974 u=master n=ansible | ok: [cn02]
2025-07-22 13:31:20,290 p=44974 u=master n=ansible | TASK [common : [COMMON] Результат проверки MUNGE] **************************************************************************************************************************
2025-07-22 13:31:20,290 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:20 +0000 (0:00:00.322)       0:00:13.129 ********** 
2025-07-22 13:31:20,321 p=44974 u=master n=ansible | ok: [sm01] => 
  msg: MUNGE работает корректно на sm01
2025-07-22 13:31:20,336 p=44974 u=master n=ansible | ok: [sm02] => 
  msg: MUNGE работает корректно на sm02
2025-07-22 13:31:20,339 p=44974 u=master n=ansible | ok: [cn01] => 
  msg: MUNGE работает корректно на cn01
2025-07-22 13:31:20,354 p=44974 u=master n=ansible | ok: [cn02] => 
  msg: MUNGE работает корректно на cn02
2025-07-22 13:31:20,358 p=44974 u=master n=ansible | TASK [common : [COMMON] Установка HWLOC] ***********************************************************************************************************************************
2025-07-22 13:31:20,358 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:20 +0000 (0:00:00.068)       0:00:13.197 ********** 
2025-07-22 13:31:21,422 p=44974 u=master n=ansible | ok: [sm02]
2025-07-22 13:31:21,451 p=44974 u=master n=ansible | ok: [sm01]
2025-07-22 13:31:21,479 p=44974 u=master n=ansible | ok: [cn01]
2025-07-22 13:31:21,491 p=44974 u=master n=ansible | ok: [cn02]
2025-07-22 13:31:21,495 p=44974 u=master n=ansible | TASK [common : [COMMON] Проверка HWLOC] ************************************************************************************************************************************
2025-07-22 13:31:21,495 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:21 +0000 (0:00:01.136)       0:00:14.334 ********** 
2025-07-22 13:31:21,772 p=44974 u=master n=ansible | ok: [sm01]
2025-07-22 13:31:21,779 p=44974 u=master n=ansible | ok: [sm02]
2025-07-22 13:31:21,799 p=44974 u=master n=ansible | ok: [cn02]
2025-07-22 13:31:21,808 p=44974 u=master n=ansible | ok: [cn01]
2025-07-22 13:31:21,813 p=44974 u=master n=ansible | TASK [common : [COMMON] Версия HWLOC] **************************************************************************************************************************************
2025-07-22 13:31:21,813 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:21 +0000 (0:00:00.318)       0:00:14.652 ********** 
2025-07-22 13:31:21,860 p=44974 u=master n=ansible | ok: [sm01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 13:31:21,861 p=44974 u=master n=ansible | ok: [sm02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 13:31:21,864 p=44974 u=master n=ansible | ok: [cn01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 13:31:21,878 p=44974 u=master n=ansible | ok: [cn02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 13:31:21,881 p=44974 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-22 13:31:21,882 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:21 +0000 (0:00:00.068)       0:00:14.720 ********** 
2025-07-22 13:31:21,914 p=44974 u=master n=ansible | skipping: [sm02]
2025-07-22 13:31:21,916 p=44974 u=master n=ansible | skipping: [cn01]
2025-07-22 13:31:21,926 p=44974 u=master n=ansible | skipping: [cn02]
2025-07-22 13:31:22,853 p=44974 u=master n=ansible | ok: [sm01]
2025-07-22 13:31:22,857 p=44974 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-22 13:31:22,857 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:22 +0000 (0:00:00.975)       0:00:15.696 ********** 
2025-07-22 13:31:22,886 p=44974 u=master n=ansible | skipping: [sm02] => (item=/shared) 
2025-07-22 13:31:22,887 p=44974 u=master n=ansible | skipping: [sm02] => (item=/home/shared) 
2025-07-22 13:31:22,892 p=44974 u=master n=ansible | skipping: [sm02]
2025-07-22 13:31:22,895 p=44974 u=master n=ansible | skipping: [cn01] => (item=/shared) 
2025-07-22 13:31:22,897 p=44974 u=master n=ansible | skipping: [cn01] => (item=/home/shared) 
2025-07-22 13:31:22,897 p=44974 u=master n=ansible | skipping: [cn01]
2025-07-22 13:31:22,905 p=44974 u=master n=ansible | skipping: [cn02] => (item=/shared) 
2025-07-22 13:31:22,908 p=44974 u=master n=ansible | skipping: [cn02] => (item=/home/shared) 
2025-07-22 13:31:22,909 p=44974 u=master n=ansible | skipping: [cn02]
2025-07-22 13:31:23,129 p=44974 u=master n=ansible | ok: [sm01] => (item=/shared)
2025-07-22 13:31:23,381 p=44974 u=master n=ansible | ok: [sm01] => (item=/home/shared)
2025-07-22 13:31:23,388 p=44974 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS] ****************************************************************************************************************************
2025-07-22 13:31:23,388 p=44974 u=master n=ansible | Tuesday 22 July 2025  13:31:23 +0000 (0:00:00.531)       0:00:16.227 ********** 
2025-07-22 13:31:23,425 p=44974 u=master n=ansible | skipping: [sm02] => (item={'path': '/shared'}) 
2025-07-22 13:31:23,427 p=44974 u=master n=ansible | skipping: [sm02] => (item={'path': '/home/shared'}) 
2025-07-22 13:31:23,428 p=44974 u=master n=ansible | skipping: [cn01] => (item={'path': '/shared'}) 
2025-07-22 13:31:23,429 p=44974 u=master n=ansible | skipping: [sm02]
2025-07-22 13:31:23,430 p=44974 u=master n=ansible | skipping: [cn01] => (item={'path': '/home/shared'}) 
2025-07-22 13:31:23,431 p=44974 u=master n=ansible | skipping: [cn01]
2025-07-22 13:31:23,437 p=44974 u=master n=ansible | skipping: [cn02] => (item={'path': '/shared'}) 
2025-07-22 13:31:23,439 p=44974 u=master n=ansible | skipping: [cn02] => (item={'path': '/home/shared'}) 
2025-07-22 13:31:23,440 p=44974 u=master n=ansible | skipping: [cn02]
2025-07-22 13:31:23,786 p=44974 u=master n=ansible | changed: [sm01] => (item={'path': '/shared'})
2025-07-22 13:31:24,058 p=44974 u=master n=ansible | changed: [sm01] => (item={'path': '/home/shared'})
2025-07-22 13:31:24,060 p=44974 u=master n=ansible | ERROR! The requested handler 'restart nfs-server' was not found in either the main handlers list nor in the listening handlers list
2025-07-22 13:35:16,108 p=45295 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:35:16,108 p=45295 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:35:16,524 p=45295 u=master n=ansible | PLAY [Тестирование роли common] ********************************************************************************************************************************************
2025-07-22 13:35:16,540 p=45295 u=master n=ansible | TASK [Информация о тестировании] *******************************************************************************************************************************************
2025-07-22 13:35:16,540 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:16 +0000 (0:00:00.017)       0:00:00.017 ********** 
2025-07-22 13:35:16,590 p=45295 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 13:35:16,597 p=45295 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 13:35:16,603 p=45295 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 13:35:16,617 p=45295 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 13:35:16,636 p=45295 u=master n=ansible | TASK [common : [COMMON] Начало выполнения роли common] *********************************************************************************************************************
2025-07-22 13:35:16,636 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:16 +0000 (0:00:00.096)       0:00:00.114 ********** 
2025-07-22 13:35:16,668 p=45295 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm01"
2025-07-22 13:35:16,669 p=45295 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm02"
2025-07-22 13:35:16,674 p=45295 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn01"
2025-07-22 13:35:16,683 p=45295 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn02"
2025-07-22 13:35:16,687 p=45295 u=master n=ansible | TASK [common : [COMMON] Обновление apt cache] ******************************************************************************************************************************
2025-07-22 13:35:16,687 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:16 +0000 (0:00:00.050)       0:00:00.165 ********** 
2025-07-22 13:35:18,320 p=45295 u=master n=ansible | ok: [sm02]
2025-07-22 13:35:18,369 p=45295 u=master n=ansible | ok: [cn02]
2025-07-22 13:35:18,382 p=45295 u=master n=ansible | ok: [sm01]
2025-07-22 13:35:18,396 p=45295 u=master n=ansible | ok: [cn01]
2025-07-22 13:35:18,400 p=45295 u=master n=ansible | TASK [common : [COMMON] Установка базовых пакетов] *************************************************************************************************************************
2025-07-22 13:35:18,400 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:18 +0000 (0:00:01.712)       0:00:01.878 ********** 
2025-07-22 13:35:19,467 p=45295 u=master n=ansible | ok: [sm02]
2025-07-22 13:35:19,468 p=45295 u=master n=ansible | ok: [cn01]
2025-07-22 13:35:19,499 p=45295 u=master n=ansible | ok: [sm01]
2025-07-22 13:35:19,555 p=45295 u=master n=ansible | ok: [cn02]
2025-07-22 13:35:19,559 p=45295 u=master n=ansible | TASK [common : [COMMON] Настройка timezone] ********************************************************************************************************************************
2025-07-22 13:35:19,559 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:19 +0000 (0:00:01.159)       0:00:03.037 ********** 
2025-07-22 13:35:20,067 p=45295 u=master n=ansible | ok: [sm02]
2025-07-22 13:35:20,068 p=45295 u=master n=ansible | ok: [sm01]
2025-07-22 13:35:20,098 p=45295 u=master n=ansible | ok: [cn01]
2025-07-22 13:35:20,098 p=45295 u=master n=ansible | ok: [cn02]
2025-07-22 13:35:20,102 p=45295 u=master n=ansible | TASK [common : [COMMON] Создание пользователя slurm] ***********************************************************************************************************************
2025-07-22 13:35:20,103 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:20 +0000 (0:00:00.543)       0:00:03.580 ********** 
2025-07-22 13:35:20,601 p=45295 u=master n=ansible | ok: [sm02]
2025-07-22 13:35:20,608 p=45295 u=master n=ansible | ok: [sm01]
2025-07-22 13:35:20,613 p=45295 u=master n=ansible | ok: [cn02]
2025-07-22 13:35:20,626 p=45295 u=master n=ansible | ok: [cn01]
2025-07-22 13:35:20,630 p=45295 u=master n=ansible | TASK [common : [COMMON] Установка MUNGE] ***********************************************************************************************************************************
2025-07-22 13:35:20,630 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:20 +0000 (0:00:00.527)       0:00:04.107 ********** 
2025-07-22 13:35:21,665 p=45295 u=master n=ansible | ok: [cn01]
2025-07-22 13:35:21,711 p=45295 u=master n=ansible | ok: [sm02]
2025-07-22 13:35:21,725 p=45295 u=master n=ansible | ok: [sm01]
2025-07-22 13:35:21,817 p=45295 u=master n=ansible | ok: [cn02]
2025-07-22 13:35:21,821 p=45295 u=master n=ansible | TASK [common : [COMMON] Остановка MUNGE перед настройкой] ******************************************************************************************************************
2025-07-22 13:35:21,821 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:21 +0000 (0:00:01.191)       0:00:05.299 ********** 
2025-07-22 13:35:23,724 p=45295 u=master n=ansible | changed: [sm02]
2025-07-22 13:35:23,731 p=45295 u=master n=ansible | changed: [sm01]
2025-07-22 13:35:23,746 p=45295 u=master n=ansible | changed: [cn01]
2025-07-22 13:35:23,820 p=45295 u=master n=ansible | changed: [cn02]
2025-07-22 13:35:23,824 p=45295 u=master n=ansible | TASK [common : [COMMON] Создание MUNGE ключа на master узле] ***************************************************************************************************************
2025-07-22 13:35:23,825 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:23 +0000 (0:00:02.003)       0:00:07.302 ********** 
2025-07-22 13:35:23,863 p=45295 u=master n=ansible | skipping: [sm02]
2025-07-22 13:35:23,864 p=45295 u=master n=ansible | skipping: [cn01]
2025-07-22 13:35:23,872 p=45295 u=master n=ansible | skipping: [cn02]
2025-07-22 13:35:24,206 p=45295 u=master n=ansible | ok: [sm01]
2025-07-22 13:35:24,210 p=45295 u=master n=ansible | TASK [common : [COMMON] Получение MUNGE ключа с master узла] ***************************************************************************************************************
2025-07-22 13:35:24,211 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:24 +0000 (0:00:00.385)       0:00:07.688 ********** 
2025-07-22 13:35:24,242 p=45295 u=master n=ansible | skipping: [sm02]
2025-07-22 13:35:24,244 p=45295 u=master n=ansible | skipping: [cn01]
2025-07-22 13:35:24,254 p=45295 u=master n=ansible | skipping: [cn02]
2025-07-22 13:35:24,589 p=45295 u=master n=ansible | ok: [sm01]
2025-07-22 13:35:24,594 p=45295 u=master n=ansible | TASK [common : [COMMON] Распространение MUNGE ключа на все узлы] ***********************************************************************************************************
2025-07-22 13:35:24,595 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:24 +0000 (0:00:00.383)       0:00:08.072 ********** 
2025-07-22 13:35:24,617 p=45295 u=master n=ansible | skipping: [sm01]
2025-07-22 13:35:25,453 p=45295 u=master n=ansible | ok: [sm02]
2025-07-22 13:35:25,457 p=45295 u=master n=ansible | ok: [cn02]
2025-07-22 13:35:25,457 p=45295 u=master n=ansible | ok: [cn01]
2025-07-22 13:35:25,461 p=45295 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа MUNGE] **********************************************************************************************************************
2025-07-22 13:35:25,461 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:25 +0000 (0:00:00.866)       0:00:08.938 ********** 
2025-07-22 13:35:25,745 p=45295 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:35:25,762 p=45295 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:35:25,767 p=45295 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:35:25,789 p=45295 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:35:25,992 p=45295 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:35:26,012 p=45295 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:35:26,027 p=45295 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:35:26,052 p=45295 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:35:26,239 p=45295 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:35:26,262 p=45295 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:35:26,283 p=45295 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:35:26,315 p=45295 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 13:35:26,488 p=45295 u=master n=ansible | changed: [sm02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 13:35:26,525 p=45295 u=master n=ansible | changed: [cn02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 13:35:26,539 p=45295 u=master n=ansible | changed: [sm01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 13:35:26,595 p=45295 u=master n=ansible | changed: [cn01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 13:35:26,601 p=45295 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа на ключ MUNGE] **************************************************************************************************************
2025-07-22 13:35:26,601 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:26 +0000 (0:00:01.139)       0:00:10.078 ********** 
2025-07-22 13:35:26,877 p=45295 u=master n=ansible | ok: [sm02]
2025-07-22 13:35:26,888 p=45295 u=master n=ansible | ok: [sm01]
2025-07-22 13:35:26,895 p=45295 u=master n=ansible | ok: [cn01]
2025-07-22 13:35:26,902 p=45295 u=master n=ansible | ok: [cn02]
2025-07-22 13:35:26,906 p=45295 u=master n=ansible | TASK [common : [COMMON] Запуск и включение MUNGE] **************************************************************************************************************************
2025-07-22 13:35:26,906 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:26 +0000 (0:00:00.305)       0:00:10.384 ********** 
2025-07-22 13:35:28,798 p=45295 u=master n=ansible | changed: [sm02]
2025-07-22 13:35:28,820 p=45295 u=master n=ansible | changed: [sm01]
2025-07-22 13:35:28,849 p=45295 u=master n=ansible | changed: [cn02]
2025-07-22 13:35:28,879 p=45295 u=master n=ansible | changed: [cn01]
2025-07-22 13:35:28,883 p=45295 u=master n=ansible | TASK [common : [COMMON] Проверка работы MUNGE] *****************************************************************************************************************************
2025-07-22 13:35:28,884 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:28 +0000 (0:00:01.977)       0:00:12.361 ********** 
2025-07-22 13:35:29,153 p=45295 u=master n=ansible | ok: [sm02]
2025-07-22 13:35:29,165 p=45295 u=master n=ansible | ok: [sm01]
2025-07-22 13:35:29,178 p=45295 u=master n=ansible | ok: [cn02]
2025-07-22 13:35:29,179 p=45295 u=master n=ansible | ok: [cn01]
2025-07-22 13:35:29,183 p=45295 u=master n=ansible | TASK [common : [COMMON] Результат проверки MUNGE] **************************************************************************************************************************
2025-07-22 13:35:29,183 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:29 +0000 (0:00:00.299)       0:00:12.661 ********** 
2025-07-22 13:35:29,216 p=45295 u=master n=ansible | ok: [sm01] => 
  msg: MUNGE работает корректно на sm01
2025-07-22 13:35:29,218 p=45295 u=master n=ansible | ok: [sm02] => 
  msg: MUNGE работает корректно на sm02
2025-07-22 13:35:29,222 p=45295 u=master n=ansible | ok: [cn01] => 
  msg: MUNGE работает корректно на cn01
2025-07-22 13:35:29,233 p=45295 u=master n=ansible | ok: [cn02] => 
  msg: MUNGE работает корректно на cn02
2025-07-22 13:35:29,237 p=45295 u=master n=ansible | TASK [common : [COMMON] Установка HWLOC] ***********************************************************************************************************************************
2025-07-22 13:35:29,238 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:29 +0000 (0:00:00.054)       0:00:12.715 ********** 
2025-07-22 13:35:30,269 p=45295 u=master n=ansible | ok: [sm02]
2025-07-22 13:35:30,318 p=45295 u=master n=ansible | ok: [cn01]
2025-07-22 13:35:30,352 p=45295 u=master n=ansible | ok: [sm01]
2025-07-22 13:35:30,388 p=45295 u=master n=ansible | ok: [cn02]
2025-07-22 13:35:30,392 p=45295 u=master n=ansible | TASK [common : [COMMON] Проверка HWLOC] ************************************************************************************************************************************
2025-07-22 13:35:30,392 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:30 +0000 (0:00:01.154)       0:00:13.870 ********** 
2025-07-22 13:35:30,669 p=45295 u=master n=ansible | ok: [sm02]
2025-07-22 13:35:30,681 p=45295 u=master n=ansible | ok: [sm01]
2025-07-22 13:35:30,698 p=45295 u=master n=ansible | ok: [cn01]
2025-07-22 13:35:30,699 p=45295 u=master n=ansible | ok: [cn02]
2025-07-22 13:35:30,703 p=45295 u=master n=ansible | TASK [common : [COMMON] Версия HWLOC] **************************************************************************************************************************************
2025-07-22 13:35:30,703 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:30 +0000 (0:00:00.310)       0:00:14.180 ********** 
2025-07-22 13:35:30,736 p=45295 u=master n=ansible | ok: [sm01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 13:35:30,737 p=45295 u=master n=ansible | ok: [sm02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 13:35:30,741 p=45295 u=master n=ansible | ok: [cn01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 13:35:30,753 p=45295 u=master n=ansible | ok: [cn02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 13:35:30,757 p=45295 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-22 13:35:30,757 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:30 +0000 (0:00:00.053)       0:00:14.234 ********** 
2025-07-22 13:35:30,792 p=45295 u=master n=ansible | skipping: [sm02]
2025-07-22 13:35:30,793 p=45295 u=master n=ansible | skipping: [cn01]
2025-07-22 13:35:30,802 p=45295 u=master n=ansible | skipping: [cn02]
2025-07-22 13:35:31,780 p=45295 u=master n=ansible | ok: [sm01]
2025-07-22 13:35:31,784 p=45295 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-22 13:35:31,784 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:31 +0000 (0:00:01.027)       0:00:15.262 ********** 
2025-07-22 13:35:31,814 p=45295 u=master n=ansible | skipping: [sm02] => (item=/shared) 
2025-07-22 13:35:31,818 p=45295 u=master n=ansible | skipping: [sm02] => (item=/home/shared) 
2025-07-22 13:35:31,821 p=45295 u=master n=ansible | skipping: [sm02]
2025-07-22 13:35:31,822 p=45295 u=master n=ansible | skipping: [cn01] => (item=/shared) 
2025-07-22 13:35:31,825 p=45295 u=master n=ansible | skipping: [cn01] => (item=/home/shared) 
2025-07-22 13:35:31,825 p=45295 u=master n=ansible | skipping: [cn01]
2025-07-22 13:35:31,833 p=45295 u=master n=ansible | skipping: [cn02] => (item=/shared) 
2025-07-22 13:35:31,835 p=45295 u=master n=ansible | skipping: [cn02] => (item=/home/shared) 
2025-07-22 13:35:31,836 p=45295 u=master n=ansible | skipping: [cn02]
2025-07-22 13:35:32,061 p=45295 u=master n=ansible | ok: [sm01] => (item=/shared)
2025-07-22 13:35:32,322 p=45295 u=master n=ansible | ok: [sm01] => (item=/home/shared)
2025-07-22 13:35:32,328 p=45295 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS] ****************************************************************************************************************************
2025-07-22 13:35:32,328 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:32 +0000 (0:00:00.544)       0:00:15.806 ********** 
2025-07-22 13:35:32,370 p=45295 u=master n=ansible | skipping: [sm02] => (item={'path': '/shared'}) 
2025-07-22 13:35:32,375 p=45295 u=master n=ansible | skipping: [sm02] => (item={'path': '/home/shared'}) 
2025-07-22 13:35:32,379 p=45295 u=master n=ansible | skipping: [cn01] => (item={'path': '/shared'}) 
2025-07-22 13:35:32,382 p=45295 u=master n=ansible | skipping: [sm02]
2025-07-22 13:35:32,382 p=45295 u=master n=ansible | skipping: [cn01] => (item={'path': '/home/shared'}) 
2025-07-22 13:35:32,383 p=45295 u=master n=ansible | skipping: [cn01]
2025-07-22 13:35:32,401 p=45295 u=master n=ansible | skipping: [cn02] => (item={'path': '/shared'}) 
2025-07-22 13:35:32,406 p=45295 u=master n=ansible | skipping: [cn02] => (item={'path': '/home/shared'}) 
2025-07-22 13:35:32,407 p=45295 u=master n=ansible | skipping: [cn02]
2025-07-22 13:35:32,753 p=45295 u=master n=ansible | ok: [sm01] => (item={'path': '/shared'})
2025-07-22 13:35:33,004 p=45295 u=master n=ansible | ok: [sm01] => (item={'path': '/home/shared'})
2025-07-22 13:35:33,009 p=45295 u=master n=ansible | TASK [common : [COMMON] Запуск и включение NFS server] *********************************************************************************************************************
2025-07-22 13:35:33,009 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:33 +0000 (0:00:00.681)       0:00:16.487 ********** 
2025-07-22 13:35:33,042 p=45295 u=master n=ansible | skipping: [sm02]
2025-07-22 13:35:33,044 p=45295 u=master n=ansible | skipping: [cn01]
2025-07-22 13:35:33,054 p=45295 u=master n=ansible | skipping: [cn02]
2025-07-22 13:35:33,502 p=45295 u=master n=ansible | ok: [sm01]
2025-07-22 13:35:33,506 p=45295 u=master n=ansible | TASK [common : [COMMON] Установка NFS client] ******************************************************************************************************************************
2025-07-22 13:35:33,506 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:33 +0000 (0:00:00.496)       0:00:16.984 ********** 
2025-07-22 13:35:33,532 p=45295 u=master n=ansible | skipping: [sm01]
2025-07-22 13:35:34,531 p=45295 u=master n=ansible | ok: [sm02]
2025-07-22 13:35:34,559 p=45295 u=master n=ansible | ok: [cn01]
2025-07-22 13:35:34,608 p=45295 u=master n=ansible | ok: [cn02]
2025-07-22 13:35:34,613 p=45295 u=master n=ansible | TASK [common : [COMMON] Создание точек монтирования NFS] *******************************************************************************************************************
2025-07-22 13:35:34,613 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:34 +0000 (0:00:01.107)       0:00:18.091 ********** 
2025-07-22 13:35:34,632 p=45295 u=master n=ansible | skipping: [sm01] => (item=/shared) 
2025-07-22 13:35:34,643 p=45295 u=master n=ansible | skipping: [sm01] => (item=/home/shared) 
2025-07-22 13:35:34,652 p=45295 u=master n=ansible | skipping: [sm01]
2025-07-22 13:35:34,898 p=45295 u=master n=ansible | ok: [sm02] => (item=/shared)
2025-07-22 13:35:34,920 p=45295 u=master n=ansible | ok: [cn01] => (item=/shared)
2025-07-22 13:35:34,933 p=45295 u=master n=ansible | ok: [cn02] => (item=/shared)
2025-07-22 13:35:35,146 p=45295 u=master n=ansible | ok: [sm02] => (item=/home/shared)
2025-07-22 13:35:35,178 p=45295 u=master n=ansible | ok: [cn01] => (item=/home/shared)
2025-07-22 13:35:35,186 p=45295 u=master n=ansible | ok: [cn02] => (item=/home/shared)
2025-07-22 13:35:35,191 p=45295 u=master n=ansible | TASK [common : [COMMON] Монтирование NFS shares] ***************************************************************************************************************************
2025-07-22 13:35:35,192 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:35 +0000 (0:00:00.578)       0:00:18.669 ********** 
2025-07-22 13:35:35,213 p=45295 u=master n=ansible | skipping: [sm01] => (item={'path': '/shared', 'src': '/shared'}) 
2025-07-22 13:35:35,217 p=45295 u=master n=ansible | skipping: [sm01] => (item={'path': '/home/shared', 'src': '/home/shared'}) 
2025-07-22 13:35:35,229 p=45295 u=master n=ansible | skipping: [sm01]
2025-07-22 13:35:35,949 p=45295 u=master n=ansible | failed: [cn02] (item={'path': '/shared', 'src': '/shared'}) => changed=false 
  ansible_loop_var: item
  item:
    path: /shared
    src: /shared
  msg: |-
    Error mounting /shared: mount.nfs4: access denied by server while mounting 10.20.90.166:/shared
2025-07-22 13:35:35,950 p=45295 u=master n=ansible | failed: [cn01] (item={'path': '/shared', 'src': '/shared'}) => changed=false 
  ansible_loop_var: item
  item:
    path: /shared
    src: /shared
  msg: |-
    Error mounting /shared: mount.nfs4: access denied by server while mounting 10.20.90.166:/shared
2025-07-22 13:35:35,974 p=45295 u=master n=ansible | failed: [sm02] (item={'path': '/shared', 'src': '/shared'}) => changed=false 
  ansible_loop_var: item
  item:
    path: /shared
    src: /shared
  msg: |-
    Error mounting /shared: mount.nfs4: access denied by server while mounting 10.20.90.166:/shared
2025-07-22 13:35:36,230 p=45295 u=master n=ansible | failed: [cn02] (item={'path': '/home/shared', 'src': '/home/shared'}) => changed=false 
  ansible_loop_var: item
  item:
    path: /home/shared
    src: /home/shared
  msg: |-
    Error mounting /home/shared: mount.nfs4: access denied by server while mounting 10.20.90.166:/home/shared
2025-07-22 13:35:36,241 p=45295 u=master n=ansible | failed: [sm02] (item={'path': '/home/shared', 'src': '/home/shared'}) => changed=false 
  ansible_loop_var: item
  item:
    path: /home/shared
    src: /home/shared
  msg: |-
    Error mounting /home/shared: mount.nfs4: access denied by server while mounting 10.20.90.166:/home/shared
2025-07-22 13:35:36,264 p=45295 u=master n=ansible | failed: [cn01] (item={'path': '/home/shared', 'src': '/home/shared'}) => changed=false 
  ansible_loop_var: item
  item:
    path: /home/shared
    src: /home/shared
  msg: |-
    Error mounting /home/shared: mount.nfs4: access denied by server while mounting 10.20.90.166:/home/shared
2025-07-22 13:35:36,269 p=45295 u=master n=ansible | TASK [common : [COMMON] Создание базовых директорий Slurm] *****************************************************************************************************************
2025-07-22 13:35:36,269 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:36 +0000 (0:00:01.077)       0:00:19.747 ********** 
2025-07-22 13:35:36,547 p=45295 u=master n=ansible | changed: [sm01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 13:35:36,801 p=45295 u=master n=ansible | changed: [sm01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 13:35:37,056 p=45295 u=master n=ansible | changed: [sm01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 13:35:37,310 p=45295 u=master n=ansible | changed: [sm01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 13:35:37,561 p=45295 u=master n=ansible | changed: [sm01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 13:35:37,817 p=45295 u=master n=ansible | changed: [sm01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 13:35:37,824 p=45295 u=master n=ansible | TASK [common : [COMMON] Роль common выполнена успешно] *********************************************************************************************************************
2025-07-22 13:35:37,824 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:37 +0000 (0:00:01.554)       0:00:21.302 ********** 
2025-07-22 13:35:37,847 p=45295 u=master n=ansible | ok: [sm01] => 
  msg: ✅ Узел sm01 готов для установки Slurm
2025-07-22 13:35:37,857 p=45295 u=master n=ansible | TASK [Проверка результатов] ************************************************************************************************************************************************
2025-07-22 13:35:37,857 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:37 +0000 (0:00:00.033)       0:00:21.335 ********** 
2025-07-22 13:35:37,879 p=45295 u=master n=ansible | ok: [sm01] => 
  msg: "✅ Роль common протестирована на sm01\n\U0001F527 Проверьте работу MUNGE: systemctl status munge\n\U0001F4C1 Проверьте NFS монтирование: df -h | grep nfs\n\U0001F464 Проверьте пользователя slurm: id slurm"
2025-07-22 13:35:37,885 p=45295 u=master n=ansible | PLAY RECAP *****************************************************************************************************************************************************************
2025-07-22 13:35:37,885 p=45295 u=master n=ansible | cn01                       : ok=19   changed=3    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-22 13:35:37,886 p=45295 u=master n=ansible | cn02                       : ok=19   changed=3    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-22 13:35:37,886 p=45295 u=master n=ansible | sm01                       : ok=25   changed=4    unreachable=0    failed=0    skipped=4    rescued=0    ignored=0   
2025-07-22 13:35:37,886 p=45295 u=master n=ansible | sm02                       : ok=19   changed=3    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-22 13:35:37,886 p=45295 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 21 seconds
2025-07-22 13:35:37,886 p=45295 u=master n=ansible | Tuesday 22 July 2025  13:35:37 +0000 (0:00:00.029)       0:00:21.364 ********** 
2025-07-22 13:35:37,886 p=45295 u=master n=ansible | =============================================================================== 
2025-07-22 13:35:37,886 p=45295 u=master n=ansible | common : [COMMON] Остановка MUNGE перед настройкой ------------------------------------------------------------------------------------------------------------------ 2.00s
2025-07-22 13:35:37,887 p=45295 u=master n=ansible | common : [COMMON] Запуск и включение MUNGE -------------------------------------------------------------------------------------------------------------------------- 1.98s
2025-07-22 13:35:37,887 p=45295 u=master n=ansible | common : [COMMON] Обновление apt cache ------------------------------------------------------------------------------------------------------------------------------ 1.71s
2025-07-22 13:35:37,887 p=45295 u=master n=ansible | common : [COMMON] Создание базовых директорий Slurm ----------------------------------------------------------------------------------------------------------------- 1.55s
2025-07-22 13:35:37,887 p=45295 u=master n=ansible | common : [COMMON] Установка MUNGE ----------------------------------------------------------------------------------------------------------------------------------- 1.19s
2025-07-22 13:35:37,887 p=45295 u=master n=ansible | common : [COMMON] Установка базовых пакетов ------------------------------------------------------------------------------------------------------------------------- 1.16s
2025-07-22 13:35:37,887 p=45295 u=master n=ansible | common : [COMMON] Установка HWLOC ----------------------------------------------------------------------------------------------------------------------------------- 1.15s
2025-07-22 13:35:37,887 p=45295 u=master n=ansible | common : [COMMON] Настройка прав доступа MUNGE ---------------------------------------------------------------------------------------------------------------------- 1.14s
2025-07-22 13:35:37,887 p=45295 u=master n=ansible | common : [COMMON] Установка NFS client ------------------------------------------------------------------------------------------------------------------------------ 1.11s
2025-07-22 13:35:37,887 p=45295 u=master n=ansible | common : [COMMON] Монтирование NFS shares --------------------------------------------------------------------------------------------------------------------------- 1.08s
2025-07-22 13:35:37,887 p=45295 u=master n=ansible | common : [COMMON] Установка NFS server на master -------------------------------------------------------------------------------------------------------------------- 1.03s
2025-07-22 13:35:37,887 p=45295 u=master n=ansible | common : [COMMON] Распространение MUNGE ключа на все узлы ----------------------------------------------------------------------------------------------------------- 0.87s
2025-07-22 13:35:37,888 p=45295 u=master n=ansible | common : [COMMON] Настройка экспорта NFS ---------------------------------------------------------------------------------------------------------------------------- 0.68s
2025-07-22 13:35:37,888 p=45295 u=master n=ansible | common : [COMMON] Создание точек монтирования NFS ------------------------------------------------------------------------------------------------------------------- 0.58s
2025-07-22 13:35:37,888 p=45295 u=master n=ansible | common : [COMMON] Создание директорий для экспорта NFS -------------------------------------------------------------------------------------------------------------- 0.54s
2025-07-22 13:35:37,888 p=45295 u=master n=ansible | common : [COMMON] Настройка timezone -------------------------------------------------------------------------------------------------------------------------------- 0.54s
2025-07-22 13:35:37,888 p=45295 u=master n=ansible | common : [COMMON] Создание пользователя slurm ----------------------------------------------------------------------------------------------------------------------- 0.53s
2025-07-22 13:35:37,888 p=45295 u=master n=ansible | common : [COMMON] Запуск и включение NFS server --------------------------------------------------------------------------------------------------------------------- 0.50s
2025-07-22 13:35:37,888 p=45295 u=master n=ansible | common : [COMMON] Создание MUNGE ключа на master узле --------------------------------------------------------------------------------------------------------------- 0.39s
2025-07-22 13:35:37,888 p=45295 u=master n=ansible | common : [COMMON] Получение MUNGE ключа с master узла --------------------------------------------------------------------------------------------------------------- 0.38s
2025-07-22 13:41:42,255 p=45681 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:41:42,256 p=45681 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:41:42,680 p=45681 u=master n=ansible | PLAY [Тестирование роли common] ********************************************************************************************************************************************
2025-07-22 13:41:42,710 p=45681 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-22 13:41:42,710 p=45681 u=master n=ansible | Tuesday 22 July 2025  13:41:42 +0000 (0:00:00.032)       0:00:00.032 ********** 
2025-07-22 13:41:42,744 p=45681 u=master n=ansible | skipping: [sm02]
2025-07-22 13:41:42,746 p=45681 u=master n=ansible | skipping: [cn01]
2025-07-22 13:41:42,753 p=45681 u=master n=ansible | skipping: [cn02]
2025-07-22 13:41:44,576 p=45681 u=master n=ansible | ok: [sm01]
2025-07-22 13:41:44,580 p=45681 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-22 13:41:44,581 p=45681 u=master n=ansible | Tuesday 22 July 2025  13:41:44 +0000 (0:00:01.870)       0:00:01.903 ********** 
2025-07-22 13:41:44,610 p=45681 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 13:41:44,612 p=45681 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 13:41:44,619 p=45681 u=master n=ansible | skipping: [sm02]
2025-07-22 13:41:44,620 p=45681 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 13:41:44,621 p=45681 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 13:41:44,622 p=45681 u=master n=ansible | skipping: [cn01]
2025-07-22 13:41:44,630 p=45681 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 13:41:44,633 p=45681 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 13:41:44,634 p=45681 u=master n=ansible | skipping: [cn02]
2025-07-22 13:41:44,989 p=45681 u=master n=ansible | ok: [sm01] => (item=/home)
2025-07-22 13:41:45,240 p=45681 u=master n=ansible | changed: [sm01] => (item=/sw)
2025-07-22 13:41:45,246 p=45681 u=master n=ansible | TASK [common : [COMMON] Очистка старых экспортов] **************************************************************************************************************************
2025-07-22 13:41:45,267 p=45681 u=master n=ansible | Tuesday 22 July 2025  13:41:45 +0000 (0:00:00.686)       0:00:02.589 ********** 
2025-07-22 13:41:45,295 p=45681 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 13:41:45,296 p=45681 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 13:41:45,301 p=45681 u=master n=ansible | skipping: [sm02]
2025-07-22 13:41:45,304 p=45681 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 13:41:45,306 p=45681 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 13:41:45,307 p=45681 u=master n=ansible | skipping: [cn01]
2025-07-22 13:41:45,314 p=45681 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 13:41:45,316 p=45681 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 13:41:45,317 p=45681 u=master n=ansible | skipping: [cn02]
2025-07-22 13:41:45,654 p=45681 u=master n=ansible | changed: [sm01] => (item=/home)
2025-07-22 13:41:45,899 p=45681 u=master n=ansible | ok: [sm01] => (item=/sw)
2025-07-22 13:41:45,905 p=45681 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS с конкретными IP] ***********************************************************************************************************
2025-07-22 13:41:45,905 p=45681 u=master n=ansible | Tuesday 22 July 2025  13:41:45 +0000 (0:00:00.638)       0:00:03.227 ********** 
2025-07-22 13:41:45,934 p=45681 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:41:45,938 p=45681 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:41:45,942 p=45681 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:41:45,945 p=45681 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:41:45,946 p=45681 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:41:45,947 p=45681 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:41:45,947 p=45681 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:41:45,948 p=45681 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:41:45,949 p=45681 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:41:45,950 p=45681 u=master n=ansible | skipping: [sm02]
2025-07-22 13:41:45,951 p=45681 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:41:45,954 p=45681 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:41:45,958 p=45681 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:41:45,958 p=45681 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:41:45,960 p=45681 u=master n=ansible | skipping: [cn01]
2025-07-22 13:41:45,961 p=45681 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:41:45,964 p=45681 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:41:45,966 p=45681 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:41:45,969 p=45681 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:41:45,972 p=45681 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:41:45,974 p=45681 u=master n=ansible | skipping: [cn02]
2025-07-22 13:41:46,170 p=45681 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.161'})
2025-07-22 13:41:46,416 p=45681 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.167'})
2025-07-22 13:41:46,658 p=45681 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.168'})
2025-07-22 13:41:46,906 p=45681 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'})
2025-07-22 13:41:47,148 p=45681 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'})
2025-07-22 13:41:47,394 p=45681 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'})
2025-07-22 13:41:47,396 p=45681 u=master n=ansible | ERROR! The requested handler 'restart nfs-server' was not found in either the main handlers list nor in the listening handlers list
2025-07-22 13:42:01,247 p=45771 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:42:01,247 p=45771 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:42:01,659 p=45771 u=master n=ansible | PLAY [Тестирование роли common] ********************************************************************************************************************************************
2025-07-22 13:42:01,689 p=45771 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-22 13:42:01,689 p=45771 u=master n=ansible | Tuesday 22 July 2025  13:42:01 +0000 (0:00:00.031)       0:00:00.031 ********** 
2025-07-22 13:42:01,722 p=45771 u=master n=ansible | skipping: [sm02]
2025-07-22 13:42:01,724 p=45771 u=master n=ansible | skipping: [cn01]
2025-07-22 13:42:01,732 p=45771 u=master n=ansible | skipping: [cn02]
2025-07-22 13:42:02,838 p=45771 u=master n=ansible | ok: [sm01]
2025-07-22 13:42:02,842 p=45771 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-22 13:42:02,843 p=45771 u=master n=ansible | Tuesday 22 July 2025  13:42:02 +0000 (0:00:01.153)       0:00:01.185 ********** 
2025-07-22 13:42:02,877 p=45771 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 13:42:02,879 p=45771 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 13:42:02,880 p=45771 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 13:42:02,881 p=45771 u=master n=ansible | skipping: [sm02]
2025-07-22 13:42:02,882 p=45771 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 13:42:02,883 p=45771 u=master n=ansible | skipping: [cn01]
2025-07-22 13:42:02,888 p=45771 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 13:42:02,891 p=45771 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 13:42:02,892 p=45771 u=master n=ansible | skipping: [cn02]
2025-07-22 13:42:03,253 p=45771 u=master n=ansible | ok: [sm01] => (item=/home)
2025-07-22 13:42:03,504 p=45771 u=master n=ansible | ok: [sm01] => (item=/sw)
2025-07-22 13:42:03,510 p=45771 u=master n=ansible | TASK [common : [COMMON] Очистка старых экспортов] **************************************************************************************************************************
2025-07-22 13:42:03,510 p=45771 u=master n=ansible | Tuesday 22 July 2025  13:42:03 +0000 (0:00:00.667)       0:00:01.852 ********** 
2025-07-22 13:42:03,542 p=45771 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 13:42:03,543 p=45771 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 13:42:03,547 p=45771 u=master n=ansible | skipping: [sm02]
2025-07-22 13:42:03,550 p=45771 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 13:42:03,551 p=45771 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 13:42:03,552 p=45771 u=master n=ansible | skipping: [cn01]
2025-07-22 13:42:03,560 p=45771 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 13:42:03,563 p=45771 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 13:42:03,563 p=45771 u=master n=ansible | skipping: [cn02]
2025-07-22 13:42:03,909 p=45771 u=master n=ansible | changed: [sm01] => (item=/home)
2025-07-22 13:42:04,153 p=45771 u=master n=ansible | changed: [sm01] => (item=/sw)
2025-07-22 13:42:04,158 p=45771 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS с конкретными IP] ***********************************************************************************************************
2025-07-22 13:42:04,158 p=45771 u=master n=ansible | Tuesday 22 July 2025  13:42:04 +0000 (0:00:00.647)       0:00:02.500 ********** 
2025-07-22 13:42:04,188 p=45771 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:42:04,190 p=45771 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:42:04,191 p=45771 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:42:04,197 p=45771 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:42:04,198 p=45771 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:42:04,199 p=45771 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:42:04,200 p=45771 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:42:04,201 p=45771 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:42:04,203 p=45771 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:42:04,204 p=45771 u=master n=ansible | skipping: [sm02]
2025-07-22 13:42:04,205 p=45771 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:42:04,207 p=45771 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:42:04,209 p=45771 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:42:04,210 p=45771 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:42:04,212 p=45771 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:42:04,212 p=45771 u=master n=ansible | skipping: [cn01]
2025-07-22 13:42:04,213 p=45771 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:42:04,216 p=45771 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:42:04,219 p=45771 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:42:04,222 p=45771 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:42:04,223 p=45771 u=master n=ansible | skipping: [cn02]
2025-07-22 13:42:04,422 p=45771 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.161'})
2025-07-22 13:42:04,665 p=45771 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.167'})
2025-07-22 13:42:04,911 p=45771 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.168'})
2025-07-22 13:42:05,155 p=45771 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'})
2025-07-22 13:42:05,403 p=45771 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'})
2025-07-22 13:42:05,648 p=45771 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'})
2025-07-22 13:42:05,650 p=45771 u=master n=ansible | ERROR! The requested handler 'restart nfs-server' was not found in either the main handlers list nor in the listening handlers list
2025-07-22 13:44:07,706 p=45853 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:44:07,706 p=45853 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:44:08,138 p=45853 u=master n=ansible | PLAY [Тестирование роли common] ********************************************************************************************************************************************
2025-07-22 13:44:08,169 p=45853 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-22 13:44:08,169 p=45853 u=master n=ansible | Tuesday 22 July 2025  13:44:08 +0000 (0:00:00.033)       0:00:00.033 ********** 
2025-07-22 13:44:08,205 p=45853 u=master n=ansible | skipping: [sm02]
2025-07-22 13:44:08,210 p=45853 u=master n=ansible | skipping: [cn01]
2025-07-22 13:44:08,215 p=45853 u=master n=ansible | skipping: [cn02]
2025-07-22 13:44:10,082 p=45853 u=master n=ansible | ok: [sm01]
2025-07-22 13:44:10,087 p=45853 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-22 13:44:10,087 p=45853 u=master n=ansible | Tuesday 22 July 2025  13:44:10 +0000 (0:00:01.918)       0:00:01.951 ********** 
2025-07-22 13:44:10,118 p=45853 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 13:44:10,119 p=45853 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 13:44:10,122 p=45853 u=master n=ansible | skipping: [sm02]
2025-07-22 13:44:10,125 p=45853 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 13:44:10,127 p=45853 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 13:44:10,128 p=45853 u=master n=ansible | skipping: [cn01]
2025-07-22 13:44:10,135 p=45853 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 13:44:10,138 p=45853 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 13:44:10,139 p=45853 u=master n=ansible | skipping: [cn02]
2025-07-22 13:44:10,497 p=45853 u=master n=ansible | ok: [sm01] => (item=/home)
2025-07-22 13:44:10,761 p=45853 u=master n=ansible | ok: [sm01] => (item=/sw)
2025-07-22 13:44:10,767 p=45853 u=master n=ansible | TASK [common : [COMMON] Очистка старых экспортов] **************************************************************************************************************************
2025-07-22 13:44:10,767 p=45853 u=master n=ansible | Tuesday 22 July 2025  13:44:10 +0000 (0:00:00.679)       0:00:02.631 ********** 
2025-07-22 13:44:10,797 p=45853 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 13:44:10,798 p=45853 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 13:44:10,802 p=45853 u=master n=ansible | skipping: [sm02]
2025-07-22 13:44:10,805 p=45853 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 13:44:10,806 p=45853 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 13:44:10,807 p=45853 u=master n=ansible | skipping: [cn01]
2025-07-22 13:44:10,814 p=45853 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 13:44:10,817 p=45853 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 13:44:10,818 p=45853 u=master n=ansible | skipping: [cn02]
2025-07-22 13:44:11,168 p=45853 u=master n=ansible | changed: [sm01] => (item=/home)
2025-07-22 13:44:11,415 p=45853 u=master n=ansible | changed: [sm01] => (item=/sw)
2025-07-22 13:44:11,421 p=45853 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS с конкретными IP] ***********************************************************************************************************
2025-07-22 13:44:11,422 p=45853 u=master n=ansible | Tuesday 22 July 2025  13:44:11 +0000 (0:00:00.654)       0:00:03.285 ********** 
2025-07-22 13:44:11,453 p=45853 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:44:11,456 p=45853 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:44:11,457 p=45853 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:44:11,463 p=45853 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:44:11,464 p=45853 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:44:11,465 p=45853 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:44:11,466 p=45853 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:44:11,467 p=45853 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:44:11,469 p=45853 u=master n=ansible | skipping: [sm02]
2025-07-22 13:44:11,469 p=45853 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:44:11,470 p=45853 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:44:11,473 p=45853 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:44:11,476 p=45853 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:44:11,478 p=45853 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:44:11,478 p=45853 u=master n=ansible | skipping: [cn01]
2025-07-22 13:44:11,480 p=45853 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:44:11,483 p=45853 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:44:11,486 p=45853 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:44:11,489 p=45853 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:44:11,493 p=45853 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:44:11,494 p=45853 u=master n=ansible | skipping: [cn02]
2025-07-22 13:44:11,691 p=45853 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.161'})
2025-07-22 13:44:11,950 p=45853 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.167'})
2025-07-22 13:44:12,196 p=45853 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.168'})
2025-07-22 13:44:12,444 p=45853 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'})
2025-07-22 13:44:12,689 p=45853 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'})
2025-07-22 13:44:12,937 p=45853 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'})
2025-07-22 13:44:12,939 p=45853 u=master n=ansible | ERROR! The requested handler 'restart nfs-server' was not found in either the main handlers list nor in the listening handlers list
2025-07-22 13:44:21,987 p=45949 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:44:21,987 p=45949 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:44:22,395 p=45949 u=master n=ansible | playbook: playbooks/test_common.yml
2025-07-22 13:45:14,886 p=46047 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:45:14,887 p=46047 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:45:15,319 p=46047 u=master n=ansible | PLAY [Тестирование роли common] ********************************************************************************************************************************************
2025-07-22 13:45:15,350 p=46047 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-22 13:45:15,350 p=46047 u=master n=ansible | Tuesday 22 July 2025  13:45:15 +0000 (0:00:00.033)       0:00:00.033 ********** 
2025-07-22 13:45:15,386 p=46047 u=master n=ansible | skipping: [sm02]
2025-07-22 13:45:15,388 p=46047 u=master n=ansible | skipping: [cn01]
2025-07-22 13:45:15,396 p=46047 u=master n=ansible | skipping: [cn02]
2025-07-22 13:45:17,300 p=46047 u=master n=ansible | ok: [sm01]
2025-07-22 13:45:17,304 p=46047 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-22 13:45:17,305 p=46047 u=master n=ansible | Tuesday 22 July 2025  13:45:17 +0000 (0:00:01.954)       0:00:01.988 ********** 
2025-07-22 13:45:17,333 p=46047 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 13:45:17,334 p=46047 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 13:45:17,339 p=46047 u=master n=ansible | skipping: [sm02]
2025-07-22 13:45:17,342 p=46047 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 13:45:17,343 p=46047 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 13:45:17,344 p=46047 u=master n=ansible | skipping: [cn01]
2025-07-22 13:45:17,352 p=46047 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 13:45:17,355 p=46047 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 13:45:17,356 p=46047 u=master n=ansible | skipping: [cn02]
2025-07-22 13:45:17,712 p=46047 u=master n=ansible | ok: [sm01] => (item=/home)
2025-07-22 13:45:17,971 p=46047 u=master n=ansible | ok: [sm01] => (item=/sw)
2025-07-22 13:45:17,976 p=46047 u=master n=ansible | TASK [common : [COMMON] Очистка старых экспортов] **************************************************************************************************************************
2025-07-22 13:45:17,976 p=46047 u=master n=ansible | Tuesday 22 July 2025  13:45:17 +0000 (0:00:00.671)       0:00:02.660 ********** 
2025-07-22 13:45:18,005 p=46047 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 13:45:18,008 p=46047 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 13:45:18,014 p=46047 u=master n=ansible | skipping: [sm02]
2025-07-22 13:45:18,017 p=46047 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 13:45:18,017 p=46047 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 13:45:18,018 p=46047 u=master n=ansible | skipping: [cn01]
2025-07-22 13:45:18,026 p=46047 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 13:45:18,029 p=46047 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 13:45:18,030 p=46047 u=master n=ansible | skipping: [cn02]
2025-07-22 13:45:18,379 p=46047 u=master n=ansible | changed: [sm01] => (item=/home)
2025-07-22 13:45:18,625 p=46047 u=master n=ansible | changed: [sm01] => (item=/sw)
2025-07-22 13:45:18,631 p=46047 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS с конкретными IP] ***********************************************************************************************************
2025-07-22 13:45:18,631 p=46047 u=master n=ansible | Tuesday 22 July 2025  13:45:18 +0000 (0:00:00.655)       0:00:03.315 ********** 
2025-07-22 13:45:18,664 p=46047 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:45:18,665 p=46047 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:45:18,672 p=46047 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:45:18,673 p=46047 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:45:18,674 p=46047 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:45:18,674 p=46047 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:45:18,675 p=46047 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:45:18,676 p=46047 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:45:18,677 p=46047 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:45:18,678 p=46047 u=master n=ansible | skipping: [sm02]
2025-07-22 13:45:18,679 p=46047 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:45:18,682 p=46047 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:45:18,684 p=46047 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:45:18,685 p=46047 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:45:18,686 p=46047 u=master n=ansible | skipping: [cn01]
2025-07-22 13:45:18,688 p=46047 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:45:18,691 p=46047 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:45:18,695 p=46047 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:45:18,697 p=46047 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:45:18,701 p=46047 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:45:18,703 p=46047 u=master n=ansible | skipping: [cn02]
2025-07-22 13:45:18,914 p=46047 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.161'})
2025-07-22 13:45:19,163 p=46047 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.167'})
2025-07-22 13:45:19,407 p=46047 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.168'})
2025-07-22 13:45:19,647 p=46047 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'})
2025-07-22 13:45:19,888 p=46047 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'})
2025-07-22 13:45:20,140 p=46047 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'})
2025-07-22 13:45:20,147 p=46047 u=master n=ansible | TASK [common : [COMMON] Запуск и включение NFS server] *********************************************************************************************************************
2025-07-22 13:45:20,147 p=46047 u=master n=ansible | Tuesday 22 July 2025  13:45:20 +0000 (0:00:01.515)       0:00:04.831 ********** 
2025-07-22 13:45:20,186 p=46047 u=master n=ansible | skipping: [sm02]
2025-07-22 13:45:20,187 p=46047 u=master n=ansible | skipping: [cn01]
2025-07-22 13:45:20,196 p=46047 u=master n=ansible | skipping: [cn02]
2025-07-22 13:45:20,978 p=46047 u=master n=ansible | ok: [sm01]
2025-07-22 13:45:20,983 p=46047 u=master n=ansible | TASK [common : [COMMON] Установка NFS client] ******************************************************************************************************************************
2025-07-22 13:45:20,984 p=46047 u=master n=ansible | Tuesday 22 July 2025  13:45:20 +0000 (0:00:00.836)       0:00:05.667 ********** 
2025-07-22 13:45:21,008 p=46047 u=master n=ansible | skipping: [sm01]
2025-07-22 13:45:22,779 p=46047 u=master n=ansible | ok: [cn01]
2025-07-22 13:45:22,791 p=46047 u=master n=ansible | ok: [sm02]
2025-07-22 13:45:22,793 p=46047 u=master n=ansible | ok: [cn02]
2025-07-22 13:45:22,797 p=46047 u=master n=ansible | TASK [common : [COMMON] Создание точек монтирования NFS] *******************************************************************************************************************
2025-07-22 13:45:22,797 p=46047 u=master n=ansible | Tuesday 22 July 2025  13:45:22 +0000 (0:00:01.813)       0:00:07.481 ********** 
2025-07-22 13:45:22,819 p=46047 u=master n=ansible | skipping: [sm01] => (item=/sw) 
2025-07-22 13:45:22,834 p=46047 u=master n=ansible | skipping: [sm01]
2025-07-22 13:45:23,080 p=46047 u=master n=ansible | changed: [sm02] => (item=/sw)
2025-07-22 13:45:23,099 p=46047 u=master n=ansible | changed: [cn02] => (item=/sw)
2025-07-22 13:45:23,108 p=46047 u=master n=ansible | changed: [cn01] => (item=/sw)
2025-07-22 13:45:23,113 p=46047 u=master n=ansible | TASK [common : [COMMON] Монтирование NFS shares] ***************************************************************************************************************************
2025-07-22 13:45:23,113 p=46047 u=master n=ansible | Tuesday 22 July 2025  13:45:23 +0000 (0:00:00.315)       0:00:07.797 ********** 
2025-07-22 13:45:23,134 p=46047 u=master n=ansible | skipping: [sm01] => (item={'path': '/home', 'src': '/home'}) 
2025-07-22 13:45:23,138 p=46047 u=master n=ansible | skipping: [sm01] => (item={'path': '/sw', 'src': '/sw'}) 
2025-07-22 13:45:23,151 p=46047 u=master n=ansible | skipping: [sm01]
2025-07-22 13:45:24,106 p=46047 u=master n=ansible | failed: [sm02] (item={'path': '/home', 'src': '/home'}) => changed=false 
  ansible_loop_var: item
  item:
    path: /home
    src: /home
  msg: |-
    Error mounting /home: Created symlink /run/systemd/system/remote-fs.target.wants/rpc-statd.service → /usr/lib/systemd/system/rpc-statd.service.
    mount.nfs: access denied by server while mounting sm01:/home
2025-07-22 13:45:24,107 p=46047 u=master n=ansible | failed: [cn01] (item={'path': '/home', 'src': '/home'}) => changed=false 
  ansible_loop_var: item
  item:
    path: /home
    src: /home
  msg: |-
    Error mounting /home: Created symlink /run/systemd/system/remote-fs.target.wants/rpc-statd.service → /usr/lib/systemd/system/rpc-statd.service.
    mount.nfs: access denied by server while mounting sm01:/home
2025-07-22 13:45:24,223 p=46047 u=master n=ansible | failed: [cn02] (item={'path': '/home', 'src': '/home'}) => changed=false 
  ansible_loop_var: item
  item:
    path: /home
    src: /home
  msg: |-
    Error mounting /home: Created symlink /run/systemd/system/remote-fs.target.wants/rpc-statd.service → /usr/lib/systemd/system/rpc-statd.service.
    mount.nfs: access denied by server while mounting sm01:/home
2025-07-22 13:45:24,379 p=46047 u=master n=ansible | failed: [sm02] (item={'path': '/sw', 'src': '/sw'}) => changed=false 
  ansible_loop_var: item
  item:
    path: /sw
    src: /sw
  msg: |-
    Error mounting /sw: mount.nfs: access denied by server while mounting sm01:/sw
2025-07-22 13:45:24,403 p=46047 u=master n=ansible | failed: [cn01] (item={'path': '/sw', 'src': '/sw'}) => changed=false 
  ansible_loop_var: item
  item:
    path: /sw
    src: /sw
  msg: |-
    Error mounting /sw: mount.nfs: access denied by server while mounting sm01:/sw
2025-07-22 13:45:24,504 p=46047 u=master n=ansible | failed: [cn02] (item={'path': '/sw', 'src': '/sw'}) => changed=false 
  ansible_loop_var: item
  item:
    path: /sw
    src: /sw
  msg: |-
    Error mounting /sw: mount.nfs: access denied by server while mounting sm01:/sw
2025-07-22 13:45:24,516 p=46047 u=master n=ansible | RUNNING HANDLER [common : restart nfs-server] ******************************************************************************************************************************
2025-07-22 13:45:24,516 p=46047 u=master n=ansible | Tuesday 22 July 2025  13:45:24 +0000 (0:00:01.402)       0:00:09.199 ********** 
2025-07-22 13:45:25,595 p=46047 u=master n=ansible | changed: [sm01]
2025-07-22 13:45:25,600 p=46047 u=master n=ansible | RUNNING HANDLER [common : reload nfs-exports] ******************************************************************************************************************************
2025-07-22 13:45:25,600 p=46047 u=master n=ansible | Tuesday 22 July 2025  13:45:25 +0000 (0:00:01.084)       0:00:10.284 ********** 
2025-07-22 13:45:25,985 p=46047 u=master n=ansible | changed: [sm01]
2025-07-22 13:45:25,992 p=46047 u=master n=ansible | PLAY RECAP *****************************************************************************************************************************************************************
2025-07-22 13:45:25,993 p=46047 u=master n=ansible | cn01                       : ok=2    changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-07-22 13:45:25,993 p=46047 u=master n=ansible | cn02                       : ok=2    changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-07-22 13:45:25,993 p=46047 u=master n=ansible | sm01                       : ok=7    changed=4    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   
2025-07-22 13:45:25,993 p=46047 u=master n=ansible | sm02                       : ok=2    changed=1    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-07-22 13:45:25,993 p=46047 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 10 seconds
2025-07-22 13:45:25,993 p=46047 u=master n=ansible | Tuesday 22 July 2025  13:45:25 +0000 (0:00:00.393)       0:00:10.677 ********** 
2025-07-22 13:45:25,993 p=46047 u=master n=ansible | =============================================================================== 
2025-07-22 13:45:25,994 p=46047 u=master n=ansible | common : [COMMON] Установка NFS server на master -------------------------------------------------------------------------------------------------------------------- 1.95s
2025-07-22 13:45:25,994 p=46047 u=master n=ansible | common : [COMMON] Установка NFS client ------------------------------------------------------------------------------------------------------------------------------ 1.81s
2025-07-22 13:45:25,994 p=46047 u=master n=ansible | common : [COMMON] Настройка экспорта NFS с конкретными IP ----------------------------------------------------------------------------------------------------------- 1.52s
2025-07-22 13:45:25,994 p=46047 u=master n=ansible | common : [COMMON] Монтирование NFS shares --------------------------------------------------------------------------------------------------------------------------- 1.40s
2025-07-22 13:45:25,994 p=46047 u=master n=ansible | common : restart nfs-server ----------------------------------------------------------------------------------------------------------------------------------------- 1.08s
2025-07-22 13:45:25,994 p=46047 u=master n=ansible | common : [COMMON] Запуск и включение NFS server --------------------------------------------------------------------------------------------------------------------- 0.84s
2025-07-22 13:45:25,994 p=46047 u=master n=ansible | common : [COMMON] Создание директорий для экспорта NFS -------------------------------------------------------------------------------------------------------------- 0.67s
2025-07-22 13:45:25,994 p=46047 u=master n=ansible | common : [COMMON] Очистка старых экспортов -------------------------------------------------------------------------------------------------------------------------- 0.66s
2025-07-22 13:45:25,994 p=46047 u=master n=ansible | common : reload nfs-exports ----------------------------------------------------------------------------------------------------------------------------------------- 0.39s
2025-07-22 13:45:25,994 p=46047 u=master n=ansible | common : [COMMON] Создание точек монтирования NFS ------------------------------------------------------------------------------------------------------------------- 0.32s
2025-07-22 13:47:27,608 p=46200 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:47:27,609 p=46200 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:47:27,918 p=46200 u=master n=ansible | ERROR! The defaults/main.yml file for role 'common' must contain a dictionary of variables
2025-07-22 13:48:56,182 p=46232 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:48:56,182 p=46232 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 13:48:56,634 p=46232 u=master n=ansible | PLAY [Тестирование роли common] ********************************************************************************************************************************************
2025-07-22 13:48:56,665 p=46232 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-22 13:48:56,666 p=46232 u=master n=ansible | Tuesday 22 July 2025  13:48:56 +0000 (0:00:00.034)       0:00:00.034 ********** 
2025-07-22 13:48:56,703 p=46232 u=master n=ansible | skipping: [sm02]
2025-07-22 13:48:56,704 p=46232 u=master n=ansible | skipping: [cn01]
2025-07-22 13:48:56,712 p=46232 u=master n=ansible | skipping: [cn02]
2025-07-22 13:48:58,734 p=46232 u=master n=ansible | ok: [sm01]
2025-07-22 13:48:58,738 p=46232 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-22 13:48:58,738 p=46232 u=master n=ansible | Tuesday 22 July 2025  13:48:58 +0000 (0:00:02.072)       0:00:02.107 ********** 
2025-07-22 13:48:58,768 p=46232 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 13:48:58,770 p=46232 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 13:48:58,777 p=46232 u=master n=ansible | skipping: [sm02]
2025-07-22 13:48:58,778 p=46232 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 13:48:58,779 p=46232 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 13:48:58,780 p=46232 u=master n=ansible | skipping: [cn01]
2025-07-22 13:48:58,789 p=46232 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 13:48:58,792 p=46232 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 13:48:58,793 p=46232 u=master n=ansible | skipping: [cn02]
2025-07-22 13:48:59,158 p=46232 u=master n=ansible | ok: [sm01] => (item=/home)
2025-07-22 13:48:59,413 p=46232 u=master n=ansible | ok: [sm01] => (item=/sw)
2025-07-22 13:48:59,418 p=46232 u=master n=ansible | TASK [common : [COMMON] Очистка старых экспортов] **************************************************************************************************************************
2025-07-22 13:48:59,419 p=46232 u=master n=ansible | Tuesday 22 July 2025  13:48:59 +0000 (0:00:00.680)       0:00:02.787 ********** 
2025-07-22 13:48:59,448 p=46232 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 13:48:59,449 p=46232 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 13:48:59,456 p=46232 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 13:48:59,457 p=46232 u=master n=ansible | skipping: [sm02]
2025-07-22 13:48:59,458 p=46232 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 13:48:59,459 p=46232 u=master n=ansible | skipping: [cn01]
2025-07-22 13:48:59,466 p=46232 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 13:48:59,469 p=46232 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 13:48:59,469 p=46232 u=master n=ansible | skipping: [cn02]
2025-07-22 13:48:59,814 p=46232 u=master n=ansible | changed: [sm01] => (item=/home)
2025-07-22 13:49:00,067 p=46232 u=master n=ansible | changed: [sm01] => (item=/sw)
2025-07-22 13:49:00,073 p=46232 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS с конкретными IP] ***********************************************************************************************************
2025-07-22 13:49:00,073 p=46232 u=master n=ansible | Tuesday 22 July 2025  13:49:00 +0000 (0:00:00.654)       0:00:03.442 ********** 
2025-07-22 13:49:00,104 p=46232 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:49:00,106 p=46232 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:49:00,111 p=46232 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:49:00,114 p=46232 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:49:00,114 p=46232 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:49:00,115 p=46232 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:49:00,116 p=46232 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:49:00,117 p=46232 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:49:00,118 p=46232 u=master n=ansible | skipping: [sm02]
2025-07-22 13:49:00,119 p=46232 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:49:00,120 p=46232 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:49:00,123 p=46232 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:49:00,126 p=46232 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:49:00,127 p=46232 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:49:00,129 p=46232 u=master n=ansible | skipping: [cn01]
2025-07-22 13:49:00,129 p=46232 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:49:00,132 p=46232 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:49:00,134 p=46232 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 13:49:00,137 p=46232 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 13:49:00,140 p=46232 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 13:49:00,141 p=46232 u=master n=ansible | skipping: [cn02]
2025-07-22 13:49:00,350 p=46232 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.161'})
2025-07-22 13:49:00,602 p=46232 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.167'})
2025-07-22 13:49:00,853 p=46232 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.168'})
2025-07-22 13:49:01,108 p=46232 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'})
2025-07-22 13:49:01,353 p=46232 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'})
2025-07-22 13:49:01,606 p=46232 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'})
2025-07-22 13:49:01,614 p=46232 u=master n=ansible | TASK [common : [COMMON] Запуск и включение NFS server] *********************************************************************************************************************
2025-07-22 13:49:01,615 p=46232 u=master n=ansible | Tuesday 22 July 2025  13:49:01 +0000 (0:00:01.541)       0:00:04.983 ********** 
2025-07-22 13:49:01,654 p=46232 u=master n=ansible | skipping: [sm02]
2025-07-22 13:49:01,655 p=46232 u=master n=ansible | skipping: [cn01]
2025-07-22 13:49:01,664 p=46232 u=master n=ansible | skipping: [cn02]
2025-07-22 13:49:02,448 p=46232 u=master n=ansible | ok: [sm01]
2025-07-22 13:49:02,453 p=46232 u=master n=ansible | TASK [common : [COMMON] Принудительная перезагрузка экспортов NFS] *********************************************************************************************************
2025-07-22 13:49:02,453 p=46232 u=master n=ansible | Tuesday 22 July 2025  13:49:02 +0000 (0:00:00.838)       0:00:05.822 ********** 
2025-07-22 13:49:02,486 p=46232 u=master n=ansible | skipping: [sm02]
2025-07-22 13:49:02,488 p=46232 u=master n=ansible | skipping: [cn01]
2025-07-22 13:49:02,497 p=46232 u=master n=ansible | skipping: [cn02]
2025-07-22 13:49:02,932 p=46232 u=master n=ansible | changed: [sm01]
2025-07-22 13:49:02,937 p=46232 u=master n=ansible | TASK [common : [COMMON] Проверка активных экспортов] ***********************************************************************************************************************
2025-07-22 13:49:02,937 p=46232 u=master n=ansible | Tuesday 22 July 2025  13:49:02 +0000 (0:00:00.483)       0:00:06.305 ********** 
2025-07-22 13:49:02,969 p=46232 u=master n=ansible | skipping: [sm02]
2025-07-22 13:49:02,972 p=46232 u=master n=ansible | skipping: [cn01]
2025-07-22 13:49:02,981 p=46232 u=master n=ansible | skipping: [cn02]
2025-07-22 13:49:03,215 p=46232 u=master n=ansible | changed: [sm01]
2025-07-22 13:49:03,220 p=46232 u=master n=ansible | TASK [common : [COMMON] Показать активные экспорты] ************************************************************************************************************************
2025-07-22 13:49:03,220 p=46232 u=master n=ansible | Tuesday 22 July 2025  13:49:03 +0000 (0:00:00.283)       0:00:06.589 ********** 
2025-07-22 13:49:03,258 p=46232 u=master n=ansible | ok: [sm01] => 
  nfs_exports_check.stdout_lines:
  - "/home         \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/shared       \t10.20.90.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
2025-07-22 13:49:03,259 p=46232 u=master n=ansible | skipping: [sm02]
2025-07-22 13:49:03,259 p=46232 u=master n=ansible | skipping: [cn01]
2025-07-22 13:49:03,267 p=46232 u=master n=ansible | skipping: [cn02]
2025-07-22 13:49:03,271 p=46232 u=master n=ansible | TASK [common : [COMMON] Установка NFS client] ******************************************************************************************************************************
2025-07-22 13:49:03,271 p=46232 u=master n=ansible | Tuesday 22 July 2025  13:49:03 +0000 (0:00:00.050)       0:00:06.640 ********** 
2025-07-22 13:49:03,294 p=46232 u=master n=ansible | skipping: [sm01]
2025-07-22 13:49:05,141 p=46232 u=master n=ansible | ok: [sm02]
2025-07-22 13:49:05,145 p=46232 u=master n=ansible | ok: [cn02]
2025-07-22 13:49:05,166 p=46232 u=master n=ansible | ok: [cn01]
2025-07-22 13:49:05,173 p=46232 u=master n=ansible | TASK [common : [COMMON] Создание точек монтирования NFS] *******************************************************************************************************************
2025-07-22 13:49:05,173 p=46232 u=master n=ansible | Tuesday 22 July 2025  13:49:05 +0000 (0:00:01.902)       0:00:08.542 ********** 
2025-07-22 13:49:05,196 p=46232 u=master n=ansible | skipping: [sm01] => (item=/sw) 
2025-07-22 13:49:05,203 p=46232 u=master n=ansible | skipping: [sm01]
2025-07-22 13:49:05,473 p=46232 u=master n=ansible | ok: [sm02] => (item=/sw)
2025-07-22 13:49:05,485 p=46232 u=master n=ansible | ok: [cn02] => (item=/sw)
2025-07-22 13:49:05,487 p=46232 u=master n=ansible | ok: [cn01] => (item=/sw)
2025-07-22 13:49:05,492 p=46232 u=master n=ansible | TASK [common : [COMMON] Монтирование NFS shares] ***************************************************************************************************************************
2025-07-22 13:49:05,492 p=46232 u=master n=ansible | Tuesday 22 July 2025  13:49:05 +0000 (0:00:00.318)       0:00:08.860 ********** 
2025-07-22 13:49:05,511 p=46232 u=master n=ansible | skipping: [sm01] => (item={'path': '/home', 'src': '/home'}) 
2025-07-22 13:49:05,514 p=46232 u=master n=ansible | skipping: [sm01] => (item={'path': '/sw', 'src': '/sw'}) 
2025-07-22 13:49:05,519 p=46232 u=master n=ansible | skipping: [sm01]
2025-07-22 13:49:05,927 p=46232 u=master n=ansible | changed: [sm02] => (item={'path': '/home', 'src': '/home'})
2025-07-22 13:49:05,929 p=46232 u=master n=ansible | changed: [cn02] => (item={'path': '/home', 'src': '/home'})
2025-07-22 13:49:05,942 p=46232 u=master n=ansible | changed: [cn01] => (item={'path': '/home', 'src': '/home'})
2025-07-22 13:49:06,217 p=46232 u=master n=ansible | changed: [sm02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 13:49:06,219 p=46232 u=master n=ansible | changed: [cn02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 13:49:06,245 p=46232 u=master n=ansible | changed: [cn01] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 13:49:06,274 p=46232 u=master n=ansible | RUNNING HANDLER [common : restart nfs-server] ******************************************************************************************************************************
2025-07-22 13:49:06,274 p=46232 u=master n=ansible | Tuesday 22 July 2025  13:49:06 +0000 (0:00:00.782)       0:00:09.643 ********** 
2025-07-22 13:49:07,446 p=46232 u=master n=ansible | changed: [sm01]
2025-07-22 13:49:07,450 p=46232 u=master n=ansible | RUNNING HANDLER [common : reload nfs-exports] ******************************************************************************************************************************
2025-07-22 13:49:07,450 p=46232 u=master n=ansible | Tuesday 22 July 2025  13:49:07 +0000 (0:00:01.175)       0:00:10.818 ********** 
2025-07-22 13:49:07,727 p=46232 u=master n=ansible | changed: [sm01]
2025-07-22 13:49:07,742 p=46232 u=master n=ansible | PLAY RECAP *****************************************************************************************************************************************************************
2025-07-22 13:49:07,742 p=46232 u=master n=ansible | cn01                       : ok=3    changed=1    unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   
2025-07-22 13:49:07,743 p=46232 u=master n=ansible | cn02                       : ok=3    changed=1    unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   
2025-07-22 13:49:07,743 p=46232 u=master n=ansible | sm01                       : ok=10   changed=6    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   
2025-07-22 13:49:07,743 p=46232 u=master n=ansible | sm02                       : ok=3    changed=1    unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   
2025-07-22 13:49:07,743 p=46232 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 11 seconds
2025-07-22 13:49:07,743 p=46232 u=master n=ansible | Tuesday 22 July 2025  13:49:07 +0000 (0:00:00.293)       0:00:11.112 ********** 
2025-07-22 13:49:07,743 p=46232 u=master n=ansible | =============================================================================== 
2025-07-22 13:49:07,743 p=46232 u=master n=ansible | common : [COMMON] Установка NFS server на master -------------------------------------------------------------------------------------------------------------------- 2.07s
2025-07-22 13:49:07,743 p=46232 u=master n=ansible | common : [COMMON] Установка NFS client ------------------------------------------------------------------------------------------------------------------------------ 1.90s
2025-07-22 13:49:07,744 p=46232 u=master n=ansible | common : [COMMON] Настройка экспорта NFS с конкретными IP ----------------------------------------------------------------------------------------------------------- 1.54s
2025-07-22 13:49:07,744 p=46232 u=master n=ansible | common : restart nfs-server ----------------------------------------------------------------------------------------------------------------------------------------- 1.18s
2025-07-22 13:49:07,744 p=46232 u=master n=ansible | common : [COMMON] Запуск и включение NFS server --------------------------------------------------------------------------------------------------------------------- 0.84s
2025-07-22 13:49:07,744 p=46232 u=master n=ansible | common : [COMMON] Монтирование NFS shares --------------------------------------------------------------------------------------------------------------------------- 0.78s
2025-07-22 13:49:07,744 p=46232 u=master n=ansible | common : [COMMON] Создание директорий для экспорта NFS -------------------------------------------------------------------------------------------------------------- 0.68s
2025-07-22 13:49:07,744 p=46232 u=master n=ansible | common : [COMMON] Очистка старых экспортов -------------------------------------------------------------------------------------------------------------------------- 0.65s
2025-07-22 13:49:07,744 p=46232 u=master n=ansible | common : [COMMON] Принудительная перезагрузка экспортов NFS --------------------------------------------------------------------------------------------------------- 0.48s
2025-07-22 13:49:07,744 p=46232 u=master n=ansible | common : [COMMON] Создание точек монтирования NFS ------------------------------------------------------------------------------------------------------------------- 0.32s
2025-07-22 13:49:07,744 p=46232 u=master n=ansible | common : reload nfs-exports ----------------------------------------------------------------------------------------------------------------------------------------- 0.29s
2025-07-22 13:49:07,744 p=46232 u=master n=ansible | common : [COMMON] Проверка активных экспортов ----------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-22 13:49:07,744 p=46232 u=master n=ansible | common : [COMMON] Показать активные экспорты ------------------------------------------------------------------------------------------------------------------------ 0.05s
2025-07-22 14:03:37,975 p=46443 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 14:03:37,975 p=46443 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 14:03:38,395 p=46443 u=master n=ansible | PLAY [Тестирование роли common] ********************************************************************************************************************************************
2025-07-22 14:03:38,411 p=46443 u=master n=ansible | TASK [Информация о тестировании] *******************************************************************************************************************************************
2025-07-22 14:03:38,411 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:03:38 +0000 (0:00:00.019)       0:00:00.019 ********** 
2025-07-22 14:03:38,465 p=46443 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 14:03:38,468 p=46443 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 14:03:38,476 p=46443 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 14:03:38,490 p=46443 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F9EA Тестируем роль common на кластере\n\U0001F3AF Узлы: ['sm01', 'sm02', 'cn01', 'cn02']\n\U0001F4CA Всего узлов: 4"
2025-07-22 14:03:38,508 p=46443 u=master n=ansible | TASK [common : [COMMON] Начало выполнения роли common] *********************************************************************************************************************
2025-07-22 14:03:38,508 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:03:38 +0000 (0:00:00.096)       0:00:00.116 ********** 
2025-07-22 14:03:38,542 p=46443 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm01"
2025-07-22 14:03:38,543 p=46443 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm02"
2025-07-22 14:03:38,546 p=46443 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn01"
2025-07-22 14:03:38,557 p=46443 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn02"
2025-07-22 14:03:38,562 p=46443 u=master n=ansible | TASK [common : [COMMON] Обновление apt cache] ******************************************************************************************************************************
2025-07-22 14:03:38,562 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:03:38 +0000 (0:00:00.053)       0:00:00.170 ********** 
2025-07-22 14:03:40,319 p=46443 u=master n=ansible | ok: [sm01]
2025-07-22 14:03:42,408 p=46443 u=master n=ansible | ok: [cn01]
2025-07-22 14:03:42,600 p=46443 u=master n=ansible | ok: [cn02]
2025-07-22 14:03:54,057 p=46443 u=master n=ansible | changed: [sm02]
2025-07-22 14:03:54,062 p=46443 u=master n=ansible | TASK [common : [COMMON] Установка базовых пакетов] *************************************************************************************************************************
2025-07-22 14:03:54,062 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:03:54 +0000 (0:00:15.500)       0:00:15.670 ********** 
2025-07-22 14:03:55,197 p=46443 u=master n=ansible | ok: [sm01]
2025-07-22 14:03:55,449 p=46443 u=master n=ansible | ok: [cn02]
2025-07-22 14:03:55,564 p=46443 u=master n=ansible | ok: [sm02]
2025-07-22 14:03:55,769 p=46443 u=master n=ansible | ok: [cn01]
2025-07-22 14:03:55,773 p=46443 u=master n=ansible | TASK [common : [COMMON] Настройка timezone] ********************************************************************************************************************************
2025-07-22 14:03:55,774 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:03:55 +0000 (0:00:01.711)       0:00:17.381 ********** 
2025-07-22 14:03:56,287 p=46443 u=master n=ansible | ok: [sm01]
2025-07-22 14:03:56,347 p=46443 u=master n=ansible | ok: [sm02]
2025-07-22 14:03:56,354 p=46443 u=master n=ansible | ok: [cn02]
2025-07-22 14:03:56,405 p=46443 u=master n=ansible | ok: [cn01]
2025-07-22 14:03:56,409 p=46443 u=master n=ansible | TASK [common : [COMMON] Обеспечение hostname resolution для кластера] ******************************************************************************************************
2025-07-22 14:03:56,409 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:03:56 +0000 (0:00:00.635)       0:00:18.017 ********** 
2025-07-22 14:03:56,811 p=46443 u=master n=ansible | changed: [sm01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 14:03:56,821 p=46443 u=master n=ansible | changed: [sm02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 14:03:56,862 p=46443 u=master n=ansible | changed: [cn01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 14:03:56,877 p=46443 u=master n=ansible | changed: [cn02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 14:03:57,064 p=46443 u=master n=ansible | changed: [sm01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 14:03:57,102 p=46443 u=master n=ansible | changed: [sm02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 14:03:57,120 p=46443 u=master n=ansible | changed: [cn02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 14:03:57,148 p=46443 u=master n=ansible | changed: [cn01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 14:03:57,314 p=46443 u=master n=ansible | changed: [sm01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 14:03:57,345 p=46443 u=master n=ansible | changed: [sm02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 14:03:57,365 p=46443 u=master n=ansible | changed: [cn02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 14:03:57,405 p=46443 u=master n=ansible | changed: [cn01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 14:03:57,567 p=46443 u=master n=ansible | changed: [sm01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 14:03:57,589 p=46443 u=master n=ansible | changed: [sm02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 14:03:57,591 p=46443 u=master n=ansible | [WARNING]: Module remote_tmp /root/.ansible/tmp did not exist and was created with a mode of 0700, this may cause issues when running as another user. To avoid this,
create the remote_tmp dir with the correct permissions manually

2025-07-22 14:03:57,610 p=46443 u=master n=ansible | changed: [cn02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 14:03:57,662 p=46443 u=master n=ansible | changed: [cn01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 14:03:57,668 p=46443 u=master n=ansible | TASK [common : [COMMON] Создание пользователя slurm] ***********************************************************************************************************************
2025-07-22 14:03:57,668 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:03:57 +0000 (0:00:01.259)       0:00:19.276 ********** 
2025-07-22 14:03:58,178 p=46443 u=master n=ansible | ok: [sm01]
2025-07-22 14:03:58,237 p=46443 u=master n=ansible | ok: [cn01]
2025-07-22 14:03:58,303 p=46443 u=master n=ansible | ok: [cn02]
2025-07-22 14:03:58,324 p=46443 u=master n=ansible | ok: [sm02]
2025-07-22 14:03:58,328 p=46443 u=master n=ansible | TASK [common : [COMMON] Установка MUNGE] ***********************************************************************************************************************************
2025-07-22 14:03:58,328 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:03:58 +0000 (0:00:00.659)       0:00:19.936 ********** 
2025-07-22 14:03:59,384 p=46443 u=master n=ansible | ok: [sm01]
2025-07-22 14:03:59,451 p=46443 u=master n=ansible | ok: [sm02]
2025-07-22 14:03:59,502 p=46443 u=master n=ansible | ok: [cn02]
2025-07-22 14:03:59,620 p=46443 u=master n=ansible | ok: [cn01]
2025-07-22 14:03:59,625 p=46443 u=master n=ansible | TASK [common : [COMMON] Остановка MUNGE перед настройкой] ******************************************************************************************************************
2025-07-22 14:03:59,625 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:03:59 +0000 (0:00:01.296)       0:00:21.233 ********** 
2025-07-22 14:04:01,534 p=46443 u=master n=ansible | changed: [sm01]
2025-07-22 14:04:01,741 p=46443 u=master n=ansible | changed: [sm02]
2025-07-22 14:04:01,901 p=46443 u=master n=ansible | changed: [cn02]
2025-07-22 14:04:02,081 p=46443 u=master n=ansible | changed: [cn01]
2025-07-22 14:04:02,085 p=46443 u=master n=ansible | TASK [common : [COMMON] Создание MUNGE ключа на master узле] ***************************************************************************************************************
2025-07-22 14:04:02,086 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:02 +0000 (0:00:02.461)       0:00:23.694 ********** 
2025-07-22 14:04:02,119 p=46443 u=master n=ansible | skipping: [sm02]
2025-07-22 14:04:02,127 p=46443 u=master n=ansible | skipping: [cn01]
2025-07-22 14:04:02,131 p=46443 u=master n=ansible | skipping: [cn02]
2025-07-22 14:04:02,485 p=46443 u=master n=ansible | ok: [sm01]
2025-07-22 14:04:02,489 p=46443 u=master n=ansible | TASK [common : [COMMON] Получение MUNGE ключа с master узла] ***************************************************************************************************************
2025-07-22 14:04:02,489 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:02 +0000 (0:00:00.403)       0:00:24.097 ********** 
2025-07-22 14:04:02,534 p=46443 u=master n=ansible | skipping: [sm02]
2025-07-22 14:04:02,535 p=46443 u=master n=ansible | skipping: [cn01]
2025-07-22 14:04:02,546 p=46443 u=master n=ansible | skipping: [cn02]
2025-07-22 14:04:02,867 p=46443 u=master n=ansible | ok: [sm01]
2025-07-22 14:04:02,873 p=46443 u=master n=ansible | TASK [common : [COMMON] Распространение MUNGE ключа на все узлы] ***********************************************************************************************************
2025-07-22 14:04:02,873 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:02 +0000 (0:00:00.383)       0:00:24.481 ********** 
2025-07-22 14:04:02,896 p=46443 u=master n=ansible | skipping: [sm01]
2025-07-22 14:04:04,016 p=46443 u=master n=ansible | ok: [cn01]
2025-07-22 14:04:04,068 p=46443 u=master n=ansible | ok: [sm02]
2025-07-22 14:04:04,118 p=46443 u=master n=ansible | ok: [cn02]
2025-07-22 14:04:04,122 p=46443 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа MUNGE] **********************************************************************************************************************
2025-07-22 14:04:04,122 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:04 +0000 (0:00:01.249)       0:00:25.730 ********** 
2025-07-22 14:04:04,418 p=46443 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:04:04,426 p=46443 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:04:04,469 p=46443 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:04:04,472 p=46443 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:04:04,676 p=46443 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:04:04,697 p=46443 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:04:04,726 p=46443 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:04:04,733 p=46443 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:04:04,936 p=46443 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:04:04,965 p=46443 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:04:04,987 p=46443 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:04:04,992 p=46443 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:04:05,189 p=46443 u=master n=ansible | changed: [sm02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 14:04:05,231 p=46443 u=master n=ansible | changed: [sm01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 14:04:05,246 p=46443 u=master n=ansible | changed: [cn02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 14:04:05,256 p=46443 u=master n=ansible | changed: [cn01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 14:04:05,262 p=46443 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа на ключ MUNGE] **************************************************************************************************************
2025-07-22 14:04:05,262 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:05 +0000 (0:00:01.139)       0:00:26.870 ********** 
2025-07-22 14:04:05,541 p=46443 u=master n=ansible | ok: [sm01]
2025-07-22 14:04:05,553 p=46443 u=master n=ansible | ok: [cn01]
2025-07-22 14:04:05,560 p=46443 u=master n=ansible | ok: [sm02]
2025-07-22 14:04:05,563 p=46443 u=master n=ansible | ok: [cn02]
2025-07-22 14:04:05,567 p=46443 u=master n=ansible | TASK [common : [COMMON] Запуск и включение MUNGE] **************************************************************************************************************************
2025-07-22 14:04:05,648 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:05 +0000 (0:00:00.386)       0:00:27.256 ********** 
2025-07-22 14:04:07,496 p=46443 u=master n=ansible | changed: [sm02]
2025-07-22 14:04:07,564 p=46443 u=master n=ansible | changed: [cn01]
2025-07-22 14:04:07,587 p=46443 u=master n=ansible | changed: [cn02]
2025-07-22 14:04:07,601 p=46443 u=master n=ansible | changed: [sm01]
2025-07-22 14:04:07,605 p=46443 u=master n=ansible | TASK [common : [COMMON] Проверка работы MUNGE] *****************************************************************************************************************************
2025-07-22 14:04:07,605 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:07 +0000 (0:00:01.956)       0:00:29.213 ********** 
2025-07-22 14:04:07,873 p=46443 u=master n=ansible | ok: [sm01]
2025-07-22 14:04:07,892 p=46443 u=master n=ansible | ok: [sm02]
2025-07-22 14:04:07,899 p=46443 u=master n=ansible | ok: [cn01]
2025-07-22 14:04:07,930 p=46443 u=master n=ansible | ok: [cn02]
2025-07-22 14:04:07,934 p=46443 u=master n=ansible | TASK [common : [COMMON] Результат проверки MUNGE] **************************************************************************************************************************
2025-07-22 14:04:07,934 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:07 +0000 (0:00:00.328)       0:00:29.542 ********** 
2025-07-22 14:04:07,968 p=46443 u=master n=ansible | ok: [sm01] => 
  msg: MUNGE работает корректно на sm01
2025-07-22 14:04:07,974 p=46443 u=master n=ansible | ok: [cn01] => 
  msg: MUNGE работает корректно на cn01
2025-07-22 14:04:07,975 p=46443 u=master n=ansible | ok: [sm02] => 
  msg: MUNGE работает корректно на sm02
2025-07-22 14:04:07,989 p=46443 u=master n=ansible | ok: [cn02] => 
  msg: MUNGE работает корректно на cn02
2025-07-22 14:04:07,993 p=46443 u=master n=ansible | TASK [common : [COMMON] Установка HWLOC] ***********************************************************************************************************************************
2025-07-22 14:04:07,993 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:07 +0000 (0:00:00.059)       0:00:29.601 ********** 
2025-07-22 14:04:09,053 p=46443 u=master n=ansible | ok: [cn02]
2025-07-22 14:04:09,064 p=46443 u=master n=ansible | ok: [cn01]
2025-07-22 14:04:09,110 p=46443 u=master n=ansible | ok: [sm02]
2025-07-22 14:04:09,214 p=46443 u=master n=ansible | ok: [sm01]
2025-07-22 14:04:09,218 p=46443 u=master n=ansible | TASK [common : [COMMON] Проверка HWLOC] ************************************************************************************************************************************
2025-07-22 14:04:09,219 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:09 +0000 (0:00:01.225)       0:00:30.827 ********** 
2025-07-22 14:04:09,494 p=46443 u=master n=ansible | ok: [sm01]
2025-07-22 14:04:09,842 p=46443 u=master n=ansible | ok: [cn02]
2025-07-22 14:04:09,879 p=46443 u=master n=ansible | ok: [cn01]
2025-07-22 14:04:09,917 p=46443 u=master n=ansible | ok: [sm02]
2025-07-22 14:04:09,921 p=46443 u=master n=ansible | TASK [common : [COMMON] Версия HWLOC] **************************************************************************************************************************************
2025-07-22 14:04:09,921 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:09 +0000 (0:00:00.702)       0:00:31.529 ********** 
2025-07-22 14:04:09,950 p=46443 u=master n=ansible | ok: [sm01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 14:04:09,962 p=46443 u=master n=ansible | ok: [sm02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 14:04:09,965 p=46443 u=master n=ansible | ok: [cn01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 14:04:09,980 p=46443 u=master n=ansible | ok: [cn02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 14:04:09,984 p=46443 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-22 14:04:09,984 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:09 +0000 (0:00:00.063)       0:00:31.592 ********** 
2025-07-22 14:04:10,021 p=46443 u=master n=ansible | skipping: [sm02]
2025-07-22 14:04:10,023 p=46443 u=master n=ansible | skipping: [cn01]
2025-07-22 14:04:10,033 p=46443 u=master n=ansible | skipping: [cn02]
2025-07-22 14:04:10,979 p=46443 u=master n=ansible | ok: [sm01]
2025-07-22 14:04:10,983 p=46443 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-22 14:04:10,983 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:10 +0000 (0:00:00.999)       0:00:32.591 ********** 
2025-07-22 14:04:11,019 p=46443 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 14:04:11,020 p=46443 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 14:04:11,021 p=46443 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 14:04:11,022 p=46443 u=master n=ansible | skipping: [sm02]
2025-07-22 14:04:11,023 p=46443 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 14:04:11,023 p=46443 u=master n=ansible | skipping: [cn01]
2025-07-22 14:04:11,031 p=46443 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 14:04:11,034 p=46443 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 14:04:11,034 p=46443 u=master n=ansible | skipping: [cn02]
2025-07-22 14:04:11,263 p=46443 u=master n=ansible | ok: [sm01] => (item=/home)
2025-07-22 14:04:11,518 p=46443 u=master n=ansible | ok: [sm01] => (item=/sw)
2025-07-22 14:04:11,523 p=46443 u=master n=ansible | TASK [common : [COMMON] Очистка старых экспортов] **************************************************************************************************************************
2025-07-22 14:04:11,524 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:11 +0000 (0:00:00.540)       0:00:33.131 ********** 
2025-07-22 14:04:11,554 p=46443 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 14:04:11,555 p=46443 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 14:04:11,559 p=46443 u=master n=ansible | skipping: [sm02]
2025-07-22 14:04:11,561 p=46443 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 14:04:11,563 p=46443 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 14:04:11,564 p=46443 u=master n=ansible | skipping: [cn01]
2025-07-22 14:04:11,573 p=46443 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 14:04:11,575 p=46443 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 14:04:11,576 p=46443 u=master n=ansible | skipping: [cn02]
2025-07-22 14:04:11,791 p=46443 u=master n=ansible | changed: [sm01] => (item=/home)
2025-07-22 14:04:12,040 p=46443 u=master n=ansible | changed: [sm01] => (item=/sw)
2025-07-22 14:04:12,045 p=46443 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS с конкретными IP] ***********************************************************************************************************
2025-07-22 14:04:12,046 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:12 +0000 (0:00:00.521)       0:00:33.653 ********** 
2025-07-22 14:04:12,083 p=46443 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 14:04:12,084 p=46443 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 14:04:12,085 p=46443 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 14:04:12,086 p=46443 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 14:04:12,087 p=46443 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 14:04:12,088 p=46443 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 14:04:12,089 p=46443 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 14:04:12,090 p=46443 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 14:04:12,092 p=46443 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 14:04:12,094 p=46443 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 14:04:12,095 p=46443 u=master n=ansible | skipping: [sm02]
2025-07-22 14:04:12,096 p=46443 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 14:04:12,098 p=46443 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 14:04:12,099 p=46443 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 14:04:12,100 p=46443 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 14:04:12,101 p=46443 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 14:04:12,102 p=46443 u=master n=ansible | skipping: [cn01]
2025-07-22 14:04:12,104 p=46443 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 14:04:12,107 p=46443 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 14:04:12,110 p=46443 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 14:04:12,110 p=46443 u=master n=ansible | skipping: [cn02]
2025-07-22 14:04:12,316 p=46443 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.161'})
2025-07-22 14:04:12,561 p=46443 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.167'})
2025-07-22 14:04:12,806 p=46443 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.168'})
2025-07-22 14:04:13,051 p=46443 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'})
2025-07-22 14:04:13,299 p=46443 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'})
2025-07-22 14:04:13,546 p=46443 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'})
2025-07-22 14:04:13,553 p=46443 u=master n=ansible | TASK [common : [COMMON] Запуск и включение NFS server] *********************************************************************************************************************
2025-07-22 14:04:13,554 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:13 +0000 (0:00:01.508)       0:00:35.162 ********** 
2025-07-22 14:04:13,588 p=46443 u=master n=ansible | skipping: [sm02]
2025-07-22 14:04:13,590 p=46443 u=master n=ansible | skipping: [cn01]
2025-07-22 14:04:13,600 p=46443 u=master n=ansible | skipping: [cn02]
2025-07-22 14:04:14,045 p=46443 u=master n=ansible | ok: [sm01]
2025-07-22 14:04:14,049 p=46443 u=master n=ansible | TASK [common : [COMMON] Принудительная перезагрузка экспортов NFS] *********************************************************************************************************
2025-07-22 14:04:14,050 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:14 +0000 (0:00:00.495)       0:00:35.657 ********** 
2025-07-22 14:04:14,083 p=46443 u=master n=ansible | skipping: [sm02]
2025-07-22 14:04:14,086 p=46443 u=master n=ansible | skipping: [cn01]
2025-07-22 14:04:14,096 p=46443 u=master n=ansible | skipping: [cn02]
2025-07-22 14:04:14,320 p=46443 u=master n=ansible | changed: [sm01]
2025-07-22 14:04:14,324 p=46443 u=master n=ansible | TASK [common : [COMMON] Проверка активных экспортов] ***********************************************************************************************************************
2025-07-22 14:04:14,324 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:14 +0000 (0:00:00.274)       0:00:35.932 ********** 
2025-07-22 14:04:14,358 p=46443 u=master n=ansible | skipping: [sm02]
2025-07-22 14:04:14,360 p=46443 u=master n=ansible | skipping: [cn01]
2025-07-22 14:04:14,373 p=46443 u=master n=ansible | skipping: [cn02]
2025-07-22 14:04:14,597 p=46443 u=master n=ansible | changed: [sm01]
2025-07-22 14:04:14,601 p=46443 u=master n=ansible | TASK [common : [COMMON] Показать активные экспорты] ************************************************************************************************************************
2025-07-22 14:04:14,601 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:14 +0000 (0:00:00.276)       0:00:36.209 ********** 
2025-07-22 14:04:14,636 p=46443 u=master n=ansible | ok: [sm01] => 
  nfs_exports_check.stdout_lines:
  - "/home         \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/shared       \t10.20.90.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
2025-07-22 14:04:14,637 p=46443 u=master n=ansible | skipping: [sm02]
2025-07-22 14:04:14,637 p=46443 u=master n=ansible | skipping: [cn01]
2025-07-22 14:04:14,646 p=46443 u=master n=ansible | skipping: [cn02]
2025-07-22 14:04:14,651 p=46443 u=master n=ansible | TASK [common : [COMMON] Установка NFS client] ******************************************************************************************************************************
2025-07-22 14:04:14,651 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:14 +0000 (0:00:00.049)       0:00:36.259 ********** 
2025-07-22 14:04:14,677 p=46443 u=master n=ansible | skipping: [sm01]
2025-07-22 14:04:15,699 p=46443 u=master n=ansible | ok: [cn01]
2025-07-22 14:04:15,720 p=46443 u=master n=ansible | ok: [sm02]
2025-07-22 14:04:15,755 p=46443 u=master n=ansible | ok: [cn02]
2025-07-22 14:04:15,759 p=46443 u=master n=ansible | TASK [common : [COMMON] Создание точек монтирования NFS] *******************************************************************************************************************
2025-07-22 14:04:15,759 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:15 +0000 (0:00:01.108)       0:00:37.367 ********** 
2025-07-22 14:04:15,781 p=46443 u=master n=ansible | skipping: [sm01] => (item=/sw) 
2025-07-22 14:04:15,786 p=46443 u=master n=ansible | skipping: [sm01]
2025-07-22 14:04:16,052 p=46443 u=master n=ansible | ok: [sm02] => (item=/sw)
2025-07-22 14:04:16,068 p=46443 u=master n=ansible | ok: [cn01] => (item=/sw)
2025-07-22 14:04:16,075 p=46443 u=master n=ansible | ok: [cn02] => (item=/sw)
2025-07-22 14:04:16,081 p=46443 u=master n=ansible | TASK [common : [COMMON] Монтирование NFS shares] ***************************************************************************************************************************
2025-07-22 14:04:16,081 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:16 +0000 (0:00:00.321)       0:00:37.689 ********** 
2025-07-22 14:04:16,107 p=46443 u=master n=ansible | skipping: [sm01] => (item={'path': '/home', 'src': '/home'}) 
2025-07-22 14:04:16,113 p=46443 u=master n=ansible | skipping: [sm01] => (item={'path': '/sw', 'src': '/sw'}) 
2025-07-22 14:04:16,120 p=46443 u=master n=ansible | skipping: [sm01]
2025-07-22 14:04:16,592 p=46443 u=master n=ansible | changed: [sm02] => (item={'path': '/home', 'src': '/home'})
2025-07-22 14:04:16,594 p=46443 u=master n=ansible | changed: [cn02] => (item={'path': '/home', 'src': '/home'})
2025-07-22 14:04:16,595 p=46443 u=master n=ansible | changed: [cn01] => (item={'path': '/home', 'src': '/home'})
2025-07-22 14:04:16,862 p=46443 u=master n=ansible | changed: [sm02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 14:04:16,863 p=46443 u=master n=ansible | changed: [cn02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 14:04:16,866 p=46443 u=master n=ansible | changed: [cn01] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 14:04:16,872 p=46443 u=master n=ansible | TASK [common : [COMMON] Создание базовых директорий Slurm] *****************************************************************************************************************
2025-07-22 14:04:16,872 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:16 +0000 (0:00:00.791)       0:00:38.480 ********** 
2025-07-22 14:04:17,159 p=46443 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:17,167 p=46443 u=master n=ansible | changed: [sm02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:17,173 p=46443 u=master n=ansible | changed: [cn01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:17,180 p=46443 u=master n=ansible | changed: [cn02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:17,419 p=46443 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:17,429 p=46443 u=master n=ansible | changed: [sm02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:17,433 p=46443 u=master n=ansible | changed: [cn01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:17,434 p=46443 u=master n=ansible | changed: [cn02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:17,682 p=46443 u=master n=ansible | changed: [cn02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:17,683 p=46443 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:17,684 p=46443 u=master n=ansible | changed: [sm02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:17,689 p=46443 u=master n=ansible | changed: [cn01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:17,931 p=46443 u=master n=ansible | changed: [cn02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:17,939 p=46443 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:17,944 p=46443 u=master n=ansible | changed: [sm02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:17,947 p=46443 u=master n=ansible | changed: [cn01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:18,185 p=46443 u=master n=ansible | changed: [cn02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 14:04:18,201 p=46443 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 14:04:18,202 p=46443 u=master n=ansible | changed: [cn01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 14:04:18,203 p=46443 u=master n=ansible | changed: [sm02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 14:04:18,433 p=46443 u=master n=ansible | changed: [cn02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:18,459 p=46443 u=master n=ansible | changed: [cn01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:18,466 p=46443 u=master n=ansible | changed: [sm02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:18,467 p=46443 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:04:18,476 p=46443 u=master n=ansible | TASK [common : [COMMON] Роль common выполнена успешно] *********************************************************************************************************************
2025-07-22 14:04:18,476 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:18 +0000 (0:00:01.603)       0:00:40.084 ********** 
2025-07-22 14:04:18,501 p=46443 u=master n=ansible | ok: [sm01] => 
  msg: ✅ Узел sm01 готов для установки Slurm
2025-07-22 14:04:18,512 p=46443 u=master n=ansible | ok: [sm02] => 
  msg: ✅ Узел sm02 готов для установки Slurm
2025-07-22 14:04:18,516 p=46443 u=master n=ansible | ok: [cn01] => 
  msg: ✅ Узел cn01 готов для установки Slurm
2025-07-22 14:04:18,528 p=46443 u=master n=ansible | ok: [cn02] => 
  msg: ✅ Узел cn02 готов для установки Slurm
2025-07-22 14:04:18,576 p=46443 u=master n=ansible | RUNNING HANDLER [common : restart nfs-server] ******************************************************************************************************************************
2025-07-22 14:04:18,577 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:18 +0000 (0:00:00.100)       0:00:40.184 ********** 
2025-07-22 14:04:19,650 p=46443 u=master n=ansible | changed: [sm01]
2025-07-22 14:04:19,654 p=46443 u=master n=ansible | RUNNING HANDLER [common : reload nfs-exports] ******************************************************************************************************************************
2025-07-22 14:04:19,654 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:19 +0000 (0:00:01.077)       0:00:41.262 ********** 
2025-07-22 14:04:19,921 p=46443 u=master n=ansible | changed: [sm01]
2025-07-22 14:04:19,925 p=46443 u=master n=ansible | TASK [Проверка результатов] ************************************************************************************************************************************************
2025-07-22 14:04:19,925 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:19 +0000 (0:00:00.270)       0:00:41.533 ********** 
2025-07-22 14:04:19,959 p=46443 u=master n=ansible | ok: [sm01] => 
  msg: "✅ Роль common протестирована на sm01\n\U0001F527 Проверьте работу MUNGE: systemctl status munge\n\U0001F4C1 Проверьте NFS монтирование: df -h | grep nfs\n\U0001F464 Проверьте пользователя slurm: id slurm"
2025-07-22 14:04:19,960 p=46443 u=master n=ansible | ok: [sm02] => 
  msg: "✅ Роль common протестирована на sm02\n\U0001F527 Проверьте работу MUNGE: systemctl status munge\n\U0001F4C1 Проверьте NFS монтирование: df -h | grep nfs\n\U0001F464 Проверьте пользователя slurm: id slurm"
2025-07-22 14:04:19,965 p=46443 u=master n=ansible | ok: [cn01] => 
  msg: "✅ Роль common протестирована на cn01\n\U0001F527 Проверьте работу MUNGE: systemctl status munge\n\U0001F4C1 Проверьте NFS монтирование: df -h | grep nfs\n\U0001F464 Проверьте пользователя slurm: id slurm"
2025-07-22 14:04:19,975 p=46443 u=master n=ansible | ok: [cn02] => 
  msg: "✅ Роль common протестирована на cn02\n\U0001F527 Проверьте работу MUNGE: systemctl status munge\n\U0001F4C1 Проверьте NFS монтирование: df -h | grep nfs\n\U0001F464 Проверьте пользователя slurm: id slurm"
2025-07-22 14:04:19,992 p=46443 u=master n=ansible | PLAY RECAP *****************************************************************************************************************************************************************
2025-07-22 14:04:19,992 p=46443 u=master n=ansible | cn01                       : ok=24   changed=6    unreachable=0    failed=0    skipped=10   rescued=0    ignored=0   
2025-07-22 14:04:19,992 p=46443 u=master n=ansible | cn02                       : ok=24   changed=6    unreachable=0    failed=0    skipped=10   rescued=0    ignored=0   
2025-07-22 14:04:19,993 p=46443 u=master n=ansible | sm01                       : ok=32   changed=10   unreachable=0    failed=0    skipped=4    rescued=0    ignored=0   
2025-07-22 14:04:19,993 p=46443 u=master n=ansible | sm02                       : ok=24   changed=7    unreachable=0    failed=0    skipped=10   rescued=0    ignored=0   
2025-07-22 14:04:19,993 p=46443 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 41 seconds
2025-07-22 14:04:19,993 p=46443 u=master n=ansible | Tuesday 22 July 2025  14:04:19 +0000 (0:00:00.068)       0:00:41.601 ********** 
2025-07-22 14:04:19,993 p=46443 u=master n=ansible | =============================================================================== 
2025-07-22 14:04:19,993 p=46443 u=master n=ansible | common : [COMMON] Обновление apt cache ----------------------------------------------------------------------------------------------------------------------------- 15.50s
2025-07-22 14:04:19,993 p=46443 u=master n=ansible | common : [COMMON] Остановка MUNGE перед настройкой ------------------------------------------------------------------------------------------------------------------ 2.46s
2025-07-22 14:04:19,994 p=46443 u=master n=ansible | common : [COMMON] Запуск и включение MUNGE -------------------------------------------------------------------------------------------------------------------------- 1.96s
2025-07-22 14:04:19,994 p=46443 u=master n=ansible | common : [COMMON] Установка базовых пакетов ------------------------------------------------------------------------------------------------------------------------- 1.71s
2025-07-22 14:04:19,994 p=46443 u=master n=ansible | common : [COMMON] Создание базовых директорий Slurm ----------------------------------------------------------------------------------------------------------------- 1.60s
2025-07-22 14:04:19,994 p=46443 u=master n=ansible | common : [COMMON] Настройка экспорта NFS с конкретными IP ----------------------------------------------------------------------------------------------------------- 1.51s
2025-07-22 14:04:19,994 p=46443 u=master n=ansible | common : [COMMON] Установка MUNGE ----------------------------------------------------------------------------------------------------------------------------------- 1.30s
2025-07-22 14:04:19,994 p=46443 u=master n=ansible | common : [COMMON] Обеспечение hostname resolution для кластера ------------------------------------------------------------------------------------------------------ 1.26s
2025-07-22 14:04:19,994 p=46443 u=master n=ansible | common : [COMMON] Распространение MUNGE ключа на все узлы ----------------------------------------------------------------------------------------------------------- 1.25s
2025-07-22 14:04:19,994 p=46443 u=master n=ansible | common : [COMMON] Установка HWLOC ----------------------------------------------------------------------------------------------------------------------------------- 1.23s
2025-07-22 14:04:19,994 p=46443 u=master n=ansible | common : [COMMON] Настройка прав доступа MUNGE ---------------------------------------------------------------------------------------------------------------------- 1.14s
2025-07-22 14:04:19,994 p=46443 u=master n=ansible | common : [COMMON] Установка NFS client ------------------------------------------------------------------------------------------------------------------------------ 1.11s
2025-07-22 14:04:19,994 p=46443 u=master n=ansible | common : restart nfs-server ----------------------------------------------------------------------------------------------------------------------------------------- 1.08s
2025-07-22 14:04:19,995 p=46443 u=master n=ansible | common : [COMMON] Установка NFS server на master -------------------------------------------------------------------------------------------------------------------- 1.00s
2025-07-22 14:04:19,995 p=46443 u=master n=ansible | common : [COMMON] Монтирование NFS shares --------------------------------------------------------------------------------------------------------------------------- 0.79s
2025-07-22 14:04:19,995 p=46443 u=master n=ansible | common : [COMMON] Проверка HWLOC ------------------------------------------------------------------------------------------------------------------------------------ 0.70s
2025-07-22 14:04:19,995 p=46443 u=master n=ansible | common : [COMMON] Создание пользователя slurm ----------------------------------------------------------------------------------------------------------------------- 0.66s
2025-07-22 14:04:19,995 p=46443 u=master n=ansible | common : [COMMON] Настройка timezone -------------------------------------------------------------------------------------------------------------------------------- 0.64s
2025-07-22 14:04:19,995 p=46443 u=master n=ansible | common : [COMMON] Создание директорий для экспорта NFS -------------------------------------------------------------------------------------------------------------- 0.54s
2025-07-22 14:04:19,995 p=46443 u=master n=ansible | common : [COMMON] Очистка старых экспортов -------------------------------------------------------------------------------------------------------------------------- 0.52s
2025-07-22 14:54:09,584 p=47205 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 14:54:09,585 p=47205 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 14:54:10,063 p=47205 u=master n=ansible | PLAY [Тестирование роли slurm_build] ***************************************************************************************************************************************
2025-07-22 14:54:10,084 p=47205 u=master n=ansible | TASK [Gathering Facts] *****************************************************************************************************************************************************
2025-07-22 14:54:10,084 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:10 +0000 (0:00:00.025)       0:00:00.025 ********** 
2025-07-22 14:54:11,700 p=47205 u=master n=ansible | ok: [sm02]
2025-07-22 14:54:11,729 p=47205 u=master n=ansible | ok: [sm01]
2025-07-22 14:54:11,750 p=47205 u=master n=ansible | ok: [cn01]
2025-07-22 14:54:11,859 p=47205 u=master n=ansible | ok: [cn02]
2025-07-22 14:54:11,863 p=47205 u=master n=ansible | TASK [Информация о сборке Slurm] *******************************************************************************************************************************************
2025-07-22 14:54:11,864 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:11 +0000 (0:00:01.779)       0:00:01.804 ********** 
2025-07-22 14:54:11,915 p=47205 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F528 Начинаем сборку Slurm 25.05.1\n\U0001F4CD Сборка на: sm01\n\U0001F4E6 Установка на: sm01, sm02, cn01, cn02\n\U0001F510 JWT поддержка включена"
2025-07-22 14:54:11,919 p=47205 u=master n=ansible | TASK [Проверка доступного места на диске] **********************************************************************************************************************************
2025-07-22 14:54:11,919 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:11 +0000 (0:00:00.055)       0:00:01.859 ********** 
2025-07-22 14:54:11,950 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:54:11,953 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:54:11,962 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:54:12,332 p=47205 u=master n=ansible | changed: [sm01]
2025-07-22 14:54:12,335 p=47205 u=master n=ansible | TASK [Предупреждение о месте на диске] *************************************************************************************************************************************
2025-07-22 14:54:12,335 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:12 +0000 (0:00:00.416)       0:00:02.276 ********** 
2025-07-22 14:54:12,368 p=47205 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4BE Доступно места в /tmp: 40G\n⚠️  Для сборки Slurm требуется ~2GB свободного места"
2025-07-22 14:54:12,370 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:54:12,370 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:54:12,378 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:54:12,394 p=47205 u=master n=ansible | TASK [common : [COMMON] Начало выполнения роли common] *********************************************************************************************************************
2025-07-22 14:54:12,394 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:12 +0000 (0:00:00.058)       0:00:02.335 ********** 
2025-07-22 14:54:12,427 p=47205 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm01"
2025-07-22 14:54:12,429 p=47205 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm02"
2025-07-22 14:54:12,432 p=47205 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn01"
2025-07-22 14:54:12,442 p=47205 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn02"
2025-07-22 14:54:12,446 p=47205 u=master n=ansible | TASK [common : [COMMON] Обновление apt cache] ******************************************************************************************************************************
2025-07-22 14:54:12,446 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:12 +0000 (0:00:00.051)       0:00:02.387 ********** 
2025-07-22 14:54:13,337 p=47205 u=master n=ansible | ok: [sm02]
2025-07-22 14:54:18,751 p=47205 u=master n=ansible | changed: [sm01]
2025-07-22 14:54:24,826 p=47205 u=master n=ansible | changed: [cn02]
2025-07-22 14:54:39,560 p=47205 u=master n=ansible | changed: [cn01]
2025-07-22 14:54:39,564 p=47205 u=master n=ansible | TASK [common : [COMMON] Установка базовых пакетов] *************************************************************************************************************************
2025-07-22 14:54:39,564 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:39 +0000 (0:00:27.117)       0:00:29.504 ********** 
2025-07-22 14:54:40,608 p=47205 u=master n=ansible | ok: [cn02]
2025-07-22 14:54:40,639 p=47205 u=master n=ansible | ok: [sm02]
2025-07-22 14:54:40,688 p=47205 u=master n=ansible | ok: [cn01]
2025-07-22 14:54:40,701 p=47205 u=master n=ansible | ok: [sm01]
2025-07-22 14:54:40,705 p=47205 u=master n=ansible | TASK [common : [COMMON] Настройка timezone] ********************************************************************************************************************************
2025-07-22 14:54:40,705 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:40 +0000 (0:00:01.140)       0:00:30.645 ********** 
2025-07-22 14:54:41,204 p=47205 u=master n=ansible | ok: [cn02]
2025-07-22 14:54:41,213 p=47205 u=master n=ansible | ok: [sm02]
2025-07-22 14:54:41,215 p=47205 u=master n=ansible | ok: [cn01]
2025-07-22 14:54:41,216 p=47205 u=master n=ansible | ok: [sm01]
2025-07-22 14:54:41,219 p=47205 u=master n=ansible | TASK [common : [COMMON] Обеспечение hostname resolution для кластера] ******************************************************************************************************
2025-07-22 14:54:41,220 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:41 +0000 (0:00:00.514)       0:00:31.160 ********** 
2025-07-22 14:54:41,617 p=47205 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 14:54:41,620 p=47205 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 14:54:41,621 p=47205 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 14:54:41,622 p=47205 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 14:54:41,864 p=47205 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 14:54:41,865 p=47205 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 14:54:41,870 p=47205 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 14:54:41,878 p=47205 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 14:54:42,113 p=47205 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 14:54:42,115 p=47205 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 14:54:42,128 p=47205 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 14:54:42,129 p=47205 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 14:54:42,356 p=47205 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 14:54:42,363 p=47205 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 14:54:42,375 p=47205 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 14:54:42,379 p=47205 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 14:54:42,385 p=47205 u=master n=ansible | TASK [common : [COMMON] Создание пользователя slurm] ***********************************************************************************************************************
2025-07-22 14:54:42,385 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:42 +0000 (0:00:01.165)       0:00:32.325 ********** 
2025-07-22 14:54:42,885 p=47205 u=master n=ansible | ok: [cn02]
2025-07-22 14:54:42,887 p=47205 u=master n=ansible | ok: [sm02]
2025-07-22 14:54:42,899 p=47205 u=master n=ansible | ok: [sm01]
2025-07-22 14:54:43,014 p=47205 u=master n=ansible | ok: [cn01]
2025-07-22 14:54:43,017 p=47205 u=master n=ansible | TASK [common : [COMMON] Установка MUNGE] ***********************************************************************************************************************************
2025-07-22 14:54:43,017 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:43 +0000 (0:00:00.632)       0:00:32.958 ********** 
2025-07-22 14:54:44,073 p=47205 u=master n=ansible | ok: [sm02]
2025-07-22 14:54:44,076 p=47205 u=master n=ansible | ok: [cn02]
2025-07-22 14:54:44,091 p=47205 u=master n=ansible | ok: [sm01]
2025-07-22 14:54:44,148 p=47205 u=master n=ansible | ok: [cn01]
2025-07-22 14:54:44,153 p=47205 u=master n=ansible | TASK [common : [COMMON] Остановка MUNGE перед настройкой] ******************************************************************************************************************
2025-07-22 14:54:44,153 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:44 +0000 (0:00:01.135)       0:00:34.093 ********** 
2025-07-22 14:54:45,981 p=47205 u=master n=ansible | changed: [sm02]
2025-07-22 14:54:46,015 p=47205 u=master n=ansible | changed: [cn02]
2025-07-22 14:54:46,026 p=47205 u=master n=ansible | changed: [cn01]
2025-07-22 14:54:46,076 p=47205 u=master n=ansible | changed: [sm01]
2025-07-22 14:54:46,081 p=47205 u=master n=ansible | TASK [common : [COMMON] Создание MUNGE ключа на master узле] ***************************************************************************************************************
2025-07-22 14:54:46,081 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:46 +0000 (0:00:01.927)       0:00:36.021 ********** 
2025-07-22 14:54:46,112 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:54:46,114 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:54:46,124 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:54:46,342 p=47205 u=master n=ansible | ok: [sm01]
2025-07-22 14:54:46,346 p=47205 u=master n=ansible | TASK [common : [COMMON] Получение MUNGE ключа с master узла] ***************************************************************************************************************
2025-07-22 14:54:46,346 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:46 +0000 (0:00:00.265)       0:00:36.287 ********** 
2025-07-22 14:54:46,380 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:54:46,383 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:54:46,392 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:54:46,730 p=47205 u=master n=ansible | ok: [sm01]
2025-07-22 14:54:46,735 p=47205 u=master n=ansible | TASK [common : [COMMON] Распространение MUNGE ключа на все узлы] ***********************************************************************************************************
2025-07-22 14:54:46,735 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:46 +0000 (0:00:00.388)       0:00:36.675 ********** 
2025-07-22 14:54:46,758 p=47205 u=master n=ansible | skipping: [sm01]
2025-07-22 14:54:48,925 p=47205 u=master n=ansible | ok: [sm02]
2025-07-22 14:54:48,926 p=47205 u=master n=ansible | ok: [cn02]
2025-07-22 14:54:48,927 p=47205 u=master n=ansible | ok: [cn01]
2025-07-22 14:54:48,931 p=47205 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа MUNGE] **********************************************************************************************************************
2025-07-22 14:54:48,931 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:48 +0000 (0:00:02.196)       0:00:38.872 ********** 
2025-07-22 14:54:49,230 p=47205 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:54:49,231 p=47205 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:54:49,249 p=47205 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:54:49,256 p=47205 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:54:49,478 p=47205 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:54:49,509 p=47205 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:54:49,511 p=47205 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:54:49,527 p=47205 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:54:49,731 p=47205 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:54:49,761 p=47205 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:54:49,787 p=47205 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:54:49,789 p=47205 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 14:54:50,051 p=47205 u=master n=ansible | changed: [cn01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 14:54:50,055 p=47205 u=master n=ansible | changed: [sm01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 14:54:50,072 p=47205 u=master n=ansible | changed: [sm02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 14:54:50,087 p=47205 u=master n=ansible | changed: [cn02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 14:54:50,093 p=47205 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа на ключ MUNGE] **************************************************************************************************************
2025-07-22 14:54:50,093 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:50 +0000 (0:00:01.161)       0:00:40.034 ********** 
2025-07-22 14:54:50,368 p=47205 u=master n=ansible | ok: [sm01]
2025-07-22 14:54:50,369 p=47205 u=master n=ansible | ok: [sm02]
2025-07-22 14:54:50,391 p=47205 u=master n=ansible | ok: [cn02]
2025-07-22 14:54:50,417 p=47205 u=master n=ansible | ok: [cn01]
2025-07-22 14:54:50,421 p=47205 u=master n=ansible | TASK [common : [COMMON] Запуск и включение MUNGE] **************************************************************************************************************************
2025-07-22 14:54:50,421 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:50 +0000 (0:00:00.328)       0:00:40.362 ********** 
2025-07-22 14:54:52,265 p=47205 u=master n=ansible | changed: [sm02]
2025-07-22 14:54:52,339 p=47205 u=master n=ansible | changed: [cn02]
2025-07-22 14:54:52,353 p=47205 u=master n=ansible | changed: [sm01]
2025-07-22 14:54:52,399 p=47205 u=master n=ansible | changed: [cn01]
2025-07-22 14:54:52,403 p=47205 u=master n=ansible | TASK [common : [COMMON] Проверка работы MUNGE] *****************************************************************************************************************************
2025-07-22 14:54:52,403 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:52 +0000 (0:00:01.981)       0:00:42.344 ********** 
2025-07-22 14:54:52,673 p=47205 u=master n=ansible | ok: [sm01]
2025-07-22 14:54:52,674 p=47205 u=master n=ansible | ok: [sm02]
2025-07-22 14:54:52,697 p=47205 u=master n=ansible | ok: [cn01]
2025-07-22 14:54:52,702 p=47205 u=master n=ansible | ok: [cn02]
2025-07-22 14:54:52,706 p=47205 u=master n=ansible | TASK [common : [COMMON] Результат проверки MUNGE] **************************************************************************************************************************
2025-07-22 14:54:52,706 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:52 +0000 (0:00:00.302)       0:00:42.646 ********** 
2025-07-22 14:54:52,740 p=47205 u=master n=ansible | ok: [sm01] => 
  msg: MUNGE работает корректно на sm01
2025-07-22 14:54:52,741 p=47205 u=master n=ansible | ok: [sm02] => 
  msg: MUNGE работает корректно на sm02
2025-07-22 14:54:52,746 p=47205 u=master n=ansible | ok: [cn01] => 
  msg: MUNGE работает корректно на cn01
2025-07-22 14:54:52,758 p=47205 u=master n=ansible | ok: [cn02] => 
  msg: MUNGE работает корректно на cn02
2025-07-22 14:54:52,761 p=47205 u=master n=ansible | TASK [common : [COMMON] Установка HWLOC] ***********************************************************************************************************************************
2025-07-22 14:54:52,761 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:52 +0000 (0:00:00.055)       0:00:42.702 ********** 
2025-07-22 14:54:53,694 p=47205 u=master n=ansible | ok: [sm02]
2025-07-22 14:54:53,802 p=47205 u=master n=ansible | ok: [sm01]
2025-07-22 14:54:53,911 p=47205 u=master n=ansible | ok: [cn02]
2025-07-22 14:54:53,930 p=47205 u=master n=ansible | ok: [cn01]
2025-07-22 14:54:53,934 p=47205 u=master n=ansible | TASK [common : [COMMON] Проверка HWLOC] ************************************************************************************************************************************
2025-07-22 14:54:53,935 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:53 +0000 (0:00:01.173)       0:00:43.875 ********** 
2025-07-22 14:54:54,209 p=47205 u=master n=ansible | ok: [sm02]
2025-07-22 14:54:54,219 p=47205 u=master n=ansible | ok: [sm01]
2025-07-22 14:54:54,232 p=47205 u=master n=ansible | ok: [cn01]
2025-07-22 14:54:54,240 p=47205 u=master n=ansible | ok: [cn02]
2025-07-22 14:54:54,244 p=47205 u=master n=ansible | TASK [common : [COMMON] Версия HWLOC] **************************************************************************************************************************************
2025-07-22 14:54:54,244 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:54 +0000 (0:00:00.309)       0:00:44.184 ********** 
2025-07-22 14:54:54,279 p=47205 u=master n=ansible | ok: [sm01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 14:54:54,280 p=47205 u=master n=ansible | ok: [sm02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 14:54:54,284 p=47205 u=master n=ansible | ok: [cn01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 14:54:54,294 p=47205 u=master n=ansible | ok: [cn02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 14:54:54,298 p=47205 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-22 14:54:54,298 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:54 +0000 (0:00:00.053)       0:00:44.238 ********** 
2025-07-22 14:54:54,331 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:54:54,333 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:54:54,344 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:54:55,309 p=47205 u=master n=ansible | ok: [sm01]
2025-07-22 14:54:55,312 p=47205 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-22 14:54:55,313 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:55 +0000 (0:00:01.014)       0:00:45.253 ********** 
2025-07-22 14:54:55,342 p=47205 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 14:54:55,343 p=47205 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 14:54:55,349 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:54:55,351 p=47205 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 14:54:55,353 p=47205 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 14:54:55,353 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:54:55,362 p=47205 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 14:54:55,364 p=47205 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 14:54:55,365 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:54:55,599 p=47205 u=master n=ansible | ok: [sm01] => (item=/home)
2025-07-22 14:54:55,866 p=47205 u=master n=ansible | ok: [sm01] => (item=/sw)
2025-07-22 14:54:55,872 p=47205 u=master n=ansible | TASK [common : [COMMON] Очистка старых экспортов] **************************************************************************************************************************
2025-07-22 14:54:55,872 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:55 +0000 (0:00:00.559)       0:00:45.812 ********** 
2025-07-22 14:54:55,904 p=47205 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 14:54:55,905 p=47205 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 14:54:55,910 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:54:55,912 p=47205 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 14:54:55,913 p=47205 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 14:54:55,914 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:54:55,931 p=47205 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 14:54:55,934 p=47205 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 14:54:55,935 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:54:56,153 p=47205 u=master n=ansible | changed: [sm01] => (item=/home)
2025-07-22 14:54:56,417 p=47205 u=master n=ansible | changed: [sm01] => (item=/sw)
2025-07-22 14:54:56,422 p=47205 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS с конкретными IP] ***********************************************************************************************************
2025-07-22 14:54:56,423 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:56 +0000 (0:00:00.550)       0:00:46.363 ********** 
2025-07-22 14:54:56,459 p=47205 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 14:54:56,461 p=47205 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 14:54:56,462 p=47205 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 14:54:56,464 p=47205 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 14:54:56,466 p=47205 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 14:54:56,468 p=47205 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 14:54:56,470 p=47205 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 14:54:56,471 p=47205 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 14:54:56,473 p=47205 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 14:54:56,474 p=47205 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 14:54:56,475 p=47205 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 14:54:56,477 p=47205 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 14:54:56,478 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:54:56,478 p=47205 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 14:54:56,479 p=47205 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 14:54:56,480 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:54:56,481 p=47205 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 14:54:56,482 p=47205 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 14:54:56,485 p=47205 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 14:54:56,488 p=47205 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 14:54:56,489 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:54:56,697 p=47205 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.161'})
2025-07-22 14:54:56,952 p=47205 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.167'})
2025-07-22 14:54:57,200 p=47205 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.168'})
2025-07-22 14:54:57,445 p=47205 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'})
2025-07-22 14:54:57,696 p=47205 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'})
2025-07-22 14:54:57,945 p=47205 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'})
2025-07-22 14:54:57,953 p=47205 u=master n=ansible | TASK [common : [COMMON] Запуск и включение NFS server] *********************************************************************************************************************
2025-07-22 14:54:57,954 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:57 +0000 (0:00:01.530)       0:00:47.894 ********** 
2025-07-22 14:54:57,991 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:54:58,088 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:54:58,089 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:54:58,454 p=47205 u=master n=ansible | ok: [sm01]
2025-07-22 14:54:58,458 p=47205 u=master n=ansible | TASK [common : [COMMON] Принудительная перезагрузка экспортов NFS] *********************************************************************************************************
2025-07-22 14:54:58,458 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:58 +0000 (0:00:00.504)       0:00:48.398 ********** 
2025-07-22 14:54:58,490 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:54:58,493 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:54:58,502 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:54:58,728 p=47205 u=master n=ansible | changed: [sm01]
2025-07-22 14:54:58,732 p=47205 u=master n=ansible | TASK [common : [COMMON] Проверка активных экспортов] ***********************************************************************************************************************
2025-07-22 14:54:58,733 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:58 +0000 (0:00:00.274)       0:00:48.673 ********** 
2025-07-22 14:54:58,772 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:54:58,773 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:54:58,781 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:54:59,043 p=47205 u=master n=ansible | changed: [sm01]
2025-07-22 14:54:59,047 p=47205 u=master n=ansible | TASK [common : [COMMON] Показать активные экспорты] ************************************************************************************************************************
2025-07-22 14:54:59,047 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:59 +0000 (0:00:00.314)       0:00:48.988 ********** 
2025-07-22 14:54:59,081 p=47205 u=master n=ansible | ok: [sm01] => 
  nfs_exports_check.stdout_lines:
  - "/home         \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/shared       \t10.20.90.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
2025-07-22 14:54:59,082 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:54:59,082 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:54:59,090 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:54:59,093 p=47205 u=master n=ansible | TASK [common : [COMMON] Установка NFS client] ******************************************************************************************************************************
2025-07-22 14:54:59,094 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:54:59 +0000 (0:00:00.046)       0:00:49.034 ********** 
2025-07-22 14:54:59,117 p=47205 u=master n=ansible | skipping: [sm01]
2025-07-22 14:55:00,077 p=47205 u=master n=ansible | ok: [sm02]
2025-07-22 14:55:00,099 p=47205 u=master n=ansible | ok: [cn01]
2025-07-22 14:55:00,145 p=47205 u=master n=ansible | ok: [cn02]
2025-07-22 14:55:00,149 p=47205 u=master n=ansible | TASK [common : [COMMON] Создание точек монтирования NFS] *******************************************************************************************************************
2025-07-22 14:55:00,150 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:00 +0000 (0:00:01.055)       0:00:50.090 ********** 
2025-07-22 14:55:00,171 p=47205 u=master n=ansible | skipping: [sm01] => (item=/sw) 
2025-07-22 14:55:00,175 p=47205 u=master n=ansible | skipping: [sm01]
2025-07-22 14:55:00,432 p=47205 u=master n=ansible | ok: [sm02] => (item=/sw)
2025-07-22 14:55:00,447 p=47205 u=master n=ansible | ok: [cn01] => (item=/sw)
2025-07-22 14:55:00,453 p=47205 u=master n=ansible | ok: [cn02] => (item=/sw)
2025-07-22 14:55:00,458 p=47205 u=master n=ansible | TASK [common : [COMMON] Монтирование NFS shares] ***************************************************************************************************************************
2025-07-22 14:55:00,458 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:00 +0000 (0:00:00.308)       0:00:50.398 ********** 
2025-07-22 14:55:00,489 p=47205 u=master n=ansible | skipping: [sm01] => (item={'path': '/home', 'src': '/home'}) 
2025-07-22 14:55:00,491 p=47205 u=master n=ansible | skipping: [sm01] => (item={'path': '/sw', 'src': '/sw'}) 
2025-07-22 14:55:00,499 p=47205 u=master n=ansible | skipping: [sm01]
2025-07-22 14:55:00,877 p=47205 u=master n=ansible | ok: [sm02] => (item={'path': '/home', 'src': '/home'})
2025-07-22 14:55:00,882 p=47205 u=master n=ansible | ok: [cn02] => (item={'path': '/home', 'src': '/home'})
2025-07-22 14:55:00,887 p=47205 u=master n=ansible | ok: [cn01] => (item={'path': '/home', 'src': '/home'})
2025-07-22 14:55:01,127 p=47205 u=master n=ansible | ok: [sm02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 14:55:01,135 p=47205 u=master n=ansible | ok: [cn02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 14:55:01,142 p=47205 u=master n=ansible | ok: [cn01] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 14:55:01,147 p=47205 u=master n=ansible | TASK [common : [COMMON] Создание базовых директорий Slurm] *****************************************************************************************************************
2025-07-22 14:55:01,147 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:01 +0000 (0:00:00.689)       0:00:51.087 ********** 
2025-07-22 14:55:01,432 p=47205 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:01,434 p=47205 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:01,448 p=47205 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:01,455 p=47205 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:01,684 p=47205 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:01,694 p=47205 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:01,706 p=47205 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:01,716 p=47205 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:01,937 p=47205 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:01,960 p=47205 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:01,967 p=47205 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:01,988 p=47205 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:02,189 p=47205 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:02,224 p=47205 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:02,226 p=47205 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:02,254 p=47205 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:02,477 p=47205 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 14:55:02,486 p=47205 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 14:55:02,494 p=47205 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 14:55:02,538 p=47205 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 14:55:02,729 p=47205 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:02,746 p=47205 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:02,762 p=47205 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:02,801 p=47205 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 14:55:02,807 p=47205 u=master n=ansible | TASK [common : [COMMON] Роль common выполнена успешно] *********************************************************************************************************************
2025-07-22 14:55:02,807 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:02 +0000 (0:00:01.660)       0:00:52.747 ********** 
2025-07-22 14:55:02,841 p=47205 u=master n=ansible | ok: [sm01] => 
  msg: ✅ Узел sm01 готов для установки Slurm
2025-07-22 14:55:02,842 p=47205 u=master n=ansible | ok: [sm02] => 
  msg: ✅ Узел sm02 готов для установки Slurm
2025-07-22 14:55:02,847 p=47205 u=master n=ansible | ok: [cn01] => 
  msg: ✅ Узел cn01 готов для установки Slurm
2025-07-22 14:55:02,858 p=47205 u=master n=ansible | ok: [cn02] => 
  msg: ✅ Узел cn02 готов для установки Slurm
2025-07-22 14:55:02,870 p=47205 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Начало сборки Slurm] *********************************************************************************************************************
2025-07-22 14:55:02,870 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:02 +0000 (0:00:00.062)       0:00:52.810 ********** 
2025-07-22 14:55:02,904 p=47205 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm01"
2025-07-22 14:55:02,905 p=47205 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm02"
2025-07-22 14:55:02,909 p=47205 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn01"
2025-07-22 14:55:02,919 p=47205 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn02"
2025-07-22 14:55:02,923 p=47205 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка дополнительных зависимостей для сборки] ****************************************************************************************
2025-07-22 14:55:02,923 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:02 +0000 (0:00:00.052)       0:00:52.863 ********** 
2025-07-22 14:55:02,958 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:55:02,960 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:55:02,969 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:55:03,657 p=47205 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  msg: No package matching 'libmariadbclient-dev' is available
2025-07-22 14:55:03,661 p=47205 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для сборки] ************************************************************************************************
2025-07-22 14:55:03,661 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:03 +0000 (0:00:00.737)       0:00:53.601 ********** 
2025-07-22 14:55:03,684 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:55:03,686 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:55:03,696 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:55:03,699 p=47205 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка существования исходников] *******************************************************************************************************
2025-07-22 14:55:03,700 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:03 +0000 (0:00:00.038)       0:00:53.640 ********** 
2025-07-22 14:55:03,724 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:55:03,726 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:55:03,735 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:55:03,756 p=47205 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Скачивание исходников Slurm 25.05.1] *****************************************************************************************************
2025-07-22 14:55:03,757 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:03 +0000 (0:00:00.056)       0:00:53.697 ********** 
2025-07-22 14:55:03,781 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:55:03,783 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:55:03,791 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:55:03,795 p=47205 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Извлечение исходников Slurm] *************************************************************************************************************
2025-07-22 14:55:03,795 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:03 +0000 (0:00:00.038)       0:00:53.736 ********** 
2025-07-22 14:55:03,818 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:55:03,821 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:55:03,828 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:55:03,832 p=47205 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Конфигурация сборки Slurm с JWT поддержкой] **********************************************************************************************
2025-07-22 14:55:03,832 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:03 +0000 (0:00:00.036)       0:00:53.772 ********** 
2025-07-22 14:55:03,855 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:55:03,858 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:55:03,866 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:55:03,869 p=47205 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат конфигурации] ******************************************************************************************************************
2025-07-22 14:55:03,869 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:03 +0000 (0:00:00.037)       0:00:53.810 ********** 
2025-07-22 14:55:03,893 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:55:03,895 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:55:03,903 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:55:03,907 p=47205 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Компиляция Slurm (это займет время...)] **************************************************************************************************
2025-07-22 14:55:03,907 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:03 +0000 (0:00:00.037)       0:00:53.847 ********** 
2025-07-22 14:55:03,932 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:55:03,933 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:55:03,941 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:55:03,945 p=47205 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка Slurm на master] ***************************************************************************************************************
2025-07-22 14:55:03,945 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:03 +0000 (0:00:00.038)       0:00:53.885 ********** 
2025-07-22 14:55:03,969 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:55:03,969 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:55:03,977 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:55:03,981 p=47205 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание архива Slurm для копирования] ***************************************************************************************************
2025-07-22 14:55:03,981 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:03 +0000 (0:00:00.036)       0:00:53.921 ********** 
2025-07-22 14:55:04,006 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:55:04,008 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:55:04,016 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:55:04,020 p=47205 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] *************************************************************************************************
2025-07-22 14:55:04,020 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:04 +0000 (0:00:00.038)       0:00:53.960 ********** 
2025-07-22 14:55:04,288 p=47205 u=master n=ansible | ok: [sm02]
2025-07-22 14:55:04,321 p=47205 u=master n=ansible | ok: [cn02]
2025-07-22 14:55:04,321 p=47205 u=master n=ansible | ok: [cn01]
2025-07-22 14:55:04,325 p=47205 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Получение архива с master узла] **********************************************************************************************************
2025-07-22 14:55:04,325 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:04 +0000 (0:00:00.305)       0:00:54.266 ********** 
2025-07-22 14:55:04,350 p=47205 u=master n=ansible | skipping: [sm02]
2025-07-22 14:55:04,351 p=47205 u=master n=ansible | skipping: [cn01]
2025-07-22 14:55:04,359 p=47205 u=master n=ansible | skipping: [cn02]
2025-07-22 14:55:04,362 p=47205 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование архива на остальные узлы] ****************************************************************************************************
2025-07-22 14:55:04,362 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:04 +0000 (0:00:00.036)       0:00:54.302 ********** 
2025-07-22 14:55:04,602 p=47205 u=master n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: If you are using a module and expect the file to exist on the remote, see the remote_src option
2025-07-22 14:55:04,603 p=47205 u=master n=ansible | fatal: [sm02]: FAILED! => changed=false 
  msg: |-
    Could not find or access '/tmp/slurm-install-sm01.tar.gz' on the Ansible Controller.
    If you are using a module and expect the file to exist on the remote, see the remote_src option
2025-07-22 14:55:04,610 p=47205 u=master n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: If you are using a module and expect the file to exist on the remote, see the remote_src option
2025-07-22 14:55:04,611 p=47205 u=master n=ansible | fatal: [cn01]: FAILED! => changed=false 
  msg: |-
    Could not find or access '/tmp/slurm-install-sm01.tar.gz' on the Ansible Controller.
    If you are using a module and expect the file to exist on the remote, see the remote_src option
2025-07-22 14:55:04,611 p=47205 u=master n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: If you are using a module and expect the file to exist on the remote, see the remote_src option
2025-07-22 14:55:04,611 p=47205 u=master n=ansible | fatal: [cn02]: FAILED! => changed=false 
  msg: |-
    Could not find or access '/tmp/slurm-install-sm01.tar.gz' on the Ansible Controller.
    If you are using a module and expect the file to exist on the remote, see the remote_src option
2025-07-22 14:55:04,613 p=47205 u=master n=ansible | PLAY RECAP *****************************************************************************************************************************************************************
2025-07-22 14:55:04,613 p=47205 u=master n=ansible | cn01                       : ok=25   changed=4    unreachable=0    failed=1    skipped=23   rescued=0    ignored=0   
2025-07-22 14:55:04,613 p=47205 u=master n=ansible | cn02                       : ok=25   changed=4    unreachable=0    failed=1    skipped=23   rescued=0    ignored=0   
2025-07-22 14:55:04,613 p=47205 u=master n=ansible | sm01                       : ok=33   changed=9    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-07-22 14:55:04,614 p=47205 u=master n=ansible | sm02                       : ok=25   changed=3    unreachable=0    failed=1    skipped=23   rescued=0    ignored=0   
2025-07-22 14:55:04,614 p=47205 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 54 seconds
2025-07-22 14:55:04,614 p=47205 u=master n=ansible | Tuesday 22 July 2025  14:55:04 +0000 (0:00:00.251)       0:00:54.554 ********** 
2025-07-22 14:55:04,614 p=47205 u=master n=ansible | =============================================================================== 
2025-07-22 14:55:04,614 p=47205 u=master n=ansible | common : [COMMON] Обновление apt cache ----------------------------------------------------------------------------------------------------------------------------- 27.12s
2025-07-22 14:55:04,614 p=47205 u=master n=ansible | common : [COMMON] Распространение MUNGE ключа на все узлы ----------------------------------------------------------------------------------------------------------- 2.20s
2025-07-22 14:55:04,614 p=47205 u=master n=ansible | common : [COMMON] Запуск и включение MUNGE -------------------------------------------------------------------------------------------------------------------------- 1.98s
2025-07-22 14:55:04,615 p=47205 u=master n=ansible | common : [COMMON] Остановка MUNGE перед настройкой ------------------------------------------------------------------------------------------------------------------ 1.93s
2025-07-22 14:55:04,615 p=47205 u=master n=ansible | Gathering Facts ----------------------------------------------------------------------------------------------------------------------------------------------------- 1.78s
2025-07-22 14:55:04,615 p=47205 u=master n=ansible | common : [COMMON] Создание базовых директорий Slurm ----------------------------------------------------------------------------------------------------------------- 1.66s
2025-07-22 14:55:04,615 p=47205 u=master n=ansible | common : [COMMON] Настройка экспорта NFS с конкретными IP ----------------------------------------------------------------------------------------------------------- 1.53s
2025-07-22 14:55:04,615 p=47205 u=master n=ansible | common : [COMMON] Установка HWLOC ----------------------------------------------------------------------------------------------------------------------------------- 1.17s
2025-07-22 14:55:04,615 p=47205 u=master n=ansible | common : [COMMON] Обеспечение hostname resolution для кластера ------------------------------------------------------------------------------------------------------ 1.17s
2025-07-22 14:55:04,615 p=47205 u=master n=ansible | common : [COMMON] Настройка прав доступа MUNGE ---------------------------------------------------------------------------------------------------------------------- 1.16s
2025-07-22 14:55:04,615 p=47205 u=master n=ansible | common : [COMMON] Установка базовых пакетов ------------------------------------------------------------------------------------------------------------------------- 1.14s
2025-07-22 14:55:04,615 p=47205 u=master n=ansible | common : [COMMON] Установка MUNGE ----------------------------------------------------------------------------------------------------------------------------------- 1.14s
2025-07-22 14:55:04,615 p=47205 u=master n=ansible | common : [COMMON] Установка NFS client ------------------------------------------------------------------------------------------------------------------------------ 1.06s
2025-07-22 14:55:04,615 p=47205 u=master n=ansible | common : [COMMON] Установка NFS server на master -------------------------------------------------------------------------------------------------------------------- 1.01s
2025-07-22 14:55:04,616 p=47205 u=master n=ansible | slurm_build : [SLURM_BUILD] Установка дополнительных зависимостей для сборки ---------------------------------------------------------------------------------------- 0.74s
2025-07-22 14:55:04,616 p=47205 u=master n=ansible | common : [COMMON] Монтирование NFS shares --------------------------------------------------------------------------------------------------------------------------- 0.69s
2025-07-22 14:55:04,616 p=47205 u=master n=ansible | common : [COMMON] Создание пользователя slurm ----------------------------------------------------------------------------------------------------------------------- 0.63s
2025-07-22 14:55:04,616 p=47205 u=master n=ansible | common : [COMMON] Создание директорий для экспорта NFS -------------------------------------------------------------------------------------------------------------- 0.56s
2025-07-22 14:55:04,616 p=47205 u=master n=ansible | common : [COMMON] Очистка старых экспортов -------------------------------------------------------------------------------------------------------------------------- 0.55s
2025-07-22 14:55:04,616 p=47205 u=master n=ansible | common : [COMMON] Настройка timezone -------------------------------------------------------------------------------------------------------------------------------- 0.51s
2025-07-22 15:00:25,046 p=47885 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 15:00:25,046 p=47885 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 15:00:25,527 p=47885 u=master n=ansible | PLAY [Тестирование роли slurm_build] ***************************************************************************************************************************************
2025-07-22 15:00:25,549 p=47885 u=master n=ansible | TASK [Информация о сборке Slurm] *******************************************************************************************************************************************
2025-07-22 15:00:25,549 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:25 +0000 (0:00:00.025)       0:00:00.025 ********** 
2025-07-22 15:00:25,604 p=47885 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F528 Начинаем сборку Slurm 25.05.1\n\U0001F4CD Сборка на: sm01\n\U0001F4E6 Установка на: sm01, sm02, cn01, cn02\n\U0001F510 JWT поддержка включена"
2025-07-22 15:00:25,609 p=47885 u=master n=ansible | TASK [Проверка доступного места на диске] **********************************************************************************************************************************
2025-07-22 15:00:25,609 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:25 +0000 (0:00:00.059)       0:00:00.085 ********** 
2025-07-22 15:00:25,654 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:25,657 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:25,666 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:26,732 p=47885 u=master n=ansible | changed: [sm01]
2025-07-22 15:00:26,736 p=47885 u=master n=ansible | TASK [Предупреждение о месте на диске] *************************************************************************************************************************************
2025-07-22 15:00:26,736 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:26 +0000 (0:00:01.127)       0:00:01.212 ********** 
2025-07-22 15:00:26,773 p=47885 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4BE Доступно места в /tmp: 40G\n⚠️  Для сборки Slurm требуется ~2GB свободного места"
2025-07-22 15:00:26,775 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:26,776 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:26,783 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:26,802 p=47885 u=master n=ansible | TASK [common : [COMMON] Начало выполнения роли common] *********************************************************************************************************************
2025-07-22 15:00:26,802 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:26 +0000 (0:00:00.065)       0:00:01.278 ********** 
2025-07-22 15:00:26,827 p=47885 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm01"
2025-07-22 15:00:26,840 p=47885 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm02"
2025-07-22 15:00:26,842 p=47885 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn01"
2025-07-22 15:00:26,855 p=47885 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn02"
2025-07-22 15:00:26,859 p=47885 u=master n=ansible | TASK [common : [COMMON] Обновление apt cache] ******************************************************************************************************************************
2025-07-22 15:00:26,859 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:26 +0000 (0:00:00.056)       0:00:01.335 ********** 
2025-07-22 15:00:27,776 p=47885 u=master n=ansible | ok: [sm01]
2025-07-22 15:00:28,498 p=47885 u=master n=ansible | ok: [sm02]
2025-07-22 15:00:28,570 p=47885 u=master n=ansible | ok: [cn02]
2025-07-22 15:00:28,645 p=47885 u=master n=ansible | ok: [cn01]
2025-07-22 15:00:28,649 p=47885 u=master n=ansible | TASK [common : [COMMON] Установка базовых пакетов] *************************************************************************************************************************
2025-07-22 15:00:28,649 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:28 +0000 (0:00:01.790)       0:00:03.125 ********** 
2025-07-22 15:00:29,675 p=47885 u=master n=ansible | ok: [sm02]
2025-07-22 15:00:29,690 p=47885 u=master n=ansible | ok: [sm01]
2025-07-22 15:00:29,705 p=47885 u=master n=ansible | ok: [cn02]
2025-07-22 15:00:29,799 p=47885 u=master n=ansible | ok: [cn01]
2025-07-22 15:00:29,803 p=47885 u=master n=ansible | TASK [common : [COMMON] Настройка timezone] ********************************************************************************************************************************
2025-07-22 15:00:29,803 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:29 +0000 (0:00:01.154)       0:00:04.279 ********** 
2025-07-22 15:00:30,304 p=47885 u=master n=ansible | ok: [sm01]
2025-07-22 15:00:30,308 p=47885 u=master n=ansible | ok: [sm02]
2025-07-22 15:00:30,310 p=47885 u=master n=ansible | ok: [cn01]
2025-07-22 15:00:30,311 p=47885 u=master n=ansible | ok: [cn02]
2025-07-22 15:00:30,315 p=47885 u=master n=ansible | TASK [common : [COMMON] Обеспечение hostname resolution для кластера] ******************************************************************************************************
2025-07-22 15:00:30,315 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:30 +0000 (0:00:00.511)       0:00:04.791 ********** 
2025-07-22 15:00:30,708 p=47885 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:00:30,710 p=47885 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:00:30,711 p=47885 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:00:30,718 p=47885 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:00:30,953 p=47885 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:00:30,958 p=47885 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:00:30,959 p=47885 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:00:30,972 p=47885 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:00:31,195 p=47885 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:00:31,204 p=47885 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:00:31,213 p=47885 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:00:31,220 p=47885 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:00:31,443 p=47885 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:00:31,452 p=47885 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:00:31,464 p=47885 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:00:31,469 p=47885 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:00:31,475 p=47885 u=master n=ansible | TASK [common : [COMMON] Создание пользователя slurm] ***********************************************************************************************************************
2025-07-22 15:00:31,475 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:31 +0000 (0:00:01.159)       0:00:05.951 ********** 
2025-07-22 15:00:31,980 p=47885 u=master n=ansible | ok: [sm02]
2025-07-22 15:00:31,984 p=47885 u=master n=ansible | ok: [cn01]
2025-07-22 15:00:31,986 p=47885 u=master n=ansible | ok: [cn02]
2025-07-22 15:00:31,993 p=47885 u=master n=ansible | ok: [sm01]
2025-07-22 15:00:31,998 p=47885 u=master n=ansible | TASK [common : [COMMON] Установка MUNGE] ***********************************************************************************************************************************
2025-07-22 15:00:31,998 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:31 +0000 (0:00:00.522)       0:00:06.474 ********** 
2025-07-22 15:00:33,039 p=47885 u=master n=ansible | ok: [sm02]
2025-07-22 15:00:33,049 p=47885 u=master n=ansible | ok: [cn01]
2025-07-22 15:00:33,083 p=47885 u=master n=ansible | ok: [sm01]
2025-07-22 15:00:33,112 p=47885 u=master n=ansible | ok: [cn02]
2025-07-22 15:00:33,116 p=47885 u=master n=ansible | TASK [common : [COMMON] Остановка MUNGE перед настройкой] ******************************************************************************************************************
2025-07-22 15:00:33,117 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:33 +0000 (0:00:01.118)       0:00:07.593 ********** 
2025-07-22 15:00:34,992 p=47885 u=master n=ansible | changed: [sm02]
2025-07-22 15:00:34,995 p=47885 u=master n=ansible | changed: [cn02]
2025-07-22 15:00:35,073 p=47885 u=master n=ansible | changed: [sm01]
2025-07-22 15:00:35,080 p=47885 u=master n=ansible | changed: [cn01]
2025-07-22 15:00:35,085 p=47885 u=master n=ansible | TASK [common : [COMMON] Создание MUNGE ключа на master узле] ***************************************************************************************************************
2025-07-22 15:00:35,085 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:35 +0000 (0:00:01.968)       0:00:09.561 ********** 
2025-07-22 15:00:35,119 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:35,121 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:35,131 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:35,347 p=47885 u=master n=ansible | ok: [sm01]
2025-07-22 15:00:35,351 p=47885 u=master n=ansible | TASK [common : [COMMON] Получение MUNGE ключа с master узла] ***************************************************************************************************************
2025-07-22 15:00:35,351 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:35 +0000 (0:00:00.266)       0:00:09.828 ********** 
2025-07-22 15:00:35,385 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:35,388 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:35,397 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:35,728 p=47885 u=master n=ansible | ok: [sm01]
2025-07-22 15:00:35,733 p=47885 u=master n=ansible | TASK [common : [COMMON] Распространение MUNGE ключа на все узлы] ***********************************************************************************************************
2025-07-22 15:00:35,733 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:35 +0000 (0:00:00.382)       0:00:10.210 ********** 
2025-07-22 15:00:35,758 p=47885 u=master n=ansible | skipping: [sm01]
2025-07-22 15:00:37,231 p=47885 u=master n=ansible | ok: [sm02]
2025-07-22 15:00:37,300 p=47885 u=master n=ansible | ok: [cn02]
2025-07-22 15:00:37,301 p=47885 u=master n=ansible | ok: [cn01]
2025-07-22 15:00:37,305 p=47885 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа MUNGE] **********************************************************************************************************************
2025-07-22 15:00:37,305 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:37 +0000 (0:00:01.571)       0:00:11.782 ********** 
2025-07-22 15:00:37,596 p=47885 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:00:37,597 p=47885 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:00:37,641 p=47885 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:00:37,837 p=47885 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:00:37,855 p=47885 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:00:37,870 p=47885 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:00:37,917 p=47885 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:00:38,118 p=47885 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:00:38,119 p=47885 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:00:38,126 p=47885 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:00:38,175 p=47885 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:00:38,378 p=47885 u=master n=ansible | changed: [sm01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:00:38,382 p=47885 u=master n=ansible | changed: [sm02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:00:38,386 p=47885 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:00:38,429 p=47885 u=master n=ansible | changed: [cn02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:00:38,650 p=47885 u=master n=ansible | changed: [cn01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:00:38,656 p=47885 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа на ключ MUNGE] **************************************************************************************************************
2025-07-22 15:00:38,656 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:38 +0000 (0:00:01.350)       0:00:13.132 ********** 
2025-07-22 15:00:38,931 p=47885 u=master n=ansible | ok: [sm01]
2025-07-22 15:00:38,942 p=47885 u=master n=ansible | ok: [sm02]
2025-07-22 15:00:38,958 p=47885 u=master n=ansible | ok: [cn02]
2025-07-22 15:00:38,972 p=47885 u=master n=ansible | ok: [cn01]
2025-07-22 15:00:38,976 p=47885 u=master n=ansible | TASK [common : [COMMON] Запуск и включение MUNGE] **************************************************************************************************************************
2025-07-22 15:00:38,976 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:38 +0000 (0:00:00.320)       0:00:13.453 ********** 
2025-07-22 15:00:40,868 p=47885 u=master n=ansible | changed: [sm02]
2025-07-22 15:00:40,905 p=47885 u=master n=ansible | changed: [cn02]
2025-07-22 15:00:40,911 p=47885 u=master n=ansible | changed: [cn01]
2025-07-22 15:00:40,938 p=47885 u=master n=ansible | changed: [sm01]
2025-07-22 15:00:40,942 p=47885 u=master n=ansible | TASK [common : [COMMON] Проверка работы MUNGE] *****************************************************************************************************************************
2025-07-22 15:00:40,942 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:40 +0000 (0:00:01.965)       0:00:15.418 ********** 
2025-07-22 15:00:41,211 p=47885 u=master n=ansible | ok: [sm02]
2025-07-22 15:00:41,214 p=47885 u=master n=ansible | ok: [sm01]
2025-07-22 15:00:41,237 p=47885 u=master n=ansible | ok: [cn02]
2025-07-22 15:00:41,238 p=47885 u=master n=ansible | ok: [cn01]
2025-07-22 15:00:41,242 p=47885 u=master n=ansible | TASK [common : [COMMON] Результат проверки MUNGE] **************************************************************************************************************************
2025-07-22 15:00:41,242 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:41 +0000 (0:00:00.300)       0:00:15.719 ********** 
2025-07-22 15:00:41,281 p=47885 u=master n=ansible | ok: [sm01] => 
  msg: MUNGE работает корректно на sm01
2025-07-22 15:00:41,282 p=47885 u=master n=ansible | ok: [sm02] => 
  msg: MUNGE работает корректно на sm02
2025-07-22 15:00:41,288 p=47885 u=master n=ansible | ok: [cn01] => 
  msg: MUNGE работает корректно на cn01
2025-07-22 15:00:41,299 p=47885 u=master n=ansible | ok: [cn02] => 
  msg: MUNGE работает корректно на cn02
2025-07-22 15:00:41,303 p=47885 u=master n=ansible | TASK [common : [COMMON] Установка HWLOC] ***********************************************************************************************************************************
2025-07-22 15:00:41,305 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:41 +0000 (0:00:00.062)       0:00:15.781 ********** 
2025-07-22 15:00:42,289 p=47885 u=master n=ansible | ok: [sm02]
2025-07-22 15:00:42,348 p=47885 u=master n=ansible | ok: [cn02]
2025-07-22 15:00:42,355 p=47885 u=master n=ansible | ok: [sm01]
2025-07-22 15:00:42,391 p=47885 u=master n=ansible | ok: [cn01]
2025-07-22 15:00:42,395 p=47885 u=master n=ansible | TASK [common : [COMMON] Проверка HWLOC] ************************************************************************************************************************************
2025-07-22 15:00:42,396 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:42 +0000 (0:00:01.090)       0:00:16.872 ********** 
2025-07-22 15:00:42,668 p=47885 u=master n=ansible | ok: [sm02]
2025-07-22 15:00:42,696 p=47885 u=master n=ansible | ok: [sm01]
2025-07-22 15:00:42,712 p=47885 u=master n=ansible | ok: [cn02]
2025-07-22 15:00:42,716 p=47885 u=master n=ansible | ok: [cn01]
2025-07-22 15:00:42,720 p=47885 u=master n=ansible | TASK [common : [COMMON] Версия HWLOC] **************************************************************************************************************************************
2025-07-22 15:00:42,720 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:42 +0000 (0:00:00.324)       0:00:17.196 ********** 
2025-07-22 15:00:42,755 p=47885 u=master n=ansible | ok: [sm01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:00:42,756 p=47885 u=master n=ansible | ok: [sm02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:00:42,760 p=47885 u=master n=ansible | ok: [cn01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:00:42,772 p=47885 u=master n=ansible | ok: [cn02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:00:42,776 p=47885 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-22 15:00:42,776 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:42 +0000 (0:00:00.056)       0:00:17.252 ********** 
2025-07-22 15:00:42,810 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:42,815 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:42,823 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:43,781 p=47885 u=master n=ansible | ok: [sm01]
2025-07-22 15:00:43,785 p=47885 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-22 15:00:43,786 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:43 +0000 (0:00:01.009)       0:00:18.262 ********** 
2025-07-22 15:00:43,815 p=47885 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 15:00:43,816 p=47885 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 15:00:43,822 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:43,825 p=47885 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 15:00:43,826 p=47885 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 15:00:43,827 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:43,836 p=47885 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 15:00:43,839 p=47885 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 15:00:43,840 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:44,060 p=47885 u=master n=ansible | ok: [sm01] => (item=/home)
2025-07-22 15:00:44,312 p=47885 u=master n=ansible | ok: [sm01] => (item=/sw)
2025-07-22 15:00:44,318 p=47885 u=master n=ansible | TASK [common : [COMMON] Очистка старых экспортов] **************************************************************************************************************************
2025-07-22 15:00:44,318 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:44 +0000 (0:00:00.532)       0:00:18.795 ********** 
2025-07-22 15:00:44,350 p=47885 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 15:00:44,351 p=47885 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 15:00:44,356 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:44,358 p=47885 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 15:00:44,359 p=47885 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 15:00:44,360 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:44,370 p=47885 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 15:00:44,373 p=47885 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 15:00:44,374 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:44,587 p=47885 u=master n=ansible | changed: [sm01] => (item=/home)
2025-07-22 15:00:44,838 p=47885 u=master n=ansible | changed: [sm01] => (item=/sw)
2025-07-22 15:00:44,843 p=47885 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS с конкретными IP] ***********************************************************************************************************
2025-07-22 15:00:44,844 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:44 +0000 (0:00:00.525)       0:00:19.320 ********** 
2025-07-22 15:00:44,879 p=47885 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:00:44,886 p=47885 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:00:44,889 p=47885 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:00:44,890 p=47885 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:00:44,891 p=47885 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:00:44,892 p=47885 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:00:44,893 p=47885 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:00:44,894 p=47885 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:00:44,894 p=47885 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:00:44,900 p=47885 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:00:44,901 p=47885 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:00:44,901 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:44,902 p=47885 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:00:44,903 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:44,911 p=47885 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:00:44,914 p=47885 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:00:44,917 p=47885 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:00:44,920 p=47885 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:00:44,922 p=47885 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:00:44,925 p=47885 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:00:44,927 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:45,174 p=47885 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.161'})
2025-07-22 15:00:45,426 p=47885 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.167'})
2025-07-22 15:00:45,675 p=47885 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.168'})
2025-07-22 15:00:45,923 p=47885 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'})
2025-07-22 15:00:46,170 p=47885 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'})
2025-07-22 15:00:46,423 p=47885 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'})
2025-07-22 15:00:46,431 p=47885 u=master n=ansible | TASK [common : [COMMON] Запуск и включение NFS server] *********************************************************************************************************************
2025-07-22 15:00:46,431 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:46 +0000 (0:00:01.587)       0:00:20.907 ********** 
2025-07-22 15:00:46,467 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:46,470 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:46,480 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:46,926 p=47885 u=master n=ansible | ok: [sm01]
2025-07-22 15:00:46,930 p=47885 u=master n=ansible | TASK [common : [COMMON] Принудительная перезагрузка экспортов NFS] *********************************************************************************************************
2025-07-22 15:00:46,930 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:46 +0000 (0:00:00.499)       0:00:21.407 ********** 
2025-07-22 15:00:46,967 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:46,969 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:46,982 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:47,199 p=47885 u=master n=ansible | changed: [sm01]
2025-07-22 15:00:47,203 p=47885 u=master n=ansible | TASK [common : [COMMON] Проверка активных экспортов] ***********************************************************************************************************************
2025-07-22 15:00:47,203 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:47 +0000 (0:00:00.272)       0:00:21.679 ********** 
2025-07-22 15:00:47,237 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:47,239 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:47,249 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:47,472 p=47885 u=master n=ansible | changed: [sm01]
2025-07-22 15:00:47,476 p=47885 u=master n=ansible | TASK [common : [COMMON] Показать активные экспорты] ************************************************************************************************************************
2025-07-22 15:00:47,476 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:47 +0000 (0:00:00.273)       0:00:21.953 ********** 
2025-07-22 15:00:47,513 p=47885 u=master n=ansible | ok: [sm01] => 
  nfs_exports_check.stdout_lines:
  - "/home         \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/shared       \t10.20.90.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
2025-07-22 15:00:47,515 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:47,515 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:47,524 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:47,529 p=47885 u=master n=ansible | TASK [common : [COMMON] Установка NFS client] ******************************************************************************************************************************
2025-07-22 15:00:47,529 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:47 +0000 (0:00:00.052)       0:00:22.005 ********** 
2025-07-22 15:00:47,553 p=47885 u=master n=ansible | skipping: [sm01]
2025-07-22 15:00:48,513 p=47885 u=master n=ansible | ok: [cn01]
2025-07-22 15:00:48,546 p=47885 u=master n=ansible | ok: [sm02]
2025-07-22 15:00:48,615 p=47885 u=master n=ansible | ok: [cn02]
2025-07-22 15:00:48,619 p=47885 u=master n=ansible | TASK [common : [COMMON] Создание точек монтирования NFS] *******************************************************************************************************************
2025-07-22 15:00:48,620 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:48 +0000 (0:00:01.090)       0:00:23.096 ********** 
2025-07-22 15:00:48,646 p=47885 u=master n=ansible | skipping: [sm01] => (item=/sw) 
2025-07-22 15:00:48,658 p=47885 u=master n=ansible | skipping: [sm01]
2025-07-22 15:00:48,904 p=47885 u=master n=ansible | ok: [sm02] => (item=/sw)
2025-07-22 15:00:48,929 p=47885 u=master n=ansible | ok: [cn01] => (item=/sw)
2025-07-22 15:00:48,930 p=47885 u=master n=ansible | ok: [cn02] => (item=/sw)
2025-07-22 15:00:48,936 p=47885 u=master n=ansible | TASK [common : [COMMON] Монтирование NFS shares] ***************************************************************************************************************************
2025-07-22 15:00:48,936 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:48 +0000 (0:00:00.316)       0:00:23.412 ********** 
2025-07-22 15:00:48,956 p=47885 u=master n=ansible | skipping: [sm01] => (item={'path': '/home', 'src': '/home'}) 
2025-07-22 15:00:48,957 p=47885 u=master n=ansible | skipping: [sm01] => (item={'path': '/sw', 'src': '/sw'}) 
2025-07-22 15:00:48,965 p=47885 u=master n=ansible | skipping: [sm01]
2025-07-22 15:00:49,398 p=47885 u=master n=ansible | ok: [sm02] => (item={'path': '/home', 'src': '/home'})
2025-07-22 15:00:49,399 p=47885 u=master n=ansible | ok: [cn02] => (item={'path': '/home', 'src': '/home'})
2025-07-22 15:00:49,404 p=47885 u=master n=ansible | ok: [cn01] => (item={'path': '/home', 'src': '/home'})
2025-07-22 15:00:49,644 p=47885 u=master n=ansible | ok: [sm02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 15:00:49,648 p=47885 u=master n=ansible | ok: [cn02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 15:00:49,660 p=47885 u=master n=ansible | ok: [cn01] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 15:00:49,665 p=47885 u=master n=ansible | TASK [common : [COMMON] Создание базовых директорий Slurm] *****************************************************************************************************************
2025-07-22 15:00:49,665 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:49 +0000 (0:00:00.729)       0:00:24.141 ********** 
2025-07-22 15:00:49,950 p=47885 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:49,952 p=47885 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:49,969 p=47885 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:49,976 p=47885 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:50,201 p=47885 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:50,230 p=47885 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:50,231 p=47885 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:50,243 p=47885 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:50,452 p=47885 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:50,485 p=47885 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:50,501 p=47885 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:50,512 p=47885 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:50,701 p=47885 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:50,740 p=47885 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:50,761 p=47885 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:50,777 p=47885 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:50,952 p=47885 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:00:50,996 p=47885 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:00:51,023 p=47885 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:00:51,038 p=47885 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:00:51,203 p=47885 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:51,252 p=47885 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:51,284 p=47885 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:51,296 p=47885 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:00:51,303 p=47885 u=master n=ansible | TASK [common : [COMMON] Роль common выполнена успешно] *********************************************************************************************************************
2025-07-22 15:00:51,303 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:51 +0000 (0:00:01.637)       0:00:25.779 ********** 
2025-07-22 15:00:51,338 p=47885 u=master n=ansible | ok: [sm01] => 
  msg: ✅ Узел sm01 готов для установки Slurm
2025-07-22 15:00:51,339 p=47885 u=master n=ansible | ok: [sm02] => 
  msg: ✅ Узел sm02 готов для установки Slurm
2025-07-22 15:00:51,342 p=47885 u=master n=ansible | ok: [cn01] => 
  msg: ✅ Узел cn01 готов для установки Slurm
2025-07-22 15:00:51,416 p=47885 u=master n=ansible | ok: [cn02] => 
  msg: ✅ Узел cn02 готов для установки Slurm
2025-07-22 15:00:51,427 p=47885 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Начало сборки Slurm] *********************************************************************************************************************
2025-07-22 15:00:51,427 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:51 +0000 (0:00:00.124)       0:00:25.903 ********** 
2025-07-22 15:00:51,462 p=47885 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm01"
2025-07-22 15:00:51,465 p=47885 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm02"
2025-07-22 15:00:51,468 p=47885 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn01"
2025-07-22 15:00:51,480 p=47885 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn02"
2025-07-22 15:00:51,483 p=47885 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка дополнительных зависимостей для сборки] ****************************************************************************************
2025-07-22 15:00:51,484 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:51 +0000 (0:00:00.056)       0:00:25.960 ********** 
2025-07-22 15:00:51,517 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:51,519 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:51,530 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:52,192 p=47885 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  msg: No package matching 'libmariadbclient-dev' is available
2025-07-22 15:00:52,196 p=47885 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для сборки] ************************************************************************************************
2025-07-22 15:00:52,197 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:52 +0000 (0:00:00.713)       0:00:26.673 ********** 
2025-07-22 15:00:52,221 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:52,224 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:52,233 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:52,237 p=47885 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка существования исходников] *******************************************************************************************************
2025-07-22 15:00:52,237 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:52 +0000 (0:00:00.040)       0:00:26.713 ********** 
2025-07-22 15:00:52,262 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:52,265 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:52,273 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:52,279 p=47885 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Скачивание исходников Slurm 25.05.1] *****************************************************************************************************
2025-07-22 15:00:52,280 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:52 +0000 (0:00:00.042)       0:00:26.756 ********** 
2025-07-22 15:00:52,304 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:52,306 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:52,314 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:52,319 p=47885 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Извлечение исходников Slurm] *************************************************************************************************************
2025-07-22 15:00:52,319 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:52 +0000 (0:00:00.039)       0:00:26.795 ********** 
2025-07-22 15:00:52,342 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:52,344 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:52,353 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:52,358 p=47885 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Конфигурация сборки Slurm с JWT поддержкой] **********************************************************************************************
2025-07-22 15:00:52,358 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:52 +0000 (0:00:00.039)       0:00:26.834 ********** 
2025-07-22 15:00:52,382 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:52,384 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:52,392 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:52,396 p=47885 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат конфигурации] ******************************************************************************************************************
2025-07-22 15:00:52,396 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:52 +0000 (0:00:00.038)       0:00:26.872 ********** 
2025-07-22 15:00:52,422 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:52,424 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:52,432 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:52,436 p=47885 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Компиляция Slurm (это займет время...)] **************************************************************************************************
2025-07-22 15:00:52,436 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:52 +0000 (0:00:00.039)       0:00:26.912 ********** 
2025-07-22 15:00:52,461 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:52,463 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:52,471 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:52,475 p=47885 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка Slurm на master] ***************************************************************************************************************
2025-07-22 15:00:52,475 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:52 +0000 (0:00:00.039)       0:00:26.951 ********** 
2025-07-22 15:00:52,503 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:52,504 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:52,513 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:52,518 p=47885 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание архива Slurm для копирования] ***************************************************************************************************
2025-07-22 15:00:52,518 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:52 +0000 (0:00:00.042)       0:00:26.994 ********** 
2025-07-22 15:00:52,544 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:52,546 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:52,554 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:52,558 p=47885 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] *************************************************************************************************
2025-07-22 15:00:52,559 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:52 +0000 (0:00:00.040)       0:00:27.035 ********** 
2025-07-22 15:00:52,826 p=47885 u=master n=ansible | ok: [sm02]
2025-07-22 15:00:52,850 p=47885 u=master n=ansible | ok: [cn02]
2025-07-22 15:00:52,917 p=47885 u=master n=ansible | ok: [cn01]
2025-07-22 15:00:52,922 p=47885 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Получение архива с master узла на контроллер Ansible] ************************************************************************************
2025-07-22 15:00:52,922 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:52 +0000 (0:00:00.363)       0:00:27.399 ********** 
2025-07-22 15:00:52,950 p=47885 u=master n=ansible | skipping: [sm02]
2025-07-22 15:00:52,952 p=47885 u=master n=ansible | skipping: [cn01]
2025-07-22 15:00:52,960 p=47885 u=master n=ansible | skipping: [cn02]
2025-07-22 15:00:52,964 p=47885 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование архива на все узлы (кроме master)] *******************************************************************************************
2025-07-22 15:00:52,964 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:52 +0000 (0:00:00.041)       0:00:27.440 ********** 
2025-07-22 15:00:53,071 p=47885 u=master n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: If you are using a module and expect the file to exist on the remote, see the remote_src option
2025-07-22 15:00:53,073 p=47885 u=master n=ansible | fatal: [sm02]: FAILED! => changed=false 
  msg: |-
    Could not find or access '/tmp/slurm-25.05.1-install.tar.gz' on the Ansible Controller.
    If you are using a module and expect the file to exist on the remote, see the remote_src option
2025-07-22 15:00:53,076 p=47885 u=master n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: If you are using a module and expect the file to exist on the remote, see the remote_src option
2025-07-22 15:00:53,076 p=47885 u=master n=ansible | fatal: [cn01]: FAILED! => changed=false 
  msg: |-
    Could not find or access '/tmp/slurm-25.05.1-install.tar.gz' on the Ansible Controller.
    If you are using a module and expect the file to exist on the remote, see the remote_src option
2025-07-22 15:00:53,077 p=47885 u=master n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: If you are using a module and expect the file to exist on the remote, see the remote_src option
2025-07-22 15:00:53,078 p=47885 u=master n=ansible | fatal: [cn02]: FAILED! => changed=false 
  msg: |-
    Could not find or access '/tmp/slurm-25.05.1-install.tar.gz' on the Ansible Controller.
    If you are using a module and expect the file to exist on the remote, see the remote_src option
2025-07-22 15:00:53,079 p=47885 u=master n=ansible | PLAY RECAP *****************************************************************************************************************************************************************
2025-07-22 15:00:53,079 p=47885 u=master n=ansible | cn01                       : ok=24   changed=3    unreachable=0    failed=1    skipped=23   rescued=0    ignored=0   
2025-07-22 15:00:53,080 p=47885 u=master n=ansible | cn02                       : ok=24   changed=3    unreachable=0    failed=1    skipped=23   rescued=0    ignored=0   
2025-07-22 15:00:53,080 p=47885 u=master n=ansible | sm01                       : ok=32   changed=8    unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-07-22 15:00:53,080 p=47885 u=master n=ansible | sm02                       : ok=24   changed=3    unreachable=0    failed=1    skipped=23   rescued=0    ignored=0   
2025-07-22 15:00:53,080 p=47885 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 27 seconds
2025-07-22 15:00:53,080 p=47885 u=master n=ansible | Tuesday 22 July 2025  15:00:53 +0000 (0:00:00.116)       0:00:27.556 ********** 
2025-07-22 15:00:53,080 p=47885 u=master n=ansible | =============================================================================== 
2025-07-22 15:00:53,081 p=47885 u=master n=ansible | common : [COMMON] Остановка MUNGE перед настройкой ------------------------------------------------------------------------------------------------------------------ 1.97s
2025-07-22 15:00:53,081 p=47885 u=master n=ansible | common : [COMMON] Запуск и включение MUNGE -------------------------------------------------------------------------------------------------------------------------- 1.97s
2025-07-22 15:00:53,081 p=47885 u=master n=ansible | common : [COMMON] Обновление apt cache ------------------------------------------------------------------------------------------------------------------------------ 1.79s
2025-07-22 15:00:53,081 p=47885 u=master n=ansible | common : [COMMON] Создание базовых директорий Slurm ----------------------------------------------------------------------------------------------------------------- 1.64s
2025-07-22 15:00:53,081 p=47885 u=master n=ansible | common : [COMMON] Настройка экспорта NFS с конкретными IP ----------------------------------------------------------------------------------------------------------- 1.59s
2025-07-22 15:00:53,081 p=47885 u=master n=ansible | common : [COMMON] Распространение MUNGE ключа на все узлы ----------------------------------------------------------------------------------------------------------- 1.57s
2025-07-22 15:00:53,081 p=47885 u=master n=ansible | common : [COMMON] Настройка прав доступа MUNGE ---------------------------------------------------------------------------------------------------------------------- 1.35s
2025-07-22 15:00:53,081 p=47885 u=master n=ansible | common : [COMMON] Обеспечение hostname resolution для кластера ------------------------------------------------------------------------------------------------------ 1.16s
2025-07-22 15:00:53,081 p=47885 u=master n=ansible | common : [COMMON] Установка базовых пакетов ------------------------------------------------------------------------------------------------------------------------- 1.15s
2025-07-22 15:00:53,081 p=47885 u=master n=ansible | Проверка доступного места на диске ---------------------------------------------------------------------------------------------------------------------------------- 1.13s
2025-07-22 15:00:53,081 p=47885 u=master n=ansible | common : [COMMON] Установка MUNGE ----------------------------------------------------------------------------------------------------------------------------------- 1.12s
2025-07-22 15:00:53,082 p=47885 u=master n=ansible | common : [COMMON] Установка HWLOC ----------------------------------------------------------------------------------------------------------------------------------- 1.09s
2025-07-22 15:00:53,082 p=47885 u=master n=ansible | common : [COMMON] Установка NFS client ------------------------------------------------------------------------------------------------------------------------------ 1.09s
2025-07-22 15:00:53,082 p=47885 u=master n=ansible | common : [COMMON] Установка NFS server на master -------------------------------------------------------------------------------------------------------------------- 1.01s
2025-07-22 15:00:53,082 p=47885 u=master n=ansible | common : [COMMON] Монтирование NFS shares --------------------------------------------------------------------------------------------------------------------------- 0.73s
2025-07-22 15:00:53,082 p=47885 u=master n=ansible | slurm_build : [SLURM_BUILD] Установка дополнительных зависимостей для сборки ---------------------------------------------------------------------------------------- 0.71s
2025-07-22 15:00:53,082 p=47885 u=master n=ansible | common : [COMMON] Создание директорий для экспорта NFS -------------------------------------------------------------------------------------------------------------- 0.53s
2025-07-22 15:00:53,082 p=47885 u=master n=ansible | common : [COMMON] Очистка старых экспортов -------------------------------------------------------------------------------------------------------------------------- 0.53s
2025-07-22 15:00:53,082 p=47885 u=master n=ansible | common : [COMMON] Создание пользователя slurm ----------------------------------------------------------------------------------------------------------------------- 0.52s
2025-07-22 15:00:53,082 p=47885 u=master n=ansible | common : [COMMON] Настройка timezone -------------------------------------------------------------------------------------------------------------------------------- 0.51s
2025-07-22 15:05:27,814 p=48421 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 15:05:27,815 p=48421 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 15:05:28,265 p=48421 u=master n=ansible | PLAY [Тестирование роли slurm_build] ***************************************************************************************************************************************
2025-07-22 15:05:28,286 p=48421 u=master n=ansible | TASK [Информация о сборке Slurm] *******************************************************************************************************************************************
2025-07-22 15:05:28,286 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:28 +0000 (0:00:00.024)       0:00:00.024 ********** 
2025-07-22 15:05:28,336 p=48421 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F528 Начинаем сборку Slurm 25.05.1\n\U0001F4CD Сборка на: sm01\n\U0001F4E6 Установка на: sm01, sm02, cn01, cn02\n\U0001F510 JWT поддержка включена"
2025-07-22 15:05:28,340 p=48421 u=master n=ansible | TASK [Проверка доступного места на диске] **********************************************************************************************************************************
2025-07-22 15:05:28,340 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:28 +0000 (0:00:00.054)       0:00:00.079 ********** 
2025-07-22 15:05:28,372 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:05:28,374 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:05:28,382 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:05:29,566 p=48421 u=master n=ansible | changed: [sm01]
2025-07-22 15:05:29,570 p=48421 u=master n=ansible | TASK [Предупреждение о месте на диске] *************************************************************************************************************************************
2025-07-22 15:05:29,570 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:29 +0000 (0:00:01.229)       0:00:01.308 ********** 
2025-07-22 15:05:29,601 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:05:29,603 p=48421 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4BE Доступно места в /tmp: 40G\n⚠️  Для сборки Slurm требуется ~2GB свободного места"
2025-07-22 15:05:29,604 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:05:29,613 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:05:29,633 p=48421 u=master n=ansible | TASK [common : [COMMON] Начало выполнения роли common] *********************************************************************************************************************
2025-07-22 15:05:29,633 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:29 +0000 (0:00:00.063)       0:00:01.372 ********** 
2025-07-22 15:05:29,666 p=48421 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm01"
2025-07-22 15:05:29,667 p=48421 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm02"
2025-07-22 15:05:29,671 p=48421 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn01"
2025-07-22 15:05:29,683 p=48421 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn02"
2025-07-22 15:05:29,687 p=48421 u=master n=ansible | TASK [common : [COMMON] Обновление apt cache] ******************************************************************************************************************************
2025-07-22 15:05:29,687 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:29 +0000 (0:00:00.054)       0:00:01.426 ********** 
2025-07-22 15:05:30,714 p=48421 u=master n=ansible | ok: [sm01]
2025-07-22 15:05:31,340 p=48421 u=master n=ansible | ok: [cn01]
2025-07-22 15:05:31,411 p=48421 u=master n=ansible | ok: [cn02]
2025-07-22 15:05:36,451 p=48421 u=master n=ansible | changed: [sm02]
2025-07-22 15:05:36,455 p=48421 u=master n=ansible | TASK [common : [COMMON] Установка базовых пакетов] *************************************************************************************************************************
2025-07-22 15:05:36,455 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:36 +0000 (0:00:06.767)       0:00:08.193 ********** 
2025-07-22 15:05:37,478 p=48421 u=master n=ansible | ok: [cn01]
2025-07-22 15:05:37,492 p=48421 u=master n=ansible | ok: [sm02]
2025-07-22 15:05:37,548 p=48421 u=master n=ansible | ok: [cn02]
2025-07-22 15:05:37,597 p=48421 u=master n=ansible | ok: [sm01]
2025-07-22 15:05:37,601 p=48421 u=master n=ansible | TASK [common : [COMMON] Настройка timezone] ********************************************************************************************************************************
2025-07-22 15:05:37,601 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:37 +0000 (0:00:01.145)       0:00:09.339 ********** 
2025-07-22 15:05:38,107 p=48421 u=master n=ansible | ok: [sm02]
2025-07-22 15:05:38,112 p=48421 u=master n=ansible | ok: [sm01]
2025-07-22 15:05:38,118 p=48421 u=master n=ansible | ok: [cn02]
2025-07-22 15:05:38,120 p=48421 u=master n=ansible | ok: [cn01]
2025-07-22 15:05:38,124 p=48421 u=master n=ansible | TASK [common : [COMMON] Обеспечение hostname resolution для кластера] ******************************************************************************************************
2025-07-22 15:05:38,124 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:38 +0000 (0:00:00.523)       0:00:09.863 ********** 
2025-07-22 15:05:38,518 p=48421 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:05:38,519 p=48421 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:05:38,520 p=48421 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:05:38,528 p=48421 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:05:38,762 p=48421 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:05:38,763 p=48421 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:05:38,774 p=48421 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:05:38,775 p=48421 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:05:39,008 p=48421 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:05:39,020 p=48421 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:05:39,025 p=48421 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:05:39,026 p=48421 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:05:39,256 p=48421 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:05:39,265 p=48421 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:05:39,284 p=48421 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:05:39,310 p=48421 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:05:39,315 p=48421 u=master n=ansible | TASK [common : [COMMON] Создание пользователя slurm] ***********************************************************************************************************************
2025-07-22 15:05:39,315 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:39 +0000 (0:00:01.191)       0:00:11.054 ********** 
2025-07-22 15:05:39,820 p=48421 u=master n=ansible | ok: [sm02]
2025-07-22 15:05:39,828 p=48421 u=master n=ansible | ok: [cn01]
2025-07-22 15:05:39,834 p=48421 u=master n=ansible | ok: [cn02]
2025-07-22 15:05:39,846 p=48421 u=master n=ansible | ok: [sm01]
2025-07-22 15:05:39,850 p=48421 u=master n=ansible | TASK [common : [COMMON] Установка MUNGE] ***********************************************************************************************************************************
2025-07-22 15:05:39,850 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:39 +0000 (0:00:00.534)       0:00:11.589 ********** 
2025-07-22 15:05:40,914 p=48421 u=master n=ansible | ok: [sm02]
2025-07-22 15:05:40,917 p=48421 u=master n=ansible | ok: [sm01]
2025-07-22 15:05:41,018 p=48421 u=master n=ansible | ok: [cn02]
2025-07-22 15:05:41,023 p=48421 u=master n=ansible | ok: [cn01]
2025-07-22 15:05:41,027 p=48421 u=master n=ansible | TASK [common : [COMMON] Остановка MUNGE перед настройкой] ******************************************************************************************************************
2025-07-22 15:05:41,027 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:41 +0000 (0:00:01.176)       0:00:12.765 ********** 
2025-07-22 15:05:42,914 p=48421 u=master n=ansible | changed: [cn02]
2025-07-22 15:05:42,920 p=48421 u=master n=ansible | changed: [sm02]
2025-07-22 15:05:42,935 p=48421 u=master n=ansible | changed: [cn01]
2025-07-22 15:05:42,944 p=48421 u=master n=ansible | changed: [sm01]
2025-07-22 15:05:42,949 p=48421 u=master n=ansible | TASK [common : [COMMON] Создание MUNGE ключа на master узле] ***************************************************************************************************************
2025-07-22 15:05:42,949 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:42 +0000 (0:00:01.922)       0:00:14.688 ********** 
2025-07-22 15:05:42,981 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:05:42,983 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:05:42,993 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:05:43,202 p=48421 u=master n=ansible | ok: [sm01]
2025-07-22 15:05:43,206 p=48421 u=master n=ansible | TASK [common : [COMMON] Получение MUNGE ключа с master узла] ***************************************************************************************************************
2025-07-22 15:05:43,207 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:43 +0000 (0:00:00.257)       0:00:14.945 ********** 
2025-07-22 15:05:43,239 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:05:43,242 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:05:43,252 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:05:43,576 p=48421 u=master n=ansible | ok: [sm01]
2025-07-22 15:05:43,582 p=48421 u=master n=ansible | TASK [common : [COMMON] Распространение MUNGE ключа на все узлы] ***********************************************************************************************************
2025-07-22 15:05:43,582 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:43 +0000 (0:00:00.375)       0:00:15.321 ********** 
2025-07-22 15:05:43,605 p=48421 u=master n=ansible | skipping: [sm01]
2025-07-22 15:05:44,520 p=48421 u=master n=ansible | ok: [sm02]
2025-07-22 15:05:44,522 p=48421 u=master n=ansible | ok: [cn02]
2025-07-22 15:05:44,526 p=48421 u=master n=ansible | ok: [cn01]
2025-07-22 15:05:44,530 p=48421 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа MUNGE] **********************************************************************************************************************
2025-07-22 15:05:44,530 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:44 +0000 (0:00:00.948)       0:00:16.269 ********** 
2025-07-22 15:05:44,810 p=48421 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:05:44,811 p=48421 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:05:44,833 p=48421 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:05:44,837 p=48421 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:05:45,073 p=48421 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:05:45,091 p=48421 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:05:45,099 p=48421 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:05:45,126 p=48421 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:05:45,350 p=48421 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:05:45,351 p=48421 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:05:45,363 p=48421 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:05:45,407 p=48421 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:05:45,604 p=48421 u=master n=ansible | changed: [sm01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:05:45,617 p=48421 u=master n=ansible | changed: [sm02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:05:45,620 p=48421 u=master n=ansible | changed: [cn01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:05:45,662 p=48421 u=master n=ansible | changed: [cn02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:05:45,668 p=48421 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа на ключ MUNGE] **************************************************************************************************************
2025-07-22 15:05:45,668 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:45 +0000 (0:00:01.137)       0:00:17.407 ********** 
2025-07-22 15:05:45,933 p=48421 u=master n=ansible | ok: [sm01]
2025-07-22 15:05:46,026 p=48421 u=master n=ansible | ok: [sm02]
2025-07-22 15:05:46,046 p=48421 u=master n=ansible | ok: [cn02]
2025-07-22 15:05:46,113 p=48421 u=master n=ansible | ok: [cn01]
2025-07-22 15:05:46,117 p=48421 u=master n=ansible | TASK [common : [COMMON] Запуск и включение MUNGE] **************************************************************************************************************************
2025-07-22 15:05:46,117 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:46 +0000 (0:00:00.448)       0:00:17.855 ********** 
2025-07-22 15:05:48,020 p=48421 u=master n=ansible | changed: [sm02]
2025-07-22 15:05:48,048 p=48421 u=master n=ansible | changed: [cn01]
2025-07-22 15:05:48,056 p=48421 u=master n=ansible | changed: [cn02]
2025-07-22 15:05:48,060 p=48421 u=master n=ansible | changed: [sm01]
2025-07-22 15:05:48,064 p=48421 u=master n=ansible | TASK [common : [COMMON] Проверка работы MUNGE] *****************************************************************************************************************************
2025-07-22 15:05:48,064 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:48 +0000 (0:00:01.946)       0:00:19.802 ********** 
2025-07-22 15:05:48,341 p=48421 u=master n=ansible | ok: [sm01]
2025-07-22 15:05:48,342 p=48421 u=master n=ansible | ok: [sm02]
2025-07-22 15:05:48,349 p=48421 u=master n=ansible | ok: [cn01]
2025-07-22 15:05:48,361 p=48421 u=master n=ansible | ok: [cn02]
2025-07-22 15:05:48,365 p=48421 u=master n=ansible | TASK [common : [COMMON] Результат проверки MUNGE] **************************************************************************************************************************
2025-07-22 15:05:48,365 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:48 +0000 (0:00:00.300)       0:00:20.103 ********** 
2025-07-22 15:05:48,400 p=48421 u=master n=ansible | ok: [sm01] => 
  msg: MUNGE работает корректно на sm01
2025-07-22 15:05:48,401 p=48421 u=master n=ansible | ok: [sm02] => 
  msg: MUNGE работает корректно на sm02
2025-07-22 15:05:48,406 p=48421 u=master n=ansible | ok: [cn01] => 
  msg: MUNGE работает корректно на cn01
2025-07-22 15:05:48,417 p=48421 u=master n=ansible | ok: [cn02] => 
  msg: MUNGE работает корректно на cn02
2025-07-22 15:05:48,420 p=48421 u=master n=ansible | TASK [common : [COMMON] Установка HWLOC] ***********************************************************************************************************************************
2025-07-22 15:05:48,421 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:48 +0000 (0:00:00.055)       0:00:20.159 ********** 
2025-07-22 15:05:49,472 p=48421 u=master n=ansible | ok: [cn01]
2025-07-22 15:05:49,516 p=48421 u=master n=ansible | ok: [cn02]
2025-07-22 15:05:49,534 p=48421 u=master n=ansible | ok: [sm02]
2025-07-22 15:05:51,031 p=48421 u=master n=ansible | ok: [sm01]
2025-07-22 15:05:51,035 p=48421 u=master n=ansible | TASK [common : [COMMON] Проверка HWLOC] ************************************************************************************************************************************
2025-07-22 15:05:51,035 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:51 +0000 (0:00:02.614)       0:00:22.773 ********** 
2025-07-22 15:05:51,313 p=48421 u=master n=ansible | ok: [sm01]
2025-07-22 15:05:51,452 p=48421 u=master n=ansible | ok: [cn01]
2025-07-22 15:05:51,453 p=48421 u=master n=ansible | ok: [cn02]
2025-07-22 15:05:51,495 p=48421 u=master n=ansible | ok: [sm02]
2025-07-22 15:05:51,499 p=48421 u=master n=ansible | TASK [common : [COMMON] Версия HWLOC] **************************************************************************************************************************************
2025-07-22 15:05:51,499 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:51 +0000 (0:00:00.464)       0:00:23.238 ********** 
2025-07-22 15:05:51,524 p=48421 u=master n=ansible | ok: [sm01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:05:51,535 p=48421 u=master n=ansible | ok: [sm02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:05:51,539 p=48421 u=master n=ansible | ok: [cn01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:05:51,552 p=48421 u=master n=ansible | ok: [cn02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:05:51,556 p=48421 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-22 15:05:51,556 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:51 +0000 (0:00:00.057)       0:00:23.295 ********** 
2025-07-22 15:05:51,591 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:05:51,593 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:05:51,603 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:05:52,573 p=48421 u=master n=ansible | ok: [sm01]
2025-07-22 15:05:52,577 p=48421 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-22 15:05:52,577 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:52 +0000 (0:00:01.020)       0:00:24.316 ********** 
2025-07-22 15:05:52,608 p=48421 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 15:05:52,609 p=48421 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 15:05:52,613 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:05:52,615 p=48421 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 15:05:52,616 p=48421 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 15:05:52,617 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:05:52,626 p=48421 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 15:05:52,630 p=48421 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 15:05:52,631 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:05:52,851 p=48421 u=master n=ansible | ok: [sm01] => (item=/home)
2025-07-22 15:05:53,099 p=48421 u=master n=ansible | ok: [sm01] => (item=/sw)
2025-07-22 15:05:53,105 p=48421 u=master n=ansible | TASK [common : [COMMON] Очистка старых экспортов] **************************************************************************************************************************
2025-07-22 15:05:53,105 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:53 +0000 (0:00:00.527)       0:00:24.843 ********** 
2025-07-22 15:05:53,138 p=48421 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 15:05:53,139 p=48421 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 15:05:53,143 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:05:53,145 p=48421 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 15:05:53,146 p=48421 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 15:05:53,147 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:05:53,156 p=48421 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 15:05:53,159 p=48421 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 15:05:53,160 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:05:53,369 p=48421 u=master n=ansible | changed: [sm01] => (item=/home)
2025-07-22 15:05:53,607 p=48421 u=master n=ansible | changed: [sm01] => (item=/sw)
2025-07-22 15:05:53,612 p=48421 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS с конкретными IP] ***********************************************************************************************************
2025-07-22 15:05:53,612 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:53 +0000 (0:00:00.507)       0:00:25.350 ********** 
2025-07-22 15:05:53,642 p=48421 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:05:53,649 p=48421 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:05:53,651 p=48421 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:05:53,652 p=48421 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:05:53,653 p=48421 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:05:53,654 p=48421 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:05:53,655 p=48421 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:05:53,656 p=48421 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:05:53,657 p=48421 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:05:53,660 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:05:53,662 p=48421 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:05:53,663 p=48421 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:05:53,663 p=48421 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:05:53,665 p=48421 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:05:53,667 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:05:53,668 p=48421 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:05:53,669 p=48421 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:05:53,672 p=48421 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:05:53,674 p=48421 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:05:53,677 p=48421 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:05:53,679 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:05:53,877 p=48421 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.161'})
2025-07-22 15:05:54,121 p=48421 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.167'})
2025-07-22 15:05:54,361 p=48421 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.168'})
2025-07-22 15:05:54,630 p=48421 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'})
2025-07-22 15:05:54,875 p=48421 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'})
2025-07-22 15:05:55,151 p=48421 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'})
2025-07-22 15:05:55,159 p=48421 u=master n=ansible | TASK [common : [COMMON] Запуск и включение NFS server] *********************************************************************************************************************
2025-07-22 15:05:55,159 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:55 +0000 (0:00:01.546)       0:00:26.897 ********** 
2025-07-22 15:05:55,193 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:05:55,196 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:05:55,205 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:05:55,636 p=48421 u=master n=ansible | ok: [sm01]
2025-07-22 15:05:55,641 p=48421 u=master n=ansible | TASK [common : [COMMON] Принудительная перезагрузка экспортов NFS] *********************************************************************************************************
2025-07-22 15:05:55,641 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:55 +0000 (0:00:00.482)       0:00:27.380 ********** 
2025-07-22 15:05:55,680 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:05:55,681 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:05:55,690 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:05:55,916 p=48421 u=master n=ansible | changed: [sm01]
2025-07-22 15:05:55,920 p=48421 u=master n=ansible | TASK [common : [COMMON] Проверка активных экспортов] ***********************************************************************************************************************
2025-07-22 15:05:55,921 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:55 +0000 (0:00:00.279)       0:00:27.659 ********** 
2025-07-22 15:05:55,958 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:05:55,960 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:05:55,970 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:05:56,189 p=48421 u=master n=ansible | changed: [sm01]
2025-07-22 15:05:56,194 p=48421 u=master n=ansible | TASK [common : [COMMON] Показать активные экспорты] ************************************************************************************************************************
2025-07-22 15:05:56,194 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:56 +0000 (0:00:00.273)       0:00:27.932 ********** 
2025-07-22 15:05:56,235 p=48421 u=master n=ansible | ok: [sm01] => 
  nfs_exports_check.stdout_lines:
  - "/home         \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/shared       \t10.20.90.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
2025-07-22 15:05:56,236 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:05:56,237 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:05:56,245 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:05:56,249 p=48421 u=master n=ansible | TASK [common : [COMMON] Установка NFS client] ******************************************************************************************************************************
2025-07-22 15:05:56,250 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:56 +0000 (0:00:00.055)       0:00:27.988 ********** 
2025-07-22 15:05:56,273 p=48421 u=master n=ansible | skipping: [sm01]
2025-07-22 15:05:57,239 p=48421 u=master n=ansible | ok: [sm02]
2025-07-22 15:05:57,246 p=48421 u=master n=ansible | ok: [cn01]
2025-07-22 15:05:57,274 p=48421 u=master n=ansible | ok: [cn02]
2025-07-22 15:05:57,278 p=48421 u=master n=ansible | TASK [common : [COMMON] Создание точек монтирования NFS] *******************************************************************************************************************
2025-07-22 15:05:57,279 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:57 +0000 (0:00:01.028)       0:00:29.017 ********** 
2025-07-22 15:05:57,297 p=48421 u=master n=ansible | skipping: [sm01] => (item=/sw) 
2025-07-22 15:05:57,304 p=48421 u=master n=ansible | skipping: [sm01]
2025-07-22 15:05:57,565 p=48421 u=master n=ansible | ok: [sm02] => (item=/sw)
2025-07-22 15:05:57,570 p=48421 u=master n=ansible | ok: [cn01] => (item=/sw)
2025-07-22 15:05:57,582 p=48421 u=master n=ansible | ok: [cn02] => (item=/sw)
2025-07-22 15:05:57,587 p=48421 u=master n=ansible | TASK [common : [COMMON] Монтирование NFS shares] ***************************************************************************************************************************
2025-07-22 15:05:57,587 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:57 +0000 (0:00:00.308)       0:00:29.325 ********** 
2025-07-22 15:05:57,609 p=48421 u=master n=ansible | skipping: [sm01] => (item={'path': '/home', 'src': '/home'}) 
2025-07-22 15:05:57,612 p=48421 u=master n=ansible | skipping: [sm01] => (item={'path': '/sw', 'src': '/sw'}) 
2025-07-22 15:05:57,624 p=48421 u=master n=ansible | skipping: [sm01]
2025-07-22 15:05:58,034 p=48421 u=master n=ansible | ok: [sm02] => (item={'path': '/home', 'src': '/home'})
2025-07-22 15:05:58,036 p=48421 u=master n=ansible | ok: [cn01] => (item={'path': '/home', 'src': '/home'})
2025-07-22 15:05:58,037 p=48421 u=master n=ansible | ok: [cn02] => (item={'path': '/home', 'src': '/home'})
2025-07-22 15:05:58,280 p=48421 u=master n=ansible | ok: [sm02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 15:05:58,287 p=48421 u=master n=ansible | ok: [cn01] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 15:05:58,288 p=48421 u=master n=ansible | ok: [cn02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 15:05:58,294 p=48421 u=master n=ansible | TASK [common : [COMMON] Создание базовых директорий Slurm] *****************************************************************************************************************
2025-07-22 15:05:58,294 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:58 +0000 (0:00:00.706)       0:00:30.032 ********** 
2025-07-22 15:05:58,574 p=48421 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:58,581 p=48421 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:58,585 p=48421 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:58,603 p=48421 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:58,837 p=48421 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:58,848 p=48421 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:58,852 p=48421 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:58,877 p=48421 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:59,102 p=48421 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:59,113 p=48421 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:59,132 p=48421 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:59,133 p=48421 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:59,364 p=48421 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:59,365 p=48421 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:59,392 p=48421 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:59,397 p=48421 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:59,615 p=48421 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:05:59,617 p=48421 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:05:59,682 p=48421 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:05:59,684 p=48421 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:05:59,868 p=48421 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:59,869 p=48421 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:59,943 p=48421 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:59,945 p=48421 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:05:59,954 p=48421 u=master n=ansible | TASK [common : [COMMON] Роль common выполнена успешно] *********************************************************************************************************************
2025-07-22 15:05:59,954 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:05:59 +0000 (0:00:01.660)       0:00:31.693 ********** 
2025-07-22 15:05:59,989 p=48421 u=master n=ansible | ok: [sm01] => 
  msg: ✅ Узел sm01 готов для установки Slurm
2025-07-22 15:05:59,990 p=48421 u=master n=ansible | ok: [sm02] => 
  msg: ✅ Узел sm02 готов для установки Slurm
2025-07-22 15:05:59,994 p=48421 u=master n=ansible | ok: [cn01] => 
  msg: ✅ Узел cn01 готов для установки Slurm
2025-07-22 15:06:00,066 p=48421 u=master n=ansible | ok: [cn02] => 
  msg: ✅ Узел cn02 готов для установки Slurm
2025-07-22 15:06:00,077 p=48421 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Начало сборки Slurm] *********************************************************************************************************************
2025-07-22 15:06:00,077 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:06:00 +0000 (0:00:00.122)       0:00:31.815 ********** 
2025-07-22 15:06:00,112 p=48421 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm01"
2025-07-22 15:06:00,113 p=48421 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm02"
2025-07-22 15:06:00,117 p=48421 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn01"
2025-07-22 15:06:00,130 p=48421 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn02"
2025-07-22 15:06:00,134 p=48421 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка дополнительных зависимостей для сборки] ****************************************************************************************
2025-07-22 15:06:00,134 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:06:00 +0000 (0:00:00.057)       0:00:31.873 ********** 
2025-07-22 15:06:00,168 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:06:00,170 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:06:00,181 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:09:41,959 p=48421 u=master n=ansible | changed: [sm01]
2025-07-22 15:09:41,965 p=48421 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для сборки] ************************************************************************************************
2025-07-22 15:09:41,965 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:09:41 +0000 (0:03:41.830)       0:04:13.703 ********** 
2025-07-22 15:09:42,001 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:09:42,006 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:09:42,015 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:09:42,248 p=48421 u=master n=ansible | changed: [sm01]
2025-07-22 15:09:42,252 p=48421 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка существования исходников] *******************************************************************************************************
2025-07-22 15:09:42,253 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:09:42 +0000 (0:00:00.287)       0:04:13.991 ********** 
2025-07-22 15:09:42,292 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:09:42,293 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:09:42,300 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:09:42,523 p=48421 u=master n=ansible | ok: [sm01]
2025-07-22 15:09:42,529 p=48421 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Скачивание исходников Slurm 25.05.1] *****************************************************************************************************
2025-07-22 15:09:42,530 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:09:42 +0000 (0:00:00.276)       0:04:14.268 ********** 
2025-07-22 15:09:42,566 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:09:42,567 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:09:42,575 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:09:45,529 p=48421 u=master n=ansible | changed: [sm01]
2025-07-22 15:09:45,534 p=48421 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Извлечение исходников Slurm] *************************************************************************************************************
2025-07-22 15:09:45,534 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:09:45 +0000 (0:00:03.004)       0:04:17.272 ********** 
2025-07-22 15:09:45,569 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:09:45,570 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:09:45,578 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:09:51,037 p=48421 u=master n=ansible | changed: [sm01]
2025-07-22 15:09:51,041 p=48421 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Конфигурация сборки Slurm с JWT поддержкой] **********************************************************************************************
2025-07-22 15:09:51,041 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:09:51 +0000 (0:00:05.507)       0:04:22.780 ********** 
2025-07-22 15:09:51,078 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:09:51,082 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:09:51,091 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:10:23,414 p=48421 u=master n=ansible | changed: [sm01]
2025-07-22 15:10:23,419 p=48421 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат конфигурации] ******************************************************************************************************************
2025-07-22 15:10:23,420 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:10:23 +0000 (0:00:32.378)       0:04:55.158 ********** 
2025-07-22 15:10:23,460 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:10:23,466 p=48421 u=master n=ansible | ok: [sm01] => 
  slurm_configure.stdout_lines:
  - checking build system type... x86_64-pc-linux-gnu
  - checking host system type... x86_64-pc-linux-gnu
  - checking target system type... x86_64-pc-linux-gnu
  - checking for a BSD-compatible install... /usr/bin/install -c
  - checking whether build environment is sane... yes
  - checking for a race-free mkdir -p... /usr/bin/mkdir -p
  - checking for gawk... gawk
  - checking whether make sets $(MAKE)... yes
  - checking whether make supports nested variables... yes
  - checking whether to enable maintainer-specific portions of Makefiles... no
  - checking whether to include rpath in build... yes
  - checking whether make supports the include directive... yes (GNU style)
  - checking for gcc... gcc
  - checking whether the C compiler works... yes
  - checking for C compiler default output file name... a.out
  - 'checking for suffix of executables... '
  - checking whether we are cross compiling... no
  - checking for suffix of object files... o
  - checking whether the compiler supports GNU C... yes
  - checking whether gcc accepts -g... yes
  - checking for gcc option to enable C11 features... none needed
  - checking whether gcc understands -c and -o together... yes
  - checking dependency style of gcc... gcc3
  - checking for mysql_config... no
  - checking for mariadb_config... /usr/bin/mariadb_config
  - MySQL 10.11.13 test program built properly.
  - checking for gcc... (cached) gcc
  - checking whether the compiler supports GNU C... (cached) yes
  - checking whether gcc accepts -g... (cached) yes
  - checking for gcc option to enable C11 features... (cached) none needed
  - checking whether gcc understands -c and -o together... (cached) yes
  - checking dependency style of gcc... (cached) gcc3
  - checking for g++... g++
  - checking whether the compiler supports GNU C++... yes
  - checking whether g++ accepts -g... yes
  - checking for g++ option to enable C++11 features... none needed
  - checking dependency style of g++... gcc3
  - checking whether make sets $(MAKE)... (cached) yes
  - checking how to print strings... printf
  - checking for a sed that does not truncate output... /usr/bin/sed
  - checking for grep that handles long lines and -e... /usr/bin/grep
  - checking for egrep... /usr/bin/grep -E
  - checking for fgrep... /usr/bin/grep -F
  - checking for ld used by gcc... /usr/bin/ld
  - checking if the linker (/usr/bin/ld) is GNU ld... yes
  - checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
  - checking the name lister (/usr/bin/nm -B) interface... BSD nm
  - checking whether ln -s works... yes
  - checking the maximum length of command line arguments... 1572864
  - checking how to convert x86_64-pc-linux-gnu file names to x86_64-pc-linux-gnu format... func_convert_file_noop
  - checking how to convert x86_64-pc-linux-gnu file names to toolchain format... func_convert_file_noop
  - checking for /usr/bin/ld option to reload object files... -r
  - checking for file... file
  - checking for objdump... objdump
  - checking how to recognize dependent libraries... pass_all
  - checking for dlltool... no
  - checking how to associate runtime and link libraries... printf %s\n
  - checking for ar... ar
  - checking for archiver @FILE support... @
  - checking for strip... strip
  - checking for ranlib... ranlib
  - checking command to parse /usr/bin/nm -B output from gcc object... ok
  - checking for sysroot... no
  - checking for a working dd... /usr/bin/dd
  - checking how to truncate binary pipes... /usr/bin/dd bs=4096 count=1
  - checking for mt... mt
  - checking if mt is a manifest tool... no
  - checking for stdio.h... yes
  - checking for stdlib.h... yes
  - checking for string.h... yes
  - checking for inttypes.h... yes
  - checking for stdint.h... yes
  - checking for strings.h... yes
  - checking for sys/stat.h... yes
  - checking for sys/types.h... yes
  - checking for unistd.h... yes
  - checking for dlfcn.h... yes
  - checking for objdir... .libs
  - checking if gcc supports -fno-rtti -fno-exceptions... no
  - checking for gcc option to produce PIC... -fPIC -DPIC
  - checking if gcc PIC flag -fPIC -DPIC works... yes
  - checking if gcc static flag -static works... yes
  - checking if gcc supports -c -o file.o... yes
  - checking if gcc supports -c -o file.o... (cached) yes
  - checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
  - checking whether -lc should be explicitly linked in... no
  - checking dynamic linker characteristics... GNU/Linux ld.so
  - checking how to hardcode library paths into programs... immediate
  - checking whether stripping libraries is possible... yes
  - checking if libtool supports shared libraries... yes
  - checking whether to build shared libraries... yes
  - checking whether to build static libraries... yes
  - checking how to run the C++ preprocessor... g++ -E
  - checking for ld used by g++... /usr/bin/ld -m elf_x86_64
  - checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes
  - checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
  - checking for g++ option to produce PIC... -fPIC -DPIC
  - checking if g++ PIC flag -fPIC -DPIC works... yes
  - checking if g++ static flag -static works... yes
  - checking if g++ supports -c -o file.o... yes
  - checking if g++ supports -c -o file.o... (cached) yes
  - checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
  - checking dynamic linker characteristics... (cached) GNU/Linux ld.so
  - checking how to hardcode library paths into programs... immediate
  - checking for pkg-config... /usr/bin/pkg-config
  - checking pkg-config is at least version 0.9.0... yes
  - checking whether to install pkg-config slurm.pc file... no
  - checking for -objcopy... no
  - checking for objcopy... objcopy
  - checking for sleep... /usr/bin/sleep
  - checking for su... /usr/bin/su
  - checking whether the compiler is Clang... no
  - checking for library containing socket... none required
  - checking for library containing gethostbyname... none required
  - checking for library containing hstrerror... none required
  - checking for library containing kstat_open... no
  - checking for library containing ns_initparse... -lresolv
  - checking for library containing log... -lm
  - checking for library containing lrint... none required
  - checking for library containing timer_create... none required
  - checking for library containing dlopen... none required
  - checking for mcheck.h... yes
  - checking for values.h... yes
  - checking for socket.h... no
  - checking for sys/socket.h... yes
  - checking for stdbool.h... yes
  - checking for sys/ipc.h... yes
  - checking for sys/shm.h... yes
  - checking for sys/sem.h... yes
  - checking for errno.h... yes
  - checking for stdlib.h... (cached) yes
  - checking for dirent.h... yes
  - checking for pthread.h... yes
  - checking for sys/prctl.h... yes
  - checking for sysint.h... no
  - checking for inttypes.h... (cached) yes
  - checking for termcap.h... yes
  - checking for netdb.h... yes
  - checking for sys/socket.h... (cached) yes
  - checking for sys/systemcfg.h... no
  - checking for sys/dr.h... no
  - checking for sys/vfs.h... yes
  - checking for pam/pam_appl.h... no
  - checking for security/pam_appl.h... yes
  - checking for sys/sysctl.h... no
  - checking for pty.h... yes
  - checking for utmp.h... yes
  - checking for sys/syslog.h... yes
  - checking for linux/sched.h... yes
  - checking for kstat.h... no
  - checking for paths.h... yes
  - checking for limits.h... yes
  - checking for sys/statfs.h... yes
  - checking for sys/ptrace.h... yes
  - checking for float.h... yes
  - checking for sys/statvfs.h... yes
  - checking for sys/wait.h that is POSIX.1 compatible... yes
  - checking for sys/mkdev.h... no
  - checking for sys/sysmacros.h... yes
  - checking for program_invocation_name... yes
  - checking for ptrace64... no
  - checking for numa_available in -lnuma... yes
  - checking whether to enable PAM support... yes
  - checking for pam_get_user in -lpam... yes
  - checking for misc_conv in -lpam_misc... yes
  - checking Link to libslurm.so instead of libslurm.o... shared
  - checking whether sbatch --get-user-env option should load .login... no
  - checking whether byte ordering is bigendian... no
  - checking for C99 support... yes
  - checking whether C compiler accepts -fno-omit-frame-pointer... yes
  - checking for uid_t and gid_t data sizes)... yes
  - checking for json installation... /usr
  - checking for jwt.h... yes
  - checking for jwt_add_header in -ljwt... yes
  - checking for http-parser installation... /usr
  - checking for libyaml installation... /usr
  - checking for linux/version.h... yes
  - checking for Linux epoll(7) interface... yes
  - checking for __builtin_bswap64... yes
  - checking for __builtin_clzll... yes
  - checking for __builtin_ctzll... yes
  - checking for __builtin_popcountll... yes
  - checking for gcc options needed to detect all undeclared functions... none needed
  - checking whether strerror_r is declared... yes
  - checking whether strerror_r returns char *... no
  - checking for fdatasync... yes
  - checking for hstrerror... yes
  - checking for strerror... yes
  - checking for mtrace... yes
  - checking for strndup... yes
  - checking for strlcpy... yes
  - checking for strsignal... yes
  - checking for inet_aton... yes
  - checking for inet_ntop... yes
  - checking for inet_pton... yes
  - checking for setproctitle... no
  - checking for sysctlbyname... no
  - checking for cfmakeraw... yes
  - checking for setresuid... yes
  - checking for get_current_dir_name... yes
  - checking for faccessat... yes
  - checking for eaccess... yes
  - checking for statvfs... yes
  - checking for statfs... yes
  - checking for memfd_create... yes
  - checking for getrandom... yes
  - checking whether hstrerror is declared... no
  - checking whether strsignal is declared... yes
  - checking whether sys_siglist is declared... no
  - checking how to run the C preprocessor... gcc -E
  - checking for egrep -e... (cached) /usr/bin/grep -E
  - checking whether gcc is Clang... no
  - checking whether pthreads work with "-pthread" and "-lpthread"... yes
  - checking for joinable pthread attribute... PTHREAD_CREATE_JOINABLE
  - checking whether more special flags are required for pthreads... no
  - checking for PTHREAD_PRIO_INHERIT... yes
  - 'checking for ofed installation... '
  - checking for h5cc... no
  - checking for h5pcc... no
  - checking for HDF5 type... neither
  - checking for HDF5 libraries... no
  - checking for hwloc installation... /usr
  - checking for nvml.h... yes
  - checking for nvmlInit in -lnvidia-ml... yes
  - 'checking whether RSMI/ROCm in installed in this system... '
  - checking for rocm_smi/rocm_smi.h... no
  - checking for rsmi_init in -lrocm_smi64... no
  - checking for rsmi_dev_drm_render_minor_get in -lrocm_smi64... no
  - checking for rocm_smi/rocm_smi.h... (cached) no
  - checking for rsmi_init in -lrocm_smi64... no
  - checking for rsmi_dev_drm_render_minor_get in -lrocm_smi64... (cached) no
  - 'checking whether oneAPI in installed in this system... '
  - checking for ze_api.h... no
  - checking for ze_api.h... no
  - checking for pmix installation... /usr/lib/x86_64-linux-gnu/pmix2
  - 'checking for freeipmi installation... '
  - 'configure: support for ucx disabled'
  - checking whether Slurm internal X11 support is enabled... yes
  - 'checking whether Slurm internal SELinux support is enabled... '
  - checking for librdkafka installation... checking for rdkafka.h... no
  - checking for rdkafka.h... no
  - ''
  - 'checking for s2n installation... '
  - checking for bpf installation... /usr
  - checking for dbus-1 >= 1.11.16... yes
  - checking for check >= 0.9.8... no
  - 'configure: checking whether to compile sview'
  - checking for pkg-config... (cached) /usr/bin/pkg-config
  - checking pkg-config is at least version 0.16... yes
  - checking for glib-2.0 >= 2.7.1 gthread-2.0... yes
  - checking for GLIB - version >= 2.7.1... yes (version 2.80.0)
  - checking for pkg-config... (cached) /usr/bin/pkg-config
  - checking pkg-config is at least version 0.7... yes
  - checking for GTK+ - version >= 2.7.1... yes (version 2.24.33)
  - 'checking whether HPE Slingshot is installed in this system... '
  - checking for libcxi/libcxi.h... no
  - checking for __progname... yes
  - checking whether optimizations are enabled... yes
  - checking whether or not developer options are enabled... yes
  - checking whether debugging is enabled... checking whether C compiler accepts -ggdb3... yes
  - 'yes'
  - checking whether memory leak debugging is enabled... no
  - checking whether debugger partial attach enabled... no
  - checking whether salloc should kill child processes at job termination... no
  - checking for slurmctld default port... 6817
  - checking for slurmd default port... 6818
  - checking for slurmdbd default port... 6819
  - checking for slurmctld default port count... 1
  - checking whether to compile slurmrestd... yes
  - checking for slurmrestd default port... 6820
  - checking whether to enable lua plugin support... checking for lua5.3... yes
  - checking for whether we can link to liblua... yes lua5.3
  - checking whether man2html is available... checking for man2html... yes
  - checking for bash-completion package... yes
  - checking for bash-completion completionsdir path... ${datarootdir}/bash-completion/completions
  - checking for support of printf("%s", NULL)... yes
  - checking for whether to include readline suport... yes
  - checking for systemd presence... yes
  - checking for munge installation... /usr
  - checking whether to enable multiple-slurmd support... no
  - checking for openpty in -lutil... yes
  - checking for gawk... (cached) gawk
  - checking for curl-config... /usr/bin/curl-config
  - checking for the version of libcurl... 8.5.0
  - checking whether libcurl is usable... yes
  - checking for curl_free... yes
  - checking size of void *... 8
  - checking whether deprecated options are enabled... no
  - checking that generated files are newer than configure... done
  - 'configure: creating ./config.status'
  - 'config.status: creating Makefile'
  - 'config.status: creating auxdir/Makefile'
  - 'config.status: creating contribs/Makefile'
  - 'config.status: creating contribs/lua/Makefile'
  - 'config.status: creating contribs/nss_slurm/Makefile'
  - 'config.status: creating contribs/openlava/Makefile'
  - 'config.status: creating contribs/pam/Makefile'
  - 'config.status: creating contribs/pam_slurm_adopt/Makefile'
  - 'config.status: creating contribs/perlapi/Makefile'
  - 'config.status: creating contribs/perlapi/libslurm/Makefile'
  - 'config.status: creating contribs/perlapi/libslurm/perl/Makefile.PL'
  - 'config.status: creating contribs/perlapi/libslurmdb/Makefile'
  - 'config.status: creating contribs/perlapi/libslurmdb/perl/Makefile.PL'
  - 'config.status: creating contribs/pmi/Makefile'
  - 'config.status: creating contribs/pmi2/Makefile'
  - 'config.status: creating contribs/seff/Makefile'
  - 'config.status: creating contribs/sgather/Makefile'
  - 'config.status: creating contribs/sjobexit/Makefile'
  - 'config.status: creating contribs/slurm_completion_help/Makefile'
  - 'config.status: creating contribs/torque/Makefile'
  - 'config.status: creating doc/Makefile'
  - 'config.status: creating doc/html/Makefile'
  - 'config.status: creating doc/html/configurator.easy.html'
  - 'config.status: creating doc/html/configurator.html'
  - 'config.status: creating doc/man/Makefile'
  - 'config.status: creating doc/man/man1/Makefile'
  - 'config.status: creating doc/man/man5/Makefile'
  - 'config.status: creating doc/man/man8/Makefile'
  - 'config.status: creating etc/Makefile'
  - 'config.status: creating src/Makefile'
  - 'config.status: creating src/api/Makefile'
  - 'config.status: creating src/bcast/Makefile'
  - 'config.status: creating src/common/Makefile'
  - 'config.status: creating src/conmgr/Makefile'
  - 'config.status: creating src/curl/Makefile'
  - 'config.status: creating src/database/Makefile'
  - 'config.status: creating src/interfaces/Makefile'
  - 'config.status: creating src/lua/Makefile'
  - 'config.status: creating src/plugins/Makefile'
  - 'config.status: creating src/plugins/accounting_storage/Makefile'
  - 'config.status: creating src/plugins/accounting_storage/common/Makefile'
  - 'config.status: creating src/plugins/accounting_storage/ctld_relay/Makefile'
  - 'config.status: creating src/plugins/accounting_storage/mysql/Makefile'
  - 'config.status: creating src/plugins/accounting_storage/slurmdbd/Makefile'
  - 'config.status: creating src/plugins/acct_gather_energy/Makefile'
  - 'config.status: creating src/plugins/acct_gather_energy/gpu/Makefile'
  - 'config.status: creating src/plugins/acct_gather_energy/ibmaem/Makefile'
  - 'config.status: creating src/plugins/acct_gather_energy/ipmi/Makefile'
  - 'config.status: creating src/plugins/acct_gather_energy/pm_counters/Makefile'
  - 'config.status: creating src/plugins/acct_gather_energy/rapl/Makefile'
  - 'config.status: creating src/plugins/acct_gather_energy/xcc/Makefile'
  - 'config.status: creating src/plugins/acct_gather_filesystem/Makefile'
  - 'config.status: creating src/plugins/acct_gather_filesystem/lustre/Makefile'
  - 'config.status: creating src/plugins/acct_gather_interconnect/Makefile'
  - 'config.status: creating src/plugins/acct_gather_interconnect/ofed/Makefile'
  - 'config.status: creating src/plugins/acct_gather_interconnect/sysfs/Makefile'
  - 'config.status: creating src/plugins/acct_gather_profile/Makefile'
  - 'config.status: creating src/plugins/acct_gather_profile/hdf5/Makefile'
  - 'config.status: creating src/plugins/acct_gather_profile/hdf5/sh5util/Makefile'
  - 'config.status: creating src/plugins/acct_gather_profile/influxdb/Makefile'
  - 'config.status: creating src/plugins/auth/Makefile'
  - 'config.status: creating src/plugins/auth/jwt/Makefile'
  - 'config.status: creating src/plugins/auth/munge/Makefile'
  - 'config.status: creating src/plugins/auth/none/Makefile'
  - 'config.status: creating src/plugins/auth/slurm/Makefile'
  - 'config.status: creating src/plugins/burst_buffer/Makefile'
  - 'config.status: creating src/plugins/burst_buffer/common/Makefile'
  - 'config.status: creating src/plugins/burst_buffer/datawarp/Makefile'
  - 'config.status: creating src/plugins/burst_buffer/lua/Makefile'
  - 'config.status: creating src/plugins/certgen/Makefile'
  - 'config.status: creating src/plugins/certgen/script/Makefile'
  - 'config.status: creating src/plugins/certmgr/Makefile'
  - 'config.status: creating src/plugins/certmgr/script/Makefile'
  - 'config.status: creating src/plugins/cgroup/Makefile'
  - 'config.status: creating src/plugins/cgroup/common/Makefile'
  - 'config.status: creating src/plugins/cgroup/v1/Makefile'
  - 'config.status: creating src/plugins/cgroup/v2/Makefile'
  - 'config.status: creating src/plugins/cli_filter/Makefile'
  - 'config.status: creating src/plugins/cli_filter/common/Makefile'
  - 'config.status: creating src/plugins/cli_filter/lua/Makefile'
  - 'config.status: creating src/plugins/cli_filter/syslog/Makefile'
  - 'config.status: creating src/plugins/cli_filter/user_defaults/Makefile'
  - 'config.status: creating src/plugins/cred/Makefile'
  - 'config.status: creating src/plugins/cred/common/Makefile'
  - 'config.status: creating src/plugins/cred/munge/Makefile'
  - 'config.status: creating src/plugins/cred/none/Makefile'
  - 'config.status: creating src/plugins/data_parser/Makefile'
  - 'config.status: creating src/plugins/data_parser/v0.0.40/Makefile'
  - 'config.status: creating src/plugins/data_parser/v0.0.41/Makefile'
  - 'config.status: creating src/plugins/data_parser/v0.0.42/Makefile'
  - 'config.status: creating src/plugins/data_parser/v0.0.43/Makefile'
  - 'config.status: creating src/plugins/gpu/Makefile'
  - 'config.status: creating src/plugins/gpu/common/Makefile'
  - 'config.status: creating src/plugins/gpu/generic/Makefile'
  - 'config.status: creating src/plugins/gpu/nrt/Makefile'
  - 'config.status: creating src/plugins/gpu/nvidia/Makefile'
  - 'config.status: creating src/plugins/gpu/nvml/Makefile'
  - 'config.status: creating src/plugins/gpu/oneapi/Makefile'
  - 'config.status: creating src/plugins/gpu/rsmi/Makefile'
  - 'config.status: creating src/plugins/gres/Makefile'
  - 'config.status: creating src/plugins/gres/common/Makefile'
  - 'config.status: creating src/plugins/gres/gpu/Makefile'
  - 'config.status: creating src/plugins/gres/mps/Makefile'
  - 'config.status: creating src/plugins/gres/nic/Makefile'
  - 'config.status: creating src/plugins/gres/shard/Makefile'
  - 'config.status: creating src/plugins/hash/Makefile'
  - 'config.status: creating src/plugins/hash/common_xkcp/Makefile'
  - 'config.status: creating src/plugins/hash/k12/Makefile'
  - 'config.status: creating src/plugins/hash/sha3/Makefile'
  - 'config.status: creating src/plugins/job_container/Makefile'
  - 'config.status: creating src/plugins/job_container/tmpfs/Makefile'
  - 'config.status: creating src/plugins/job_submit/Makefile'
  - 'config.status: creating src/plugins/job_submit/all_partitions/Makefile'
  - 'config.status: creating src/plugins/job_submit/defaults/Makefile'
  - 'config.status: creating src/plugins/job_submit/logging/Makefile'
  - 'config.status: creating src/plugins/job_submit/lua/Makefile'
  - 'config.status: creating src/plugins/job_submit/partition/Makefile'
  - 'config.status: creating src/plugins/job_submit/pbs/Makefile'
  - 'config.status: creating src/plugins/job_submit/require_timelimit/Makefile'
  - 'config.status: creating src/plugins/job_submit/throttle/Makefile'
  - 'config.status: creating src/plugins/jobacct_gather/Makefile'
  - 'config.status: creating src/plugins/jobacct_gather/cgroup/Makefile'
  - 'config.status: creating src/plugins/jobacct_gather/common/Makefile'
  - 'config.status: creating src/plugins/jobacct_gather/linux/Makefile'
  - 'config.status: creating src/plugins/jobcomp/Makefile'
  - 'config.status: creating src/plugins/jobcomp/common/Makefile'
  - 'config.status: creating src/plugins/jobcomp/elasticsearch/Makefile'
  - 'config.status: creating src/plugins/jobcomp/filetxt/Makefile'
  - 'config.status: creating src/plugins/jobcomp/kafka/Makefile'
  - 'config.status: creating src/plugins/jobcomp/lua/Makefile'
  - 'config.status: creating src/plugins/jobcomp/mysql/Makefile'
  - 'config.status: creating src/plugins/jobcomp/script/Makefile'
  - 'config.status: creating src/plugins/mcs/Makefile'
  - 'config.status: creating src/plugins/mcs/account/Makefile'
  - 'config.status: creating src/plugins/mcs/group/Makefile'
  - 'config.status: creating src/plugins/mcs/label/Makefile'
  - 'config.status: creating src/plugins/mcs/user/Makefile'
  - 'config.status: creating src/plugins/mpi/Makefile'
  - 'config.status: creating src/plugins/mpi/cray_shasta/Makefile'
  - 'config.status: creating src/plugins/mpi/pmi2/Makefile'
  - 'config.status: creating src/plugins/mpi/pmix/Makefile'
  - 'config.status: creating src/plugins/node_features/Makefile'
  - 'config.status: creating src/plugins/node_features/helpers/Makefile'
  - 'config.status: creating src/plugins/node_features/knl_generic/Makefile'
  - 'config.status: creating src/plugins/preempt/Makefile'
  - 'config.status: creating src/plugins/preempt/partition_prio/Makefile'
  - 'config.status: creating src/plugins/preempt/qos/Makefile'
  - 'config.status: creating src/plugins/prep/Makefile'
  - 'config.status: creating src/plugins/prep/script/Makefile'
  - 'config.status: creating src/plugins/priority/Makefile'
  - 'config.status: creating src/plugins/priority/basic/Makefile'
  - 'config.status: creating src/plugins/priority/multifactor/Makefile'
  - 'config.status: creating src/plugins/proctrack/Makefile'
  - 'config.status: creating src/plugins/proctrack/cgroup/Makefile'
  - 'config.status: creating src/plugins/proctrack/linuxproc/Makefile'
  - 'config.status: creating src/plugins/proctrack/pgid/Makefile'
  - 'config.status: creating src/plugins/sched/Makefile'
  - 'config.status: creating src/plugins/sched/backfill/Makefile'
  - 'config.status: creating src/plugins/sched/builtin/Makefile'
  - 'config.status: creating src/plugins/select/Makefile'
  - 'config.status: creating src/plugins/select/cons_tres/Makefile'
  - 'config.status: creating src/plugins/select/linear/Makefile'
  - 'config.status: creating src/plugins/serializer/Makefile'
  - 'config.status: creating src/plugins/serializer/json/Makefile'
  - 'config.status: creating src/plugins/serializer/url-encoded/Makefile'
  - 'config.status: creating src/plugins/serializer/yaml/Makefile'
  - 'config.status: creating src/plugins/site_factor/Makefile'
  - 'config.status: creating src/plugins/site_factor/example/Makefile'
  - 'config.status: creating src/plugins/switch/Makefile'
  - 'config.status: creating src/plugins/switch/hpe_slingshot/Makefile'
  - 'config.status: creating src/plugins/switch/nvidia_imex/Makefile'
  - 'config.status: creating src/plugins/task/Makefile'
  - 'config.status: creating src/plugins/task/affinity/Makefile'
  - 'config.status: creating src/plugins/task/cgroup/Makefile'
  - 'config.status: creating src/plugins/tls/Makefile'
  - 'config.status: creating src/plugins/tls/none/Makefile'
  - 'config.status: creating src/plugins/tls/s2n/Makefile'
  - 'config.status: creating src/plugins/topology/Makefile'
  - 'config.status: creating src/plugins/topology/block/Makefile'
  - 'config.status: creating src/plugins/topology/common/Makefile'
  - 'config.status: creating src/plugins/topology/flat/Makefile'
  - 'config.status: creating src/plugins/topology/tree/Makefile'
  - 'config.status: creating src/sacct/Makefile'
  - 'config.status: creating src/sackd/Makefile'
  - 'config.status: creating src/sacctmgr/Makefile'
  - 'config.status: creating src/salloc/Makefile'
  - 'config.status: creating src/sattach/Makefile'
  - 'config.status: creating src/scrun/Makefile'
  - 'config.status: creating src/sbatch/Makefile'
  - 'config.status: creating src/sbcast/Makefile'
  - 'config.status: creating src/scancel/Makefile'
  - 'config.status: creating src/scontrol/Makefile'
  - 'config.status: creating src/scrontab/Makefile'
  - 'config.status: creating src/sdiag/Makefile'
  - 'config.status: creating src/sinfo/Makefile'
  - 'config.status: creating src/slurmctld/Makefile'
  - 'config.status: creating src/slurmd/Makefile'
  - 'config.status: creating src/slurmd/common/Makefile'
  - 'config.status: creating src/slurmd/slurmd/Makefile'
  - 'config.status: creating src/slurmd/slurmstepd/Makefile'
  - 'config.status: creating src/slurmdbd/Makefile'
  - 'config.status: creating src/slurmrestd/Makefile'
  - 'config.status: creating src/slurmrestd/plugins/Makefile'
  - 'config.status: creating src/slurmrestd/plugins/auth/Makefile'
  - 'config.status: creating src/slurmrestd/plugins/auth/jwt/Makefile'
  - 'config.status: creating src/slurmrestd/plugins/auth/local/Makefile'
  - 'config.status: creating src/slurmrestd/plugins/openapi/Makefile'
  - 'config.status: creating src/slurmrestd/plugins/openapi/slurmctld/Makefile'
  - 'config.status: creating src/slurmrestd/plugins/openapi/slurmdbd/Makefile'
  - 'config.status: creating src/sprio/Makefile'
  - 'config.status: creating src/squeue/Makefile'
  - 'config.status: creating src/sreport/Makefile'
  - 'config.status: creating src/srun/Makefile'
  - 'config.status: creating src/sshare/Makefile'
  - 'config.status: creating src/sstat/Makefile'
  - 'config.status: creating src/stepmgr/Makefile'
  - 'config.status: creating src/strigger/Makefile'
  - 'config.status: creating src/sview/Makefile'
  - 'config.status: creating testsuite/Makefile'
  - 'config.status: creating testsuite/testsuite.conf.sample'
  - 'config.status: creating testsuite/expect/Makefile'
  - 'config.status: creating testsuite/slurm_unit/Makefile'
  - 'config.status: creating testsuite/slurm_unit/backfill/Makefile'
  - 'config.status: creating testsuite/slurm_unit/common/Makefile'
  - 'config.status: creating testsuite/slurm_unit/common/bitstring/Makefile'
  - 'config.status: creating testsuite/slurm_unit/common/hostlist/Makefile'
  - 'config.status: creating testsuite/slurm_unit/common/slurm_protocol_defs/Makefile'
  - 'config.status: creating testsuite/slurm_unit/common/slurm_protocol_pack/Makefile'
  - 'config.status: creating testsuite/slurm_unit/common/slurmdb_defs/Makefile'
  - 'config.status: creating testsuite/slurm_unit/common/slurmdb_pack/Makefile'
  - 'config.status: creating testsuite/slurm_unit/topology/Makefile'
  - 'config.status: creating config.h'
  - 'config.status: creating slurm/slurm_version.h'
  - 'config.status: executing depfiles commands'
  - 'config.status: executing libtool commands'
2025-07-22 15:10:23,468 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:10:23,468 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:10:23,472 p=48421 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Компиляция Slurm (это займет время...)] **************************************************************************************************
2025-07-22 15:10:23,472 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:10:23 +0000 (0:00:00.052)       0:04:55.210 ********** 
2025-07-22 15:10:23,498 p=48421 u=master n=ansible | fatal: [sm01]: FAILED! => 
  msg: |-
    The task includes an option with an undefined variable. The error was: 'ansible_processor_vcpus' is undefined. 'ansible_processor_vcpus' is undefined
  
    The error appears to be in '/home/master/22Jul/slurm-hpc-cluster/roles/slurm_build/tasks/main.yml': line 106, column 3, but may
    be elsewhere in the file depending on the exact syntax problem.
  
    The offending line appears to be:
  
  
    - name: "[SLURM_BUILD] Компиляция Slurm (это займет время...)"
      ^ here
2025-07-22 15:10:23,507 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:10:23,509 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:10:23,519 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:10:23,524 p=48421 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка Slurm на master] ***************************************************************************************************************
2025-07-22 15:10:23,524 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:10:23 +0000 (0:00:00.051)       0:04:55.262 ********** 
2025-07-22 15:10:23,547 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:10:23,549 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:10:23,557 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:10:23,561 p=48421 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание архива Slurm для копирования] ***************************************************************************************************
2025-07-22 15:10:23,562 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:10:23 +0000 (0:00:00.037)       0:04:55.300 ********** 
2025-07-22 15:10:23,588 p=48421 u=master n=ansible | skipping: [sm02]
2025-07-22 15:10:23,590 p=48421 u=master n=ansible | skipping: [cn01]
2025-07-22 15:10:23,598 p=48421 u=master n=ansible | skipping: [cn02]
2025-07-22 15:10:23,602 p=48421 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] *************************************************************************************************
2025-07-22 15:10:23,603 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:10:23 +0000 (0:00:00.040)       0:04:55.341 ********** 
2025-07-22 15:10:24,602 p=48421 u=master n=ansible | changed: [sm02]
2025-07-22 15:10:24,611 p=48421 u=master n=ansible | changed: [cn02]
2025-07-22 15:10:24,653 p=48421 u=master n=ansible | changed: [cn01]
2025-07-22 15:10:24,659 p=48421 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Синхронизация Slurm с master на все остальные узлы] **************************************************************************************
2025-07-22 15:10:24,659 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:10:24 +0000 (0:00:01.056)       0:04:56.398 ********** 
2025-07-22 15:10:25,338 p=48421 u=master n=ansible | fatal: [cn01 -> sm01]: FAILED! => changed=false 
  cmd: /usr/bin/rsync --delay-updates -F --compress --archive --rsh='/usr/bin/ssh -S none -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null' --rsync-path='sudo -u root rsync' --exclude=*.log --exclude=*.pid --out-format='<<CHANGED>>%i %n%L' /opt/slurm/ master@cn01:/opt/slurm/
  msg: |-
    Warning: Permanently added 'cn01' (ED25519) to the list of known hosts.
    Permission denied, please try again.
    Permission denied, please try again.
    master@cn01: Permission denied (publickey,password).
    rsync: connection unexpectedly closed (0 bytes received so far) [sender]
    rsync error: unexplained error (code 255) at io.c(232) [sender=3.2.7]
  rc: 255
2025-07-22 15:10:25,343 p=48421 u=master n=ansible | fatal: [cn02 -> sm01]: FAILED! => changed=false 
  cmd: /usr/bin/rsync --delay-updates -F --compress --archive --rsh='/usr/bin/ssh -S none -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null' --rsync-path='sudo -u root rsync' --exclude=*.log --exclude=*.pid --out-format='<<CHANGED>>%i %n%L' /opt/slurm/ master@cn02:/opt/slurm/
  msg: |-
    Warning: Permanently added 'cn02' (ED25519) to the list of known hosts.
    Permission denied, please try again.
    Permission denied, please try again.
    master@cn02: Permission denied (publickey,password).
    rsync: connection unexpectedly closed (0 bytes received so far) [sender]
    rsync error: unexplained error (code 255) at io.c(232) [sender=3.2.7]
  rc: 255
2025-07-22 15:10:25,345 p=48421 u=master n=ansible | fatal: [sm02 -> sm01]: FAILED! => changed=false 
  cmd: /usr/bin/rsync --delay-updates -F --compress --archive --rsh='/usr/bin/ssh -S none -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null' --rsync-path='sudo -u root rsync' --exclude=*.log --exclude=*.pid --out-format='<<CHANGED>>%i %n%L' /opt/slurm/ master@sm02:/opt/slurm/
  msg: |-
    Warning: Permanently added 'sm02' (ED25519) to the list of known hosts.
    Permission denied, please try again.
    Permission denied, please try again.
    master@sm02: Permission denied (publickey,password).
    rsync: connection unexpectedly closed (0 bytes received so far) [sender]
    rsync error: unexplained error (code 255) at io.c(232) [sender=3.2.7]
  rc: 255
2025-07-22 15:10:25,346 p=48421 u=master n=ansible | PLAY RECAP *****************************************************************************************************************************************************************
2025-07-22 15:10:25,347 p=48421 u=master n=ansible | cn01                       : ok=24   changed=4    unreachable=0    failed=1    skipped=22   rescued=0    ignored=0   
2025-07-22 15:10:25,347 p=48421 u=master n=ansible | cn02                       : ok=24   changed=4    unreachable=0    failed=1    skipped=22   rescued=0    ignored=0   
2025-07-22 15:10:25,347 p=48421 u=master n=ansible | sm01                       : ok=39   changed=13   unreachable=0    failed=1    skipped=4    rescued=0    ignored=0   
2025-07-22 15:10:25,347 p=48421 u=master n=ansible | sm02                       : ok=24   changed=5    unreachable=0    failed=1    skipped=22   rescued=0    ignored=0   
2025-07-22 15:10:25,347 p=48421 u=master n=ansible | Playbook run took 0 days, 0 hours, 4 minutes, 57 seconds
2025-07-22 15:10:25,347 p=48421 u=master n=ansible | Tuesday 22 July 2025  15:10:25 +0000 (0:00:00.687)       0:04:57.086 ********** 
2025-07-22 15:10:25,347 p=48421 u=master n=ansible | =============================================================================== 
2025-07-22 15:10:25,348 p=48421 u=master n=ansible | slurm_build : [SLURM_BUILD] Установка дополнительных зависимостей для сборки -------------------------------------------------------------------------------------- 221.83s
2025-07-22 15:10:25,348 p=48421 u=master n=ansible | slurm_build : [SLURM_BUILD] Конфигурация сборки Slurm с JWT поддержкой --------------------------------------------------------------------------------------------- 32.38s
2025-07-22 15:10:25,348 p=48421 u=master n=ansible | common : [COMMON] Обновление apt cache ------------------------------------------------------------------------------------------------------------------------------ 6.77s
2025-07-22 15:10:25,348 p=48421 u=master n=ansible | slurm_build : [SLURM_BUILD] Извлечение исходников Slurm ------------------------------------------------------------------------------------------------------------- 5.51s
2025-07-22 15:10:25,348 p=48421 u=master n=ansible | slurm_build : [SLURM_BUILD] Скачивание исходников Slurm 25.05.1 ----------------------------------------------------------------------------------------------------- 3.00s
2025-07-22 15:10:25,348 p=48421 u=master n=ansible | common : [COMMON] Установка HWLOC ----------------------------------------------------------------------------------------------------------------------------------- 2.61s
2025-07-22 15:10:25,348 p=48421 u=master n=ansible | common : [COMMON] Запуск и включение MUNGE -------------------------------------------------------------------------------------------------------------------------- 1.95s
2025-07-22 15:10:25,348 p=48421 u=master n=ansible | common : [COMMON] Остановка MUNGE перед настройкой ------------------------------------------------------------------------------------------------------------------ 1.92s
2025-07-22 15:10:25,348 p=48421 u=master n=ansible | common : [COMMON] Создание базовых директорий Slurm ----------------------------------------------------------------------------------------------------------------- 1.66s
2025-07-22 15:10:25,348 p=48421 u=master n=ansible | common : [COMMON] Настройка экспорта NFS с конкретными IP ----------------------------------------------------------------------------------------------------------- 1.55s
2025-07-22 15:10:25,349 p=48421 u=master n=ansible | Проверка доступного места на диске ---------------------------------------------------------------------------------------------------------------------------------- 1.23s
2025-07-22 15:10:25,349 p=48421 u=master n=ansible | common : [COMMON] Обеспечение hostname resolution для кластера ------------------------------------------------------------------------------------------------------ 1.19s
2025-07-22 15:10:25,349 p=48421 u=master n=ansible | common : [COMMON] Установка MUNGE ----------------------------------------------------------------------------------------------------------------------------------- 1.18s
2025-07-22 15:10:25,349 p=48421 u=master n=ansible | common : [COMMON] Установка базовых пакетов ------------------------------------------------------------------------------------------------------------------------- 1.15s
2025-07-22 15:10:25,349 p=48421 u=master n=ansible | common : [COMMON] Настройка прав доступа MUNGE ---------------------------------------------------------------------------------------------------------------------- 1.14s
2025-07-22 15:10:25,349 p=48421 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------- 1.06s
2025-07-22 15:10:25,349 p=48421 u=master n=ansible | common : [COMMON] Установка NFS client ------------------------------------------------------------------------------------------------------------------------------ 1.03s
2025-07-22 15:10:25,349 p=48421 u=master n=ansible | common : [COMMON] Установка NFS server на master -------------------------------------------------------------------------------------------------------------------- 1.02s
2025-07-22 15:10:25,349 p=48421 u=master n=ansible | common : [COMMON] Распространение MUNGE ключа на все узлы ----------------------------------------------------------------------------------------------------------- 0.95s
2025-07-22 15:10:25,349 p=48421 u=master n=ansible | common : [COMMON] Монтирование NFS shares --------------------------------------------------------------------------------------------------------------------------- 0.71s
2025-07-22 15:18:42,424 p=49182 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 15:18:42,425 p=49182 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 15:18:42,875 p=49182 u=master n=ansible | PLAY [Тестирование роли slurm_build] ***************************************************************************************************************************************
2025-07-22 15:18:42,897 p=49182 u=master n=ansible | TASK [Информация о сборке Slurm] *******************************************************************************************************************************************
2025-07-22 15:18:42,897 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:18:42 +0000 (0:00:00.025)       0:00:00.025 ********** 
2025-07-22 15:18:42,947 p=49182 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F528 Начинаем сборку Slurm 25.05.1\n\U0001F4CD Сборка на: sm01\n\U0001F4E6 Установка на: sm01, sm02, cn01, cn02\n\U0001F510 JWT поддержка включена"
2025-07-22 15:18:42,952 p=49182 u=master n=ansible | TASK [Проверка доступного места на диске] **********************************************************************************************************************************
2025-07-22 15:18:42,952 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:18:42 +0000 (0:00:00.054)       0:00:00.080 ********** 
2025-07-22 15:18:42,983 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:18:42,985 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:18:42,993 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:18:44,073 p=49182 u=master n=ansible | changed: [sm01]
2025-07-22 15:18:44,077 p=49182 u=master n=ansible | TASK [Предупреждение о месте на диске] *************************************************************************************************************************************
2025-07-22 15:18:44,077 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:18:44 +0000 (0:00:01.125)       0:00:01.205 ********** 
2025-07-22 15:18:44,110 p=49182 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4BE Доступно места в /tmp: 39G\n⚠️  Для сборки Slurm требуется ~2GB свободного места"
2025-07-22 15:18:44,110 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:18:44,111 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:18:44,118 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:18:44,138 p=49182 u=master n=ansible | TASK [common : [COMMON] Начало выполнения роли common] *********************************************************************************************************************
2025-07-22 15:18:44,138 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:18:44 +0000 (0:00:00.061)       0:00:01.266 ********** 
2025-07-22 15:18:44,171 p=49182 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm01"
2025-07-22 15:18:44,172 p=49182 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm02"
2025-07-22 15:18:44,176 p=49182 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn01"
2025-07-22 15:18:44,186 p=49182 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn02"
2025-07-22 15:18:44,190 p=49182 u=master n=ansible | TASK [common : [COMMON] Обновление apt cache] ******************************************************************************************************************************
2025-07-22 15:18:44,190 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:18:44 +0000 (0:00:00.051)       0:00:01.318 ********** 
2025-07-22 15:18:45,046 p=49182 u=master n=ansible | ok: [sm01]
2025-07-22 15:18:45,766 p=49182 u=master n=ansible | ok: [sm02]
2025-07-22 15:18:45,787 p=49182 u=master n=ansible | ok: [cn02]
2025-07-22 15:18:45,810 p=49182 u=master n=ansible | ok: [cn01]
2025-07-22 15:18:45,814 p=49182 u=master n=ansible | TASK [common : [COMMON] Установка базовых пакетов] *************************************************************************************************************************
2025-07-22 15:18:45,815 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:18:45 +0000 (0:00:01.624)       0:00:02.943 ********** 
2025-07-22 15:18:46,809 p=49182 u=master n=ansible | ok: [cn01]
2025-07-22 15:18:46,848 p=49182 u=master n=ansible | ok: [sm02]
2025-07-22 15:18:46,912 p=49182 u=master n=ansible | ok: [cn02]
2025-07-22 15:19:01,350 p=49182 u=master n=ansible | changed: [sm01]
2025-07-22 15:19:01,355 p=49182 u=master n=ansible | TASK [common : [COMMON] Настройка timezone] ********************************************************************************************************************************
2025-07-22 15:19:01,355 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:01 +0000 (0:00:15.540)       0:00:18.483 ********** 
2025-07-22 15:19:01,852 p=49182 u=master n=ansible | ok: [sm01]
2025-07-22 15:19:01,856 p=49182 u=master n=ansible | ok: [cn01]
2025-07-22 15:19:01,868 p=49182 u=master n=ansible | ok: [sm02]
2025-07-22 15:19:01,872 p=49182 u=master n=ansible | ok: [cn02]
2025-07-22 15:19:01,876 p=49182 u=master n=ansible | TASK [common : [COMMON] Обеспечение hostname resolution для кластера] ******************************************************************************************************
2025-07-22 15:19:01,877 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:01 +0000 (0:00:00.521)       0:00:19.005 ********** 
2025-07-22 15:19:02,262 p=49182 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:19:02,265 p=49182 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:19:02,268 p=49182 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:19:02,272 p=49182 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:19:02,502 p=49182 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:19:02,512 p=49182 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:19:02,514 p=49182 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:19:02,515 p=49182 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:19:02,742 p=49182 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:19:02,754 p=49182 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:19:02,760 p=49182 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:19:02,762 p=49182 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:19:02,985 p=49182 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:19:02,999 p=49182 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:19:03,004 p=49182 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:19:03,011 p=49182 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:19:03,016 p=49182 u=master n=ansible | TASK [common : [COMMON] Создание пользователя slurm] ***********************************************************************************************************************
2025-07-22 15:19:03,016 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:03 +0000 (0:00:01.139)       0:00:20.144 ********** 
2025-07-22 15:19:03,513 p=49182 u=master n=ansible | ok: [cn01]
2025-07-22 15:19:03,514 p=49182 u=master n=ansible | ok: [sm02]
2025-07-22 15:19:03,515 p=49182 u=master n=ansible | ok: [cn02]
2025-07-22 15:19:03,524 p=49182 u=master n=ansible | ok: [sm01]
2025-07-22 15:19:03,528 p=49182 u=master n=ansible | TASK [common : [COMMON] Установка MUNGE] ***********************************************************************************************************************************
2025-07-22 15:19:03,528 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:03 +0000 (0:00:00.511)       0:00:20.656 ********** 
2025-07-22 15:19:04,522 p=49182 u=master n=ansible | ok: [cn01]
2025-07-22 15:19:04,549 p=49182 u=master n=ansible | ok: [sm02]
2025-07-22 15:19:04,565 p=49182 u=master n=ansible | ok: [sm01]
2025-07-22 15:19:04,611 p=49182 u=master n=ansible | ok: [cn02]
2025-07-22 15:19:04,615 p=49182 u=master n=ansible | TASK [common : [COMMON] Остановка MUNGE перед настройкой] ******************************************************************************************************************
2025-07-22 15:19:04,616 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:04 +0000 (0:00:01.087)       0:00:21.744 ********** 
2025-07-22 15:19:06,462 p=49182 u=master n=ansible | changed: [sm02]
2025-07-22 15:19:06,469 p=49182 u=master n=ansible | changed: [cn01]
2025-07-22 15:19:06,518 p=49182 u=master n=ansible | changed: [cn02]
2025-07-22 15:19:06,625 p=49182 u=master n=ansible | changed: [sm01]
2025-07-22 15:19:06,630 p=49182 u=master n=ansible | TASK [common : [COMMON] Создание MUNGE ключа на master узле] ***************************************************************************************************************
2025-07-22 15:19:06,630 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:06 +0000 (0:00:02.014)       0:00:23.758 ********** 
2025-07-22 15:19:06,664 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:06,666 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:06,675 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:06,889 p=49182 u=master n=ansible | ok: [sm01]
2025-07-22 15:19:06,893 p=49182 u=master n=ansible | TASK [common : [COMMON] Получение MUNGE ключа с master узла] ***************************************************************************************************************
2025-07-22 15:19:06,893 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:06 +0000 (0:00:00.263)       0:00:24.021 ********** 
2025-07-22 15:19:06,929 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:06,931 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:06,941 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:07,266 p=49182 u=master n=ansible | ok: [sm01]
2025-07-22 15:19:07,271 p=49182 u=master n=ansible | TASK [common : [COMMON] Распространение MUNGE ключа на все узлы] ***********************************************************************************************************
2025-07-22 15:19:07,271 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:07 +0000 (0:00:00.378)       0:00:24.399 ********** 
2025-07-22 15:19:07,296 p=49182 u=master n=ansible | skipping: [sm01]
2025-07-22 15:19:08,240 p=49182 u=master n=ansible | ok: [sm02]
2025-07-22 15:19:08,242 p=49182 u=master n=ansible | ok: [cn01]
2025-07-22 15:19:08,243 p=49182 u=master n=ansible | ok: [cn02]
2025-07-22 15:19:08,247 p=49182 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа MUNGE] **********************************************************************************************************************
2025-07-22 15:19:08,247 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:08 +0000 (0:00:00.975)       0:00:25.375 ********** 
2025-07-22 15:19:08,535 p=49182 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:19:08,537 p=49182 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:19:08,549 p=49182 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:19:08,563 p=49182 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:19:08,790 p=49182 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:19:08,792 p=49182 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:19:08,809 p=49182 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:19:08,818 p=49182 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:19:09,044 p=49182 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:19:09,046 p=49182 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:19:09,063 p=49182 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:19:09,076 p=49182 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:19:09,299 p=49182 u=master n=ansible | changed: [sm02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:19:09,303 p=49182 u=master n=ansible | changed: [sm01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:19:09,326 p=49182 u=master n=ansible | changed: [cn01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:19:09,332 p=49182 u=master n=ansible | changed: [cn02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:19:09,339 p=49182 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа на ключ MUNGE] **************************************************************************************************************
2025-07-22 15:19:09,339 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:09 +0000 (0:00:01.091)       0:00:26.467 ********** 
2025-07-22 15:19:09,612 p=49182 u=master n=ansible | ok: [sm01]
2025-07-22 15:19:09,617 p=49182 u=master n=ansible | ok: [sm02]
2025-07-22 15:19:09,630 p=49182 u=master n=ansible | ok: [cn01]
2025-07-22 15:19:09,648 p=49182 u=master n=ansible | ok: [cn02]
2025-07-22 15:19:09,652 p=49182 u=master n=ansible | TASK [common : [COMMON] Запуск и включение MUNGE] **************************************************************************************************************************
2025-07-22 15:19:09,653 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:09 +0000 (0:00:00.313)       0:00:26.781 ********** 
2025-07-22 15:19:11,538 p=49182 u=master n=ansible | changed: [cn01]
2025-07-22 15:19:11,557 p=49182 u=master n=ansible | changed: [cn02]
2025-07-22 15:19:11,596 p=49182 u=master n=ansible | changed: [sm01]
2025-07-22 15:19:11,599 p=49182 u=master n=ansible | changed: [sm02]
2025-07-22 15:19:11,603 p=49182 u=master n=ansible | TASK [common : [COMMON] Проверка работы MUNGE] *****************************************************************************************************************************
2025-07-22 15:19:11,603 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:11 +0000 (0:00:01.950)       0:00:28.731 ********** 
2025-07-22 15:19:11,870 p=49182 u=master n=ansible | ok: [sm01]
2025-07-22 15:19:11,894 p=49182 u=master n=ansible | ok: [cn01]
2025-07-22 15:19:11,911 p=49182 u=master n=ansible | ok: [cn02]
2025-07-22 15:19:12,076 p=49182 u=master n=ansible | ok: [sm02]
2025-07-22 15:19:12,080 p=49182 u=master n=ansible | TASK [common : [COMMON] Результат проверки MUNGE] **************************************************************************************************************************
2025-07-22 15:19:12,080 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:12 +0000 (0:00:00.476)       0:00:29.208 ********** 
2025-07-22 15:19:12,115 p=49182 u=master n=ansible | ok: [sm01] => 
  msg: MUNGE работает корректно на sm01
2025-07-22 15:19:12,116 p=49182 u=master n=ansible | ok: [sm02] => 
  msg: MUNGE работает корректно на sm02
2025-07-22 15:19:12,121 p=49182 u=master n=ansible | ok: [cn01] => 
  msg: MUNGE работает корректно на cn01
2025-07-22 15:19:12,132 p=49182 u=master n=ansible | ok: [cn02] => 
  msg: MUNGE работает корректно на cn02
2025-07-22 15:19:12,136 p=49182 u=master n=ansible | TASK [common : [COMMON] Установка HWLOC] ***********************************************************************************************************************************
2025-07-22 15:19:12,137 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:12 +0000 (0:00:00.056)       0:00:29.265 ********** 
2025-07-22 15:19:13,121 p=49182 u=master n=ansible | ok: [cn01]
2025-07-22 15:19:13,150 p=49182 u=master n=ansible | ok: [sm02]
2025-07-22 15:19:13,172 p=49182 u=master n=ansible | ok: [sm01]
2025-07-22 15:19:13,238 p=49182 u=master n=ansible | ok: [cn02]
2025-07-22 15:19:13,242 p=49182 u=master n=ansible | TASK [common : [COMMON] Проверка HWLOC] ************************************************************************************************************************************
2025-07-22 15:19:13,242 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:13 +0000 (0:00:01.105)       0:00:30.370 ********** 
2025-07-22 15:19:13,515 p=49182 u=master n=ansible | ok: [sm02]
2025-07-22 15:19:13,527 p=49182 u=master n=ansible | ok: [cn01]
2025-07-22 15:19:13,545 p=49182 u=master n=ansible | ok: [sm01]
2025-07-22 15:19:13,547 p=49182 u=master n=ansible | ok: [cn02]
2025-07-22 15:19:13,551 p=49182 u=master n=ansible | TASK [common : [COMMON] Версия HWLOC] **************************************************************************************************************************************
2025-07-22 15:19:13,551 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:13 +0000 (0:00:00.309)       0:00:30.679 ********** 
2025-07-22 15:19:13,586 p=49182 u=master n=ansible | ok: [sm01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:19:13,587 p=49182 u=master n=ansible | ok: [sm02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:19:13,590 p=49182 u=master n=ansible | ok: [cn01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:19:13,602 p=49182 u=master n=ansible | ok: [cn02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:19:13,606 p=49182 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-22 15:19:13,606 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:13 +0000 (0:00:00.054)       0:00:30.734 ********** 
2025-07-22 15:19:13,640 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:13,643 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:13,654 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:14,595 p=49182 u=master n=ansible | ok: [sm01]
2025-07-22 15:19:14,599 p=49182 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-22 15:19:14,599 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:14 +0000 (0:00:00.993)       0:00:31.727 ********** 
2025-07-22 15:19:14,630 p=49182 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 15:19:14,631 p=49182 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 15:19:14,636 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:14,638 p=49182 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 15:19:14,640 p=49182 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 15:19:14,641 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:14,650 p=49182 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 15:19:14,653 p=49182 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 15:19:14,654 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:14,877 p=49182 u=master n=ansible | ok: [sm01] => (item=/home)
2025-07-22 15:19:15,132 p=49182 u=master n=ansible | ok: [sm01] => (item=/sw)
2025-07-22 15:19:15,138 p=49182 u=master n=ansible | TASK [common : [COMMON] Очистка старых экспортов] **************************************************************************************************************************
2025-07-22 15:19:15,139 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:15 +0000 (0:00:00.539)       0:00:32.267 ********** 
2025-07-22 15:19:15,176 p=49182 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 15:19:15,177 p=49182 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 15:19:15,178 p=49182 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 15:19:15,179 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:15,180 p=49182 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 15:19:15,181 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:15,188 p=49182 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 15:19:15,191 p=49182 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 15:19:15,192 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:15,408 p=49182 u=master n=ansible | changed: [sm01] => (item=/home)
2025-07-22 15:19:15,654 p=49182 u=master n=ansible | changed: [sm01] => (item=/sw)
2025-07-22 15:19:15,660 p=49182 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS с конкретными IP] ***********************************************************************************************************
2025-07-22 15:19:15,660 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:15 +0000 (0:00:00.521)       0:00:32.788 ********** 
2025-07-22 15:19:15,693 p=49182 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:19:15,701 p=49182 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:19:15,702 p=49182 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:19:15,703 p=49182 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:19:15,704 p=49182 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:19:15,705 p=49182 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:19:15,707 p=49182 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:19:15,707 p=49182 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:19:15,709 p=49182 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:19:15,710 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:15,710 p=49182 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:19:15,711 p=49182 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:19:15,714 p=49182 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:19:15,715 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:15,716 p=49182 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:19:15,719 p=49182 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:19:15,722 p=49182 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:19:15,725 p=49182 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:19:15,727 p=49182 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:19:15,730 p=49182 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:19:15,732 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:15,933 p=49182 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.161'})
2025-07-22 15:19:16,178 p=49182 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.167'})
2025-07-22 15:19:16,424 p=49182 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.168'})
2025-07-22 15:19:16,666 p=49182 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'})
2025-07-22 15:19:16,910 p=49182 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'})
2025-07-22 15:19:17,157 p=49182 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'})
2025-07-22 15:19:17,166 p=49182 u=master n=ansible | TASK [common : [COMMON] Запуск и включение NFS server] *********************************************************************************************************************
2025-07-22 15:19:17,166 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:17 +0000 (0:00:01.505)       0:00:34.294 ********** 
2025-07-22 15:19:17,202 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:17,204 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:17,216 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:17,655 p=49182 u=master n=ansible | ok: [sm01]
2025-07-22 15:19:17,660 p=49182 u=master n=ansible | TASK [common : [COMMON] Принудительная перезагрузка экспортов NFS] *********************************************************************************************************
2025-07-22 15:19:17,660 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:17 +0000 (0:00:00.493)       0:00:34.788 ********** 
2025-07-22 15:19:17,695 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:17,697 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:17,710 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:17,933 p=49182 u=master n=ansible | changed: [sm01]
2025-07-22 15:19:17,937 p=49182 u=master n=ansible | TASK [common : [COMMON] Проверка активных экспортов] ***********************************************************************************************************************
2025-07-22 15:19:17,937 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:17 +0000 (0:00:00.277)       0:00:35.065 ********** 
2025-07-22 15:19:17,972 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:17,975 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:17,986 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:18,207 p=49182 u=master n=ansible | changed: [sm01]
2025-07-22 15:19:18,211 p=49182 u=master n=ansible | TASK [common : [COMMON] Показать активные экспорты] ************************************************************************************************************************
2025-07-22 15:19:18,211 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:18 +0000 (0:00:00.274)       0:00:35.339 ********** 
2025-07-22 15:19:18,246 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:18,249 p=49182 u=master n=ansible | ok: [sm01] => 
  nfs_exports_check.stdout_lines:
  - "/home         \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/shared       \t10.20.90.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
2025-07-22 15:19:18,249 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:18,257 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:18,262 p=49182 u=master n=ansible | TASK [common : [COMMON] Установка NFS client] ******************************************************************************************************************************
2025-07-22 15:19:18,262 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:18 +0000 (0:00:00.050)       0:00:35.390 ********** 
2025-07-22 15:19:18,286 p=49182 u=master n=ansible | skipping: [sm01]
2025-07-22 15:19:19,229 p=49182 u=master n=ansible | ok: [sm02]
2025-07-22 15:19:19,242 p=49182 u=master n=ansible | ok: [cn01]
2025-07-22 15:19:19,376 p=49182 u=master n=ansible | ok: [cn02]
2025-07-22 15:19:19,381 p=49182 u=master n=ansible | TASK [common : [COMMON] Создание точек монтирования NFS] *******************************************************************************************************************
2025-07-22 15:19:19,381 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:19 +0000 (0:00:01.118)       0:00:36.509 ********** 
2025-07-22 15:19:19,401 p=49182 u=master n=ansible | skipping: [sm01] => (item=/sw) 
2025-07-22 15:19:19,408 p=49182 u=master n=ansible | skipping: [sm01]
2025-07-22 15:19:19,663 p=49182 u=master n=ansible | ok: [sm02] => (item=/sw)
2025-07-22 15:19:19,680 p=49182 u=master n=ansible | ok: [cn01] => (item=/sw)
2025-07-22 15:19:19,695 p=49182 u=master n=ansible | ok: [cn02] => (item=/sw)
2025-07-22 15:19:19,701 p=49182 u=master n=ansible | TASK [common : [COMMON] Монтирование NFS shares] ***************************************************************************************************************************
2025-07-22 15:19:19,701 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:19 +0000 (0:00:00.320)       0:00:36.829 ********** 
2025-07-22 15:19:19,725 p=49182 u=master n=ansible | skipping: [sm01] => (item={'path': '/home', 'src': '/home'}) 
2025-07-22 15:19:19,730 p=49182 u=master n=ansible | skipping: [sm01] => (item={'path': '/sw', 'src': '/sw'}) 
2025-07-22 15:19:19,743 p=49182 u=master n=ansible | skipping: [sm01]
2025-07-22 15:19:20,165 p=49182 u=master n=ansible | ok: [sm02] => (item={'path': '/home', 'src': '/home'})
2025-07-22 15:19:20,168 p=49182 u=master n=ansible | ok: [cn01] => (item={'path': '/home', 'src': '/home'})
2025-07-22 15:19:20,177 p=49182 u=master n=ansible | ok: [cn02] => (item={'path': '/home', 'src': '/home'})
2025-07-22 15:19:20,413 p=49182 u=master n=ansible | ok: [sm02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 15:19:20,423 p=49182 u=master n=ansible | ok: [cn01] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 15:19:20,431 p=49182 u=master n=ansible | ok: [cn02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 15:19:20,436 p=49182 u=master n=ansible | TASK [common : [COMMON] Создание базовых директорий Slurm] *****************************************************************************************************************
2025-07-22 15:19:20,436 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:20 +0000 (0:00:00.735)       0:00:37.564 ********** 
2025-07-22 15:19:20,723 p=49182 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:20,725 p=49182 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:20,731 p=49182 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:20,758 p=49182 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:20,977 p=49182 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:20,983 p=49182 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:20,984 p=49182 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:21,014 p=49182 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:21,230 p=49182 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:21,240 p=49182 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:21,242 p=49182 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:21,312 p=49182 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:21,482 p=49182 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:21,494 p=49182 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:21,503 p=49182 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:21,572 p=49182 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:21,766 p=49182 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:19:21,767 p=49182 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:19:21,784 p=49182 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:19:21,834 p=49182 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:19:22,018 p=49182 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:22,063 p=49182 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:22,089 p=49182 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:22,115 p=49182 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:19:22,122 p=49182 u=master n=ansible | TASK [common : [COMMON] Роль common выполнена успешно] *********************************************************************************************************************
2025-07-22 15:19:22,122 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:22 +0000 (0:00:01.685)       0:00:39.250 ********** 
2025-07-22 15:19:22,149 p=49182 u=master n=ansible | ok: [sm01] => 
  msg: ✅ Узел sm01 готов для установки Slurm
2025-07-22 15:19:22,161 p=49182 u=master n=ansible | ok: [sm02] => 
  msg: ✅ Узел sm02 готов для установки Slurm
2025-07-22 15:19:22,165 p=49182 u=master n=ansible | ok: [cn01] => 
  msg: ✅ Узел cn01 готов для установки Slurm
2025-07-22 15:19:22,178 p=49182 u=master n=ansible | ok: [cn02] => 
  msg: ✅ Узел cn02 готов для установки Slurm
2025-07-22 15:19:22,190 p=49182 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Начало сборки Slurm] *********************************************************************************************************************
2025-07-22 15:19:22,191 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:22 +0000 (0:00:00.068)       0:00:39.319 ********** 
2025-07-22 15:19:22,225 p=49182 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm01"
2025-07-22 15:19:22,226 p=49182 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm02"
2025-07-22 15:19:22,230 p=49182 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn01"
2025-07-22 15:19:22,241 p=49182 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn02"
2025-07-22 15:19:22,246 p=49182 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка дополнительных зависимостей для сборки] ****************************************************************************************
2025-07-22 15:19:22,246 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:22 +0000 (0:00:00.055)       0:00:39.374 ********** 
2025-07-22 15:19:22,282 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:22,285 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:22,294 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:32,953 p=49182 u=master n=ansible | changed: [sm01]
2025-07-22 15:19:32,957 p=49182 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для сборки] ************************************************************************************************
2025-07-22 15:19:32,957 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:32 +0000 (0:00:10.710)       0:00:50.085 ********** 
2025-07-22 15:19:32,991 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:32,993 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:33,003 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:33,232 p=49182 u=master n=ansible | ok: [sm01]
2025-07-22 15:19:33,236 p=49182 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка существования исходников] *******************************************************************************************************
2025-07-22 15:19:33,237 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:33 +0000 (0:00:00.279)       0:00:50.365 ********** 
2025-07-22 15:19:33,270 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:33,272 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:33,283 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:33,624 p=49182 u=master n=ansible | ok: [sm01]
2025-07-22 15:19:33,631 p=49182 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Скачивание исходников Slurm 25.05.1] *****************************************************************************************************
2025-07-22 15:19:33,632 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:33 +0000 (0:00:00.394)       0:00:50.759 ********** 
2025-07-22 15:19:33,657 p=49182 u=master n=ansible | skipping: [sm01]
2025-07-22 15:19:33,669 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:33,671 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:33,679 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:33,684 p=49182 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Извлечение исходников Slurm] *************************************************************************************************************
2025-07-22 15:19:33,684 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:33 +0000 (0:00:00.052)       0:00:50.812 ********** 
2025-07-22 15:19:33,719 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:33,721 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:33,729 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:33,774 p=49182 u=master n=ansible | skipping: [sm01]
2025-07-22 15:19:33,778 p=49182 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Конфигурация сборки Slurm с JWT поддержкой] **********************************************************************************************
2025-07-22 15:19:33,778 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:33 +0000 (0:00:00.094)       0:00:50.906 ********** 
2025-07-22 15:19:33,813 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:33,814 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:33,822 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:34,036 p=49182 u=master n=ansible | ok: [sm01]
2025-07-22 15:19:34,040 p=49182 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат конфигурации] ******************************************************************************************************************
2025-07-22 15:19:34,040 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:34 +0000 (0:00:00.262)       0:00:51.168 ********** 
2025-07-22 15:19:34,065 p=49182 u=master n=ansible | skipping: [sm01]
2025-07-22 15:19:34,078 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:34,078 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:34,086 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:34,090 p=49182 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Компиляция Slurm (это займет время...)] **************************************************************************************************
2025-07-22 15:19:34,091 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:34 +0000 (0:00:00.050)       0:00:51.218 ********** 
2025-07-22 15:19:34,115 p=49182 u=master n=ansible | fatal: [sm01]: FAILED! => 
  msg: |-
    The task includes an option with an undefined variable. The error was: 'ansible_processor_vcpus' is undefined. 'ansible_processor_vcpus' is undefined
  
    The error appears to be in '/home/master/22Jul/slurm-hpc-cluster/roles/slurm_build/tasks/main.yml': line 106, column 3, but may
    be elsewhere in the file depending on the exact syntax problem.
  
    The offending line appears to be:
  
  
    - name: "[SLURM_BUILD] Компиляция Slurm (это займет время...)"
      ^ here
2025-07-22 15:19:34,126 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:34,129 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:34,137 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:34,141 p=49182 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка Slurm на master] ***************************************************************************************************************
2025-07-22 15:19:34,141 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:34 +0000 (0:00:00.050)       0:00:51.269 ********** 
2025-07-22 15:19:34,165 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:34,166 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:34,175 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:34,179 p=49182 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание архива Slurm для копирования] ***************************************************************************************************
2025-07-22 15:19:34,180 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:34 +0000 (0:00:00.038)       0:00:51.308 ********** 
2025-07-22 15:19:34,205 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:34,206 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:34,214 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:34,218 p=49182 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] *************************************************************************************************
2025-07-22 15:19:34,218 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:34 +0000 (0:00:00.038)       0:00:51.346 ********** 
2025-07-22 15:19:34,483 p=49182 u=master n=ansible | ok: [sm02]
2025-07-22 15:19:34,502 p=49182 u=master n=ansible | ok: [cn01]
2025-07-22 15:19:34,516 p=49182 u=master n=ansible | ok: [cn02]
2025-07-22 15:19:34,520 p=49182 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание архива Slurm в NFS shared директории] *******************************************************************************************
2025-07-22 15:19:34,520 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:34 +0000 (0:00:00.302)       0:00:51.648 ********** 
2025-07-22 15:19:34,549 p=49182 u=master n=ansible | skipping: [sm02]
2025-07-22 15:19:34,550 p=49182 u=master n=ansible | skipping: [cn01]
2025-07-22 15:19:34,557 p=49182 u=master n=ansible | skipping: [cn02]
2025-07-22 15:19:34,561 p=49182 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание появления архива в NFS] *********************************************************************************************************
2025-07-22 15:19:34,562 p=49182 u=master n=ansible | Tuesday 22 July 2025  15:19:34 +0000 (0:00:00.041)       0:00:51.690 ********** 
2025-07-22 15:20:01,329 p=49182 u=master n=ansible |  [ERROR]: User interrupted execution

2025-07-22 15:22:00,177 p=49904 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 15:22:00,177 p=49904 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-22 15:22:00,641 p=49904 u=master n=ansible | PLAY [Тестирование роли slurm_build] ***************************************************************************************************************************************
2025-07-22 15:22:00,663 p=49904 u=master n=ansible | TASK [Информация о сборке Slurm] *******************************************************************************************************************************************
2025-07-22 15:22:00,664 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:00 +0000 (0:00:00.025)       0:00:00.025 ********** 
2025-07-22 15:22:00,719 p=49904 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F528 Начинаем сборку Slurm 25.05.1\n\U0001F4CD Сборка на: sm01\n\U0001F4E6 Установка на: sm01, sm02, cn01, cn02\n\U0001F510 JWT поддержка включена"
2025-07-22 15:22:00,724 p=49904 u=master n=ansible | TASK [Проверка доступного места на диске] **********************************************************************************************************************************
2025-07-22 15:22:00,724 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:00 +0000 (0:00:00.060)       0:00:00.086 ********** 
2025-07-22 15:22:00,761 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:00,762 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:00,771 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:01,852 p=49904 u=master n=ansible | changed: [sm01]
2025-07-22 15:22:01,858 p=49904 u=master n=ansible | TASK [Предупреждение о месте на диске] *************************************************************************************************************************************
2025-07-22 15:22:01,859 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:01 +0000 (0:00:01.134)       0:00:01.221 ********** 
2025-07-22 15:22:01,898 p=49904 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4BE Доступно места в /tmp: 39G\n⚠️  Для сборки Slurm требуется ~2GB свободного места"
2025-07-22 15:22:01,899 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:01,899 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:01,906 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:01,926 p=49904 u=master n=ansible | TASK [common : [COMMON] Начало выполнения роли common] *********************************************************************************************************************
2025-07-22 15:22:01,926 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:01 +0000 (0:00:00.067)       0:00:01.288 ********** 
2025-07-22 15:22:01,950 p=49904 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm01"
2025-07-22 15:22:01,964 p=49904 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm02"
2025-07-22 15:22:01,965 p=49904 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn01"
2025-07-22 15:22:01,976 p=49904 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn02"
2025-07-22 15:22:01,980 p=49904 u=master n=ansible | TASK [common : [COMMON] Обновление apt cache] ******************************************************************************************************************************
2025-07-22 15:22:01,981 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:01 +0000 (0:00:00.054)       0:00:01.342 ********** 
2025-07-22 15:22:02,943 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:22:03,563 p=49904 u=master n=ansible | ok: [cn01]
2025-07-22 15:22:03,576 p=49904 u=master n=ansible | ok: [sm02]
2025-07-22 15:22:03,636 p=49904 u=master n=ansible | ok: [cn02]
2025-07-22 15:22:03,641 p=49904 u=master n=ansible | TASK [common : [COMMON] Установка базовых пакетов] *************************************************************************************************************************
2025-07-22 15:22:03,641 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:03 +0000 (0:00:01.660)       0:00:03.003 ********** 
2025-07-22 15:22:04,655 p=49904 u=master n=ansible | ok: [sm02]
2025-07-22 15:22:04,656 p=49904 u=master n=ansible | ok: [cn01]
2025-07-22 15:22:04,733 p=49904 u=master n=ansible | ok: [cn02]
2025-07-22 15:22:12,083 p=49904 u=master n=ansible | changed: [sm01]
2025-07-22 15:22:12,088 p=49904 u=master n=ansible | TASK [common : [COMMON] Настройка timezone] ********************************************************************************************************************************
2025-07-22 15:22:12,088 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:12 +0000 (0:00:08.447)       0:00:11.450 ********** 
2025-07-22 15:22:12,589 p=49904 u=master n=ansible | ok: [sm02]
2025-07-22 15:22:12,595 p=49904 u=master n=ansible | ok: [cn01]
2025-07-22 15:22:12,598 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:22:12,599 p=49904 u=master n=ansible | ok: [cn02]
2025-07-22 15:22:12,603 p=49904 u=master n=ansible | TASK [common : [COMMON] Обеспечение hostname resolution для кластера] ******************************************************************************************************
2025-07-22 15:22:12,604 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:12 +0000 (0:00:00.515)       0:00:11.965 ********** 
2025-07-22 15:22:13,014 p=49904 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:22:13,017 p=49904 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:22:13,020 p=49904 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:22:13,055 p=49904 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-22 15:22:13,258 p=49904 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:22:13,266 p=49904 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:22:13,268 p=49904 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:22:13,300 p=49904 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-22 15:22:13,509 p=49904 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:22:13,527 p=49904 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:22:13,537 p=49904 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:22:13,542 p=49904 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-22 15:22:13,750 p=49904 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:22:13,769 p=49904 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:22:13,787 p=49904 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:22:13,788 p=49904 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-22 15:22:13,796 p=49904 u=master n=ansible | TASK [common : [COMMON] Создание пользователя slurm] ***********************************************************************************************************************
2025-07-22 15:22:13,796 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:13 +0000 (0:00:01.192)       0:00:13.158 ********** 
2025-07-22 15:22:14,295 p=49904 u=master n=ansible | ok: [cn01]
2025-07-22 15:22:14,296 p=49904 u=master n=ansible | ok: [sm02]
2025-07-22 15:22:14,298 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:22:14,304 p=49904 u=master n=ansible | ok: [cn02]
2025-07-22 15:22:14,308 p=49904 u=master n=ansible | TASK [common : [COMMON] Установка MUNGE] ***********************************************************************************************************************************
2025-07-22 15:22:14,308 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:14 +0000 (0:00:00.511)       0:00:13.670 ********** 
2025-07-22 15:22:15,315 p=49904 u=master n=ansible | ok: [sm02]
2025-07-22 15:22:15,318 p=49904 u=master n=ansible | ok: [cn01]
2025-07-22 15:22:15,340 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:22:15,375 p=49904 u=master n=ansible | ok: [cn02]
2025-07-22 15:22:15,380 p=49904 u=master n=ansible | TASK [common : [COMMON] Остановка MUNGE перед настройкой] ******************************************************************************************************************
2025-07-22 15:22:15,380 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:15 +0000 (0:00:01.071)       0:00:14.742 ********** 
2025-07-22 15:22:17,246 p=49904 u=master n=ansible | changed: [sm01]
2025-07-22 15:22:17,248 p=49904 u=master n=ansible | changed: [cn01]
2025-07-22 15:22:17,282 p=49904 u=master n=ansible | changed: [cn02]
2025-07-22 15:22:17,292 p=49904 u=master n=ansible | changed: [sm02]
2025-07-22 15:22:17,297 p=49904 u=master n=ansible | TASK [common : [COMMON] Создание MUNGE ключа на master узле] ***************************************************************************************************************
2025-07-22 15:22:17,297 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:17 +0000 (0:00:01.916)       0:00:16.659 ********** 
2025-07-22 15:22:17,336 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:17,339 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:17,347 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:17,553 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:22:17,557 p=49904 u=master n=ansible | TASK [common : [COMMON] Получение MUNGE ключа с master узла] ***************************************************************************************************************
2025-07-22 15:22:17,557 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:17 +0000 (0:00:00.260)       0:00:16.919 ********** 
2025-07-22 15:22:17,592 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:17,599 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:17,604 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:17,941 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:22:17,947 p=49904 u=master n=ansible | TASK [common : [COMMON] Распространение MUNGE ключа на все узлы] ***********************************************************************************************************
2025-07-22 15:22:17,947 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:17 +0000 (0:00:00.390)       0:00:17.309 ********** 
2025-07-22 15:22:17,981 p=49904 u=master n=ansible | skipping: [sm01]
2025-07-22 15:22:18,939 p=49904 u=master n=ansible | ok: [sm02]
2025-07-22 15:22:18,941 p=49904 u=master n=ansible | ok: [cn02]
2025-07-22 15:22:18,941 p=49904 u=master n=ansible | ok: [cn01]
2025-07-22 15:22:18,945 p=49904 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа MUNGE] **********************************************************************************************************************
2025-07-22 15:22:18,946 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:18 +0000 (0:00:00.998)       0:00:18.307 ********** 
2025-07-22 15:22:19,222 p=49904 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:22:19,223 p=49904 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:22:19,244 p=49904 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:22:19,255 p=49904 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:22:19,475 p=49904 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:22:19,476 p=49904 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:22:19,494 p=49904 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:22:19,513 p=49904 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:22:19,726 p=49904 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:22:19,730 p=49904 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:22:19,743 p=49904 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:22:19,765 p=49904 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-22 15:22:19,982 p=49904 u=master n=ansible | changed: [sm02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:22:19,987 p=49904 u=master n=ansible | changed: [sm01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:22:19,994 p=49904 u=master n=ansible | changed: [cn01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:22:20,029 p=49904 u=master n=ansible | changed: [cn02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-22 15:22:20,035 p=49904 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа на ключ MUNGE] **************************************************************************************************************
2025-07-22 15:22:20,035 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:20 +0000 (0:00:01.089)       0:00:19.397 ********** 
2025-07-22 15:22:20,303 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:22:20,308 p=49904 u=master n=ansible | ok: [sm02]
2025-07-22 15:22:20,322 p=49904 u=master n=ansible | ok: [cn01]
2025-07-22 15:22:20,345 p=49904 u=master n=ansible | ok: [cn02]
2025-07-22 15:22:20,349 p=49904 u=master n=ansible | TASK [common : [COMMON] Запуск и включение MUNGE] **************************************************************************************************************************
2025-07-22 15:22:20,350 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:20 +0000 (0:00:00.314)       0:00:19.711 ********** 
2025-07-22 15:22:22,228 p=49904 u=master n=ansible | changed: [sm02]
2025-07-22 15:22:22,232 p=49904 u=master n=ansible | changed: [sm01]
2025-07-22 15:22:22,240 p=49904 u=master n=ansible | changed: [cn01]
2025-07-22 15:22:22,324 p=49904 u=master n=ansible | changed: [cn02]
2025-07-22 15:22:22,329 p=49904 u=master n=ansible | TASK [common : [COMMON] Проверка работы MUNGE] *****************************************************************************************************************************
2025-07-22 15:22:22,329 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:22 +0000 (0:00:01.979)       0:00:21.691 ********** 
2025-07-22 15:22:22,597 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:22:22,603 p=49904 u=master n=ansible | ok: [sm02]
2025-07-22 15:22:22,626 p=49904 u=master n=ansible | ok: [cn02]
2025-07-22 15:22:22,708 p=49904 u=master n=ansible | ok: [cn01]
2025-07-22 15:22:22,714 p=49904 u=master n=ansible | TASK [common : [COMMON] Результат проверки MUNGE] **************************************************************************************************************************
2025-07-22 15:22:22,715 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:22 +0000 (0:00:00.385)       0:00:22.077 ********** 
2025-07-22 15:22:22,759 p=49904 u=master n=ansible | ok: [sm01] => 
  msg: MUNGE работает корректно на sm01
2025-07-22 15:22:22,776 p=49904 u=master n=ansible | ok: [sm02] => 
  msg: MUNGE работает корректно на sm02
2025-07-22 15:22:22,778 p=49904 u=master n=ansible | ok: [cn01] => 
  msg: MUNGE работает корректно на cn01
2025-07-22 15:22:22,794 p=49904 u=master n=ansible | ok: [cn02] => 
  msg: MUNGE работает корректно на cn02
2025-07-22 15:22:22,798 p=49904 u=master n=ansible | TASK [common : [COMMON] Установка HWLOC] ***********************************************************************************************************************************
2025-07-22 15:22:22,798 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:22 +0000 (0:00:00.083)       0:00:22.160 ********** 
2025-07-22 15:22:23,799 p=49904 u=master n=ansible | ok: [sm02]
2025-07-22 15:22:23,875 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:22:23,928 p=49904 u=master n=ansible | ok: [cn02]
2025-07-22 15:22:28,063 p=49904 u=master n=ansible | ok: [cn01]
2025-07-22 15:22:28,068 p=49904 u=master n=ansible | TASK [common : [COMMON] Проверка HWLOC] ************************************************************************************************************************************
2025-07-22 15:22:28,068 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:28 +0000 (0:00:05.269)       0:00:27.430 ********** 
2025-07-22 15:22:28,344 p=49904 u=master n=ansible | ok: [sm02]
2025-07-22 15:22:28,345 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:22:28,361 p=49904 u=master n=ansible | ok: [cn01]
2025-07-22 15:22:28,376 p=49904 u=master n=ansible | ok: [cn02]
2025-07-22 15:22:28,380 p=49904 u=master n=ansible | TASK [common : [COMMON] Версия HWLOC] **************************************************************************************************************************************
2025-07-22 15:22:28,380 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:28 +0000 (0:00:00.312)       0:00:27.742 ********** 
2025-07-22 15:22:28,405 p=49904 u=master n=ansible | ok: [sm01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:22:28,417 p=49904 u=master n=ansible | ok: [sm02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:22:28,421 p=49904 u=master n=ansible | ok: [cn01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:22:28,435 p=49904 u=master n=ansible | ok: [cn02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-22 15:22:28,439 p=49904 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-22 15:22:28,439 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:28 +0000 (0:00:00.058)       0:00:27.801 ********** 
2025-07-22 15:22:28,473 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:28,476 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:28,487 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:29,400 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:22:29,404 p=49904 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-22 15:22:29,404 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:29 +0000 (0:00:00.964)       0:00:28.766 ********** 
2025-07-22 15:22:29,436 p=49904 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 15:22:29,442 p=49904 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 15:22:29,444 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:29,445 p=49904 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 15:22:29,446 p=49904 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 15:22:29,447 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:29,455 p=49904 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 15:22:29,458 p=49904 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 15:22:29,459 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:29,675 p=49904 u=master n=ansible | ok: [sm01] => (item=/home)
2025-07-22 15:22:29,929 p=49904 u=master n=ansible | ok: [sm01] => (item=/sw)
2025-07-22 15:22:29,935 p=49904 u=master n=ansible | TASK [common : [COMMON] Очистка старых экспортов] **************************************************************************************************************************
2025-07-22 15:22:29,935 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:29 +0000 (0:00:00.531)       0:00:29.297 ********** 
2025-07-22 15:22:29,966 p=49904 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-22 15:22:29,968 p=49904 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-22 15:22:29,971 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:29,974 p=49904 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-22 15:22:29,975 p=49904 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-22 15:22:29,975 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:29,986 p=49904 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-22 15:22:29,989 p=49904 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-22 15:22:29,990 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:30,217 p=49904 u=master n=ansible | changed: [sm01] => (item=/home)
2025-07-22 15:22:30,458 p=49904 u=master n=ansible | changed: [sm01] => (item=/sw)
2025-07-22 15:22:30,464 p=49904 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS с конкретными IP] ***********************************************************************************************************
2025-07-22 15:22:30,464 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:30 +0000 (0:00:00.528)       0:00:29.826 ********** 
2025-07-22 15:22:30,504 p=49904 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:22:30,505 p=49904 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:22:30,506 p=49904 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:22:30,507 p=49904 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:22:30,509 p=49904 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:22:30,512 p=49904 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:22:30,515 p=49904 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:22:30,517 p=49904 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:22:30,520 p=49904 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:22:30,521 p=49904 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:22:30,522 p=49904 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:22:30,523 p=49904 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:22:30,524 p=49904 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:22:30,526 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:30,527 p=49904 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:22:30,527 p=49904 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-22 15:22:30,528 p=49904 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-22 15:22:30,529 p=49904 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:22:30,530 p=49904 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-22 15:22:30,531 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:30,533 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:30,733 p=49904 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.161'})
2025-07-22 15:22:30,981 p=49904 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.167'})
2025-07-22 15:22:31,227 p=49904 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.168'})
2025-07-22 15:22:31,466 p=49904 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'})
2025-07-22 15:22:31,708 p=49904 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'})
2025-07-22 15:22:31,952 p=49904 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'})
2025-07-22 15:22:31,959 p=49904 u=master n=ansible | TASK [common : [COMMON] Запуск и включение NFS server] *********************************************************************************************************************
2025-07-22 15:22:31,959 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:31 +0000 (0:00:01.495)       0:00:31.321 ********** 
2025-07-22 15:22:31,993 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:31,995 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:32,005 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:32,439 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:22:32,444 p=49904 u=master n=ansible | TASK [common : [COMMON] Принудительная перезагрузка экспортов NFS] *********************************************************************************************************
2025-07-22 15:22:32,444 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:32 +0000 (0:00:00.484)       0:00:31.806 ********** 
2025-07-22 15:22:32,478 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:32,480 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:32,491 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:32,713 p=49904 u=master n=ansible | changed: [sm01]
2025-07-22 15:22:32,717 p=49904 u=master n=ansible | TASK [common : [COMMON] Проверка активных экспортов] ***********************************************************************************************************************
2025-07-22 15:22:32,717 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:32 +0000 (0:00:00.272)       0:00:32.079 ********** 
2025-07-22 15:22:32,751 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:32,754 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:32,764 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:32,988 p=49904 u=master n=ansible | changed: [sm01]
2025-07-22 15:22:32,992 p=49904 u=master n=ansible | TASK [common : [COMMON] Показать активные экспорты] ************************************************************************************************************************
2025-07-22 15:22:32,992 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:32 +0000 (0:00:00.274)       0:00:32.354 ********** 
2025-07-22 15:22:33,027 p=49904 u=master n=ansible | ok: [sm01] => 
  nfs_exports_check.stdout_lines:
  - "/home         \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/shared       \t10.20.90.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
2025-07-22 15:22:33,028 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:33,028 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:33,038 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:33,042 p=49904 u=master n=ansible | TASK [common : [COMMON] Установка NFS client] ******************************************************************************************************************************
2025-07-22 15:22:33,042 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:33 +0000 (0:00:00.050)       0:00:32.404 ********** 
2025-07-22 15:22:33,067 p=49904 u=master n=ansible | skipping: [sm01]
2025-07-22 15:22:34,019 p=49904 u=master n=ansible | ok: [sm02]
2025-07-22 15:22:34,026 p=49904 u=master n=ansible | ok: [cn01]
2025-07-22 15:22:34,101 p=49904 u=master n=ansible | ok: [cn02]
2025-07-22 15:22:34,105 p=49904 u=master n=ansible | TASK [common : [COMMON] Создание точек монтирования NFS] *******************************************************************************************************************
2025-07-22 15:22:34,105 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:34 +0000 (0:00:01.063)       0:00:33.467 ********** 
2025-07-22 15:22:34,125 p=49904 u=master n=ansible | skipping: [sm01] => (item=/sw) 
2025-07-22 15:22:34,132 p=49904 u=master n=ansible | skipping: [sm01]
2025-07-22 15:22:34,385 p=49904 u=master n=ansible | ok: [sm02] => (item=/sw)
2025-07-22 15:22:34,401 p=49904 u=master n=ansible | ok: [cn01] => (item=/sw)
2025-07-22 15:22:34,412 p=49904 u=master n=ansible | ok: [cn02] => (item=/sw)
2025-07-22 15:22:34,417 p=49904 u=master n=ansible | TASK [common : [COMMON] Монтирование NFS shares] ***************************************************************************************************************************
2025-07-22 15:22:34,417 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:34 +0000 (0:00:00.311)       0:00:33.779 ********** 
2025-07-22 15:22:34,442 p=49904 u=master n=ansible | skipping: [sm01] => (item={'path': '/home', 'src': '/home'}) 
2025-07-22 15:22:34,448 p=49904 u=master n=ansible | skipping: [sm01] => (item={'path': '/sw', 'src': '/sw'}) 
2025-07-22 15:22:34,455 p=49904 u=master n=ansible | skipping: [sm01]
2025-07-22 15:22:34,873 p=49904 u=master n=ansible | ok: [sm02] => (item={'path': '/home', 'src': '/home'})
2025-07-22 15:22:34,875 p=49904 u=master n=ansible | ok: [cn02] => (item={'path': '/home', 'src': '/home'})
2025-07-22 15:22:34,879 p=49904 u=master n=ansible | ok: [cn01] => (item={'path': '/home', 'src': '/home'})
2025-07-22 15:22:35,123 p=49904 u=master n=ansible | ok: [sm02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 15:22:35,133 p=49904 u=master n=ansible | ok: [cn01] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 15:22:35,163 p=49904 u=master n=ansible | ok: [cn02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-22 15:22:35,168 p=49904 u=master n=ansible | TASK [common : [COMMON] Создание базовых директорий Slurm] *****************************************************************************************************************
2025-07-22 15:22:35,168 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:35 +0000 (0:00:00.751)       0:00:34.530 ********** 
2025-07-22 15:22:35,462 p=49904 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:35,463 p=49904 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:35,465 p=49904 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:35,490 p=49904 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:35,712 p=49904 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:35,716 p=49904 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:35,724 p=49904 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:35,745 p=49904 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:35,968 p=49904 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:35,970 p=49904 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:35,988 p=49904 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:36,035 p=49904 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:36,223 p=49904 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:36,225 p=49904 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:36,252 p=49904 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:36,291 p=49904 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:36,509 p=49904 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:22:36,517 p=49904 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:22:36,519 p=49904 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:22:36,549 p=49904 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-22 15:22:36,763 p=49904 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:36,796 p=49904 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:36,806 p=49904 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:36,832 p=49904 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-22 15:22:36,837 p=49904 u=master n=ansible | TASK [common : [COMMON] Роль common выполнена успешно] *********************************************************************************************************************
2025-07-22 15:22:36,837 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:36 +0000 (0:00:01.668)       0:00:36.199 ********** 
2025-07-22 15:22:36,862 p=49904 u=master n=ansible | ok: [sm01] => 
  msg: ✅ Узел sm01 готов для установки Slurm
2025-07-22 15:22:36,873 p=49904 u=master n=ansible | ok: [sm02] => 
  msg: ✅ Узел sm02 готов для установки Slurm
2025-07-22 15:22:36,885 p=49904 u=master n=ansible | ok: [cn01] => 
  msg: ✅ Узел cn01 готов для установки Slurm
2025-07-22 15:22:36,890 p=49904 u=master n=ansible | ok: [cn02] => 
  msg: ✅ Узел cn02 готов для установки Slurm
2025-07-22 15:22:36,902 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Начало сборки Slurm] *********************************************************************************************************************
2025-07-22 15:22:36,903 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:36 +0000 (0:00:00.065)       0:00:36.264 ********** 
2025-07-22 15:22:36,937 p=49904 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm01"
2025-07-22 15:22:36,938 p=49904 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm02"
2025-07-22 15:22:36,942 p=49904 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn01"
2025-07-22 15:22:36,956 p=49904 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn02"
2025-07-22 15:22:36,960 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка дополнительных зависимостей для сборки] ****************************************************************************************
2025-07-22 15:22:36,960 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:36 +0000 (0:00:00.057)       0:00:36.322 ********** 
2025-07-22 15:22:36,994 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:36,996 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:37,007 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:48,705 p=49904 u=master n=ansible | changed: [sm01]
2025-07-22 15:22:48,709 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для сборки] ************************************************************************************************
2025-07-22 15:22:48,709 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:48 +0000 (0:00:11.748)       0:00:48.071 ********** 
2025-07-22 15:22:48,744 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:48,746 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:48,756 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:48,979 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:22:48,983 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка существования исходников] *******************************************************************************************************
2025-07-22 15:22:48,983 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:48 +0000 (0:00:00.273)       0:00:48.345 ********** 
2025-07-22 15:22:49,018 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:49,027 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:49,036 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:49,286 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:22:49,294 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Скачивание исходников Slurm 25.05.1] *****************************************************************************************************
2025-07-22 15:22:49,294 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:49 +0000 (0:00:00.310)       0:00:48.656 ********** 
2025-07-22 15:22:49,324 p=49904 u=master n=ansible | skipping: [sm01]
2025-07-22 15:22:49,335 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:49,337 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:49,345 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:49,350 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Извлечение исходников Slurm] *************************************************************************************************************
2025-07-22 15:22:49,350 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:49 +0000 (0:00:00.056)       0:00:48.712 ********** 
2025-07-22 15:22:49,392 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:49,393 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:49,401 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:49,438 p=49904 u=master n=ansible | skipping: [sm01]
2025-07-22 15:22:49,443 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Конфигурация сборки Slurm с JWT поддержкой] **********************************************************************************************
2025-07-22 15:22:49,443 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:49 +0000 (0:00:00.092)       0:00:48.805 ********** 
2025-07-22 15:22:49,482 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:49,484 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:49,495 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:49,700 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:22:49,704 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат конфигурации] ******************************************************************************************************************
2025-07-22 15:22:49,704 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:49 +0000 (0:00:00.261)       0:00:49.066 ********** 
2025-07-22 15:22:49,728 p=49904 u=master n=ansible | skipping: [sm01]
2025-07-22 15:22:49,744 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:49,745 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:49,751 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:22:49,756 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Компиляция Slurm (это займет время...)] **************************************************************************************************
2025-07-22 15:22:49,756 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:22:49 +0000 (0:00:00.051)       0:00:49.118 ********** 
2025-07-22 15:22:49,803 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:22:49,804 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:22:49,811 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:27:37,928 p=49904 u=master n=ansible | changed: [sm01]
2025-07-22 15:27:37,945 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка Slurm на master] ***************************************************************************************************************
2025-07-22 15:27:37,945 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:27:37 +0000 (0:04:48.189)       0:05:37.307 ********** 
2025-07-22 15:27:37,987 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:27:37,990 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:27:37,999 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:28:19,437 p=49904 u=master n=ansible | changed: [sm01]
2025-07-22 15:28:19,453 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание архива Slurm для копирования] ***************************************************************************************************
2025-07-22 15:28:19,453 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:28:19 +0000 (0:00:41.507)       0:06:18.815 ********** 
2025-07-22 15:28:19,491 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:28:19,493 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:28:19,502 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:31:20,183 p=49904 u=master n=ansible | changed: [sm01]
2025-07-22 15:31:20,188 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] *************************************************************************************************
2025-07-22 15:31:20,188 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:31:20 +0000 (0:03:00.735)       0:09:19.550 ********** 
2025-07-22 15:31:20,484 p=49904 u=master n=ansible | ok: [sm01]
2025-07-22 15:31:21,182 p=49904 u=master n=ansible | ok: [sm02]
2025-07-22 15:31:21,251 p=49904 u=master n=ansible | ok: [cn01]
2025-07-22 15:31:21,261 p=49904 u=master n=ansible | ok: [cn02]
2025-07-22 15:31:21,265 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание архива Slurm в NFS shared директории] *******************************************************************************************
2025-07-22 15:31:21,266 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:31:21 +0000 (0:00:01.077)       0:09:20.627 ********** 
2025-07-22 15:31:21,304 p=49904 u=master n=ansible | skipping: [sm02]
2025-07-22 15:31:21,305 p=49904 u=master n=ansible | skipping: [cn01]
2025-07-22 15:31:21,316 p=49904 u=master n=ansible | skipping: [cn02]
2025-07-22 15:34:21,120 p=49904 u=master n=ansible | changed: [sm01]
2025-07-22 15:34:21,126 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание появления архива в NFS] *********************************************************************************************************
2025-07-22 15:34:21,126 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:34:21 +0000 (0:02:59.860)       0:12:20.488 ********** 
2025-07-22 15:34:21,153 p=49904 u=master n=ansible | skipping: [sm01]
2025-07-22 15:35:22,276 p=49904 u=master n=ansible | fatal: [sm02]: FAILED! => changed=false 
  elapsed: 60
  msg: Timeout when waiting for file /shared/slurm-25.05.1-install.tar.gz
2025-07-22 15:35:22,281 p=49904 u=master n=ansible | fatal: [cn01]: FAILED! => changed=false 
  elapsed: 60
  msg: Timeout when waiting for file /shared/slurm-25.05.1-install.tar.gz
2025-07-22 15:35:22,290 p=49904 u=master n=ansible | fatal: [cn02]: FAILED! => changed=false 
  elapsed: 60
  msg: Timeout when waiting for file /shared/slurm-25.05.1-install.tar.gz
2025-07-22 15:35:22,296 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Извлечение Slurm на все узлы из NFS] *****************************************************************************************************
2025-07-22 15:35:22,296 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:35:22 +0000 (0:01:01.170)       0:13:21.658 ********** 
2025-07-22 15:35:22,317 p=49904 u=master n=ansible | skipping: [sm01]
2025-07-22 15:35:22,322 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка архива из NFS] *******************************************************************************************************************
2025-07-22 15:35:22,322 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:35:22 +0000 (0:00:00.025)       0:13:21.684 ********** 
2025-07-22 15:35:23,385 p=49904 u=master n=ansible | changed: [sm01]
2025-07-22 15:35:23,390 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание символических ссылок для пользовательских команд Slurm] *************************************************************************
2025-07-22 15:35:23,390 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:35:23 +0000 (0:00:01.067)       0:13:22.752 ********** 
2025-07-22 15:35:23,662 p=49904 u=master n=ansible | changed: [sm01] => (item=sinfo)
2025-07-22 15:35:23,906 p=49904 u=master n=ansible | changed: [sm01] => (item=squeue)
2025-07-22 15:35:24,154 p=49904 u=master n=ansible | changed: [sm01] => (item=scancel)
2025-07-22 15:35:24,398 p=49904 u=master n=ansible | changed: [sm01] => (item=sbatch)
2025-07-22 15:35:24,644 p=49904 u=master n=ansible | changed: [sm01] => (item=salloc)
2025-07-22 15:35:24,889 p=49904 u=master n=ansible | changed: [sm01] => (item=srun)
2025-07-22 15:35:25,135 p=49904 u=master n=ansible | changed: [sm01] => (item=sacct)
2025-07-22 15:35:25,379 p=49904 u=master n=ansible | changed: [sm01] => (item=scontrol)
2025-07-22 15:35:25,622 p=49904 u=master n=ansible | changed: [sm01] => (item=sprio)
2025-07-22 15:35:25,895 p=49904 u=master n=ansible | changed: [sm01] => (item=smap)
2025-07-22 15:35:26,140 p=49904 u=master n=ansible | changed: [sm01] => (item=sdiag)
2025-07-22 15:35:26,393 p=49904 u=master n=ansible | changed: [sm01] => (item=sstat)
2025-07-22 15:35:26,643 p=49904 u=master n=ansible | changed: [sm01] => (item=sreport)
2025-07-22 15:35:26,887 p=49904 u=master n=ansible | changed: [sm01] => (item=sacctmgr)
2025-07-22 15:35:27,131 p=49904 u=master n=ansible | changed: [sm01] => (item=sattach)
2025-07-22 15:35:27,380 p=49904 u=master n=ansible | changed: [sm01] => (item=sbcast)
2025-07-22 15:35:27,628 p=49904 u=master n=ansible | changed: [sm01] => (item=sshare)
2025-07-22 15:35:27,873 p=49904 u=master n=ansible | changed: [sm01] => (item=sview)
2025-07-22 15:35:27,881 p=49904 u=master n=ansible | [WARNING]: Cannot set fs attributes on a non-existent symlink target. follow should be set to False to avoid this.

2025-07-22 15:35:27,887 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание символических ссылок для системных демонов Slurm] *******************************************************************************
2025-07-22 15:35:27,887 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:35:27 +0000 (0:00:04.497)       0:13:27.249 ********** 
2025-07-22 15:35:28,160 p=49904 u=master n=ansible | changed: [sm01] => (item=slurmctld)
2025-07-22 15:35:28,406 p=49904 u=master n=ansible | changed: [sm01] => (item=slurmd)
2025-07-22 15:35:28,655 p=49904 u=master n=ansible | changed: [sm01] => (item=slurmdbd)
2025-07-22 15:35:28,906 p=49904 u=master n=ansible | changed: [sm01] => (item=slurmrestd)
2025-07-22 15:35:29,149 p=49904 u=master n=ansible | changed: [sm01] => (item=slurmstepd)
2025-07-22 15:35:29,156 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Обновление библиотечного кеша] ***********************************************************************************************************
2025-07-22 15:35:29,156 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:35:29 +0000 (0:00:01.269)       0:13:28.518 ********** 
2025-07-22 15:35:29,480 p=49904 u=master n=ansible | changed: [sm01]
2025-07-22 15:35:29,484 p=49904 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка версии Slurm] *******************************************************************************************************************
2025-07-22 15:35:29,485 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:35:29 +0000 (0:00:00.328)       0:13:28.847 ********** 
2025-07-22 15:35:29,786 p=49904 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  cmd:
  - /opt/slurm/bin/sinfo
  - --version
  delta: '0:00:00.038023'
  end: '2025-07-22 18:35:29.760530'
  msg: non-zero return code
  rc: 1
  start: '2025-07-22 18:35:29.722507'
  stderr: |-
    sinfo: error: resolve_ctls_from_dns_srv: res_nsearch error: Unknown host
    sinfo: error: fetch_config: DNS SRV lookup failed
    sinfo: error: _establish_config_source: failed to fetch config
    sinfo: fatal: Could not establish a configuration source
  stderr_lines: <omitted>
  stdout: ''
  stdout_lines: <omitted>
2025-07-22 15:35:29,788 p=49904 u=master n=ansible | PLAY RECAP *****************************************************************************************************************************************************************
2025-07-22 15:35:29,788 p=49904 u=master n=ansible | cn01                       : ok=24   changed=3    unreachable=0    failed=1    skipped=23   rescued=0    ignored=0   
2025-07-22 15:35:29,788 p=49904 u=master n=ansible | cn02                       : ok=24   changed=3    unreachable=0    failed=1    skipped=23   rescued=0    ignored=0   
2025-07-22 15:35:29,788 p=49904 u=master n=ansible | sm01                       : ok=45   changed=18   unreachable=0    failed=1    skipped=9    rescued=0    ignored=0   
2025-07-22 15:35:29,788 p=49904 u=master n=ansible | sm02                       : ok=24   changed=3    unreachable=0    failed=1    skipped=23   rescued=0    ignored=0   
2025-07-22 15:35:29,788 p=49904 u=master n=ansible | Playbook run took 0 days, 0 hours, 13 minutes, 29 seconds
2025-07-22 15:35:29,789 p=49904 u=master n=ansible | Tuesday 22 July 2025  15:35:29 +0000 (0:00:00.303)       0:13:29.150 ********** 
2025-07-22 15:35:29,789 p=49904 u=master n=ansible | =============================================================================== 
2025-07-22 15:35:29,789 p=49904 u=master n=ansible | slurm_build : [SLURM_BUILD] Компиляция Slurm (это займет время...) ------------------------------------------------------------------------------------------------ 288.19s
2025-07-22 15:35:29,789 p=49904 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание архива Slurm для копирования ------------------------------------------------------------------------------------------------- 180.74s
2025-07-22 15:35:29,789 p=49904 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание архива Slurm в NFS shared директории ----------------------------------------------------------------------------------------- 179.86s
2025-07-22 15:35:29,789 p=49904 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание появления архива в NFS -------------------------------------------------------------------------------------------------------- 61.17s
2025-07-22 15:35:29,789 p=49904 u=master n=ansible | slurm_build : [SLURM_BUILD] Установка Slurm на master -------------------------------------------------------------------------------------------------------------- 41.51s
2025-07-22 15:35:29,789 p=49904 u=master n=ansible | slurm_build : [SLURM_BUILD] Установка дополнительных зависимостей для сборки --------------------------------------------------------------------------------------- 11.75s
2025-07-22 15:35:29,790 p=49904 u=master n=ansible | common : [COMMON] Установка базовых пакетов ------------------------------------------------------------------------------------------------------------------------- 8.45s
2025-07-22 15:35:29,790 p=49904 u=master n=ansible | common : [COMMON] Установка HWLOC ----------------------------------------------------------------------------------------------------------------------------------- 5.27s
2025-07-22 15:35:29,790 p=49904 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание символических ссылок для пользовательских команд Slurm ------------------------------------------------------------------------- 4.50s
2025-07-22 15:35:29,790 p=49904 u=master n=ansible | common : [COMMON] Запуск и включение MUNGE -------------------------------------------------------------------------------------------------------------------------- 1.98s
2025-07-22 15:35:29,790 p=49904 u=master n=ansible | common : [COMMON] Остановка MUNGE перед настройкой ------------------------------------------------------------------------------------------------------------------ 1.92s
2025-07-22 15:35:29,790 p=49904 u=master n=ansible | common : [COMMON] Создание базовых директорий Slurm ----------------------------------------------------------------------------------------------------------------- 1.67s
2025-07-22 15:35:29,790 p=49904 u=master n=ansible | common : [COMMON] Обновление apt cache ------------------------------------------------------------------------------------------------------------------------------ 1.66s
2025-07-22 15:35:29,790 p=49904 u=master n=ansible | common : [COMMON] Настройка экспорта NFS с конкретными IP ----------------------------------------------------------------------------------------------------------- 1.50s
2025-07-22 15:35:29,790 p=49904 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание символических ссылок для системных демонов Slurm ------------------------------------------------------------------------------- 1.27s
2025-07-22 15:35:29,790 p=49904 u=master n=ansible | common : [COMMON] Обеспечение hostname resolution для кластера ------------------------------------------------------------------------------------------------------ 1.19s
2025-07-22 15:35:29,791 p=49904 u=master n=ansible | Проверка доступного места на диске ---------------------------------------------------------------------------------------------------------------------------------- 1.13s
2025-07-22 15:35:29,791 p=49904 u=master n=ansible | common : [COMMON] Настройка прав доступа MUNGE ---------------------------------------------------------------------------------------------------------------------- 1.09s
2025-07-22 15:35:29,791 p=49904 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------- 1.08s
2025-07-22 15:35:29,791 p=49904 u=master n=ansible | common : [COMMON] Установка MUNGE ----------------------------------------------------------------------------------------------------------------------------------- 1.07s
2025-07-23 07:52:09,220 p=53540 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-23 07:52:09,220 p=53540 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-23 07:52:09,685 p=53540 u=master n=ansible | PLAY [Тестирование роли slurm_build] ***************************************************************************************************************************************
2025-07-23 07:52:09,704 p=53540 u=master n=ansible | TASK [Gathering Facts] *****************************************************************************************************************************************************
2025-07-23 07:52:09,705 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:09 +0000 (0:00:00.023)       0:00:00.023 ******** 
2025-07-23 07:52:11,413 p=53540 u=master n=ansible | ok: [sm02]
2025-07-23 07:52:11,511 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:52:11,559 p=53540 u=master n=ansible | ok: [cn01]
2025-07-23 07:52:11,583 p=53540 u=master n=ansible | ok: [cn02]
2025-07-23 07:52:11,587 p=53540 u=master n=ansible | TASK [Информация о сборке Slurm] *******************************************************************************************************************************************
2025-07-23 07:52:11,587 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:11 +0000 (0:00:01.882)       0:00:01.906 ******** 
2025-07-23 07:52:11,641 p=53540 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F528 Начинаем сборку Slurm 25.05.1\n\U0001F4CD Сборка на: sm01\n\U0001F4E6 Установка на: sm01, sm02, cn01, cn02\n\U0001F510 JWT поддержка включена"
2025-07-23 07:52:11,645 p=53540 u=master n=ansible | TASK [Проверка доступного места на диске] **********************************************************************************************************************************
2025-07-23 07:52:11,645 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:11 +0000 (0:00:00.057)       0:00:01.963 ******** 
2025-07-23 07:52:11,676 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:52:11,678 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:52:11,685 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:52:12,031 p=53540 u=master n=ansible | changed: [sm01]
2025-07-23 07:52:12,034 p=53540 u=master n=ansible | TASK [Предупреждение о месте на диске] *************************************************************************************************************************************
2025-07-23 07:52:12,035 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:12 +0000 (0:00:00.389)       0:00:02.353 ******** 
2025-07-23 07:52:12,067 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:52:12,069 p=53540 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4BE Доступно места в /tmp: 37G\n⚠️  Для сборки Slurm требуется ~2GB свободного места"
2025-07-23 07:52:12,070 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:52:12,079 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:52:12,095 p=53540 u=master n=ansible | TASK [common : [COMMON] Начало выполнения роли common] *********************************************************************************************************************
2025-07-23 07:52:12,095 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:12 +0000 (0:00:00.060)       0:00:02.414 ******** 
2025-07-23 07:52:12,128 p=53540 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm01"
2025-07-23 07:52:12,129 p=53540 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm02"
2025-07-23 07:52:12,135 p=53540 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn01"
2025-07-23 07:52:12,145 p=53540 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn02"
2025-07-23 07:52:12,148 p=53540 u=master n=ansible | TASK [common : [COMMON] Обновление apt cache] ******************************************************************************************************************************
2025-07-23 07:52:12,149 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:12 +0000 (0:00:00.053)       0:00:02.467 ******** 
2025-07-23 07:52:20,468 p=53540 u=master n=ansible | changed: [sm01]
2025-07-23 07:52:20,737 p=53540 u=master n=ansible | changed: [sm02]
2025-07-23 07:52:21,031 p=53540 u=master n=ansible | changed: [cn02]
2025-07-23 07:52:22,210 p=53540 u=master n=ansible | changed: [cn01]
2025-07-23 07:52:22,214 p=53540 u=master n=ansible | TASK [common : [COMMON] Установка базовых пакетов] *************************************************************************************************************************
2025-07-23 07:52:22,214 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:22 +0000 (0:00:10.065)       0:00:12.532 ******** 
2025-07-23 07:52:23,303 p=53540 u=master n=ansible | ok: [sm02]
2025-07-23 07:52:23,352 p=53540 u=master n=ansible | ok: [cn02]
2025-07-23 07:52:23,365 p=53540 u=master n=ansible | ok: [cn01]
2025-07-23 07:52:33,115 p=53540 u=master n=ansible | changed: [sm01]
2025-07-23 07:52:33,119 p=53540 u=master n=ansible | TASK [common : [COMMON] Настройка timezone] ********************************************************************************************************************************
2025-07-23 07:52:33,120 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:33 +0000 (0:00:10.905)       0:00:23.438 ******** 
2025-07-23 07:52:33,625 p=53540 u=master n=ansible | ok: [sm02]
2025-07-23 07:52:33,626 p=53540 u=master n=ansible | ok: [cn02]
2025-07-23 07:52:33,626 p=53540 u=master n=ansible | ok: [cn01]
2025-07-23 07:52:33,627 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:52:33,630 p=53540 u=master n=ansible | TASK [common : [COMMON] Обеспечение hostname resolution для кластера] ******************************************************************************************************
2025-07-23 07:52:33,631 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:33 +0000 (0:00:00.510)       0:00:23.949 ******** 
2025-07-23 07:52:34,018 p=53540 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-23 07:52:34,022 p=53540 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-23 07:52:34,023 p=53540 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-23 07:52:34,027 p=53540 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-23 07:52:34,262 p=53540 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-23 07:52:34,266 p=53540 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-23 07:52:34,272 p=53540 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-23 07:52:34,276 p=53540 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-23 07:52:34,503 p=53540 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-23 07:52:34,513 p=53540 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-23 07:52:34,515 p=53540 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-23 07:52:34,516 p=53540 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-23 07:52:34,751 p=53540 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-23 07:52:34,754 p=53540 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-23 07:52:34,756 p=53540 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-23 07:52:34,764 p=53540 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-23 07:52:34,770 p=53540 u=master n=ansible | TASK [common : [COMMON] Создание пользователя slurm] ***********************************************************************************************************************
2025-07-23 07:52:34,770 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:34 +0000 (0:00:01.139)       0:00:25.089 ******** 
2025-07-23 07:52:35,267 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:52:35,267 p=53540 u=master n=ansible | ok: [cn02]
2025-07-23 07:52:35,273 p=53540 u=master n=ansible | ok: [sm02]
2025-07-23 07:52:35,276 p=53540 u=master n=ansible | ok: [cn01]
2025-07-23 07:52:35,280 p=53540 u=master n=ansible | TASK [common : [COMMON] Установка MUNGE] ***********************************************************************************************************************************
2025-07-23 07:52:35,280 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:35 +0000 (0:00:00.510)       0:00:25.599 ******** 
2025-07-23 07:52:36,342 p=53540 u=master n=ansible | ok: [sm02]
2025-07-23 07:52:36,342 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:52:36,344 p=53540 u=master n=ansible | ok: [cn02]
2025-07-23 07:52:36,407 p=53540 u=master n=ansible | ok: [cn01]
2025-07-23 07:52:36,411 p=53540 u=master n=ansible | TASK [common : [COMMON] Остановка MUNGE перед настройкой] ******************************************************************************************************************
2025-07-23 07:52:36,411 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:36 +0000 (0:00:01.131)       0:00:26.730 ******** 
2025-07-23 07:52:38,269 p=53540 u=master n=ansible | changed: [cn02]
2025-07-23 07:52:38,271 p=53540 u=master n=ansible | changed: [sm02]
2025-07-23 07:52:38,389 p=53540 u=master n=ansible | changed: [sm01]
2025-07-23 07:52:38,432 p=53540 u=master n=ansible | changed: [cn01]
2025-07-23 07:52:38,437 p=53540 u=master n=ansible | TASK [common : [COMMON] Создание MUNGE ключа на master узле] ***************************************************************************************************************
2025-07-23 07:52:38,437 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:38 +0000 (0:00:02.025)       0:00:28.755 ******** 
2025-07-23 07:52:38,472 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:52:38,475 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:52:38,490 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:52:38,697 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:52:38,701 p=53540 u=master n=ansible | TASK [common : [COMMON] Получение MUNGE ключа с master узла] ***************************************************************************************************************
2025-07-23 07:52:38,701 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:38 +0000 (0:00:00.263)       0:00:29.019 ******** 
2025-07-23 07:52:38,734 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:52:38,740 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:52:38,748 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:52:39,077 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:52:39,082 p=53540 u=master n=ansible | TASK [common : [COMMON] Распространение MUNGE ключа на все узлы] ***********************************************************************************************************
2025-07-23 07:52:39,082 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:39 +0000 (0:00:00.381)       0:00:29.401 ******** 
2025-07-23 07:52:39,108 p=53540 u=master n=ansible | skipping: [sm01]
2025-07-23 07:52:40,061 p=53540 u=master n=ansible | ok: [cn02]
2025-07-23 07:52:40,061 p=53540 u=master n=ansible | ok: [sm02]
2025-07-23 07:52:40,062 p=53540 u=master n=ansible | ok: [cn01]
2025-07-23 07:52:40,065 p=53540 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа MUNGE] **********************************************************************************************************************
2025-07-23 07:52:40,066 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:40 +0000 (0:00:00.983)       0:00:30.384 ******** 
2025-07-23 07:52:40,342 p=53540 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 07:52:40,348 p=53540 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 07:52:40,363 p=53540 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 07:52:40,367 p=53540 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 07:52:40,601 p=53540 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 07:52:40,605 p=53540 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 07:52:40,619 p=53540 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 07:52:40,623 p=53540 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 07:52:40,854 p=53540 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 07:52:40,869 p=53540 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 07:52:40,874 p=53540 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 07:52:40,885 p=53540 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 07:52:41,108 p=53540 u=master n=ansible | changed: [sm01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-23 07:52:41,125 p=53540 u=master n=ansible | changed: [cn02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-23 07:52:41,128 p=53540 u=master n=ansible | changed: [sm02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-23 07:52:41,147 p=53540 u=master n=ansible | changed: [cn01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-23 07:52:41,153 p=53540 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа на ключ MUNGE] **************************************************************************************************************
2025-07-23 07:52:41,153 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:41 +0000 (0:00:01.087)       0:00:31.471 ******** 
2025-07-23 07:52:41,427 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:52:41,436 p=53540 u=master n=ansible | ok: [sm02]
2025-07-23 07:52:41,440 p=53540 u=master n=ansible | ok: [cn01]
2025-07-23 07:52:41,456 p=53540 u=master n=ansible | ok: [cn02]
2025-07-23 07:52:41,460 p=53540 u=master n=ansible | TASK [common : [COMMON] Запуск и включение MUNGE] **************************************************************************************************************************
2025-07-23 07:52:41,460 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:41 +0000 (0:00:00.306)       0:00:31.778 ******** 
2025-07-23 07:52:43,321 p=53540 u=master n=ansible | changed: [cn02]
2025-07-23 07:52:43,341 p=53540 u=master n=ansible | changed: [sm01]
2025-07-23 07:52:43,358 p=53540 u=master n=ansible | changed: [sm02]
2025-07-23 07:52:43,459 p=53540 u=master n=ansible | changed: [cn01]
2025-07-23 07:52:43,464 p=53540 u=master n=ansible | TASK [common : [COMMON] Проверка работы MUNGE] *****************************************************************************************************************************
2025-07-23 07:52:43,464 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:43 +0000 (0:00:02.004)       0:00:33.783 ******** 
2025-07-23 07:52:43,741 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:52:43,743 p=53540 u=master n=ansible | ok: [sm02]
2025-07-23 07:52:43,755 p=53540 u=master n=ansible | ok: [cn01]
2025-07-23 07:52:43,757 p=53540 u=master n=ansible | ok: [cn02]
2025-07-23 07:52:43,761 p=53540 u=master n=ansible | TASK [common : [COMMON] Результат проверки MUNGE] **************************************************************************************************************************
2025-07-23 07:52:43,761 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:43 +0000 (0:00:00.297)       0:00:34.080 ******** 
2025-07-23 07:52:43,796 p=53540 u=master n=ansible | ok: [sm01] => 
  msg: MUNGE работает корректно на sm01
2025-07-23 07:52:43,797 p=53540 u=master n=ansible | ok: [sm02] => 
  msg: MUNGE работает корректно на sm02
2025-07-23 07:52:43,801 p=53540 u=master n=ansible | ok: [cn01] => 
  msg: MUNGE работает корректно на cn01
2025-07-23 07:52:43,812 p=53540 u=master n=ansible | ok: [cn02] => 
  msg: MUNGE работает корректно на cn02
2025-07-23 07:52:43,815 p=53540 u=master n=ansible | TASK [common : [COMMON] Установка HWLOC] ***********************************************************************************************************************************
2025-07-23 07:52:43,816 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:43 +0000 (0:00:00.054)       0:00:34.134 ******** 
2025-07-23 07:52:44,806 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:52:44,916 p=53540 u=master n=ansible | ok: [sm02]
2025-07-23 07:52:44,930 p=53540 u=master n=ansible | ok: [cn02]
2025-07-23 07:52:44,961 p=53540 u=master n=ansible | ok: [cn01]
2025-07-23 07:52:44,965 p=53540 u=master n=ansible | TASK [common : [COMMON] Проверка HWLOC] ************************************************************************************************************************************
2025-07-23 07:52:44,965 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:44 +0000 (0:00:01.149)       0:00:35.283 ******** 
2025-07-23 07:52:45,243 p=53540 u=master n=ansible | ok: [sm02]
2025-07-23 07:52:45,256 p=53540 u=master n=ansible | ok: [cn01]
2025-07-23 07:52:45,273 p=53540 u=master n=ansible | ok: [cn02]
2025-07-23 07:52:45,373 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:52:45,377 p=53540 u=master n=ansible | TASK [common : [COMMON] Версия HWLOC] **************************************************************************************************************************************
2025-07-23 07:52:45,377 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:45 +0000 (0:00:00.412)       0:00:35.696 ******** 
2025-07-23 07:52:45,413 p=53540 u=master n=ansible | ok: [sm01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 07:52:45,414 p=53540 u=master n=ansible | ok: [sm02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 07:52:45,418 p=53540 u=master n=ansible | ok: [cn01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 07:52:45,429 p=53540 u=master n=ansible | ok: [cn02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 07:52:45,433 p=53540 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-23 07:52:45,433 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:45 +0000 (0:00:00.056)       0:00:35.752 ******** 
2025-07-23 07:52:45,466 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:52:45,469 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:52:45,484 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:52:46,420 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:52:46,424 p=53540 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-23 07:52:46,424 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:46 +0000 (0:00:00.990)       0:00:36.742 ******** 
2025-07-23 07:52:46,461 p=53540 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-23 07:52:46,462 p=53540 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-23 07:52:46,463 p=53540 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-23 07:52:46,464 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:52:46,464 p=53540 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-23 07:52:46,465 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:52:46,470 p=53540 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-23 07:52:46,474 p=53540 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-23 07:52:46,474 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:52:46,696 p=53540 u=master n=ansible | ok: [sm01] => (item=/home)
2025-07-23 07:52:46,942 p=53540 u=master n=ansible | ok: [sm01] => (item=/sw)
2025-07-23 07:52:46,948 p=53540 u=master n=ansible | TASK [common : [COMMON] Очистка старых экспортов] **************************************************************************************************************************
2025-07-23 07:52:46,948 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:46 +0000 (0:00:00.523)       0:00:37.266 ******** 
2025-07-23 07:52:46,982 p=53540 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-23 07:52:46,987 p=53540 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-23 07:52:46,990 p=53540 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-23 07:52:46,991 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:52:46,993 p=53540 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-23 07:52:46,993 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:52:47,000 p=53540 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-23 07:52:47,003 p=53540 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-23 07:52:47,004 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:52:47,215 p=53540 u=master n=ansible | changed: [sm01] => (item=/home)
2025-07-23 07:52:47,458 p=53540 u=master n=ansible | changed: [sm01] => (item=/sw)
2025-07-23 07:52:47,463 p=53540 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS с конкретными IP] ***********************************************************************************************************
2025-07-23 07:52:47,464 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:47 +0000 (0:00:00.515)       0:00:37.782 ******** 
2025-07-23 07:52:47,495 p=53540 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-23 07:52:47,502 p=53540 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-23 07:52:47,504 p=53540 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-23 07:52:47,505 p=53540 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-23 07:52:47,506 p=53540 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-23 07:52:47,507 p=53540 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-23 07:52:47,509 p=53540 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-23 07:52:47,510 p=53540 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-23 07:52:47,510 p=53540 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-23 07:52:47,511 p=53540 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-23 07:52:47,513 p=53540 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-23 07:52:47,514 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:52:47,516 p=53540 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-23 07:52:47,518 p=53540 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-23 07:52:47,519 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:52:47,523 p=53540 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-23 07:52:47,528 p=53540 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-23 07:52:47,533 p=53540 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-23 07:52:47,538 p=53540 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-23 07:52:47,543 p=53540 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-23 07:52:47,545 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:52:47,746 p=53540 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.161'})
2025-07-23 07:52:47,989 p=53540 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.167'})
2025-07-23 07:52:48,231 p=53540 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.168'})
2025-07-23 07:52:48,474 p=53540 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'})
2025-07-23 07:52:48,714 p=53540 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'})
2025-07-23 07:52:48,954 p=53540 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'})
2025-07-23 07:52:48,962 p=53540 u=master n=ansible | TASK [common : [COMMON] Запуск и включение NFS server] *********************************************************************************************************************
2025-07-23 07:52:48,962 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:48 +0000 (0:00:01.498)       0:00:39.280 ******** 
2025-07-23 07:52:48,993 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:52:48,996 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:52:49,008 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:52:49,440 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:52:49,445 p=53540 u=master n=ansible | TASK [common : [COMMON] Принудительная перезагрузка экспортов NFS] *********************************************************************************************************
2025-07-23 07:52:49,445 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:49 +0000 (0:00:00.482)       0:00:39.763 ******** 
2025-07-23 07:52:49,477 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:52:49,480 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:52:49,491 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:52:49,710 p=53540 u=master n=ansible | changed: [sm01]
2025-07-23 07:52:49,715 p=53540 u=master n=ansible | TASK [common : [COMMON] Проверка активных экспортов] ***********************************************************************************************************************
2025-07-23 07:52:49,715 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:49 +0000 (0:00:00.270)       0:00:40.033 ******** 
2025-07-23 07:52:49,747 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:52:49,754 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:52:49,760 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:52:49,976 p=53540 u=master n=ansible | changed: [sm01]
2025-07-23 07:52:49,980 p=53540 u=master n=ansible | TASK [common : [COMMON] Показать активные экспорты] ************************************************************************************************************************
2025-07-23 07:52:49,980 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:49 +0000 (0:00:00.265)       0:00:40.299 ******** 
2025-07-23 07:52:50,017 p=53540 u=master n=ansible | ok: [sm01] => 
  nfs_exports_check.stdout_lines:
  - "/home         \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/shared       \t10.20.90.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
2025-07-23 07:52:50,018 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:52:50,018 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:52:50,027 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:52:50,030 p=53540 u=master n=ansible | TASK [common : [COMMON] Установка NFS client] ******************************************************************************************************************************
2025-07-23 07:52:50,030 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:50 +0000 (0:00:00.050)       0:00:40.349 ******** 
2025-07-23 07:52:50,054 p=53540 u=master n=ansible | skipping: [sm01]
2025-07-23 07:52:50,979 p=53540 u=master n=ansible | ok: [cn02]
2025-07-23 07:52:51,125 p=53540 u=master n=ansible | ok: [sm02]
2025-07-23 07:52:51,137 p=53540 u=master n=ansible | ok: [cn01]
2025-07-23 07:52:51,141 p=53540 u=master n=ansible | TASK [common : [COMMON] Создание точек монтирования NFS] *******************************************************************************************************************
2025-07-23 07:52:51,141 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:51 +0000 (0:00:01.110)       0:00:41.460 ******** 
2025-07-23 07:52:51,163 p=53540 u=master n=ansible | skipping: [sm01] => (item=/sw) 
2025-07-23 07:52:51,167 p=53540 u=master n=ansible | skipping: [sm01]
2025-07-23 07:52:51,430 p=53540 u=master n=ansible | ok: [sm02] => (item=/sw)
2025-07-23 07:52:51,438 p=53540 u=master n=ansible | ok: [cn01] => (item=/sw)
2025-07-23 07:52:51,455 p=53540 u=master n=ansible | ok: [cn02] => (item=/sw)
2025-07-23 07:52:51,460 p=53540 u=master n=ansible | TASK [common : [COMMON] Монтирование NFS shares] ***************************************************************************************************************************
2025-07-23 07:52:51,460 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:51 +0000 (0:00:00.318)       0:00:41.778 ******** 
2025-07-23 07:52:51,481 p=53540 u=master n=ansible | skipping: [sm01] => (item={'path': '/home', 'src': '/home'}) 
2025-07-23 07:52:51,485 p=53540 u=master n=ansible | skipping: [sm01] => (item={'path': '/sw', 'src': '/sw'}) 
2025-07-23 07:52:51,498 p=53540 u=master n=ansible | skipping: [sm01]
2025-07-23 07:52:51,870 p=53540 u=master n=ansible | ok: [sm02] => (item={'path': '/home', 'src': '/home'})
2025-07-23 07:52:51,871 p=53540 u=master n=ansible | ok: [cn02] => (item={'path': '/home', 'src': '/home'})
2025-07-23 07:52:51,872 p=53540 u=master n=ansible | ok: [cn01] => (item={'path': '/home', 'src': '/home'})
2025-07-23 07:52:52,118 p=53540 u=master n=ansible | ok: [cn01] => (item={'path': '/sw', 'src': '/sw'})
2025-07-23 07:52:52,120 p=53540 u=master n=ansible | ok: [sm02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-23 07:52:52,127 p=53540 u=master n=ansible | ok: [cn02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-23 07:52:52,132 p=53540 u=master n=ansible | TASK [common : [COMMON] Создание базовых директорий Slurm] *****************************************************************************************************************
2025-07-23 07:52:52,132 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:52 +0000 (0:00:00.672)       0:00:42.451 ******** 
2025-07-23 07:52:52,417 p=53540 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:52,424 p=53540 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:52,437 p=53540 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:52,442 p=53540 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:52,670 p=53540 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:52,682 p=53540 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:52,696 p=53540 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:52,697 p=53540 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:52,928 p=53540 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:52,940 p=53540 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:52,944 p=53540 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:52,964 p=53540 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:53,188 p=53540 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:53,195 p=53540 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:53,196 p=53540 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:53,213 p=53540 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:53,443 p=53540 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-23 07:52:53,448 p=53540 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-23 07:52:53,454 p=53540 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-23 07:52:53,469 p=53540 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-23 07:52:53,695 p=53540 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:53,700 p=53540 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:53,706 p=53540 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:53,721 p=53540 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 07:52:53,727 p=53540 u=master n=ansible | TASK [common : [COMMON] Роль common выполнена успешно] *********************************************************************************************************************
2025-07-23 07:52:53,727 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:53 +0000 (0:00:01.594)       0:00:44.045 ******** 
2025-07-23 07:52:53,761 p=53540 u=master n=ansible | ok: [sm01] => 
  msg: ✅ Узел sm01 готов для установки Slurm
2025-07-23 07:52:53,762 p=53540 u=master n=ansible | ok: [sm02] => 
  msg: ✅ Узел sm02 готов для установки Slurm
2025-07-23 07:52:53,766 p=53540 u=master n=ansible | ok: [cn01] => 
  msg: ✅ Узел cn01 готов для установки Slurm
2025-07-23 07:52:53,776 p=53540 u=master n=ansible | ok: [cn02] => 
  msg: ✅ Узел cn02 готов для установки Slurm
2025-07-23 07:52:53,791 p=53540 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Начало сборки Slurm] *********************************************************************************************************************
2025-07-23 07:52:53,791 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:53 +0000 (0:00:00.063)       0:00:44.109 ******** 
2025-07-23 07:52:53,827 p=53540 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm01"
2025-07-23 07:52:53,828 p=53540 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm02"
2025-07-23 07:52:53,833 p=53540 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn01"
2025-07-23 07:52:53,846 p=53540 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn02"
2025-07-23 07:52:53,850 p=53540 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка дополнительных зависимостей для сборки] ****************************************************************************************
2025-07-23 07:52:53,850 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:52:53 +0000 (0:00:00.059)       0:00:44.168 ******** 
2025-07-23 07:52:53,884 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:52:53,886 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:52:53,898 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:53:06,854 p=53540 u=master n=ansible | changed: [sm01]
2025-07-23 07:53:06,859 p=53540 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для сборки] ************************************************************************************************
2025-07-23 07:53:06,859 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:53:06 +0000 (0:00:13.008)       0:00:57.177 ******** 
2025-07-23 07:53:06,894 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:53:06,894 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:53:06,904 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:53:07,121 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:53:07,125 p=53540 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка существования исходников] *******************************************************************************************************
2025-07-23 07:53:07,125 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:53:07 +0000 (0:00:00.266)       0:00:57.444 ******** 
2025-07-23 07:53:07,157 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:53:07,159 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:53:07,169 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:53:07,421 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:53:07,429 p=53540 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Скачивание исходников Slurm 25.05.1] *****************************************************************************************************
2025-07-23 07:53:07,429 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:53:07 +0000 (0:00:00.303)       0:00:57.748 ******** 
2025-07-23 07:53:07,453 p=53540 u=master n=ansible | skipping: [sm01]
2025-07-23 07:53:07,464 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:53:07,466 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:53:07,474 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:53:07,478 p=53540 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Извлечение исходников Slurm] *************************************************************************************************************
2025-07-23 07:53:07,479 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:53:07 +0000 (0:00:00.049)       0:00:57.797 ******** 
2025-07-23 07:53:07,514 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:53:07,514 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:53:07,523 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:53:07,568 p=53540 u=master n=ansible | skipping: [sm01]
2025-07-23 07:53:07,572 p=53540 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Конфигурация сборки Slurm с JWT поддержкой] **********************************************************************************************
2025-07-23 07:53:07,572 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:53:07 +0000 (0:00:00.093)       0:00:57.891 ******** 
2025-07-23 07:53:07,606 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:53:07,607 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:53:07,615 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:53:07,823 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:53:07,827 p=53540 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат конфигурации] ******************************************************************************************************************
2025-07-23 07:53:07,827 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:53:07 +0000 (0:00:00.255)       0:00:58.146 ******** 
2025-07-23 07:53:07,855 p=53540 u=master n=ansible | skipping: [sm01]
2025-07-23 07:53:07,865 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:53:07,866 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:53:07,875 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:53:07,879 p=53540 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Компиляция Slurm (это займет время...)] **************************************************************************************************
2025-07-23 07:53:07,880 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:53:07 +0000 (0:00:00.052)       0:00:58.198 ******** 
2025-07-23 07:53:07,912 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:53:07,914 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:53:07,923 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:53:08,135 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:53:08,139 p=53540 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка Slurm на master] ***************************************************************************************************************
2025-07-23 07:53:08,139 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:53:08 +0000 (0:00:00.259)       0:00:58.457 ******** 
2025-07-23 07:53:08,172 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:53:08,175 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:53:08,183 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:53:08,397 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:53:08,401 p=53540 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание архива Slurm для копирования] ***************************************************************************************************
2025-07-23 07:53:08,402 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:53:08 +0000 (0:00:00.262)       0:00:58.720 ******** 
2025-07-23 07:53:08,436 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:53:08,439 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:53:08,447 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:56:14,283 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:56:14,287 p=53540 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] *************************************************************************************************
2025-07-23 07:56:14,288 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:56:14 +0000 (0:03:05.885)       0:04:04.606 ******** 
2025-07-23 07:56:14,558 p=53540 u=master n=ansible | ok: [sm01]
2025-07-23 07:56:15,484 p=53540 u=master n=ansible | ok: [sm02]
2025-07-23 07:56:15,487 p=53540 u=master n=ansible | ok: [cn01]
2025-07-23 07:56:15,535 p=53540 u=master n=ansible | ok: [cn02]
2025-07-23 07:56:15,539 p=53540 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание архива Slurm в NFS shared директории] *******************************************************************************************
2025-07-23 07:56:15,540 p=53540 u=master n=ansible | Wednesday 23 July 2025  07:56:15 +0000 (0:00:01.251)       0:04:05.858 ******** 
2025-07-23 07:56:15,572 p=53540 u=master n=ansible | skipping: [sm02]
2025-07-23 07:56:15,575 p=53540 u=master n=ansible | skipping: [cn01]
2025-07-23 07:56:15,584 p=53540 u=master n=ansible | skipping: [cn02]
2025-07-23 07:58:59,937 p=53540 u=master n=ansible |  [ERROR]: User interrupted execution

2025-07-23 08:00:10,943 p=54374 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-23 08:00:10,943 p=54374 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-23 08:00:11,609 p=54374 u=master n=ansible | sm01 | CHANGED | rc=0 >>
rm: cannot remove '/shared/slurm-25.05.1-install.tar.gz': Permission denied

2025-07-23 08:00:24,534 p=54428 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-23 08:00:24,534 p=54428 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-23 08:00:25,214 p=54428 u=master n=ansible | sm01 | CHANGED | rc=0 >>


2025-07-23 08:06:46,602 p=54485 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-23 08:06:46,602 p=54485 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the 
M(ansible.builtin.gather_facts) or M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. 
Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
2025-07-23 08:06:47,068 p=54485 u=master n=ansible | PLAY [Тестирование роли slurm_build] ***************************************************************************************************************************************
2025-07-23 08:06:47,091 p=54485 u=master n=ansible | TASK [Информация о сборке Slurm] *******************************************************************************************************************************************
2025-07-23 08:06:47,092 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:06:47 +0000 (0:00:00.026)       0:00:00.026 ******** 
2025-07-23 08:06:47,143 p=54485 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F528 Начинаем сборку Slurm 25.05.1\n\U0001F4CD Сборка на: sm01\n\U0001F4E6 Установка на: sm01, sm02, cn01, cn02\n\U0001F510 JWT поддержка включена"
2025-07-23 08:06:47,147 p=54485 u=master n=ansible | TASK [Проверка доступного места на диске] **********************************************************************************************************************************
2025-07-23 08:06:47,148 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:06:47 +0000 (0:00:00.055)       0:00:00.082 ******** 
2025-07-23 08:06:47,191 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:06:47,192 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:06:47,202 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:06:48,434 p=54485 u=master n=ansible | changed: [sm01]
2025-07-23 08:06:48,438 p=54485 u=master n=ansible | TASK [Предупреждение о месте на диске] *************************************************************************************************************************************
2025-07-23 08:06:48,438 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:06:48 +0000 (0:00:01.290)       0:00:01.373 ******** 
2025-07-23 08:06:48,470 p=54485 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4BE Доступно места в /tmp: 37G\n⚠️  Для сборки Slurm требуется ~2GB свободного места"
2025-07-23 08:06:48,481 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:06:48,482 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:06:48,483 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:06:48,503 p=54485 u=master n=ansible | TASK [common : [COMMON] Начало выполнения роли common] *********************************************************************************************************************
2025-07-23 08:06:48,503 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:06:48 +0000 (0:00:00.064)       0:00:01.438 ******** 
2025-07-23 08:06:48,535 p=54485 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm01"
2025-07-23 08:06:48,540 p=54485 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm02"
2025-07-23 08:06:48,542 p=54485 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn01"
2025-07-23 08:06:48,554 p=54485 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn02"
2025-07-23 08:06:48,558 p=54485 u=master n=ansible | TASK [common : [COMMON] Обновление apt cache] ******************************************************************************************************************************
2025-07-23 08:06:48,559 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:06:48 +0000 (0:00:00.055)       0:00:01.493 ******** 
2025-07-23 08:06:49,459 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:06:50,345 p=54485 u=master n=ansible | ok: [sm02]
2025-07-23 08:06:50,407 p=54485 u=master n=ansible | ok: [cn01]
2025-07-23 08:06:50,408 p=54485 u=master n=ansible | ok: [cn02]
2025-07-23 08:06:50,412 p=54485 u=master n=ansible | TASK [common : [COMMON] Установка базовых пакетов] *************************************************************************************************************************
2025-07-23 08:06:50,413 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:06:50 +0000 (0:00:01.854)       0:00:03.347 ******** 
2025-07-23 08:06:51,429 p=54485 u=master n=ansible | ok: [sm02]
2025-07-23 08:06:51,457 p=54485 u=master n=ansible | ok: [cn01]
2025-07-23 08:06:51,471 p=54485 u=master n=ansible | ok: [cn02]
2025-07-23 08:07:00,307 p=54485 u=master n=ansible | changed: [sm01]
2025-07-23 08:07:00,311 p=54485 u=master n=ansible | TASK [common : [COMMON] Настройка timezone] ********************************************************************************************************************************
2025-07-23 08:07:00,311 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:00 +0000 (0:00:09.898)       0:00:13.246 ******** 
2025-07-23 08:07:00,796 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:00,813 p=54485 u=master n=ansible | ok: [cn01]
2025-07-23 08:07:00,838 p=54485 u=master n=ansible | ok: [cn02]
2025-07-23 08:07:00,843 p=54485 u=master n=ansible | ok: [sm02]
2025-07-23 08:07:00,847 p=54485 u=master n=ansible | TASK [common : [COMMON] Обеспечение hostname resolution для кластера] ******************************************************************************************************
2025-07-23 08:07:00,847 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:00 +0000 (0:00:00.535)       0:00:13.782 ******** 
2025-07-23 08:07:01,238 p=54485 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-23 08:07:01,239 p=54485 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-23 08:07:01,241 p=54485 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-23 08:07:01,248 p=54485 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-23 08:07:01,477 p=54485 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-23 08:07:01,479 p=54485 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-23 08:07:01,480 p=54485 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-23 08:07:01,494 p=54485 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-23 08:07:01,717 p=54485 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-23 08:07:01,719 p=54485 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-23 08:07:01,724 p=54485 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-23 08:07:01,745 p=54485 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-23 08:07:01,957 p=54485 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-23 08:07:01,961 p=54485 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-23 08:07:01,972 p=54485 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-23 08:07:01,989 p=54485 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-23 08:07:01,994 p=54485 u=master n=ansible | TASK [common : [COMMON] Создание пользователя slurm] ***********************************************************************************************************************
2025-07-23 08:07:01,995 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:01 +0000 (0:00:01.147)       0:00:14.929 ******** 
2025-07-23 08:07:02,491 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:02,491 p=54485 u=master n=ansible | ok: [sm02]
2025-07-23 08:07:02,492 p=54485 u=master n=ansible | ok: [cn02]
2025-07-23 08:07:02,493 p=54485 u=master n=ansible | ok: [cn01]
2025-07-23 08:07:02,497 p=54485 u=master n=ansible | TASK [common : [COMMON] Установка MUNGE] ***********************************************************************************************************************************
2025-07-23 08:07:02,497 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:02 +0000 (0:00:00.502)       0:00:15.432 ******** 
2025-07-23 08:07:03,488 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:03,514 p=54485 u=master n=ansible | ok: [sm02]
2025-07-23 08:07:03,518 p=54485 u=master n=ansible | ok: [cn01]
2025-07-23 08:07:03,542 p=54485 u=master n=ansible | ok: [cn02]
2025-07-23 08:07:03,546 p=54485 u=master n=ansible | TASK [common : [COMMON] Остановка MUNGE перед настройкой] ******************************************************************************************************************
2025-07-23 08:07:03,546 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:03 +0000 (0:00:01.048)       0:00:16.481 ******** 
2025-07-23 08:07:05,418 p=54485 u=master n=ansible | changed: [sm01]
2025-07-23 08:07:05,428 p=54485 u=master n=ansible | changed: [cn02]
2025-07-23 08:07:05,436 p=54485 u=master n=ansible | changed: [sm02]
2025-07-23 08:07:05,456 p=54485 u=master n=ansible | changed: [cn01]
2025-07-23 08:07:05,461 p=54485 u=master n=ansible | TASK [common : [COMMON] Создание MUNGE ключа на master узле] ***************************************************************************************************************
2025-07-23 08:07:05,461 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:05 +0000 (0:00:01.915)       0:00:18.396 ******** 
2025-07-23 08:07:05,494 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:05,496 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:05,505 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:05,711 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:05,715 p=54485 u=master n=ansible | TASK [common : [COMMON] Получение MUNGE ключа с master узла] ***************************************************************************************************************
2025-07-23 08:07:05,715 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:05 +0000 (0:00:00.253)       0:00:18.650 ******** 
2025-07-23 08:07:05,757 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:05,758 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:05,768 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:06,096 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:06,102 p=54485 u=master n=ansible | TASK [common : [COMMON] Распространение MUNGE ключа на все узлы] ***********************************************************************************************************
2025-07-23 08:07:06,102 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:06 +0000 (0:00:00.386)       0:00:19.037 ******** 
2025-07-23 08:07:06,128 p=54485 u=master n=ansible | skipping: [sm01]
2025-07-23 08:07:07,475 p=54485 u=master n=ansible | ok: [cn02]
2025-07-23 08:07:07,475 p=54485 u=master n=ansible | ok: [sm02]
2025-07-23 08:07:07,476 p=54485 u=master n=ansible | ok: [cn01]
2025-07-23 08:07:07,480 p=54485 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа MUNGE] **********************************************************************************************************************
2025-07-23 08:07:07,480 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:07 +0000 (0:00:01.378)       0:00:20.415 ******** 
2025-07-23 08:07:07,757 p=54485 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:07:07,765 p=54485 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:07:07,781 p=54485 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:07:07,782 p=54485 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:07:08,012 p=54485 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:07:08,016 p=54485 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:07:08,035 p=54485 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:07:08,047 p=54485 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:07:08,265 p=54485 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:07:08,266 p=54485 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:07:08,290 p=54485 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:07:08,310 p=54485 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:07:08,514 p=54485 u=master n=ansible | changed: [sm01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-23 08:07:08,516 p=54485 u=master n=ansible | changed: [sm02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-23 08:07:08,545 p=54485 u=master n=ansible | changed: [cn02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-23 08:07:08,565 p=54485 u=master n=ansible | changed: [cn01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-23 08:07:08,571 p=54485 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа на ключ MUNGE] **************************************************************************************************************
2025-07-23 08:07:08,572 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:08 +0000 (0:00:01.091)       0:00:21.506 ******** 
2025-07-23 08:07:08,835 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:08,845 p=54485 u=master n=ansible | ok: [sm02]
2025-07-23 08:07:08,866 p=54485 u=master n=ansible | ok: [cn01]
2025-07-23 08:07:08,867 p=54485 u=master n=ansible | ok: [cn02]
2025-07-23 08:07:08,871 p=54485 u=master n=ansible | TASK [common : [COMMON] Запуск и включение MUNGE] **************************************************************************************************************************
2025-07-23 08:07:08,871 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:08 +0000 (0:00:00.299)       0:00:21.806 ******** 
2025-07-23 08:07:10,727 p=54485 u=master n=ansible | changed: [sm01]
2025-07-23 08:07:10,751 p=54485 u=master n=ansible | changed: [cn01]
2025-07-23 08:07:10,754 p=54485 u=master n=ansible | changed: [sm02]
2025-07-23 08:07:10,874 p=54485 u=master n=ansible | changed: [cn02]
2025-07-23 08:07:10,879 p=54485 u=master n=ansible | TASK [common : [COMMON] Проверка работы MUNGE] *****************************************************************************************************************************
2025-07-23 08:07:10,879 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:10 +0000 (0:00:02.007)       0:00:23.814 ******** 
2025-07-23 08:07:11,145 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:11,146 p=54485 u=master n=ansible | ok: [sm02]
2025-07-23 08:07:11,167 p=54485 u=master n=ansible | ok: [cn02]
2025-07-23 08:07:11,171 p=54485 u=master n=ansible | ok: [cn01]
2025-07-23 08:07:11,176 p=54485 u=master n=ansible | TASK [common : [COMMON] Результат проверки MUNGE] **************************************************************************************************************************
2025-07-23 08:07:11,176 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:11 +0000 (0:00:00.296)       0:00:24.110 ******** 
2025-07-23 08:07:11,210 p=54485 u=master n=ansible | ok: [sm01] => 
  msg: MUNGE работает корректно на sm01
2025-07-23 08:07:11,211 p=54485 u=master n=ansible | ok: [sm02] => 
  msg: MUNGE работает корректно на sm02
2025-07-23 08:07:11,216 p=54485 u=master n=ansible | ok: [cn01] => 
  msg: MUNGE работает корректно на cn01
2025-07-23 08:07:11,228 p=54485 u=master n=ansible | ok: [cn02] => 
  msg: MUNGE работает корректно на cn02
2025-07-23 08:07:11,233 p=54485 u=master n=ansible | TASK [common : [COMMON] Установка HWLOC] ***********************************************************************************************************************************
2025-07-23 08:07:11,233 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:11 +0000 (0:00:00.057)       0:00:24.168 ******** 
2025-07-23 08:07:12,213 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:12,279 p=54485 u=master n=ansible | ok: [cn01]
2025-07-23 08:07:12,310 p=54485 u=master n=ansible | ok: [sm02]
2025-07-23 08:07:12,312 p=54485 u=master n=ansible | ok: [cn02]
2025-07-23 08:07:12,316 p=54485 u=master n=ansible | TASK [common : [COMMON] Проверка HWLOC] ************************************************************************************************************************************
2025-07-23 08:07:12,316 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:12 +0000 (0:00:01.083)       0:00:25.251 ******** 
2025-07-23 08:07:12,586 p=54485 u=master n=ansible | ok: [sm02]
2025-07-23 08:07:12,601 p=54485 u=master n=ansible | ok: [cn01]
2025-07-23 08:07:12,611 p=54485 u=master n=ansible | ok: [cn02]
2025-07-23 08:07:12,737 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:12,741 p=54485 u=master n=ansible | TASK [common : [COMMON] Версия HWLOC] **************************************************************************************************************************************
2025-07-23 08:07:12,741 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:12 +0000 (0:00:00.424)       0:00:25.675 ******** 
2025-07-23 08:07:12,767 p=54485 u=master n=ansible | ok: [sm01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 08:07:12,778 p=54485 u=master n=ansible | ok: [sm02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 08:07:12,782 p=54485 u=master n=ansible | ok: [cn01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 08:07:12,795 p=54485 u=master n=ansible | ok: [cn02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 08:07:12,799 p=54485 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] ********************************************************************************************************************
2025-07-23 08:07:12,799 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:12 +0000 (0:00:00.058)       0:00:25.734 ******** 
2025-07-23 08:07:12,832 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:12,834 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:12,846 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:13,706 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:13,710 p=54485 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] **************************************************************************************************************
2025-07-23 08:07:13,710 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:13 +0000 (0:00:00.911)       0:00:26.645 ******** 
2025-07-23 08:07:13,740 p=54485 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-23 08:07:13,747 p=54485 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-23 08:07:13,748 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:13,752 p=54485 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-23 08:07:13,753 p=54485 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-23 08:07:13,753 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:13,759 p=54485 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-23 08:07:13,761 p=54485 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-23 08:07:13,762 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:13,978 p=54485 u=master n=ansible | ok: [sm01] => (item=/home)
2025-07-23 08:07:14,222 p=54485 u=master n=ansible | ok: [sm01] => (item=/sw)
2025-07-23 08:07:14,227 p=54485 u=master n=ansible | TASK [common : [COMMON] Очистка старых экспортов] **************************************************************************************************************************
2025-07-23 08:07:14,227 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:14 +0000 (0:00:00.517)       0:00:27.162 ******** 
2025-07-23 08:07:14,257 p=54485 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-23 08:07:14,259 p=54485 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-23 08:07:14,263 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:14,265 p=54485 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-23 08:07:14,266 p=54485 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-23 08:07:14,267 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:14,276 p=54485 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-23 08:07:14,279 p=54485 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-23 08:07:14,279 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:14,490 p=54485 u=master n=ansible | changed: [sm01] => (item=/home)
2025-07-23 08:07:14,728 p=54485 u=master n=ansible | changed: [sm01] => (item=/sw)
2025-07-23 08:07:14,733 p=54485 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS с конкретными IP] ***********************************************************************************************************
2025-07-23 08:07:14,734 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:14 +0000 (0:00:00.506)       0:00:27.668 ******** 
2025-07-23 08:07:14,770 p=54485 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-23 08:07:14,771 p=54485 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-23 08:07:14,772 p=54485 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-23 08:07:14,773 p=54485 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-23 08:07:14,774 p=54485 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-23 08:07:14,775 p=54485 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-23 08:07:14,776 p=54485 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-23 08:07:14,777 p=54485 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-23 08:07:14,779 p=54485 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-23 08:07:14,780 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:14,781 p=54485 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-23 08:07:14,782 p=54485 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-23 08:07:14,784 p=54485 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-23 08:07:14,785 p=54485 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-23 08:07:14,787 p=54485 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-23 08:07:14,788 p=54485 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-23 08:07:14,788 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:14,791 p=54485 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-23 08:07:14,794 p=54485 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-23 08:07:14,796 p=54485 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-23 08:07:14,797 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:14,996 p=54485 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.161'})
2025-07-23 08:07:15,241 p=54485 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.167'})
2025-07-23 08:07:15,481 p=54485 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.168'})
2025-07-23 08:07:15,720 p=54485 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'})
2025-07-23 08:07:15,959 p=54485 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'})
2025-07-23 08:07:16,199 p=54485 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'})
2025-07-23 08:07:16,206 p=54485 u=master n=ansible | TASK [common : [COMMON] Запуск и включение NFS server] *********************************************************************************************************************
2025-07-23 08:07:16,207 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:16 +0000 (0:00:01.472)       0:00:29.141 ******** 
2025-07-23 08:07:16,241 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:16,243 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:16,254 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:16,681 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:16,686 p=54485 u=master n=ansible | TASK [common : [COMMON] Принудительная перезагрузка экспортов NFS] *********************************************************************************************************
2025-07-23 08:07:16,686 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:16 +0000 (0:00:00.479)       0:00:29.621 ******** 
2025-07-23 08:07:16,719 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:16,721 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:16,732 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:16,952 p=54485 u=master n=ansible | changed: [sm01]
2025-07-23 08:07:16,956 p=54485 u=master n=ansible | TASK [common : [COMMON] Проверка активных экспортов] ***********************************************************************************************************************
2025-07-23 08:07:16,956 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:16 +0000 (0:00:00.270)       0:00:29.891 ******** 
2025-07-23 08:07:16,989 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:16,992 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:17,001 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:17,216 p=54485 u=master n=ansible | changed: [sm01]
2025-07-23 08:07:17,220 p=54485 u=master n=ansible | TASK [common : [COMMON] Показать активные экспорты] ************************************************************************************************************************
2025-07-23 08:07:17,220 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:17 +0000 (0:00:00.263)       0:00:30.155 ******** 
2025-07-23 08:07:17,254 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:17,257 p=54485 u=master n=ansible | ok: [sm01] => 
  nfs_exports_check.stdout_lines:
  - "/home         \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/shared       \t10.20.90.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
2025-07-23 08:07:17,257 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:17,267 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:17,272 p=54485 u=master n=ansible | TASK [common : [COMMON] Установка NFS client] ******************************************************************************************************************************
2025-07-23 08:07:17,272 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:17 +0000 (0:00:00.051)       0:00:30.207 ******** 
2025-07-23 08:07:17,296 p=54485 u=master n=ansible | skipping: [sm01]
2025-07-23 08:07:18,272 p=54485 u=master n=ansible | ok: [cn02]
2025-07-23 08:07:18,289 p=54485 u=master n=ansible | ok: [sm02]
2025-07-23 08:07:18,342 p=54485 u=master n=ansible | ok: [cn01]
2025-07-23 08:07:18,346 p=54485 u=master n=ansible | TASK [common : [COMMON] Создание точек монтирования NFS] *******************************************************************************************************************
2025-07-23 08:07:18,346 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:18 +0000 (0:00:01.073)       0:00:31.281 ******** 
2025-07-23 08:07:18,365 p=54485 u=master n=ansible | skipping: [sm01] => (item=/sw) 
2025-07-23 08:07:18,372 p=54485 u=master n=ansible | skipping: [sm01]
2025-07-23 08:07:18,630 p=54485 u=master n=ansible | ok: [sm02] => (item=/sw)
2025-07-23 08:07:18,644 p=54485 u=master n=ansible | ok: [cn01] => (item=/sw)
2025-07-23 08:07:18,647 p=54485 u=master n=ansible | ok: [cn02] => (item=/sw)
2025-07-23 08:07:18,652 p=54485 u=master n=ansible | TASK [common : [COMMON] Монтирование NFS shares] ***************************************************************************************************************************
2025-07-23 08:07:18,652 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:18 +0000 (0:00:00.305)       0:00:31.587 ******** 
2025-07-23 08:07:18,674 p=54485 u=master n=ansible | skipping: [sm01] => (item={'path': '/home', 'src': '/home'}) 
2025-07-23 08:07:18,678 p=54485 u=master n=ansible | skipping: [sm01] => (item={'path': '/sw', 'src': '/sw'}) 
2025-07-23 08:07:18,690 p=54485 u=master n=ansible | skipping: [sm01]
2025-07-23 08:07:19,111 p=54485 u=master n=ansible | ok: [sm02] => (item={'path': '/home', 'src': '/home'})
2025-07-23 08:07:19,111 p=54485 u=master n=ansible | ok: [cn02] => (item={'path': '/home', 'src': '/home'})
2025-07-23 08:07:19,113 p=54485 u=master n=ansible | ok: [cn01] => (item={'path': '/home', 'src': '/home'})
2025-07-23 08:07:19,370 p=54485 u=master n=ansible | ok: [cn01] => (item={'path': '/sw', 'src': '/sw'})
2025-07-23 08:07:19,390 p=54485 u=master n=ansible | ok: [sm02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-23 08:07:19,401 p=54485 u=master n=ansible | ok: [cn02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-23 08:07:19,407 p=54485 u=master n=ansible | TASK [common : [COMMON] Создание базовых директорий Slurm] *****************************************************************************************************************
2025-07-23 08:07:19,407 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:19 +0000 (0:00:00.754)       0:00:32.341 ******** 
2025-07-23 08:07:19,685 p=54485 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:19,687 p=54485 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:19,711 p=54485 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:19,713 p=54485 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:19,936 p=54485 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:19,938 p=54485 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:19,965 p=54485 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:19,977 p=54485 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:20,190 p=54485 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:20,191 p=54485 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:20,231 p=54485 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:20,256 p=54485 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:20,443 p=54485 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:20,444 p=54485 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:20,485 p=54485 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:20,506 p=54485 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:20,694 p=54485 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-23 08:07:20,746 p=54485 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-23 08:07:20,752 p=54485 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-23 08:07:20,792 p=54485 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-23 08:07:20,997 p=54485 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:21,027 p=54485 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:21,029 p=54485 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:21,051 p=54485 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:07:21,057 p=54485 u=master n=ansible | TASK [common : [COMMON] Роль common выполнена успешно] *********************************************************************************************************************
2025-07-23 08:07:21,057 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:21 +0000 (0:00:01.650)       0:00:33.992 ******** 
2025-07-23 08:07:21,092 p=54485 u=master n=ansible | ok: [sm01] => 
  msg: ✅ Узел sm01 готов для установки Slurm
2025-07-23 08:07:21,094 p=54485 u=master n=ansible | ok: [sm02] => 
  msg: ✅ Узел sm02 готов для установки Slurm
2025-07-23 08:07:21,103 p=54485 u=master n=ansible | ok: [cn01] => 
  msg: ✅ Узел cn01 готов для установки Slurm
2025-07-23 08:07:21,111 p=54485 u=master n=ansible | ok: [cn02] => 
  msg: ✅ Узел cn02 готов для установки Slurm
2025-07-23 08:07:21,123 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Начало сборки Slurm] *********************************************************************************************************************
2025-07-23 08:07:21,123 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:21 +0000 (0:00:00.065)       0:00:34.058 ******** 
2025-07-23 08:07:21,157 p=54485 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm01"
2025-07-23 08:07:21,158 p=54485 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm02"
2025-07-23 08:07:21,162 p=54485 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn01"
2025-07-23 08:07:21,175 p=54485 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn02"
2025-07-23 08:07:21,180 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка дополнительных зависимостей для сборки] ****************************************************************************************
2025-07-23 08:07:21,180 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:21 +0000 (0:00:00.057)       0:00:34.115 ******** 
2025-07-23 08:07:21,213 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:21,215 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:21,227 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:30,815 p=54485 u=master n=ansible | changed: [sm01]
2025-07-23 08:07:30,820 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для сборки] ************************************************************************************************
2025-07-23 08:07:30,821 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:30 +0000 (0:00:09.640)       0:00:43.755 ******** 
2025-07-23 08:07:30,855 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:30,858 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:30,868 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:31,087 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:31,091 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка существования исходников] *******************************************************************************************************
2025-07-23 08:07:31,091 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:31 +0000 (0:00:00.270)       0:00:44.026 ******** 
2025-07-23 08:07:31,127 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:31,128 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:31,140 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:31,384 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:31,390 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Скачивание исходников Slurm 25.05.1] *****************************************************************************************************
2025-07-23 08:07:31,391 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:31 +0000 (0:00:00.299)       0:00:44.325 ******** 
2025-07-23 08:07:31,416 p=54485 u=master n=ansible | skipping: [sm01]
2025-07-23 08:07:31,426 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:31,429 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:31,438 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:31,443 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Извлечение исходников Slurm] *************************************************************************************************************
2025-07-23 08:07:31,443 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:31 +0000 (0:00:00.052)       0:00:44.377 ******** 
2025-07-23 08:07:31,479 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:31,480 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:31,491 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:31,532 p=54485 u=master n=ansible | skipping: [sm01]
2025-07-23 08:07:31,536 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Конфигурация сборки Slurm с JWT поддержкой] **********************************************************************************************
2025-07-23 08:07:31,536 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:31 +0000 (0:00:00.093)       0:00:44.471 ******** 
2025-07-23 08:07:31,571 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:31,572 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:31,586 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:31,789 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:31,793 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат конфигурации] ******************************************************************************************************************
2025-07-23 08:07:31,793 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:31 +0000 (0:00:00.257)       0:00:44.728 ******** 
2025-07-23 08:07:31,816 p=54485 u=master n=ansible | skipping: [sm01]
2025-07-23 08:07:31,828 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:31,831 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:31,841 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:31,845 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Компиляция Slurm (это займет время...)] **************************************************************************************************
2025-07-23 08:07:31,845 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:31 +0000 (0:00:00.051)       0:00:44.780 ******** 
2025-07-23 08:07:31,881 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:31,883 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:31,891 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:32,097 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:32,101 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка Slurm на master] ***************************************************************************************************************
2025-07-23 08:07:32,101 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:32 +0000 (0:00:00.256)       0:00:45.036 ******** 
2025-07-23 08:07:32,136 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:32,138 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:32,146 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:07:32,356 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:07:32,361 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание архива Slurm для копирования] ***************************************************************************************************
2025-07-23 08:07:32,361 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:07:32 +0000 (0:00:00.259)       0:00:45.296 ******** 
2025-07-23 08:07:32,396 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:07:32,398 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:07:32,407 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:10:36,409 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:10:36,415 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] *************************************************************************************************
2025-07-23 08:10:36,416 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:10:36 +0000 (0:03:04.054)       0:03:49.350 ******** 
2025-07-23 08:10:36,692 p=54485 u=master n=ansible | ok: [sm01]
2025-07-23 08:10:37,598 p=54485 u=master n=ansible | ok: [sm02]
2025-07-23 08:10:37,649 p=54485 u=master n=ansible | ok: [cn02]
2025-07-23 08:10:37,650 p=54485 u=master n=ansible | ok: [cn01]
2025-07-23 08:10:37,655 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] **********************************************************************************************
2025-07-23 08:10:37,655 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:10:37 +0000 (0:00:01.239)       0:03:50.590 ******** 
2025-07-23 08:10:37,690 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:10:37,692 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:10:37,702 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:10:37,916 p=54485 u=master n=ansible | changed: [sm01]
2025-07-23 08:10:37,920 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] ******************************************************************************************************************
2025-07-23 08:10:37,920 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:10:37 +0000 (0:00:00.265)       0:03:50.855 ******** 
2025-07-23 08:10:37,959 p=54485 u=master n=ansible | ok: [sm01] => 
  msg: "Размер установки Slurm на sm01: 483M\t/opt/slurm"
2025-07-23 08:10:37,960 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:10:37,961 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:10:37,970 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:10:37,973 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS] ************************************************************************************************
2025-07-23 08:10:37,974 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:10:37 +0000 (0:00:00.053)       0:03:50.908 ******** 
2025-07-23 08:10:38,008 p=54485 u=master n=ansible | skipping: [sm02]
2025-07-23 08:10:38,010 p=54485 u=master n=ansible | skipping: [cn01]
2025-07-23 08:10:38,019 p=54485 u=master n=ansible | skipping: [cn02]
2025-07-23 08:10:38,237 p=54485 u=master n=ansible | changed: [sm01]
2025-07-23 08:10:38,241 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] **************************************************************************************************************
2025-07-23 08:10:38,241 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:10:38 +0000 (0:00:00.267)       0:03:51.176 ******** 
2025-07-23 08:10:38,265 p=54485 u=master n=ansible | skipping: [sm01]
2025-07-23 08:11:08,683 p=54485 u=master n=ansible | fatal: [sm02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 08:11:08,684 p=54485 u=master n=ansible | fatal: [cn02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 08:11:08,687 p=54485 u=master n=ansible | fatal: [cn01]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 08:11:08,693 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ****************************************************************************************************
2025-07-23 08:11:08,694 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:11:08 +0000 (0:00:30.452)       0:04:21.628 ******** 
2025-07-23 08:11:08,718 p=54485 u=master n=ansible | skipping: [sm01]
2025-07-23 08:11:08,722 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] *********************************************************************************************************
2025-07-23 08:11:08,722 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:11:08 +0000 (0:00:00.028)       0:04:21.657 ******** 
2025-07-23 08:11:09,001 p=54485 u=master n=ansible | changed: [sm01]
2025-07-23 08:11:09,006 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание символических ссылок для пользовательских команд Slurm] *************************************************************************
2025-07-23 08:11:09,006 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:11:09 +0000 (0:00:00.283)       0:04:21.940 ******** 
2025-07-23 08:11:09,278 p=54485 u=master n=ansible | ok: [sm01] => (item=sinfo)
2025-07-23 08:11:09,524 p=54485 u=master n=ansible | ok: [sm01] => (item=squeue)
2025-07-23 08:11:09,774 p=54485 u=master n=ansible | ok: [sm01] => (item=scancel)
2025-07-23 08:11:10,017 p=54485 u=master n=ansible | ok: [sm01] => (item=sbatch)
2025-07-23 08:11:10,260 p=54485 u=master n=ansible | ok: [sm01] => (item=salloc)
2025-07-23 08:11:10,504 p=54485 u=master n=ansible | ok: [sm01] => (item=srun)
2025-07-23 08:11:10,746 p=54485 u=master n=ansible | ok: [sm01] => (item=sacct)
2025-07-23 08:11:10,990 p=54485 u=master n=ansible | ok: [sm01] => (item=scontrol)
2025-07-23 08:11:11,232 p=54485 u=master n=ansible | ok: [sm01] => (item=sprio)
2025-07-23 08:11:11,476 p=54485 u=master n=ansible | ok: [sm01] => (item=smap)
2025-07-23 08:11:11,721 p=54485 u=master n=ansible | ok: [sm01] => (item=sdiag)
2025-07-23 08:11:11,967 p=54485 u=master n=ansible | ok: [sm01] => (item=sstat)
2025-07-23 08:11:12,211 p=54485 u=master n=ansible | ok: [sm01] => (item=sreport)
2025-07-23 08:11:12,458 p=54485 u=master n=ansible | ok: [sm01] => (item=sacctmgr)
2025-07-23 08:11:12,702 p=54485 u=master n=ansible | ok: [sm01] => (item=sattach)
2025-07-23 08:11:12,946 p=54485 u=master n=ansible | ok: [sm01] => (item=sbcast)
2025-07-23 08:11:13,190 p=54485 u=master n=ansible | ok: [sm01] => (item=sshare)
2025-07-23 08:11:13,432 p=54485 u=master n=ansible | ok: [sm01] => (item=sview)
2025-07-23 08:11:13,440 p=54485 u=master n=ansible | [WARNING]: Cannot set fs attributes on a non-existent symlink target. follow should be set to False to avoid this.

2025-07-23 08:11:13,445 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание символических ссылок для системных демонов Slurm] *******************************************************************************
2025-07-23 08:11:13,446 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:11:13 +0000 (0:00:04.439)       0:04:26.380 ******** 
2025-07-23 08:11:13,714 p=54485 u=master n=ansible | ok: [sm01] => (item=slurmctld)
2025-07-23 08:11:13,980 p=54485 u=master n=ansible | ok: [sm01] => (item=slurmd)
2025-07-23 08:11:14,226 p=54485 u=master n=ansible | ok: [sm01] => (item=slurmdbd)
2025-07-23 08:11:14,471 p=54485 u=master n=ansible | ok: [sm01] => (item=slurmrestd)
2025-07-23 08:11:14,716 p=54485 u=master n=ansible | ok: [sm01] => (item=slurmstepd)
2025-07-23 08:11:14,722 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Обновление библиотечного кеша] ***********************************************************************************************************
2025-07-23 08:11:14,723 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:11:14 +0000 (0:00:01.276)       0:04:27.657 ******** 
2025-07-23 08:11:15,013 p=54485 u=master n=ansible | changed: [sm01]
2025-07-23 08:11:15,017 p=54485 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка версии Slurm] *******************************************************************************************************************
2025-07-23 08:11:15,017 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:11:15 +0000 (0:00:00.294)       0:04:27.952 ******** 
2025-07-23 08:11:15,314 p=54485 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  cmd:
  - /opt/slurm/bin/sinfo
  - --version
  delta: '0:00:00.040146'
  end: '2025-07-23 11:11:15.286538'
  msg: non-zero return code
  rc: 1
  start: '2025-07-23 11:11:15.246392'
  stderr: |-
    sinfo: error: resolve_ctls_from_dns_srv: res_nsearch error: Unknown host
    sinfo: error: fetch_config: DNS SRV lookup failed
    sinfo: error: _establish_config_source: failed to fetch config
    sinfo: fatal: Could not establish a configuration source
  stderr_lines: <omitted>
  stdout: ''
  stdout_lines: <omitted>
2025-07-23 08:11:15,316 p=54485 u=master n=ansible | PLAY RECAP *****************************************************************************************************************************************************************
2025-07-23 08:11:15,316 p=54485 u=master n=ansible | cn01                       : ok=24   changed=3    unreachable=0    failed=1    skipped=25   rescued=0    ignored=0   
2025-07-23 08:11:15,316 p=54485 u=master n=ansible | cn02                       : ok=24   changed=3    unreachable=0    failed=1    skipped=25   rescued=0    ignored=0   
2025-07-23 08:11:15,317 p=54485 u=master n=ansible | sm01                       : ok=47   changed=14   unreachable=0    failed=1    skipped=9    rescued=0    ignored=0   
2025-07-23 08:11:15,317 p=54485 u=master n=ansible | sm02                       : ok=24   changed=3    unreachable=0    failed=1    skipped=25   rescued=0    ignored=0   
2025-07-23 08:11:15,317 p=54485 u=master n=ansible | Playbook run took 0 days, 0 hours, 4 minutes, 28 seconds
2025-07-23 08:11:15,317 p=54485 u=master n=ansible | Wednesday 23 July 2025  08:11:15 +0000 (0:00:00.299)       0:04:28.252 ******** 
2025-07-23 08:11:15,317 p=54485 u=master n=ansible | =============================================================================== 
2025-07-23 08:11:15,318 p=54485 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание архива Slurm для копирования ------------------------------------------------------------------------------------------------- 184.05s
2025-07-23 08:11:15,318 p=54485 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------- 30.45s
2025-07-23 08:11:15,318 p=54485 u=master n=ansible | common : [COMMON] Установка базовых пакетов ------------------------------------------------------------------------------------------------------------------------- 9.90s
2025-07-23 08:11:15,318 p=54485 u=master n=ansible | slurm_build : [SLURM_BUILD] Установка дополнительных зависимостей для сборки ---------------------------------------------------------------------------------------- 9.64s
2025-07-23 08:11:15,318 p=54485 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание символических ссылок для пользовательских команд Slurm ------------------------------------------------------------------------- 4.44s
2025-07-23 08:11:15,318 p=54485 u=master n=ansible | common : [COMMON] Запуск и включение MUNGE -------------------------------------------------------------------------------------------------------------------------- 2.01s
2025-07-23 08:11:15,319 p=54485 u=master n=ansible | common : [COMMON] Остановка MUNGE перед настройкой ------------------------------------------------------------------------------------------------------------------ 1.92s
2025-07-23 08:11:15,319 p=54485 u=master n=ansible | common : [COMMON] Обновление apt cache ------------------------------------------------------------------------------------------------------------------------------ 1.85s
2025-07-23 08:11:15,319 p=54485 u=master n=ansible | common : [COMMON] Создание базовых директорий Slurm ----------------------------------------------------------------------------------------------------------------- 1.65s
2025-07-23 08:11:15,319 p=54485 u=master n=ansible | common : [COMMON] Настройка экспорта NFS с конкретными IP ----------------------------------------------------------------------------------------------------------- 1.47s
2025-07-23 08:11:15,319 p=54485 u=master n=ansible | common : [COMMON] Распространение MUNGE ключа на все узлы ----------------------------------------------------------------------------------------------------------- 1.38s
2025-07-23 08:11:15,319 p=54485 u=master n=ansible | Проверка доступного места на диске ---------------------------------------------------------------------------------------------------------------------------------- 1.29s
2025-07-23 08:11:15,320 p=54485 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание символических ссылок для системных демонов Slurm ------------------------------------------------------------------------------- 1.28s
2025-07-23 08:11:15,320 p=54485 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------- 1.24s
2025-07-23 08:11:15,320 p=54485 u=master n=ansible | common : [COMMON] Обеспечение hostname resolution для кластера ------------------------------------------------------------------------------------------------------ 1.15s
2025-07-23 08:11:15,320 p=54485 u=master n=ansible | common : [COMMON] Настройка прав доступа MUNGE ---------------------------------------------------------------------------------------------------------------------- 1.09s
2025-07-23 08:11:15,320 p=54485 u=master n=ansible | common : [COMMON] Установка HWLOC ----------------------------------------------------------------------------------------------------------------------------------- 1.08s
2025-07-23 08:11:15,320 p=54485 u=master n=ansible | common : [COMMON] Установка NFS client ------------------------------------------------------------------------------------------------------------------------------ 1.07s
2025-07-23 08:11:15,320 p=54485 u=master n=ansible | common : [COMMON] Установка MUNGE ----------------------------------------------------------------------------------------------------------------------------------- 1.05s
2025-07-23 08:11:15,321 p=54485 u=master n=ansible | common : [COMMON] Установка NFS server на master -------------------------------------------------------------------------------------------------------------------- 0.91s
2025-07-23 08:18:33,631 p=55354 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:18:33,631 p=55354 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:18:35,199 p=55354 u=master n=ansible | cn02 | CHANGED | rc=0 >>
10.20.90.166:/sw on /sw type nfs4 (rw,relatime,vers=4.2,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.20.90.168,local_lock=none,addr=10.20.90.166)

2025-07-23 08:18:35,220 p=55354 u=master n=ansible | cn01 | CHANGED | rc=0 >>
10.20.90.166:/sw on /sw type nfs4 (rw,relatime,vers=4.2,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.20.90.167,local_lock=none,addr=10.20.90.166)

2025-07-23 08:18:35,230 p=55354 u=master n=ansible | sm02 | CHANGED | rc=0 >>
10.20.90.166:/sw on /sw type nfs4 (rw,relatime,vers=4.2,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.20.90.161,local_lock=none,addr=10.20.90.166)

2025-07-23 08:18:35,235 p=55354 u=master n=ansible | sm01 | FAILED | rc=1 >>
non-zero return code

2025-07-23 08:20:13,084 p=55433 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:20:13,085 p=55433 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:20:14,393 p=55433 u=master n=ansible | sm01 | FAILED | rc=1 >>
non-zero return code

2025-07-23 08:20:14,650 p=55433 u=master n=ansible | cn02 | CHANGED | rc=0 >>
10.20.90.166:/sw on /sw type nfs4 (rw,relatime,vers=4.2,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.20.90.168,local_lock=none,addr=10.20.90.166)

2025-07-23 08:20:14,679 p=55433 u=master n=ansible | sm02 | CHANGED | rc=0 >>
10.20.90.166:/sw on /sw type nfs4 (rw,relatime,vers=4.2,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.20.90.161,local_lock=none,addr=10.20.90.166)

2025-07-23 08:20:14,689 p=55433 u=master n=ansible | cn01 | CHANGED | rc=0 >>
10.20.90.166:/sw on /sw type nfs4 (rw,relatime,vers=4.2,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.20.90.167,local_lock=none,addr=10.20.90.166)

2025-07-23 08:21:17,549 p=55511 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:21:17,549 p=55511 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:21:18,962 p=55511 u=master n=ansible | sm01 | FAILED | rc=1 >>
touch: cannot touch '/sw/test': Permission deniednon-zero return code

2025-07-23 08:22:23,285 p=55566 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:22:23,285 p=55566 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:22:24,851 p=55566 u=master n=ansible | sm02 | FAILED | rc=2 >>
ls: cannot access '/sw/test': No such file or directorynon-zero return code

2025-07-23 08:22:24,854 p=55566 u=master n=ansible | cn02 | FAILED | rc=2 >>
ls: cannot access '/sw/test': No such file or directorynon-zero return code

2025-07-23 08:22:24,895 p=55566 u=master n=ansible | cn01 | FAILED | rc=2 >>
ls: cannot access '/sw/test': No such file or directorynon-zero return code

2025-07-23 08:26:54,254 p=55682 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:26:54,254 p=55682 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:26:54,715 p=55682 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 08:26:54,738 p=55682 u=master n=ansible | TASK [Информация о сборке Slurm] ******************************************************************************************************************************************************
2025-07-23 08:26:54,738 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:26:54 +0000 (0:00:00.025)       0:00:00.025 ******** 
2025-07-23 08:26:54,793 p=55682 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F528 Начинаем сборку Slurm 25.05.1\n\U0001F4CD Сборка на: sm01\n\U0001F4E6 Установка на: sm01, sm02, cn01, cn02\n\U0001F510 JWT поддержка включена"
2025-07-23 08:26:54,797 p=55682 u=master n=ansible | TASK [Проверка доступного места на диске] *********************************************************************************************************************************************
2025-07-23 08:26:54,797 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:26:54 +0000 (0:00:00.059)       0:00:00.084 ******** 
2025-07-23 08:26:54,829 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:26:54,831 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:26:54,839 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:26:56,059 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:26:56,063 p=55682 u=master n=ansible | TASK [Предупреждение о месте на диске] ************************************************************************************************************************************************
2025-07-23 08:26:56,063 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:26:56 +0000 (0:00:01.266)       0:00:01.350 ******** 
2025-07-23 08:26:56,096 p=55682 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4BE Доступно места в /tmp: 39G\n⚠️  Для сборки Slurm требуется ~2GB свободного места"
2025-07-23 08:26:56,097 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:26:56,099 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:26:56,105 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:26:56,124 p=55682 u=master n=ansible | TASK [common : [COMMON] Начало выполнения роли common] ********************************************************************************************************************************
2025-07-23 08:26:56,125 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:26:56 +0000 (0:00:00.061)       0:00:01.412 ******** 
2025-07-23 08:26:56,152 p=55682 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm01"
2025-07-23 08:26:56,166 p=55682 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Настройка базовых компонентов на sm02"
2025-07-23 08:26:56,168 p=55682 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn01"
2025-07-23 08:26:56,182 p=55682 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Настройка базовых компонентов на cn02"
2025-07-23 08:26:56,186 p=55682 u=master n=ansible | TASK [common : [COMMON] Обновление apt cache] *****************************************************************************************************************************************
2025-07-23 08:26:56,186 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:26:56 +0000 (0:00:00.061)       0:00:01.473 ******** 
2025-07-23 08:26:57,930 p=55682 u=master n=ansible | ok: [sm02]
2025-07-23 08:26:58,033 p=55682 u=master n=ansible | ok: [cn02]
2025-07-23 08:26:58,064 p=55682 u=master n=ansible | ok: [cn01]
2025-07-23 08:26:59,872 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:26:59,876 p=55682 u=master n=ansible | TASK [common : [COMMON] Установка базовых пакетов] ************************************************************************************************************************************
2025-07-23 08:26:59,877 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:26:59 +0000 (0:00:03.690)       0:00:05.164 ******** 
2025-07-23 08:27:00,888 p=55682 u=master n=ansible | ok: [sm02]
2025-07-23 08:27:01,038 p=55682 u=master n=ansible | ok: [cn02]
2025-07-23 08:27:01,039 p=55682 u=master n=ansible | ok: [cn01]
2025-07-23 08:27:21,853 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:27:21,858 p=55682 u=master n=ansible | TASK [common : [COMMON] Настройка timezone] *******************************************************************************************************************************************
2025-07-23 08:27:21,858 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:21 +0000 (0:00:21.981)       0:00:27.145 ******** 
2025-07-23 08:27:22,350 p=55682 u=master n=ansible | ok: [sm02]
2025-07-23 08:27:22,374 p=55682 u=master n=ansible | ok: [cn01]
2025-07-23 08:27:22,383 p=55682 u=master n=ansible | ok: [cn02]
2025-07-23 08:27:22,436 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:27:22,440 p=55682 u=master n=ansible | TASK [common : [COMMON] Обеспечение hostname resolution для кластера] *****************************************************************************************************************
2025-07-23 08:27:22,441 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:22 +0000 (0:00:00.582)       0:00:27.728 ******** 
2025-07-23 08:27:22,839 p=55682 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-23 08:27:22,842 p=55682 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-23 08:27:22,878 p=55682 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-23 08:27:22,880 p=55682 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.166', 'hostname': 'sm01'})
2025-07-23 08:27:23,079 p=55682 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-23 08:27:23,082 p=55682 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-23 08:27:23,123 p=55682 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-23 08:27:23,125 p=55682 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.161', 'hostname': 'sm02'})
2025-07-23 08:27:23,318 p=55682 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-23 08:27:23,322 p=55682 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-23 08:27:23,373 p=55682 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-23 08:27:23,374 p=55682 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.167', 'hostname': 'cn01'})
2025-07-23 08:27:23,558 p=55682 u=master n=ansible | ok: [sm02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-23 08:27:23,567 p=55682 u=master n=ansible | ok: [sm01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-23 08:27:23,616 p=55682 u=master n=ansible | ok: [cn02] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-23 08:27:23,622 p=55682 u=master n=ansible | ok: [cn01] => (item={'ip': '10.20.90.168', 'hostname': 'cn02'})
2025-07-23 08:27:23,629 p=55682 u=master n=ansible | TASK [common : [COMMON] Создание пользователя slurm] **********************************************************************************************************************************
2025-07-23 08:27:23,629 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:23 +0000 (0:00:01.188)       0:00:28.916 ******** 
2025-07-23 08:27:24,124 p=55682 u=master n=ansible | ok: [sm02]
2025-07-23 08:27:24,129 p=55682 u=master n=ansible | ok: [cn02]
2025-07-23 08:27:24,146 p=55682 u=master n=ansible | ok: [cn01]
2025-07-23 08:27:24,188 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:27:24,192 p=55682 u=master n=ansible | TASK [common : [COMMON] Установка MUNGE] **********************************************************************************************************************************************
2025-07-23 08:27:24,193 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:24 +0000 (0:00:00.563)       0:00:29.480 ******** 
2025-07-23 08:27:25,154 p=55682 u=master n=ansible | ok: [sm02]
2025-07-23 08:27:25,229 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:27:25,255 p=55682 u=master n=ansible | ok: [cn02]
2025-07-23 08:27:25,306 p=55682 u=master n=ansible | ok: [cn01]
2025-07-23 08:27:25,310 p=55682 u=master n=ansible | TASK [common : [COMMON] Остановка MUNGE перед настройкой] *****************************************************************************************************************************
2025-07-23 08:27:25,310 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:25 +0000 (0:00:01.117)       0:00:30.597 ******** 
2025-07-23 08:27:27,164 p=55682 u=master n=ansible | changed: [sm02]
2025-07-23 08:27:27,168 p=55682 u=master n=ansible | changed: [cn02]
2025-07-23 08:27:27,269 p=55682 u=master n=ansible | changed: [cn01]
2025-07-23 08:27:27,298 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:27:27,303 p=55682 u=master n=ansible | TASK [common : [COMMON] Создание MUNGE ключа на master узле] **************************************************************************************************************************
2025-07-23 08:27:27,303 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:27 +0000 (0:00:01.993)       0:00:32.591 ******** 
2025-07-23 08:27:27,335 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:27:27,337 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:27:27,348 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:27:27,555 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:27:27,559 p=55682 u=master n=ansible | TASK [common : [COMMON] Получение MUNGE ключа с master узла] **************************************************************************************************************************
2025-07-23 08:27:27,560 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:27 +0000 (0:00:00.256)       0:00:32.847 ******** 
2025-07-23 08:27:27,594 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:27:27,596 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:27:27,607 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:27:27,929 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:27:27,935 p=55682 u=master n=ansible | TASK [common : [COMMON] Распространение MUNGE ключа на все узлы] **********************************************************************************************************************
2025-07-23 08:27:27,935 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:27 +0000 (0:00:00.375)       0:00:33.222 ******** 
2025-07-23 08:27:27,958 p=55682 u=master n=ansible | skipping: [sm01]
2025-07-23 08:27:29,184 p=55682 u=master n=ansible | ok: [sm02]
2025-07-23 08:27:29,192 p=55682 u=master n=ansible | ok: [cn02]
2025-07-23 08:27:29,192 p=55682 u=master n=ansible | ok: [cn01]
2025-07-23 08:27:29,197 p=55682 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа MUNGE] *********************************************************************************************************************************
2025-07-23 08:27:29,197 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:29 +0000 (0:00:01.262)       0:00:34.484 ******** 
2025-07-23 08:27:29,476 p=55682 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:27:29,479 p=55682 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:27:29,496 p=55682 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:27:29,531 p=55682 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:27:29,724 p=55682 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:27:29,761 p=55682 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:27:29,775 p=55682 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:27:29,783 p=55682 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:27:29,974 p=55682 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:27:30,021 p=55682 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:27:30,029 p=55682 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:27:30,040 p=55682 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0700'})
2025-07-23 08:27:30,223 p=55682 u=master n=ansible | changed: [sm01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-23 08:27:30,268 p=55682 u=master n=ansible | changed: [sm02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-23 08:27:30,291 p=55682 u=master n=ansible | changed: [cn01] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-23 08:27:30,295 p=55682 u=master n=ansible | changed: [cn02] => (item={'path': '/run/munge', 'owner': 'munge', 'group': 'munge', 'mode': '0755'})
2025-07-23 08:27:30,301 p=55682 u=master n=ansible | TASK [common : [COMMON] Настройка прав доступа на ключ MUNGE] *************************************************************************************************************************
2025-07-23 08:27:30,301 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:30 +0000 (0:00:01.104)       0:00:35.588 ******** 
2025-07-23 08:27:30,575 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:27:30,582 p=55682 u=master n=ansible | ok: [sm02]
2025-07-23 08:27:30,588 p=55682 u=master n=ansible | ok: [cn01]
2025-07-23 08:27:30,600 p=55682 u=master n=ansible | ok: [cn02]
2025-07-23 08:27:30,604 p=55682 u=master n=ansible | TASK [common : [COMMON] Запуск и включение MUNGE] *************************************************************************************************************************************
2025-07-23 08:27:30,604 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:30 +0000 (0:00:00.302)       0:00:35.891 ******** 
2025-07-23 08:27:32,455 p=55682 u=master n=ansible | changed: [sm02]
2025-07-23 08:27:32,457 p=55682 u=master n=ansible | changed: [cn02]
2025-07-23 08:27:32,508 p=55682 u=master n=ansible | changed: [cn01]
2025-07-23 08:27:32,528 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:27:32,532 p=55682 u=master n=ansible | TASK [common : [COMMON] Проверка работы MUNGE] ****************************************************************************************************************************************
2025-07-23 08:27:32,533 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:32 +0000 (0:00:01.928)       0:00:37.820 ******** 
2025-07-23 08:27:32,802 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:27:32,803 p=55682 u=master n=ansible | ok: [sm02]
2025-07-23 08:27:32,821 p=55682 u=master n=ansible | ok: [cn01]
2025-07-23 08:27:32,823 p=55682 u=master n=ansible | ok: [cn02]
2025-07-23 08:27:32,828 p=55682 u=master n=ansible | TASK [common : [COMMON] Результат проверки MUNGE] *************************************************************************************************************************************
2025-07-23 08:27:32,828 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:32 +0000 (0:00:00.295)       0:00:38.115 ******** 
2025-07-23 08:27:32,855 p=55682 u=master n=ansible | ok: [sm01] => 
  msg: MUNGE работает корректно на sm01
2025-07-23 08:27:32,870 p=55682 u=master n=ansible | ok: [sm02] => 
  msg: MUNGE работает корректно на sm02
2025-07-23 08:27:32,874 p=55682 u=master n=ansible | ok: [cn01] => 
  msg: MUNGE работает корректно на cn01
2025-07-23 08:27:32,890 p=55682 u=master n=ansible | ok: [cn02] => 
  msg: MUNGE работает корректно на cn02
2025-07-23 08:27:32,893 p=55682 u=master n=ansible | TASK [common : [COMMON] Установка HWLOC] **********************************************************************************************************************************************
2025-07-23 08:27:32,894 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:32 +0000 (0:00:00.065)       0:00:38.181 ******** 
2025-07-23 08:27:33,892 p=55682 u=master n=ansible | ok: [sm02]
2025-07-23 08:27:33,904 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:27:33,924 p=55682 u=master n=ansible | ok: [cn02]
2025-07-23 08:27:33,966 p=55682 u=master n=ansible | ok: [cn01]
2025-07-23 08:27:33,969 p=55682 u=master n=ansible | TASK [common : [COMMON] Проверка HWLOC] ***********************************************************************************************************************************************
2025-07-23 08:27:33,970 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:33 +0000 (0:00:01.075)       0:00:39.257 ******** 
2025-07-23 08:27:34,237 p=55682 u=master n=ansible | ok: [sm02]
2025-07-23 08:27:34,255 p=55682 u=master n=ansible | ok: [cn01]
2025-07-23 08:27:34,275 p=55682 u=master n=ansible | ok: [cn02]
2025-07-23 08:27:34,587 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:27:34,591 p=55682 u=master n=ansible | TASK [common : [COMMON] Версия HWLOC] *************************************************************************************************************************************************
2025-07-23 08:27:34,592 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:34 +0000 (0:00:00.621)       0:00:39.879 ******** 
2025-07-23 08:27:34,627 p=55682 u=master n=ansible | ok: [sm01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 08:27:34,628 p=55682 u=master n=ansible | ok: [sm02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 08:27:34,632 p=55682 u=master n=ansible | ok: [cn01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 08:27:34,644 p=55682 u=master n=ansible | ok: [cn02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 08:27:34,648 p=55682 u=master n=ansible | TASK [common : [COMMON] Установка NFS server на master] *******************************************************************************************************************************
2025-07-23 08:27:34,648 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:34 +0000 (0:00:00.056)       0:00:39.936 ******** 
2025-07-23 08:27:34,681 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:27:34,684 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:27:34,693 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:27:35,542 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:27:35,546 p=55682 u=master n=ansible | TASK [common : [COMMON] Создание директорий для экспорта NFS] *************************************************************************************************************************
2025-07-23 08:27:35,547 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:35 +0000 (0:00:00.898)       0:00:40.834 ******** 
2025-07-23 08:27:35,581 p=55682 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-23 08:27:35,583 p=55682 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-23 08:27:35,588 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:27:35,589 p=55682 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-23 08:27:35,590 p=55682 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-23 08:27:35,591 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:27:35,600 p=55682 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-23 08:27:35,603 p=55682 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-23 08:27:35,604 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:27:35,813 p=55682 u=master n=ansible | ok: [sm01] => (item=/home)
2025-07-23 08:27:36,057 p=55682 u=master n=ansible | ok: [sm01] => (item=/sw)
2025-07-23 08:27:36,062 p=55682 u=master n=ansible | TASK [common : [COMMON] Очистка старых экспортов] *************************************************************************************************************************************
2025-07-23 08:27:36,063 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:36 +0000 (0:00:00.515)       0:00:41.350 ******** 
2025-07-23 08:27:36,096 p=55682 u=master n=ansible | skipping: [sm02] => (item=/home) 
2025-07-23 08:27:36,100 p=55682 u=master n=ansible | skipping: [sm02] => (item=/sw) 
2025-07-23 08:27:36,103 p=55682 u=master n=ansible | skipping: [cn01] => (item=/home) 
2025-07-23 08:27:36,104 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:27:36,105 p=55682 u=master n=ansible | skipping: [cn01] => (item=/sw) 
2025-07-23 08:27:36,106 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:27:36,116 p=55682 u=master n=ansible | skipping: [cn02] => (item=/home) 
2025-07-23 08:27:36,118 p=55682 u=master n=ansible | skipping: [cn02] => (item=/sw) 
2025-07-23 08:27:36,119 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:27:36,339 p=55682 u=master n=ansible | changed: [sm01] => (item=/home)
2025-07-23 08:27:36,577 p=55682 u=master n=ansible | changed: [sm01] => (item=/sw)
2025-07-23 08:27:36,582 p=55682 u=master n=ansible | TASK [common : [COMMON] Настройка экспорта NFS с конкретными IP] **********************************************************************************************************************
2025-07-23 08:27:36,583 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:36 +0000 (0:00:00.519)       0:00:41.870 ******** 
2025-07-23 08:27:36,613 p=55682 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-23 08:27:36,621 p=55682 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-23 08:27:36,623 p=55682 u=master n=ansible | skipping: [sm02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-23 08:27:36,624 p=55682 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-23 08:27:36,625 p=55682 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-23 08:27:36,626 p=55682 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-23 08:27:36,626 p=55682 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-23 08:27:36,627 p=55682 u=master n=ansible | skipping: [cn01] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-23 08:27:36,628 p=55682 u=master n=ansible | skipping: [sm02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-23 08:27:36,629 p=55682 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-23 08:27:36,630 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:27:36,633 p=55682 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-23 08:27:36,634 p=55682 u=master n=ansible | skipping: [cn01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-23 08:27:36,635 p=55682 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.161'}) 
2025-07-23 08:27:36,636 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:27:36,638 p=55682 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.167'}) 
2025-07-23 08:27:36,640 p=55682 u=master n=ansible | skipping: [cn02] => (item={'path': '/home', 'client_ip': '10.20.90.168'}) 
2025-07-23 08:27:36,643 p=55682 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.161'}) 
2025-07-23 08:27:36,646 p=55682 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.167'}) 
2025-07-23 08:27:36,649 p=55682 u=master n=ansible | skipping: [cn02] => (item={'path': '/sw', 'client_ip': '10.20.90.168'}) 
2025-07-23 08:27:36,650 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:27:36,844 p=55682 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.161'})
2025-07-23 08:27:37,082 p=55682 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.167'})
2025-07-23 08:27:37,318 p=55682 u=master n=ansible | changed: [sm01] => (item={'path': '/home', 'client_ip': '10.20.90.168'})
2025-07-23 08:27:37,554 p=55682 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.161'})
2025-07-23 08:27:37,791 p=55682 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.167'})
2025-07-23 08:27:38,030 p=55682 u=master n=ansible | changed: [sm01] => (item={'path': '/sw', 'client_ip': '10.20.90.168'})
2025-07-23 08:27:38,038 p=55682 u=master n=ansible | TASK [common : [COMMON] Запуск и включение NFS server] ********************************************************************************************************************************
2025-07-23 08:27:38,038 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:38 +0000 (0:00:01.455)       0:00:43.325 ******** 
2025-07-23 08:27:38,071 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:27:38,074 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:27:38,084 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:27:38,511 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:27:38,515 p=55682 u=master n=ansible | TASK [common : [COMMON] Принудительная перезагрузка экспортов NFS] ********************************************************************************************************************
2025-07-23 08:27:38,515 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:38 +0000 (0:00:00.477)       0:00:43.802 ******** 
2025-07-23 08:27:38,548 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:27:38,550 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:27:38,560 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:27:38,777 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:27:38,781 p=55682 u=master n=ansible | TASK [common : [COMMON] Проверка активных экспортов] **********************************************************************************************************************************
2025-07-23 08:27:38,781 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:38 +0000 (0:00:00.265)       0:00:44.068 ******** 
2025-07-23 08:27:38,813 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:27:38,816 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:27:38,825 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:27:39,043 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:27:39,047 p=55682 u=master n=ansible | TASK [common : [COMMON] Показать активные экспорты] ***********************************************************************************************************************************
2025-07-23 08:27:39,047 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:39 +0000 (0:00:00.265)       0:00:44.334 ******** 
2025-07-23 08:27:39,081 p=55682 u=master n=ansible | ok: [sm01] => 
  nfs_exports_check.stdout_lines:
  - "/home         \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/home         \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.161(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.167(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/sw           \t10.20.90.168(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
  - "/shared       \t10.20.90.0/24(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,no_root_squash,no_all_squash)"
2025-07-23 08:27:39,082 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:27:39,083 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:27:39,093 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:27:39,097 p=55682 u=master n=ansible | TASK [common : [COMMON] Установка NFS client] *****************************************************************************************************************************************
2025-07-23 08:27:39,097 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:39 +0000 (0:00:00.050)       0:00:44.384 ******** 
2025-07-23 08:27:39,121 p=55682 u=master n=ansible | skipping: [sm01]
2025-07-23 08:27:40,049 p=55682 u=master n=ansible | ok: [sm02]
2025-07-23 08:27:40,100 p=55682 u=master n=ansible | ok: [cn02]
2025-07-23 08:27:40,123 p=55682 u=master n=ansible | ok: [cn01]
2025-07-23 08:27:40,128 p=55682 u=master n=ansible | TASK [common : [COMMON] Создание точек монтирования NFS] ******************************************************************************************************************************
2025-07-23 08:27:40,128 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:40 +0000 (0:00:01.030)       0:00:45.415 ******** 
2025-07-23 08:27:40,149 p=55682 u=master n=ansible | skipping: [sm01] => (item=/sw) 
2025-07-23 08:27:40,153 p=55682 u=master n=ansible | skipping: [sm01]
2025-07-23 08:27:40,402 p=55682 u=master n=ansible | ok: [sm02] => (item=/sw)
2025-07-23 08:27:40,426 p=55682 u=master n=ansible | ok: [cn02] => (item=/sw)
2025-07-23 08:27:40,427 p=55682 u=master n=ansible | ok: [cn01] => (item=/sw)
2025-07-23 08:27:40,432 p=55682 u=master n=ansible | TASK [common : [COMMON] Монтирование NFS shares] **************************************************************************************************************************************
2025-07-23 08:27:40,433 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:40 +0000 (0:00:00.304)       0:00:45.720 ******** 
2025-07-23 08:27:40,456 p=55682 u=master n=ansible | skipping: [sm01] => (item={'path': '/home', 'src': '/home'}) 
2025-07-23 08:27:40,462 p=55682 u=master n=ansible | skipping: [sm01] => (item={'path': '/sw', 'src': '/sw'}) 
2025-07-23 08:27:40,469 p=55682 u=master n=ansible | skipping: [sm01]
2025-07-23 08:27:40,870 p=55682 u=master n=ansible | ok: [cn02] => (item={'path': '/home', 'src': '/home'})
2025-07-23 08:27:40,871 p=55682 u=master n=ansible | ok: [sm02] => (item={'path': '/home', 'src': '/home'})
2025-07-23 08:27:40,875 p=55682 u=master n=ansible | ok: [cn01] => (item={'path': '/home', 'src': '/home'})
2025-07-23 08:27:41,118 p=55682 u=master n=ansible | ok: [sm02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-23 08:27:41,120 p=55682 u=master n=ansible | ok: [cn02] => (item={'path': '/sw', 'src': '/sw'})
2025-07-23 08:27:41,130 p=55682 u=master n=ansible | ok: [cn01] => (item={'path': '/sw', 'src': '/sw'})
2025-07-23 08:27:41,135 p=55682 u=master n=ansible | TASK [common : [COMMON] Создание базовых директорий Slurm] ****************************************************************************************************************************
2025-07-23 08:27:41,135 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:41 +0000 (0:00:00.702)       0:00:46.422 ******** 
2025-07-23 08:27:41,416 p=55682 u=master n=ansible | ok: [sm01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:41,429 p=55682 u=master n=ansible | ok: [sm02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:41,433 p=55682 u=master n=ansible | ok: [cn02] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:41,440 p=55682 u=master n=ansible | ok: [cn01] => (item={'path': '/var/log/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:41,670 p=55682 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:41,677 p=55682 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:41,680 p=55682 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:41,697 p=55682 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:41,925 p=55682 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:41,926 p=55682 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:41,931 p=55682 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:41,949 p=55682 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/ctld', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:42,172 p=55682 u=master n=ansible | ok: [sm02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:42,179 p=55682 u=master n=ansible | ok: [sm01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:42,183 p=55682 u=master n=ansible | ok: [cn02] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:42,205 p=55682 u=master n=ansible | ok: [cn01] => (item={'path': '/var/spool/slurm/d', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:42,433 p=55682 u=master n=ansible | ok: [cn02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-23 08:27:42,434 p=55682 u=master n=ansible | ok: [sm02] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-23 08:27:42,435 p=55682 u=master n=ansible | ok: [sm01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-23 08:27:42,465 p=55682 u=master n=ansible | ok: [cn01] => (item={'path': '/etc/slurm', 'owner': 'root', 'group': 'root', 'mode': '0755'})
2025-07-23 08:27:42,681 p=55682 u=master n=ansible | ok: [sm02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:42,685 p=55682 u=master n=ansible | ok: [cn02] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:42,688 p=55682 u=master n=ansible | ok: [sm01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:42,745 p=55682 u=master n=ansible | ok: [cn01] => (item={'path': '/var/lib/slurm', 'owner': 'slurm', 'group': 'slurm', 'mode': '0755'})
2025-07-23 08:27:42,751 p=55682 u=master n=ansible | TASK [common : [COMMON] Роль common выполнена успешно] ********************************************************************************************************************************
2025-07-23 08:27:42,751 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:42 +0000 (0:00:01.615)       0:00:48.038 ******** 
2025-07-23 08:27:42,775 p=55682 u=master n=ansible | ok: [sm01] => 
  msg: ✅ Узел sm01 готов для установки Slurm
2025-07-23 08:27:42,786 p=55682 u=master n=ansible | ok: [sm02] => 
  msg: ✅ Узел sm02 готов для установки Slurm
2025-07-23 08:27:42,790 p=55682 u=master n=ansible | ok: [cn01] => 
  msg: ✅ Узел cn01 готов для установки Slurm
2025-07-23 08:27:42,805 p=55682 u=master n=ansible | ok: [cn02] => 
  msg: ✅ Узел cn02 готов для установки Slurm
2025-07-23 08:27:42,817 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Начало сборки Slurm] ********************************************************************************************************************************
2025-07-23 08:27:42,817 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:42 +0000 (0:00:00.066)       0:00:48.105 ******** 
2025-07-23 08:27:42,851 p=55682 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm01"
2025-07-23 08:27:42,852 p=55682 u=master n=ansible | ok: [sm02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на sm02"
2025-07-23 08:27:42,856 p=55682 u=master n=ansible | ok: [cn01] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn01"
2025-07-23 08:27:42,867 p=55682 u=master n=ansible | ok: [cn02] => 
  msg: "\U0001F527 Сборка Slurm 25.05.1 с JWT поддержкой на cn02"
2025-07-23 08:27:42,871 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка дополнительных зависимостей для сборки] ***************************************************************************************************
2025-07-23 08:27:42,872 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:42 +0000 (0:00:00.054)       0:00:48.159 ******** 
2025-07-23 08:27:42,904 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:27:42,907 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:27:42,916 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:27:53,862 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:27:53,866 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для сборки] ***********************************************************************************************************
2025-07-23 08:27:53,866 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:53 +0000 (0:00:10.994)       0:00:59.153 ******** 
2025-07-23 08:27:53,899 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:27:53,902 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:27:53,912 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:27:54,131 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:27:54,135 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка существования исходников] ******************************************************************************************************************
2025-07-23 08:27:54,135 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:54 +0000 (0:00:00.269)       0:00:59.422 ******** 
2025-07-23 08:27:54,169 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:27:54,171 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:27:54,181 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:27:54,386 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:27:54,393 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Скачивание исходников Slurm 25.05.1] ****************************************************************************************************************
2025-07-23 08:27:54,394 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:54 +0000 (0:00:00.258)       0:00:59.681 ******** 
2025-07-23 08:27:54,428 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:27:54,430 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:27:54,438 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:27:57,289 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:27:57,294 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Извлечение исходников Slurm] ************************************************************************************************************************
2025-07-23 08:27:57,295 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:27:57 +0000 (0:00:02.901)       0:01:02.582 ******** 
2025-07-23 08:27:57,330 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:27:57,333 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:27:57,342 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:28:02,968 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:28:02,972 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Конфигурация сборки Slurm с JWT поддержкой] *********************************************************************************************************
2025-07-23 08:28:02,972 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:28:02 +0000 (0:00:05.677)       0:01:08.260 ******** 
2025-07-23 08:28:03,007 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:28:03,008 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:28:03,016 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:28:36,474 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:28:36,479 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат конфигурации] *****************************************************************************************************************************
2025-07-23 08:28:36,480 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:28:36 +0000 (0:00:33.507)       0:01:41.767 ******** 
2025-07-23 08:28:36,522 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:28:36,529 p=55682 u=master n=ansible | ok: [sm01] => 
  slurm_configure.stdout_lines:
  - checking build system type... x86_64-pc-linux-gnu
  - checking host system type... x86_64-pc-linux-gnu
  - checking target system type... x86_64-pc-linux-gnu
  - checking for a BSD-compatible install... /usr/bin/install -c
  - checking whether build environment is sane... yes
  - checking for a race-free mkdir -p... /usr/bin/mkdir -p
  - checking for gawk... gawk
  - checking whether make sets $(MAKE)... yes
  - checking whether make supports nested variables... yes
  - checking whether to enable maintainer-specific portions of Makefiles... no
  - checking whether to include rpath in build... yes
  - checking whether make supports the include directive... yes (GNU style)
  - checking for gcc... gcc
  - checking whether the C compiler works... yes
  - checking for C compiler default output file name... a.out
  - 'checking for suffix of executables... '
  - checking whether we are cross compiling... no
  - checking for suffix of object files... o
  - checking whether the compiler supports GNU C... yes
  - checking whether gcc accepts -g... yes
  - checking for gcc option to enable C11 features... none needed
  - checking whether gcc understands -c and -o together... yes
  - checking dependency style of gcc... gcc3
  - checking for mysql_config... no
  - checking for mariadb_config... /usr/bin/mariadb_config
  - MySQL 10.11.13 test program built properly.
  - checking for gcc... (cached) gcc
  - checking whether the compiler supports GNU C... (cached) yes
  - checking whether gcc accepts -g... (cached) yes
  - checking for gcc option to enable C11 features... (cached) none needed
  - checking whether gcc understands -c and -o together... (cached) yes
  - checking dependency style of gcc... (cached) gcc3
  - checking for g++... g++
  - checking whether the compiler supports GNU C++... yes
  - checking whether g++ accepts -g... yes
  - checking for g++ option to enable C++11 features... none needed
  - checking dependency style of g++... gcc3
  - checking whether make sets $(MAKE)... (cached) yes
  - checking how to print strings... printf
  - checking for a sed that does not truncate output... /usr/bin/sed
  - checking for grep that handles long lines and -e... /usr/bin/grep
  - checking for egrep... /usr/bin/grep -E
  - checking for fgrep... /usr/bin/grep -F
  - checking for ld used by gcc... /usr/bin/ld
  - checking if the linker (/usr/bin/ld) is GNU ld... yes
  - checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
  - checking the name lister (/usr/bin/nm -B) interface... BSD nm
  - checking whether ln -s works... yes
  - checking the maximum length of command line arguments... 1572864
  - checking how to convert x86_64-pc-linux-gnu file names to x86_64-pc-linux-gnu format... func_convert_file_noop
  - checking how to convert x86_64-pc-linux-gnu file names to toolchain format... func_convert_file_noop
  - checking for /usr/bin/ld option to reload object files... -r
  - checking for file... file
  - checking for objdump... objdump
  - checking how to recognize dependent libraries... pass_all
  - checking for dlltool... no
  - checking how to associate runtime and link libraries... printf %s\n
  - checking for ar... ar
  - checking for archiver @FILE support... @
  - checking for strip... strip
  - checking for ranlib... ranlib
  - checking command to parse /usr/bin/nm -B output from gcc object... ok
  - checking for sysroot... no
  - checking for a working dd... /usr/bin/dd
  - checking how to truncate binary pipes... /usr/bin/dd bs=4096 count=1
  - checking for mt... mt
  - checking if mt is a manifest tool... no
  - checking for stdio.h... yes
  - checking for stdlib.h... yes
  - checking for string.h... yes
  - checking for inttypes.h... yes
  - checking for stdint.h... yes
  - checking for strings.h... yes
  - checking for sys/stat.h... yes
  - checking for sys/types.h... yes
  - checking for unistd.h... yes
  - checking for dlfcn.h... yes
  - checking for objdir... .libs
  - checking if gcc supports -fno-rtti -fno-exceptions... no
  - checking for gcc option to produce PIC... -fPIC -DPIC
  - checking if gcc PIC flag -fPIC -DPIC works... yes
  - checking if gcc static flag -static works... yes
  - checking if gcc supports -c -o file.o... yes
  - checking if gcc supports -c -o file.o... (cached) yes
  - checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
  - checking whether -lc should be explicitly linked in... no
  - checking dynamic linker characteristics... GNU/Linux ld.so
  - checking how to hardcode library paths into programs... immediate
  - checking whether stripping libraries is possible... yes
  - checking if libtool supports shared libraries... yes
  - checking whether to build shared libraries... yes
  - checking whether to build static libraries... yes
  - checking how to run the C++ preprocessor... g++ -E
  - checking for ld used by g++... /usr/bin/ld -m elf_x86_64
  - checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes
  - checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
  - checking for g++ option to produce PIC... -fPIC -DPIC
  - checking if g++ PIC flag -fPIC -DPIC works... yes
  - checking if g++ static flag -static works... yes
  - checking if g++ supports -c -o file.o... yes
  - checking if g++ supports -c -o file.o... (cached) yes
  - checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
  - checking dynamic linker characteristics... (cached) GNU/Linux ld.so
  - checking how to hardcode library paths into programs... immediate
  - checking for pkg-config... /usr/bin/pkg-config
  - checking pkg-config is at least version 0.9.0... yes
  - checking whether to install pkg-config slurm.pc file... no
  - checking for -objcopy... no
  - checking for objcopy... objcopy
  - checking for sleep... /usr/bin/sleep
  - checking for su... /usr/bin/su
  - checking whether the compiler is Clang... no
  - checking for library containing socket... none required
  - checking for library containing gethostbyname... none required
  - checking for library containing hstrerror... none required
  - checking for library containing kstat_open... no
  - checking for library containing ns_initparse... -lresolv
  - checking for library containing log... -lm
  - checking for library containing lrint... none required
  - checking for library containing timer_create... none required
  - checking for library containing dlopen... none required
  - checking for mcheck.h... yes
  - checking for values.h... yes
  - checking for socket.h... no
  - checking for sys/socket.h... yes
  - checking for stdbool.h... yes
  - checking for sys/ipc.h... yes
  - checking for sys/shm.h... yes
  - checking for sys/sem.h... yes
  - checking for errno.h... yes
  - checking for stdlib.h... (cached) yes
  - checking for dirent.h... yes
  - checking for pthread.h... yes
  - checking for sys/prctl.h... yes
  - checking for sysint.h... no
  - checking for inttypes.h... (cached) yes
  - checking for termcap.h... yes
  - checking for netdb.h... yes
  - checking for sys/socket.h... (cached) yes
  - checking for sys/systemcfg.h... no
  - checking for sys/dr.h... no
  - checking for sys/vfs.h... yes
  - checking for pam/pam_appl.h... no
  - checking for security/pam_appl.h... yes
  - checking for sys/sysctl.h... no
  - checking for pty.h... yes
  - checking for utmp.h... yes
  - checking for sys/syslog.h... yes
  - checking for linux/sched.h... yes
  - checking for kstat.h... no
  - checking for paths.h... yes
  - checking for limits.h... yes
  - checking for sys/statfs.h... yes
  - checking for sys/ptrace.h... yes
  - checking for float.h... yes
  - checking for sys/statvfs.h... yes
  - checking for sys/wait.h that is POSIX.1 compatible... yes
  - checking for sys/mkdev.h... no
  - checking for sys/sysmacros.h... yes
  - checking for program_invocation_name... yes
  - checking for ptrace64... no
  - checking for numa_available in -lnuma... yes
  - checking whether to enable PAM support... yes
  - checking for pam_get_user in -lpam... yes
  - checking for misc_conv in -lpam_misc... yes
  - checking Link to libslurm.so instead of libslurm.o... shared
  - checking whether sbatch --get-user-env option should load .login... no
  - checking whether byte ordering is bigendian... no
  - checking for C99 support... yes
  - checking whether C compiler accepts -fno-omit-frame-pointer... yes
  - checking for uid_t and gid_t data sizes)... yes
  - checking for json installation... /usr
  - checking for jwt.h... yes
  - checking for jwt_add_header in -ljwt... yes
  - checking for http-parser installation... /usr
  - checking for libyaml installation... /usr
  - checking for linux/version.h... yes
  - checking for Linux epoll(7) interface... yes
  - checking for __builtin_bswap64... yes
  - checking for __builtin_clzll... yes
  - checking for __builtin_ctzll... yes
  - checking for __builtin_popcountll... yes
  - checking for gcc options needed to detect all undeclared functions... none needed
  - checking whether strerror_r is declared... yes
  - checking whether strerror_r returns char *... no
  - checking for fdatasync... yes
  - checking for hstrerror... yes
  - checking for strerror... yes
  - checking for mtrace... yes
  - checking for strndup... yes
  - checking for strlcpy... yes
  - checking for strsignal... yes
  - checking for inet_aton... yes
  - checking for inet_ntop... yes
  - checking for inet_pton... yes
  - checking for setproctitle... no
  - checking for sysctlbyname... no
  - checking for cfmakeraw... yes
  - checking for setresuid... yes
  - checking for get_current_dir_name... yes
  - checking for faccessat... yes
  - checking for eaccess... yes
  - checking for statvfs... yes
  - checking for statfs... yes
  - checking for memfd_create... yes
  - checking for getrandom... yes
  - checking whether hstrerror is declared... no
  - checking whether strsignal is declared... yes
  - checking whether sys_siglist is declared... no
  - checking how to run the C preprocessor... gcc -E
  - checking for egrep -e... (cached) /usr/bin/grep -E
  - checking whether gcc is Clang... no
  - checking whether pthreads work with "-pthread" and "-lpthread"... yes
  - checking for joinable pthread attribute... PTHREAD_CREATE_JOINABLE
  - checking whether more special flags are required for pthreads... no
  - checking for PTHREAD_PRIO_INHERIT... yes
  - 'checking for ofed installation... '
  - checking for h5cc... no
  - checking for h5pcc... no
  - checking for HDF5 type... neither
  - checking for HDF5 libraries... no
  - checking for hwloc installation... /usr
  - checking for nvml.h... yes
  - checking for nvmlInit in -lnvidia-ml... yes
  - 'checking whether RSMI/ROCm in installed in this system... '
  - checking for rocm_smi/rocm_smi.h... no
  - checking for rsmi_init in -lrocm_smi64... no
  - checking for rsmi_dev_drm_render_minor_get in -lrocm_smi64... no
  - checking for rocm_smi/rocm_smi.h... (cached) no
  - checking for rsmi_init in -lrocm_smi64... no
  - checking for rsmi_dev_drm_render_minor_get in -lrocm_smi64... (cached) no
  - 'checking whether oneAPI in installed in this system... '
  - checking for ze_api.h... no
  - checking for ze_api.h... no
  - checking for pmix installation... /usr/lib/x86_64-linux-gnu/pmix2
  - 'checking for freeipmi installation... '
  - 'configure: support for ucx disabled'
  - checking whether Slurm internal X11 support is enabled... yes
  - 'checking whether Slurm internal SELinux support is enabled... '
  - checking for librdkafka installation... checking for rdkafka.h... no
  - checking for rdkafka.h... no
  - ''
  - 'checking for s2n installation... '
  - checking for bpf installation... /usr
  - checking for dbus-1 >= 1.11.16... yes
  - checking for check >= 0.9.8... no
  - 'configure: checking whether to compile sview'
  - checking for pkg-config... (cached) /usr/bin/pkg-config
  - checking pkg-config is at least version 0.16... yes
  - checking for glib-2.0 >= 2.7.1 gthread-2.0... yes
  - checking for GLIB - version >= 2.7.1... yes (version 2.80.0)
  - checking for pkg-config... (cached) /usr/bin/pkg-config
  - checking pkg-config is at least version 0.7... yes
  - checking for GTK+ - version >= 2.7.1... yes (version 2.24.33)
  - 'checking whether HPE Slingshot is installed in this system... '
  - checking for libcxi/libcxi.h... no
  - checking for __progname... yes
  - checking whether optimizations are enabled... yes
  - checking whether or not developer options are enabled... yes
  - checking whether debugging is enabled... checking whether C compiler accepts -ggdb3... yes
  - 'yes'
  - checking whether memory leak debugging is enabled... no
  - checking whether debugger partial attach enabled... no
  - checking whether salloc should kill child processes at job termination... no
  - checking for slurmctld default port... 6817
  - checking for slurmd default port... 6818
  - checking for slurmdbd default port... 6819
  - checking for slurmctld default port count... 1
  - checking whether to compile slurmrestd... yes
  - checking for slurmrestd default port... 6820
  - checking whether to enable lua plugin support... checking for lua5.3... yes
  - checking for whether we can link to liblua... yes lua5.3
  - checking whether man2html is available... checking for man2html... yes
  - checking for bash-completion package... yes
  - checking for bash-completion completionsdir path... ${datarootdir}/bash-completion/completions
  - checking for support of printf("%s", NULL)... yes
  - checking for whether to include readline suport... yes
  - checking for systemd presence... yes
  - checking for munge installation... /usr
  - checking whether to enable multiple-slurmd support... no
  - checking for openpty in -lutil... yes
  - checking for gawk... (cached) gawk
  - checking for curl-config... /usr/bin/curl-config
  - checking for the version of libcurl... 8.5.0
  - checking whether libcurl is usable... yes
  - checking for curl_free... yes
  - checking size of void *... 8
  - checking whether deprecated options are enabled... no
  - checking that generated files are newer than configure... done
  - 'configure: creating ./config.status'
  - 'config.status: creating Makefile'
  - 'config.status: creating auxdir/Makefile'
  - 'config.status: creating contribs/Makefile'
  - 'config.status: creating contribs/lua/Makefile'
  - 'config.status: creating contribs/nss_slurm/Makefile'
  - 'config.status: creating contribs/openlava/Makefile'
  - 'config.status: creating contribs/pam/Makefile'
  - 'config.status: creating contribs/pam_slurm_adopt/Makefile'
  - 'config.status: creating contribs/perlapi/Makefile'
  - 'config.status: creating contribs/perlapi/libslurm/Makefile'
  - 'config.status: creating contribs/perlapi/libslurm/perl/Makefile.PL'
  - 'config.status: creating contribs/perlapi/libslurmdb/Makefile'
  - 'config.status: creating contribs/perlapi/libslurmdb/perl/Makefile.PL'
  - 'config.status: creating contribs/pmi/Makefile'
  - 'config.status: creating contribs/pmi2/Makefile'
  - 'config.status: creating contribs/seff/Makefile'
  - 'config.status: creating contribs/sgather/Makefile'
  - 'config.status: creating contribs/sjobexit/Makefile'
  - 'config.status: creating contribs/slurm_completion_help/Makefile'
  - 'config.status: creating contribs/torque/Makefile'
  - 'config.status: creating doc/Makefile'
  - 'config.status: creating doc/html/Makefile'
  - 'config.status: creating doc/html/configurator.easy.html'
  - 'config.status: creating doc/html/configurator.html'
  - 'config.status: creating doc/man/Makefile'
  - 'config.status: creating doc/man/man1/Makefile'
  - 'config.status: creating doc/man/man5/Makefile'
  - 'config.status: creating doc/man/man8/Makefile'
  - 'config.status: creating etc/Makefile'
  - 'config.status: creating src/Makefile'
  - 'config.status: creating src/api/Makefile'
  - 'config.status: creating src/bcast/Makefile'
  - 'config.status: creating src/common/Makefile'
  - 'config.status: creating src/conmgr/Makefile'
  - 'config.status: creating src/curl/Makefile'
  - 'config.status: creating src/database/Makefile'
  - 'config.status: creating src/interfaces/Makefile'
  - 'config.status: creating src/lua/Makefile'
  - 'config.status: creating src/plugins/Makefile'
  - 'config.status: creating src/plugins/accounting_storage/Makefile'
  - 'config.status: creating src/plugins/accounting_storage/common/Makefile'
  - 'config.status: creating src/plugins/accounting_storage/ctld_relay/Makefile'
  - 'config.status: creating src/plugins/accounting_storage/mysql/Makefile'
  - 'config.status: creating src/plugins/accounting_storage/slurmdbd/Makefile'
  - 'config.status: creating src/plugins/acct_gather_energy/Makefile'
  - 'config.status: creating src/plugins/acct_gather_energy/gpu/Makefile'
  - 'config.status: creating src/plugins/acct_gather_energy/ibmaem/Makefile'
  - 'config.status: creating src/plugins/acct_gather_energy/ipmi/Makefile'
  - 'config.status: creating src/plugins/acct_gather_energy/pm_counters/Makefile'
  - 'config.status: creating src/plugins/acct_gather_energy/rapl/Makefile'
  - 'config.status: creating src/plugins/acct_gather_energy/xcc/Makefile'
  - 'config.status: creating src/plugins/acct_gather_filesystem/Makefile'
  - 'config.status: creating src/plugins/acct_gather_filesystem/lustre/Makefile'
  - 'config.status: creating src/plugins/acct_gather_interconnect/Makefile'
  - 'config.status: creating src/plugins/acct_gather_interconnect/ofed/Makefile'
  - 'config.status: creating src/plugins/acct_gather_interconnect/sysfs/Makefile'
  - 'config.status: creating src/plugins/acct_gather_profile/Makefile'
  - 'config.status: creating src/plugins/acct_gather_profile/hdf5/Makefile'
  - 'config.status: creating src/plugins/acct_gather_profile/hdf5/sh5util/Makefile'
  - 'config.status: creating src/plugins/acct_gather_profile/influxdb/Makefile'
  - 'config.status: creating src/plugins/auth/Makefile'
  - 'config.status: creating src/plugins/auth/jwt/Makefile'
  - 'config.status: creating src/plugins/auth/munge/Makefile'
  - 'config.status: creating src/plugins/auth/none/Makefile'
  - 'config.status: creating src/plugins/auth/slurm/Makefile'
  - 'config.status: creating src/plugins/burst_buffer/Makefile'
  - 'config.status: creating src/plugins/burst_buffer/common/Makefile'
  - 'config.status: creating src/plugins/burst_buffer/datawarp/Makefile'
  - 'config.status: creating src/plugins/burst_buffer/lua/Makefile'
  - 'config.status: creating src/plugins/certgen/Makefile'
  - 'config.status: creating src/plugins/certgen/script/Makefile'
  - 'config.status: creating src/plugins/certmgr/Makefile'
  - 'config.status: creating src/plugins/certmgr/script/Makefile'
  - 'config.status: creating src/plugins/cgroup/Makefile'
  - 'config.status: creating src/plugins/cgroup/common/Makefile'
  - 'config.status: creating src/plugins/cgroup/v1/Makefile'
  - 'config.status: creating src/plugins/cgroup/v2/Makefile'
  - 'config.status: creating src/plugins/cli_filter/Makefile'
  - 'config.status: creating src/plugins/cli_filter/common/Makefile'
  - 'config.status: creating src/plugins/cli_filter/lua/Makefile'
  - 'config.status: creating src/plugins/cli_filter/syslog/Makefile'
  - 'config.status: creating src/plugins/cli_filter/user_defaults/Makefile'
  - 'config.status: creating src/plugins/cred/Makefile'
  - 'config.status: creating src/plugins/cred/common/Makefile'
  - 'config.status: creating src/plugins/cred/munge/Makefile'
  - 'config.status: creating src/plugins/cred/none/Makefile'
  - 'config.status: creating src/plugins/data_parser/Makefile'
  - 'config.status: creating src/plugins/data_parser/v0.0.40/Makefile'
  - 'config.status: creating src/plugins/data_parser/v0.0.41/Makefile'
  - 'config.status: creating src/plugins/data_parser/v0.0.42/Makefile'
  - 'config.status: creating src/plugins/data_parser/v0.0.43/Makefile'
  - 'config.status: creating src/plugins/gpu/Makefile'
  - 'config.status: creating src/plugins/gpu/common/Makefile'
  - 'config.status: creating src/plugins/gpu/generic/Makefile'
  - 'config.status: creating src/plugins/gpu/nrt/Makefile'
  - 'config.status: creating src/plugins/gpu/nvidia/Makefile'
  - 'config.status: creating src/plugins/gpu/nvml/Makefile'
  - 'config.status: creating src/plugins/gpu/oneapi/Makefile'
  - 'config.status: creating src/plugins/gpu/rsmi/Makefile'
  - 'config.status: creating src/plugins/gres/Makefile'
  - 'config.status: creating src/plugins/gres/common/Makefile'
  - 'config.status: creating src/plugins/gres/gpu/Makefile'
  - 'config.status: creating src/plugins/gres/mps/Makefile'
  - 'config.status: creating src/plugins/gres/nic/Makefile'
  - 'config.status: creating src/plugins/gres/shard/Makefile'
  - 'config.status: creating src/plugins/hash/Makefile'
  - 'config.status: creating src/plugins/hash/common_xkcp/Makefile'
  - 'config.status: creating src/plugins/hash/k12/Makefile'
  - 'config.status: creating src/plugins/hash/sha3/Makefile'
  - 'config.status: creating src/plugins/job_container/Makefile'
  - 'config.status: creating src/plugins/job_container/tmpfs/Makefile'
  - 'config.status: creating src/plugins/job_submit/Makefile'
  - 'config.status: creating src/plugins/job_submit/all_partitions/Makefile'
  - 'config.status: creating src/plugins/job_submit/defaults/Makefile'
  - 'config.status: creating src/plugins/job_submit/logging/Makefile'
  - 'config.status: creating src/plugins/job_submit/lua/Makefile'
  - 'config.status: creating src/plugins/job_submit/partition/Makefile'
  - 'config.status: creating src/plugins/job_submit/pbs/Makefile'
  - 'config.status: creating src/plugins/job_submit/require_timelimit/Makefile'
  - 'config.status: creating src/plugins/job_submit/throttle/Makefile'
  - 'config.status: creating src/plugins/jobacct_gather/Makefile'
  - 'config.status: creating src/plugins/jobacct_gather/cgroup/Makefile'
  - 'config.status: creating src/plugins/jobacct_gather/common/Makefile'
  - 'config.status: creating src/plugins/jobacct_gather/linux/Makefile'
  - 'config.status: creating src/plugins/jobcomp/Makefile'
  - 'config.status: creating src/plugins/jobcomp/common/Makefile'
  - 'config.status: creating src/plugins/jobcomp/elasticsearch/Makefile'
  - 'config.status: creating src/plugins/jobcomp/filetxt/Makefile'
  - 'config.status: creating src/plugins/jobcomp/kafka/Makefile'
  - 'config.status: creating src/plugins/jobcomp/lua/Makefile'
  - 'config.status: creating src/plugins/jobcomp/mysql/Makefile'
  - 'config.status: creating src/plugins/jobcomp/script/Makefile'
  - 'config.status: creating src/plugins/mcs/Makefile'
  - 'config.status: creating src/plugins/mcs/account/Makefile'
  - 'config.status: creating src/plugins/mcs/group/Makefile'
  - 'config.status: creating src/plugins/mcs/label/Makefile'
  - 'config.status: creating src/plugins/mcs/user/Makefile'
  - 'config.status: creating src/plugins/mpi/Makefile'
  - 'config.status: creating src/plugins/mpi/cray_shasta/Makefile'
  - 'config.status: creating src/plugins/mpi/pmi2/Makefile'
  - 'config.status: creating src/plugins/mpi/pmix/Makefile'
  - 'config.status: creating src/plugins/node_features/Makefile'
  - 'config.status: creating src/plugins/node_features/helpers/Makefile'
  - 'config.status: creating src/plugins/node_features/knl_generic/Makefile'
  - 'config.status: creating src/plugins/preempt/Makefile'
  - 'config.status: creating src/plugins/preempt/partition_prio/Makefile'
  - 'config.status: creating src/plugins/preempt/qos/Makefile'
  - 'config.status: creating src/plugins/prep/Makefile'
  - 'config.status: creating src/plugins/prep/script/Makefile'
  - 'config.status: creating src/plugins/priority/Makefile'
  - 'config.status: creating src/plugins/priority/basic/Makefile'
  - 'config.status: creating src/plugins/priority/multifactor/Makefile'
  - 'config.status: creating src/plugins/proctrack/Makefile'
  - 'config.status: creating src/plugins/proctrack/cgroup/Makefile'
  - 'config.status: creating src/plugins/proctrack/linuxproc/Makefile'
  - 'config.status: creating src/plugins/proctrack/pgid/Makefile'
  - 'config.status: creating src/plugins/sched/Makefile'
  - 'config.status: creating src/plugins/sched/backfill/Makefile'
  - 'config.status: creating src/plugins/sched/builtin/Makefile'
  - 'config.status: creating src/plugins/select/Makefile'
  - 'config.status: creating src/plugins/select/cons_tres/Makefile'
  - 'config.status: creating src/plugins/select/linear/Makefile'
  - 'config.status: creating src/plugins/serializer/Makefile'
  - 'config.status: creating src/plugins/serializer/json/Makefile'
  - 'config.status: creating src/plugins/serializer/url-encoded/Makefile'
  - 'config.status: creating src/plugins/serializer/yaml/Makefile'
  - 'config.status: creating src/plugins/site_factor/Makefile'
  - 'config.status: creating src/plugins/site_factor/example/Makefile'
  - 'config.status: creating src/plugins/switch/Makefile'
  - 'config.status: creating src/plugins/switch/hpe_slingshot/Makefile'
  - 'config.status: creating src/plugins/switch/nvidia_imex/Makefile'
  - 'config.status: creating src/plugins/task/Makefile'
  - 'config.status: creating src/plugins/task/affinity/Makefile'
  - 'config.status: creating src/plugins/task/cgroup/Makefile'
  - 'config.status: creating src/plugins/tls/Makefile'
  - 'config.status: creating src/plugins/tls/none/Makefile'
  - 'config.status: creating src/plugins/tls/s2n/Makefile'
  - 'config.status: creating src/plugins/topology/Makefile'
  - 'config.status: creating src/plugins/topology/block/Makefile'
  - 'config.status: creating src/plugins/topology/common/Makefile'
  - 'config.status: creating src/plugins/topology/flat/Makefile'
  - 'config.status: creating src/plugins/topology/tree/Makefile'
  - 'config.status: creating src/sacct/Makefile'
  - 'config.status: creating src/sackd/Makefile'
  - 'config.status: creating src/sacctmgr/Makefile'
  - 'config.status: creating src/salloc/Makefile'
  - 'config.status: creating src/sattach/Makefile'
  - 'config.status: creating src/scrun/Makefile'
  - 'config.status: creating src/sbatch/Makefile'
  - 'config.status: creating src/sbcast/Makefile'
  - 'config.status: creating src/scancel/Makefile'
  - 'config.status: creating src/scontrol/Makefile'
  - 'config.status: creating src/scrontab/Makefile'
  - 'config.status: creating src/sdiag/Makefile'
  - 'config.status: creating src/sinfo/Makefile'
  - 'config.status: creating src/slurmctld/Makefile'
  - 'config.status: creating src/slurmd/Makefile'
  - 'config.status: creating src/slurmd/common/Makefile'
  - 'config.status: creating src/slurmd/slurmd/Makefile'
  - 'config.status: creating src/slurmd/slurmstepd/Makefile'
  - 'config.status: creating src/slurmdbd/Makefile'
  - 'config.status: creating src/slurmrestd/Makefile'
  - 'config.status: creating src/slurmrestd/plugins/Makefile'
  - 'config.status: creating src/slurmrestd/plugins/auth/Makefile'
  - 'config.status: creating src/slurmrestd/plugins/auth/jwt/Makefile'
  - 'config.status: creating src/slurmrestd/plugins/auth/local/Makefile'
  - 'config.status: creating src/slurmrestd/plugins/openapi/Makefile'
  - 'config.status: creating src/slurmrestd/plugins/openapi/slurmctld/Makefile'
  - 'config.status: creating src/slurmrestd/plugins/openapi/slurmdbd/Makefile'
  - 'config.status: creating src/sprio/Makefile'
  - 'config.status: creating src/squeue/Makefile'
  - 'config.status: creating src/sreport/Makefile'
  - 'config.status: creating src/srun/Makefile'
  - 'config.status: creating src/sshare/Makefile'
  - 'config.status: creating src/sstat/Makefile'
  - 'config.status: creating src/stepmgr/Makefile'
  - 'config.status: creating src/strigger/Makefile'
  - 'config.status: creating src/sview/Makefile'
  - 'config.status: creating testsuite/Makefile'
  - 'config.status: creating testsuite/testsuite.conf.sample'
  - 'config.status: creating testsuite/expect/Makefile'
  - 'config.status: creating testsuite/slurm_unit/Makefile'
  - 'config.status: creating testsuite/slurm_unit/backfill/Makefile'
  - 'config.status: creating testsuite/slurm_unit/common/Makefile'
  - 'config.status: creating testsuite/slurm_unit/common/bitstring/Makefile'
  - 'config.status: creating testsuite/slurm_unit/common/hostlist/Makefile'
  - 'config.status: creating testsuite/slurm_unit/common/slurm_protocol_defs/Makefile'
  - 'config.status: creating testsuite/slurm_unit/common/slurm_protocol_pack/Makefile'
  - 'config.status: creating testsuite/slurm_unit/common/slurmdb_defs/Makefile'
  - 'config.status: creating testsuite/slurm_unit/common/slurmdb_pack/Makefile'
  - 'config.status: creating testsuite/slurm_unit/topology/Makefile'
  - 'config.status: creating config.h'
  - 'config.status: creating slurm/slurm_version.h'
  - 'config.status: executing depfiles commands'
  - 'config.status: executing libtool commands'
2025-07-23 08:28:36,531 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:28:36,531 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:28:36,535 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Компиляция Slurm (это займет время...)] *************************************************************************************************************
2025-07-23 08:28:36,535 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:28:36 +0000 (0:00:00.055)       0:01:41.822 ******** 
2025-07-23 08:28:36,570 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:28:36,584 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:28:36,593 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:33:27,633 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:33:27,648 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Установка Slurm на master] **************************************************************************************************************************
2025-07-23 08:33:27,649 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:33:27 +0000 (0:04:51.113)       0:06:32.936 ******** 
2025-07-23 08:33:27,688 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:33:27,689 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:33:27,699 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:33:27,941 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:33:27,946 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание архива Slurm для копирования] **************************************************************************************************************
2025-07-23 08:33:27,946 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:33:27 +0000 (0:00:00.297)       0:06:33.233 ******** 
2025-07-23 08:33:27,983 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:33:27,985 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:33:27,994 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:36:34,929 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:36:34,935 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] ************************************************************************************************************
2025-07-23 08:36:34,935 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:36:34 +0000 (0:03:06.988)       0:09:40.222 ******** 
2025-07-23 08:36:35,217 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:36:36,158 p=55682 u=master n=ansible | ok: [sm02]
2025-07-23 08:36:36,179 p=55682 u=master n=ansible | ok: [cn01]
2025-07-23 08:36:36,180 p=55682 u=master n=ansible | ok: [cn02]
2025-07-23 08:36:36,184 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] *********************************************************************************************************
2025-07-23 08:36:36,184 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:36:36 +0000 (0:00:01.249)       0:09:41.471 ******** 
2025-07-23 08:36:36,220 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:36:36,221 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:36:36,230 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:36:36,467 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:36:36,471 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] *****************************************************************************************************************************
2025-07-23 08:36:36,471 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:36:36 +0000 (0:00:00.286)       0:09:41.758 ******** 
2025-07-23 08:36:36,507 p=55682 u=master n=ansible | ok: [sm01] => 
  msg: "Размер установки Slurm на sm01: 483M\t/opt/slurm"
2025-07-23 08:36:36,508 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:36:36,508 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:36:36,516 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:36:36,521 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для распространения] **************************************************************************************************
2025-07-23 08:36:36,521 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:36:36 +0000 (0:00:00.049)       0:09:41.808 ******** 
2025-07-23 08:36:36,555 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:36:36,557 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:36:36,567 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:36:36,786 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:36:36,789 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS] ***********************************************************************************************************
2025-07-23 08:36:36,790 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:36:36 +0000 (0:00:00.268)       0:09:42.077 ******** 
2025-07-23 08:36:36,824 p=55682 u=master n=ansible | skipping: [sm02]
2025-07-23 08:36:36,826 p=55682 u=master n=ansible | skipping: [cn01]
2025-07-23 08:36:36,837 p=55682 u=master n=ansible | skipping: [cn02]
2025-07-23 08:36:37,060 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:36:37,064 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 08:36:37,064 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:36:37 +0000 (0:00:00.274)       0:09:42.352 ******** 
2025-07-23 08:36:37,089 p=55682 u=master n=ansible | skipping: [sm01]
2025-07-23 08:37:07,494 p=55682 u=master n=ansible | fatal: [cn01]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /home/slurm-dist/bin/sinfo
2025-07-23 08:37:07,496 p=55682 u=master n=ansible | fatal: [sm02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /home/slurm-dist/bin/sinfo
2025-07-23 08:37:07,501 p=55682 u=master n=ansible | fatal: [cn02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /home/slurm-dist/bin/sinfo
2025-07-23 08:37:07,506 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 08:37:07,506 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:07 +0000 (0:00:30.441)       0:10:12.793 ******** 
2025-07-23 08:37:07,525 p=55682 u=master n=ansible | skipping: [sm01]
2025-07-23 08:37:07,530 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 08:37:07,530 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:07 +0000 (0:00:00.024)       0:10:12.818 ******** 
2025-07-23 08:37:07,799 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:37:07,804 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 08:37:07,804 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:07 +0000 (0:00:00.273)       0:10:13.091 ******** 
2025-07-23 08:37:07,822 p=55682 u=master n=ansible | skipping: [sm01]
2025-07-23 08:37:07,826 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 08:37:07,826 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:07 +0000 (0:00:00.022)       0:10:13.113 ******** 
2025-07-23 08:37:07,844 p=55682 u=master n=ansible | skipping: [sm01]
2025-07-23 08:37:07,849 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 08:37:07,849 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:07 +0000 (0:00:00.023)       0:10:13.137 ******** 
2025-07-23 08:37:08,113 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:37:08,118 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание символических ссылок для пользовательских команд Slurm] ************************************************************************************
2025-07-23 08:37:08,118 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:08 +0000 (0:00:00.268)       0:10:13.405 ******** 
2025-07-23 08:37:08,382 p=55682 u=master n=ansible | ok: [sm01] => (item=sinfo)
2025-07-23 08:37:08,638 p=55682 u=master n=ansible | ok: [sm01] => (item=squeue)
2025-07-23 08:37:08,879 p=55682 u=master n=ansible | ok: [sm01] => (item=scancel)
2025-07-23 08:37:09,124 p=55682 u=master n=ansible | ok: [sm01] => (item=sbatch)
2025-07-23 08:37:09,366 p=55682 u=master n=ansible | ok: [sm01] => (item=salloc)
2025-07-23 08:37:09,612 p=55682 u=master n=ansible | ok: [sm01] => (item=srun)
2025-07-23 08:37:09,857 p=55682 u=master n=ansible | ok: [sm01] => (item=sacct)
2025-07-23 08:37:10,098 p=55682 u=master n=ansible | ok: [sm01] => (item=scontrol)
2025-07-23 08:37:10,342 p=55682 u=master n=ansible | ok: [sm01] => (item=sprio)
2025-07-23 08:37:10,586 p=55682 u=master n=ansible | ok: [sm01] => (item=smap)
2025-07-23 08:37:10,834 p=55682 u=master n=ansible | ok: [sm01] => (item=sdiag)
2025-07-23 08:37:11,078 p=55682 u=master n=ansible | ok: [sm01] => (item=sstat)
2025-07-23 08:37:11,322 p=55682 u=master n=ansible | ok: [sm01] => (item=sreport)
2025-07-23 08:37:11,567 p=55682 u=master n=ansible | ok: [sm01] => (item=sacctmgr)
2025-07-23 08:37:11,807 p=55682 u=master n=ansible | ok: [sm01] => (item=sattach)
2025-07-23 08:37:12,047 p=55682 u=master n=ansible | ok: [sm01] => (item=sbcast)
2025-07-23 08:37:12,288 p=55682 u=master n=ansible | ok: [sm01] => (item=sshare)
2025-07-23 08:37:12,529 p=55682 u=master n=ansible | ok: [sm01] => (item=sview)
2025-07-23 08:37:12,535 p=55682 u=master n=ansible | [WARNING]: Cannot set fs attributes on a non-existent symlink target. follow should be set to False to avoid this.

2025-07-23 08:37:12,541 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание символических ссылок для системных демонов Slurm] ******************************************************************************************
2025-07-23 08:37:12,541 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:12 +0000 (0:00:04.423)       0:10:17.829 ******** 
2025-07-23 08:37:12,804 p=55682 u=master n=ansible | ok: [sm01] => (item=slurmctld)
2025-07-23 08:37:13,044 p=55682 u=master n=ansible | ok: [sm01] => (item=slurmd)
2025-07-23 08:37:13,286 p=55682 u=master n=ansible | ok: [sm01] => (item=slurmdbd)
2025-07-23 08:37:13,527 p=55682 u=master n=ansible | ok: [sm01] => (item=slurmrestd)
2025-07-23 08:37:13,771 p=55682 u=master n=ansible | ok: [sm01] => (item=slurmstepd)
2025-07-23 08:37:13,777 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Обновление библиотечного кеша] **********************************************************************************************************************
2025-07-23 08:37:13,777 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:13 +0000 (0:00:01.235)       0:10:19.065 ******** 
2025-07-23 08:37:14,202 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:37:14,206 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка версии Slurm (без подключения к демону)] ***************************************************************************************************
2025-07-23 08:37:14,207 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:14 +0000 (0:00:00.429)       0:10:19.494 ******** 
2025-07-23 08:37:14,518 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:37:14,522 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка поддержки JWT] *****************************************************************************************************************************
2025-07-23 08:37:14,522 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:14 +0000 (0:00:00.315)       0:10:19.809 ******** 
2025-07-23 08:37:14,782 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:37:14,787 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка поддержки GPU/NVIDIA] **********************************************************************************************************************
2025-07-23 08:37:14,787 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:14 +0000 (0:00:00.265)       0:10:20.075 ******** 
2025-07-23 08:37:15,084 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:37:15,088 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка поддержки MySQL] ***************************************************************************************************************************
2025-07-23 08:37:15,089 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:15 +0000 (0:00:00.301)       0:10:20.376 ******** 
2025-07-23 08:37:15,353 p=55682 u=master n=ansible | ok: [sm01]
2025-07-23 08:37:15,357 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результаты проверки] ********************************************************************************************************************************
2025-07-23 08:37:15,357 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:15 +0000 (0:00:00.268)       0:10:20.644 ******** 
2025-07-23 08:37:15,383 p=55682 u=master n=ansible | ok: [sm01] => 
  msg: "✅ Slurm успешно установлен на sm01\n\U0001F4CB Версия:\n\U0001F510 JWT поддержка: JWT support check\n\U0001F3AE GPU поддержка: GRES support available\n\U0001F4BE MySQL поддержка: MySQL support check\n\U0001F4CD Путь установки: /opt/slurm\n\U0001F517 Команды доступны в /usr/bin/, демоны в /usr/sbin/"
2025-07-23 08:37:15,387 p=55682 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Сборка завершена успешно] ***************************************************************************************************************************
2025-07-23 08:37:15,388 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:15 +0000 (0:00:00.030)       0:10:20.675 ******** 
2025-07-23 08:37:15,409 p=55682 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F389 Slurm 25.05.1 с JWT готов к настройке на sm01"
2025-07-23 08:37:15,421 p=55682 u=master n=ansible | RUNNING HANDLER [common : restart nfs-server] *****************************************************************************************************************************************
2025-07-23 08:37:15,421 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:15 +0000 (0:00:00.033)       0:10:20.708 ******** 
2025-07-23 08:37:16,493 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:37:16,498 p=55682 u=master n=ansible | RUNNING HANDLER [common : reload nfs-exports] *****************************************************************************************************************************************
2025-07-23 08:37:16,498 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:16 +0000 (0:00:01.077)       0:10:21.785 ******** 
2025-07-23 08:37:16,754 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:37:16,758 p=55682 u=master n=ansible | TASK [Проверка установки Slurm] *******************************************************************************************************************************************************
2025-07-23 08:37:16,758 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:16 +0000 (0:00:00.260)       0:10:22.045 ******** 
2025-07-23 08:37:17,047 p=55682 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  cmd:
  - /usr/bin/sinfo
  - --version
  delta: '0:00:00.034470'
  end: '2025-07-23 11:37:17.047885'
  msg: non-zero return code
  rc: 1
  start: '2025-07-23 11:37:17.013415'
  stderr: |-
    sinfo: error: resolve_ctls_from_dns_srv: res_nsearch error: Unknown host
    sinfo: error: fetch_config: DNS SRV lookup failed
    sinfo: error: _establish_config_source: failed to fetch config
    sinfo: fatal: Could not establish a configuration source
  stderr_lines: <omitted>
  stdout: ''
  stdout_lines: <omitted>
2025-07-23 08:37:17,047 p=55682 u=master n=ansible | ...ignoring
2025-07-23 08:37:17,051 p=55682 u=master n=ansible | TASK [Результаты установки] ***********************************************************************************************************************************************************
2025-07-23 08:37:17,051 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:17 +0000 (0:00:00.292)       0:10:22.338 ******** 
2025-07-23 08:37:17,076 p=55682 u=master n=ansible | ok: [sm01] => 
  msg: |-
    ❌ Ошибка проверки Slurm на sm01
2025-07-23 08:37:17,081 p=55682 u=master n=ansible | TASK [Проверка доступности команд Slurm] **********************************************************************************************************************************************
2025-07-23 08:37:17,081 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:17 +0000 (0:00:00.029)       0:10:22.368 ******** 
2025-07-23 08:37:17,354 p=55682 u=master n=ansible | changed: [sm01]
2025-07-23 08:37:17,359 p=55682 u=master n=ansible | TASK [Список установленных компонентов] ***********************************************************************************************************************************************
2025-07-23 08:37:17,359 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:17 +0000 (0:00:00.277)       0:10:22.646 ******** 
2025-07-23 08:37:17,384 p=55682 u=master n=ansible | ok: [sm01] => 
  slurm_binaries.stdout_lines:
  - === Пользовательские команды Slurm ===
  - lrwxrwxrwx 1 root root       20 Jul 22 18:35 /usr/bin/sacct -> /opt/slurm/bin/sacct
  - lrwxrwxrwx 1 root root       23 Jul 22 18:35 /usr/bin/sacctmgr -> /opt/slurm/bin/sacctmgr
  - lrwxrwxrwx 1 root root       21 Jul 22 18:35 /usr/bin/salloc -> /opt/slurm/bin/salloc
  - lrwxrwxrwx 1 root root       22 Jul 22 18:35 /usr/bin/sattach -> /opt/slurm/bin/sattach
  - lrwxrwxrwx 1 root root       21 Jul 22 18:35 /usr/bin/sbatch -> /opt/slurm/bin/sbatch
  - lrwxrwxrwx 1 root root       21 Jul 22 18:35 /usr/bin/sbcast -> /opt/slurm/bin/sbcast
  - lrwxrwxrwx 1 root root       22 Jul 22 18:35 /usr/bin/scancel -> /opt/slurm/bin/scancel
  - lrwxrwxrwx 1 root root       23 Jul 22 18:35 /usr/bin/scontrol -> /opt/slurm/bin/scontrol
  - lrwxrwxrwx 1 root root       20 Jul 22 18:35 /usr/bin/sdiag -> /opt/slurm/bin/sdiag
  - lrwxrwxrwx 1 root root       20 Jul 22 18:35 /usr/bin/sinfo -> /opt/slurm/bin/sinfo
  - lrwxrwxrwx 1 root root       19 Jul 22 18:35 /usr/bin/smap -> /opt/slurm/bin/smap
  - lrwxrwxrwx 1 root root       20 Jul 22 18:35 /usr/bin/sprio -> /opt/slurm/bin/sprio
  - lrwxrwxrwx 1 root root       21 Jul 22 18:35 /usr/bin/squeue -> /opt/slurm/bin/squeue
  - lrwxrwxrwx 1 root root       22 Jul 22 18:35 /usr/bin/sreport -> /opt/slurm/bin/sreport
  - lrwxrwxrwx 1 root root       19 Jul 22 18:35 /usr/bin/srun -> /opt/slurm/bin/srun
  - lrwxrwxrwx 1 root root       21 Jul 22 18:35 /usr/bin/sshare -> /opt/slurm/bin/sshare
  - lrwxrwxrwx 1 root root       20 Jul 22 18:35 /usr/bin/sstat -> /opt/slurm/bin/sstat
  - lrwxrwxrwx 1 root root       20 Jul 22 18:35 /usr/bin/sview -> /opt/slurm/bin/sview
  - === Системные демоны Slurm ===
  - lrwxrwxrwx 1 root root 25 Jul 22 18:35 /usr/sbin/slurmctld -> /opt/slurm/sbin/slurmctld
  - lrwxrwxrwx 1 root root 22 Jul 22 18:35 /usr/sbin/slurmd -> /opt/slurm/sbin/slurmd
  - lrwxrwxrwx 1 root root 24 Jul 22 18:35 /usr/sbin/slurmdbd -> /opt/slurm/sbin/slurmdbd
  - lrwxrwxrwx 1 root root 26 Jul 22 18:35 /usr/sbin/slurmrestd -> /opt/slurm/sbin/slurmrestd
  - lrwxrwxrwx 1 root root 26 Jul 22 18:35 /usr/sbin/slurmstepd -> /opt/slurm/sbin/slurmstepd
  - === Установочная директория ===
  - total 11948
  - drwxr-xr-x 2 root root    4096 Jul 22 18:28 .
  - drwxr-xr-x 7 root root    4096 Jul 22 18:28 ..
  - -rwxr-xr-x 1 root root  452744 Jul 22 18:28 sacct
  - -rwxr-xr-x 1 root root 1370760 Jul 22 18:28 sacctmgr
2025-07-23 08:37:17,391 p=55682 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 08:37:17,391 p=55682 u=master n=ansible | cn01                       : ok=24   changed=3    unreachable=0    failed=1    skipped=26   rescued=0    ignored=0   
2025-07-23 08:37:17,391 p=55682 u=master n=ansible | cn02                       : ok=24   changed=3    unreachable=0    failed=1    skipped=26   rescued=0    ignored=0   
2025-07-23 08:37:17,391 p=55682 u=master n=ansible | sm01                       : ok=64   changed=24   unreachable=0    failed=0    skipped=8    rescued=0    ignored=1   
2025-07-23 08:37:17,391 p=55682 u=master n=ansible | sm02                       : ok=24   changed=3    unreachable=0    failed=1    skipped=26   rescued=0    ignored=0   
2025-07-23 08:37:17,391 p=55682 u=master n=ansible | Playbook run took 0 days, 0 hours, 10 minutes, 22 seconds
2025-07-23 08:37:17,392 p=55682 u=master n=ansible | Wednesday 23 July 2025  08:37:17 +0000 (0:00:00.032)       0:10:22.679 ******** 
2025-07-23 08:37:17,392 p=55682 u=master n=ansible | =============================================================================== 
2025-07-23 08:37:17,392 p=55682 u=master n=ansible | slurm_build : [SLURM_BUILD] Компиляция Slurm (это займет время...) ----------------------------------------------------------------------------------------------------------- 291.11s
2025-07-23 08:37:17,392 p=55682 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание архива Slurm для копирования ------------------------------------------------------------------------------------------------------------ 186.99s
2025-07-23 08:37:17,392 p=55682 u=master n=ansible | slurm_build : [SLURM_BUILD] Конфигурация сборки Slurm с JWT поддержкой -------------------------------------------------------------------------------------------------------- 33.51s
2025-07-23 08:37:17,392 p=55682 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------ 30.44s
2025-07-23 08:37:17,392 p=55682 u=master n=ansible | common : [COMMON] Установка базовых пакетов ----------------------------------------------------------------------------------------------------------------------------------- 21.98s
2025-07-23 08:37:17,392 p=55682 u=master n=ansible | slurm_build : [SLURM_BUILD] Установка дополнительных зависимостей для сборки -------------------------------------------------------------------------------------------------- 10.99s
2025-07-23 08:37:17,392 p=55682 u=master n=ansible | slurm_build : [SLURM_BUILD] Извлечение исходников Slurm ------------------------------------------------------------------------------------------------------------------------ 5.68s
2025-07-23 08:37:17,393 p=55682 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание символических ссылок для пользовательских команд Slurm ------------------------------------------------------------------------------------ 4.42s
2025-07-23 08:37:17,393 p=55682 u=master n=ansible | common : [COMMON] Обновление apt cache ----------------------------------------------------------------------------------------------------------------------------------------- 3.69s
2025-07-23 08:37:17,393 p=55682 u=master n=ansible | slurm_build : [SLURM_BUILD] Скачивание исходников Slurm 25.05.1 ---------------------------------------------------------------------------------------------------------------- 2.90s
2025-07-23 08:37:17,393 p=55682 u=master n=ansible | common : [COMMON] Остановка MUNGE перед настройкой ----------------------------------------------------------------------------------------------------------------------------- 1.99s
2025-07-23 08:37:17,393 p=55682 u=master n=ansible | common : [COMMON] Запуск и включение MUNGE ------------------------------------------------------------------------------------------------------------------------------------- 1.93s
2025-07-23 08:37:17,393 p=55682 u=master n=ansible | common : [COMMON] Создание базовых директорий Slurm ---------------------------------------------------------------------------------------------------------------------------- 1.62s
2025-07-23 08:37:17,393 p=55682 u=master n=ansible | common : [COMMON] Настройка экспорта NFS с конкретными IP ---------------------------------------------------------------------------------------------------------------------- 1.46s
2025-07-23 08:37:17,393 p=55682 u=master n=ansible | Проверка доступного места на диске --------------------------------------------------------------------------------------------------------------------------------------------- 1.27s
2025-07-23 08:37:17,393 p=55682 u=master n=ansible | common : [COMMON] Распространение MUNGE ключа на все узлы ---------------------------------------------------------------------------------------------------------------------- 1.26s
2025-07-23 08:37:17,393 p=55682 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------------------ 1.25s
2025-07-23 08:37:17,393 p=55682 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание символических ссылок для системных демонов Slurm ------------------------------------------------------------------------------------------ 1.24s
2025-07-23 08:37:17,393 p=55682 u=master n=ansible | common : [COMMON] Обеспечение hostname resolution для кластера ----------------------------------------------------------------------------------------------------------------- 1.19s
2025-07-23 08:37:17,394 p=55682 u=master n=ansible | common : [COMMON] Установка MUNGE ---------------------------------------------------------------------------------------------------------------------------------------------- 1.12s
2025-07-23 08:42:14,883 p=56613 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:42:14,883 p=56613 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:42:16,234 p=56613 u=master n=ansible | sm01 | FAILED | rc=1 >>
touch: cannot touch '/home/test': Permission deniednon-zero return code

2025-07-23 08:53:27,794 p=56680 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:53:27,795 p=56680 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:53:29,133 p=56680 u=master n=ansible | sm01 | CHANGED | rc=0 >>
drwxr-xr-x 2 root root 4096 Jul 23 11:11 /sw

2025-07-23 08:54:10,268 p=56736 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:54:10,268 p=56736 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:54:10,888 p=56736 u=master n=ansible | sm01 | CHANGED | rc=0 >>
total 8
drwxr-xr-x  2 root root 4096 Jul 23 11:11 .
drwxr-xr-x 25 root root 4096 Jul 22 16:41 ..

2025-07-23 08:54:41,503 p=56775 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:54:41,504 p=56775 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:54:42,143 p=56775 u=master n=ansible | sm01 | CHANGED | rc=0 >>
/sw 10.20.90.161(rw,sync,no_root_squash)
/sw 10.20.90.167(rw,sync,no_root_squash)
/sw 10.20.90.168(rw,sync,no_root_squash)

2025-07-23 08:55:36,718 p=56825 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:55:36,718 p=56825 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:55:37,367 p=56825 u=master n=ansible | sm01 | CHANGED | rc=0 >>


2025-07-23 08:55:50,869 p=56872 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:55:50,869 p=56872 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:55:51,501 p=56872 u=master n=ansible | sm01 | CHANGED | rc=0 >>
drwxr-xr-x 2 root root 4096 Jul 23 11:11 /sw

2025-07-23 08:57:05,307 p=56951 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:57:05,308 p=56951 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:57:06,698 p=56951 u=master n=ansible | sm01 | CHANGED | rc=0 >>
-rw-r--r-- 1 root root 0 Jul 23 11:57 /sw/test

2025-07-23 08:57:51,518 p=57032 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:57:51,518 p=57032 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:57:52,869 p=57032 u=master n=ansible | cn02 | CHANGED | rc=0 >>
-rw-r--r-- 1 root root 0 Jul 23 11:57 /sw/test

2025-07-23 08:57:53,165 p=57032 u=master n=ansible | sm02 | CHANGED | rc=0 >>
-rw-r--r-- 1 root root 0 Jul 23 11:57 /sw/test

2025-07-23 08:57:53,334 p=57032 u=master n=ansible | cn01 | CHANGED | rc=0 >>
-rw-r--r-- 1 root root 0 Jul 23 11:57 /sw/test

2025-07-23 08:59:09,202 p=57106 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:59:09,202 p=57106 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 08:59:09,686 p=57106 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 08:59:09,707 p=57106 u=master n=ansible | TASK [Gathering Facts] ****************************************************************************************************************************************************************
2025-07-23 08:59:09,707 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:09 +0000 (0:00:00.023)       0:00:00.023 ******** 
2025-07-23 08:59:11,258 p=57106 u=master n=ansible | ok: [cn02]
2025-07-23 08:59:11,405 p=57106 u=master n=ansible | ok: [sm01]
2025-07-23 08:59:11,421 p=57106 u=master n=ansible | ok: [cn01]
2025-07-23 08:59:11,439 p=57106 u=master n=ansible | ok: [sm02]
2025-07-23 08:59:11,456 p=57106 u=master n=ansible | TASK [common : [COMMON] Проверка работы MUNGE] ****************************************************************************************************************************************
2025-07-23 08:59:11,457 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:11 +0000 (0:00:01.749)       0:00:01.773 ******** 
2025-07-23 08:59:11,846 p=57106 u=master n=ansible | ok: [cn02]
2025-07-23 08:59:11,857 p=57106 u=master n=ansible | ok: [sm02]
2025-07-23 08:59:11,857 p=57106 u=master n=ansible | ok: [cn01]
2025-07-23 08:59:11,863 p=57106 u=master n=ansible | ok: [sm01]
2025-07-23 08:59:11,867 p=57106 u=master n=ansible | TASK [common : [COMMON] Результат проверки MUNGE] *************************************************************************************************************************************
2025-07-23 08:59:11,867 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:11 +0000 (0:00:00.410)       0:00:02.184 ******** 
2025-07-23 08:59:11,900 p=57106 u=master n=ansible | ok: [sm01] => 
  msg: MUNGE работает корректно на sm01
2025-07-23 08:59:11,903 p=57106 u=master n=ansible | ok: [sm02] => 
  msg: MUNGE работает корректно на sm02
2025-07-23 08:59:11,906 p=57106 u=master n=ansible | ok: [cn01] => 
  msg: MUNGE работает корректно на cn01
2025-07-23 08:59:11,917 p=57106 u=master n=ansible | ok: [cn02] => 
  msg: MUNGE работает корректно на cn02
2025-07-23 08:59:11,921 p=57106 u=master n=ansible | TASK [common : [COMMON] Проверка HWLOC] ***********************************************************************************************************************************************
2025-07-23 08:59:11,921 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:11 +0000 (0:00:00.053)       0:00:02.238 ******** 
2025-07-23 08:59:12,195 p=57106 u=master n=ansible | ok: [sm01]
2025-07-23 08:59:12,196 p=57106 u=master n=ansible | ok: [sm02]
2025-07-23 08:59:12,202 p=57106 u=master n=ansible | ok: [cn02]
2025-07-23 08:59:12,206 p=57106 u=master n=ansible | ok: [cn01]
2025-07-23 08:59:12,209 p=57106 u=master n=ansible | TASK [common : [COMMON] Версия HWLOC] *************************************************************************************************************************************************
2025-07-23 08:59:12,209 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:12 +0000 (0:00:00.288)       0:00:02.526 ******** 
2025-07-23 08:59:12,244 p=57106 u=master n=ansible | ok: [sm01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 08:59:12,245 p=57106 u=master n=ansible | ok: [sm02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 08:59:12,248 p=57106 u=master n=ansible | ok: [cn01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 08:59:12,258 p=57106 u=master n=ansible | ok: [cn02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 08:59:12,261 p=57106 u=master n=ansible | TASK [common : [COMMON] Роль common выполнена успешно] ********************************************************************************************************************************
2025-07-23 08:59:12,261 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:12 +0000 (0:00:00.051)       0:00:02.578 ******** 
2025-07-23 08:59:12,290 p=57106 u=master n=ansible | ok: [sm01] => 
  msg: ✅ Узел sm01 готов для установки Slurm
2025-07-23 08:59:12,303 p=57106 u=master n=ansible | ok: [sm02] => 
  msg: ✅ Узел sm02 готов для установки Slurm
2025-07-23 08:59:12,305 p=57106 u=master n=ansible | ok: [cn01] => 
  msg: ✅ Узел cn01 готов для установки Slurm
2025-07-23 08:59:12,317 p=57106 u=master n=ansible | ok: [cn02] => 
  msg: ✅ Узел cn02 готов для установки Slurm
2025-07-23 08:59:12,328 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] ************************************************************************************************************
2025-07-23 08:59:12,328 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:12 +0000 (0:00:00.067)       0:00:02.645 ******** 
2025-07-23 08:59:12,730 p=57106 u=master n=ansible | ok: [cn02]
2025-07-23 08:59:12,732 p=57106 u=master n=ansible | ok: [sm02]
2025-07-23 08:59:12,734 p=57106 u=master n=ansible | ok: [cn01]
2025-07-23 08:59:12,745 p=57106 u=master n=ansible | ok: [sm01]
2025-07-23 08:59:12,749 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] *********************************************************************************************************
2025-07-23 08:59:12,750 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:12 +0000 (0:00:00.421)       0:00:03.066 ******** 
2025-07-23 08:59:12,781 p=57106 u=master n=ansible | skipping: [sm02]
2025-07-23 08:59:12,783 p=57106 u=master n=ansible | skipping: [cn01]
2025-07-23 08:59:12,791 p=57106 u=master n=ansible | skipping: [cn02]
2025-07-23 08:59:13,022 p=57106 u=master n=ansible | changed: [sm01]
2025-07-23 08:59:13,026 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] *****************************************************************************************************************************
2025-07-23 08:59:13,026 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:13 +0000 (0:00:00.276)       0:00:03.343 ******** 
2025-07-23 08:59:13,060 p=57106 u=master n=ansible | ok: [sm01] => 
  msg: "Размер установки Slurm на sm01: 483M\t/opt/slurm"
2025-07-23 08:59:13,062 p=57106 u=master n=ansible | skipping: [sm02]
2025-07-23 08:59:13,063 p=57106 u=master n=ansible | skipping: [cn01]
2025-07-23 08:59:13,071 p=57106 u=master n=ansible | skipping: [cn02]
2025-07-23 08:59:13,075 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере] ******************************************************************************************************
2025-07-23 08:59:13,075 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:13 +0000 (0:00:00.048)       0:00:03.391 ******** 
2025-07-23 08:59:13,110 p=57106 u=master n=ansible | skipping: [sm02]
2025-07-23 08:59:13,112 p=57106 u=master n=ansible | skipping: [cn01]
2025-07-23 08:59:13,120 p=57106 u=master n=ansible | skipping: [cn02]
2025-07-23 08:59:13,350 p=57106 u=master n=ansible | ok: [sm01]
2025-07-23 08:59:13,354 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для распространения] **************************************************************************************************
2025-07-23 08:59:13,354 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:13 +0000 (0:00:00.278)       0:00:03.670 ******** 
2025-07-23 08:59:13,387 p=57106 u=master n=ansible | skipping: [sm02]
2025-07-23 08:59:13,389 p=57106 u=master n=ansible | skipping: [cn01]
2025-07-23 08:59:13,398 p=57106 u=master n=ansible | skipping: [cn02]
2025-07-23 08:59:13,625 p=57106 u=master n=ansible | changed: [sm01]
2025-07-23 08:59:13,629 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS] ***********************************************************************************************************
2025-07-23 08:59:13,630 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:13 +0000 (0:00:00.275)       0:00:03.946 ******** 
2025-07-23 08:59:13,661 p=57106 u=master n=ansible | skipping: [sm02]
2025-07-23 08:59:13,663 p=57106 u=master n=ansible | skipping: [cn01]
2025-07-23 08:59:13,673 p=57106 u=master n=ansible | skipping: [cn02]
2025-07-23 08:59:13,897 p=57106 u=master n=ansible | changed: [sm01]
2025-07-23 08:59:13,901 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 08:59:13,902 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:13 +0000 (0:00:00.272)       0:00:04.218 ******** 
2025-07-23 08:59:13,928 p=57106 u=master n=ansible | skipping: [sm01]
2025-07-23 08:59:44,323 p=57106 u=master n=ansible | fatal: [sm02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 08:59:44,325 p=57106 u=master n=ansible | fatal: [cn02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 08:59:44,327 p=57106 u=master n=ansible | fatal: [cn01]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 08:59:44,331 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 08:59:44,331 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:44 +0000 (0:00:30.429)       0:00:34.648 ******** 
2025-07-23 08:59:44,353 p=57106 u=master n=ansible | skipping: [sm01]
2025-07-23 08:59:44,357 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 08:59:44,357 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:44 +0000 (0:00:00.025)       0:00:34.674 ******** 
2025-07-23 08:59:44,639 p=57106 u=master n=ansible | changed: [sm01]
2025-07-23 08:59:44,644 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 08:59:44,644 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:44 +0000 (0:00:00.287)       0:00:34.961 ******** 
2025-07-23 08:59:44,662 p=57106 u=master n=ansible | skipping: [sm01]
2025-07-23 08:59:44,665 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 08:59:44,666 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:44 +0000 (0:00:00.021)       0:00:34.982 ******** 
2025-07-23 08:59:44,682 p=57106 u=master n=ansible | skipping: [sm01]
2025-07-23 08:59:44,685 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 08:59:44,686 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:44 +0000 (0:00:00.020)       0:00:35.002 ******** 
2025-07-23 08:59:44,949 p=57106 u=master n=ansible | ok: [sm01]
2025-07-23 08:59:44,953 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание символических ссылок для пользовательских команд Slurm] ************************************************************************************
2025-07-23 08:59:44,953 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:44 +0000 (0:00:00.267)       0:00:35.270 ******** 
2025-07-23 08:59:45,229 p=57106 u=master n=ansible | ok: [sm01] => (item=sinfo)
2025-07-23 08:59:45,477 p=57106 u=master n=ansible | ok: [sm01] => (item=squeue)
2025-07-23 08:59:45,727 p=57106 u=master n=ansible | ok: [sm01] => (item=scancel)
2025-07-23 08:59:45,974 p=57106 u=master n=ansible | ok: [sm01] => (item=sbatch)
2025-07-23 08:59:46,227 p=57106 u=master n=ansible | ok: [sm01] => (item=salloc)
2025-07-23 08:59:46,562 p=57106 u=master n=ansible | ok: [sm01] => (item=srun)
2025-07-23 08:59:46,885 p=57106 u=master n=ansible | ok: [sm01] => (item=sacct)
2025-07-23 08:59:47,131 p=57106 u=master n=ansible | ok: [sm01] => (item=scontrol)
2025-07-23 08:59:47,380 p=57106 u=master n=ansible | ok: [sm01] => (item=sprio)
2025-07-23 08:59:47,630 p=57106 u=master n=ansible | ok: [sm01] => (item=smap)
2025-07-23 08:59:47,877 p=57106 u=master n=ansible | ok: [sm01] => (item=sdiag)
2025-07-23 08:59:48,125 p=57106 u=master n=ansible | ok: [sm01] => (item=sstat)
2025-07-23 08:59:48,371 p=57106 u=master n=ansible | ok: [sm01] => (item=sreport)
2025-07-23 08:59:48,616 p=57106 u=master n=ansible | ok: [sm01] => (item=sacctmgr)
2025-07-23 08:59:48,863 p=57106 u=master n=ansible | ok: [sm01] => (item=sattach)
2025-07-23 08:59:49,110 p=57106 u=master n=ansible | ok: [sm01] => (item=sbcast)
2025-07-23 08:59:49,360 p=57106 u=master n=ansible | ok: [sm01] => (item=sshare)
2025-07-23 08:59:49,605 p=57106 u=master n=ansible | ok: [sm01] => (item=sview)
2025-07-23 08:59:49,611 p=57106 u=master n=ansible | [WARNING]: Cannot set fs attributes on a non-existent symlink target. follow should be set to False to avoid this.

2025-07-23 08:59:49,617 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание символических ссылок для системных демонов Slurm] ******************************************************************************************
2025-07-23 08:59:49,618 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:49 +0000 (0:00:04.664)       0:00:39.934 ******** 
2025-07-23 08:59:49,893 p=57106 u=master n=ansible | ok: [sm01] => (item=slurmctld)
2025-07-23 08:59:50,138 p=57106 u=master n=ansible | ok: [sm01] => (item=slurmd)
2025-07-23 08:59:50,384 p=57106 u=master n=ansible | ok: [sm01] => (item=slurmdbd)
2025-07-23 08:59:50,628 p=57106 u=master n=ansible | ok: [sm01] => (item=slurmrestd)
2025-07-23 08:59:50,876 p=57106 u=master n=ansible | ok: [sm01] => (item=slurmstepd)
2025-07-23 08:59:50,882 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Обновление библиотечного кеша] **********************************************************************************************************************
2025-07-23 08:59:50,882 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:50 +0000 (0:00:01.264)       0:00:41.199 ******** 
2025-07-23 08:59:51,177 p=57106 u=master n=ansible | changed: [sm01]
2025-07-23 08:59:51,181 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка версии Slurm (без подключения к демону)] ***************************************************************************************************
2025-07-23 08:59:51,181 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:51 +0000 (0:00:00.298)       0:00:41.498 ******** 
2025-07-23 08:59:51,475 p=57106 u=master n=ansible | ok: [sm01]
2025-07-23 08:59:51,480 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка поддержки JWT] *****************************************************************************************************************************
2025-07-23 08:59:51,480 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:51 +0000 (0:00:00.298)       0:00:41.796 ******** 
2025-07-23 08:59:51,753 p=57106 u=master n=ansible | ok: [sm01]
2025-07-23 08:59:51,758 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка поддержки GPU/NVIDIA] **********************************************************************************************************************
2025-07-23 08:59:51,758 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:51 +0000 (0:00:00.277)       0:00:42.074 ******** 
2025-07-23 08:59:52,059 p=57106 u=master n=ansible | ok: [sm01]
2025-07-23 08:59:52,063 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка поддержки MySQL] ***************************************************************************************************************************
2025-07-23 08:59:52,064 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:52 +0000 (0:00:00.305)       0:00:42.380 ******** 
2025-07-23 08:59:52,332 p=57106 u=master n=ansible | ok: [sm01]
2025-07-23 08:59:52,336 p=57106 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результаты проверки] ********************************************************************************************************************************
2025-07-23 08:59:52,336 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:52 +0000 (0:00:00.272)       0:00:42.652 ******** 
2025-07-23 08:59:52,361 p=57106 u=master n=ansible | ok: [sm01] => 
  msg: "✅ Slurm успешно установлен на sm01\n\U0001F4CB Версия:\n\U0001F510 JWT поддержка: JWT support check\n\U0001F3AE GPU поддержка: GRES support available\n\U0001F4BE MySQL поддержка: MySQL support check\n\U0001F4CD Путь установки: /opt/slurm\n\U0001F517 Команды доступны в /usr/bin/, демоны в /usr/sbin/"
2025-07-23 08:59:52,373 p=57106 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 08:59:52,373 p=57106 u=master n=ansible | cn01                       : ok=7    changed=0    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-07-23 08:59:52,373 p=57106 u=master n=ansible | cn02                       : ok=7    changed=0    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-07-23 08:59:52,373 p=57106 u=master n=ansible | sm01                       : ok=22   changed=5    unreachable=0    failed=0    skipped=4    rescued=0    ignored=0   
2025-07-23 08:59:52,373 p=57106 u=master n=ansible | sm02                       : ok=7    changed=0    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-07-23 08:59:52,374 p=57106 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 42 seconds
2025-07-23 08:59:52,374 p=57106 u=master n=ansible | Wednesday 23 July 2025  08:59:52 +0000 (0:00:00.037)       0:00:42.690 ******** 
2025-07-23 08:59:52,374 p=57106 u=master n=ansible | =============================================================================== 
2025-07-23 08:59:52,374 p=57106 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------ 30.43s
2025-07-23 08:59:52,374 p=57106 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание символических ссылок для пользовательских команд Slurm ------------------------------------------------------------------------------------ 4.66s
2025-07-23 08:59:52,374 p=57106 u=master n=ansible | Gathering Facts ---------------------------------------------------------------------------------------------------------------------------------------------------------------- 1.75s
2025-07-23 08:59:52,374 p=57106 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание символических ссылок для системных демонов Slurm ------------------------------------------------------------------------------------------ 1.26s
2025-07-23 08:59:52,375 p=57106 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------------------ 0.42s
2025-07-23 08:59:52,375 p=57106 u=master n=ansible | common : [COMMON] Проверка работы MUNGE ---------------------------------------------------------------------------------------------------------------------------------------- 0.41s
2025-07-23 08:59:52,375 p=57106 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка поддержки GPU/NVIDIA ---------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-23 08:59:52,375 p=57106 u=master n=ansible | slurm_build : [SLURM_BUILD] Обновление библиотечного кеша ---------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-23 08:59:52,375 p=57106 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка версии Slurm (без подключения к демону) --------------------------------------------------------------------------------------------------- 0.30s
2025-07-23 08:59:52,375 p=57106 u=master n=ansible | common : [COMMON] Проверка HWLOC ----------------------------------------------------------------------------------------------------------------------------------------------- 0.29s
2025-07-23 08:59:52,375 p=57106 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.29s
2025-07-23 08:59:52,375 p=57106 u=master n=ansible | slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере ------------------------------------------------------------------------------------------------------ 0.28s
2025-07-23 08:59:52,375 p=57106 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка поддержки JWT ----------------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 08:59:52,375 p=57106 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master --------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 08:59:52,376 p=57106 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание временной директории для распространения -------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 08:59:52,376 p=57106 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка поддержки MySQL --------------------------------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 08:59:52,376 p=57106 u=master n=ansible | slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS ----------------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 08:59:52,376 p=57106 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 08:59:52,376 p=57106 u=master n=ansible | common : [COMMON] Роль common выполнена успешно -------------------------------------------------------------------------------------------------------------------------------- 0.07s
2025-07-23 08:59:52,376 p=57106 u=master n=ansible | common : [COMMON] Результат проверки MUNGE ------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:00:39,418 p=57387 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:00:39,418 p=57387 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:00:40,421 p=57387 u=master n=ansible | sm01 | CHANGED | rc=0 >>
drwxr-xr-x 2 root root 4096 Jul 23 11:59 /sw

2025-07-23 09:02:15,986 p=57437 u=master n=ansible | Using /home/master/22Jul/slurm-hpc-cluster/ansible.cfg as config file
2025-07-23 09:02:15,986 p=57437 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:02:15,987 p=57437 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:02:16,451 p=57437 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 09:02:16,495 p=57437 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] ************************************************************************************************************
2025-07-23 09:02:16,495 p=57437 u=master n=ansible | Wednesday 23 July 2025  09:02:16 +0000 (0:00:00.047)       0:00:00.047 ******** 
2025-07-23 09:02:17,633 p=57437 u=master n=ansible | ok: [cn02] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:02:17,636 p=57437 u=master n=ansible | ok: [sm01] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:02:17,839 p=57437 u=master n=ansible | ok: [sm02] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:02:17,882 p=57437 u=master n=ansible | ok: [cn01] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:02:17,887 p=57437 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] *********************************************************************************************************
2025-07-23 09:02:17,887 p=57437 u=master n=ansible | Wednesday 23 July 2025  09:02:17 +0000 (0:00:01.391)       0:00:01.439 ******** 
2025-07-23 09:02:17,921 p=57437 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:17,923 p=57437 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:17,931 p=57437 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:18,274 p=57437 u=master n=ansible | changed: [sm01] => changed=true 
  cmd: du -sh /opt/slurm
  delta: '0:00:00.006526'
  end: '2025-07-23 12:02:18.279074'
  msg: ''
  rc: 0
  start: '2025-07-23 12:02:18.272548'
  stderr: ''
  stderr_lines: <omitted>
  stdout: "483M\t/opt/slurm"
  stdout_lines: <omitted>
2025-07-23 09:02:18,278 p=57437 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] *****************************************************************************************************************************
2025-07-23 09:02:18,279 p=57437 u=master n=ansible | Wednesday 23 July 2025  09:02:18 +0000 (0:00:00.391)       0:00:01.830 ******** 
2025-07-23 09:02:18,314 p=57437 u=master n=ansible | ok: [sm01] => 
  msg: "Размер установки Slurm на sm01: 483M\t/opt/slurm"
2025-07-23 09:02:18,316 p=57437 u=master n=ansible | skipping: [sm02] => 
  false_condition: inventory_hostname in groups['slurm_master']
2025-07-23 09:02:18,316 p=57437 u=master n=ansible | skipping: [cn01] => 
  false_condition: inventory_hostname in groups['slurm_master']
2025-07-23 09:02:18,324 p=57437 u=master n=ansible | skipping: [cn02] => 
  false_condition: inventory_hostname in groups['slurm_master']
2025-07-23 09:02:18,327 p=57437 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере] ******************************************************************************************************
2025-07-23 09:02:18,328 p=57437 u=master n=ansible | Wednesday 23 July 2025  09:02:18 +0000 (0:00:00.048)       0:00:01.879 ******** 
2025-07-23 09:02:18,362 p=57437 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:18,364 p=57437 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:18,372 p=57437 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:18,603 p=57437 u=master n=ansible | ok: [sm01] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /sw
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:02:18,607 p=57437 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для распространения] **************************************************************************************************
2025-07-23 09:02:18,608 p=57437 u=master n=ansible | Wednesday 23 July 2025  09:02:18 +0000 (0:00:00.280)       0:00:02.159 ******** 
2025-07-23 09:02:18,645 p=57437 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:18,647 p=57437 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:18,655 p=57437 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:18,876 p=57437 u=master n=ansible | changed: [sm01] => changed=true 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /sw/slurm-dist
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:02:18,880 p=57437 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS] ***********************************************************************************************************
2025-07-23 09:02:18,880 p=57437 u=master n=ansible | Wednesday 23 July 2025  09:02:18 +0000 (0:00:00.272)       0:00:02.432 ******** 
2025-07-23 09:02:18,915 p=57437 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:18,916 p=57437 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:18,925 p=57437 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:19,154 p=57437 u=master n=ansible | changed: [sm01] => changed=true 
  cmd: |-
    # Создаем структуру в /sw (исправлены права)
    mkdir -p /sw/slurm-dist/{bin,sbin,lib,share}
    cp -r /opt/slurm/bin/* /sw/slurm-dist/bin/ 2>&1
    cp -r /opt/slurm/sbin/* /sw/slurm-dist/sbin/ 2>&1
    cp -r /opt/slurm/lib/* /sw/slurm-dist/lib/ 2>&1
    cp -r /opt/slurm/share/* /sw/slurm-dist/share/ 2>&1
  
    # Проверяем результат
    ls -la /sw/slurm-dist/bin/sinfo
    echo "Копирование в /sw/slurm-dist завершено"
  delta: '0:00:00.012922'
  end: '2025-07-23 12:02:19.157877'
  msg: ''
  rc: 0
  start: '2025-07-23 12:02:19.144955'
  stderr: 'ls: cannot access ''/sw/slurm-dist/bin/sinfo'': No such file or directory'
  stderr_lines: <omitted>
  stdout: |-
    cp: target '/sw/slurm-dist/bin/': No such file or directory
    cp: target '/sw/slurm-dist/sbin/': No such file or directory
    cp: target '/sw/slurm-dist/lib/': No such file or directory
    cp: target '/sw/slurm-dist/share/': No such file or directory
    Копирование в /sw/slurm-dist завершено
  stdout_lines: <omitted>
2025-07-23 09:02:19,158 p=57437 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:02:19,159 p=57437 u=master n=ansible | Wednesday 23 July 2025  09:02:19 +0000 (0:00:00.278)       0:00:02.710 ******** 
2025-07-23 09:02:19,184 p=57437 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:49,582 p=57437 u=master n=ansible | fatal: [sm02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:02:49,590 p=57437 u=master n=ansible | fatal: [cn02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:02:49,592 p=57437 u=master n=ansible | fatal: [cn01]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:02:49,597 p=57437 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:02:49,597 p=57437 u=master n=ansible | Wednesday 23 July 2025  09:02:49 +0000 (0:00:30.438)       0:00:33.149 ******** 
2025-07-23 09:02:49,619 p=57437 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:49,624 p=57437 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:02:49,624 p=57437 u=master n=ansible | Wednesday 23 July 2025  09:02:49 +0000 (0:00:00.026)       0:00:33.176 ******** 
2025-07-23 09:02:49,896 p=57437 u=master n=ansible | changed: [sm01] => changed=true 
  path: /sw/slurm-dist
  state: absent
2025-07-23 09:02:49,900 p=57437 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:02:49,900 p=57437 u=master n=ansible | Wednesday 23 July 2025  09:02:49 +0000 (0:00:00.276)       0:00:33.452 ******** 
2025-07-23 09:02:49,918 p=57437 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:49,922 p=57437 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:02:49,922 p=57437 u=master n=ansible | Wednesday 23 July 2025  09:02:49 +0000 (0:00:00.022)       0:00:33.474 ******** 
2025-07-23 09:02:49,939 p=57437 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:02:49,943 p=57437 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:02:49,943 p=57437 u=master n=ansible | Wednesday 23 July 2025  09:02:49 +0000 (0:00:00.020)       0:00:33.495 ******** 
2025-07-23 09:02:50,204 p=57437 u=master n=ansible | ok: [sm01] => changed=false 
  path: /sw/slurm-dist
  state: absent
2025-07-23 09:02:50,216 p=57437 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 09:02:50,217 p=57437 u=master n=ansible | cn01                       : ok=1    changed=0    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-07-23 09:02:50,217 p=57437 u=master n=ansible | cn02                       : ok=1    changed=0    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-07-23 09:02:50,217 p=57437 u=master n=ansible | sm01                       : ok=8    changed=4    unreachable=0    failed=0    skipped=4    rescued=0    ignored=0   
2025-07-23 09:02:50,217 p=57437 u=master n=ansible | sm02                       : ok=1    changed=0    unreachable=0    failed=1    skipped=5    rescued=0    ignored=0   
2025-07-23 09:02:50,217 p=57437 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 33 seconds
2025-07-23 09:02:50,217 p=57437 u=master n=ansible | Wednesday 23 July 2025  09:02:50 +0000 (0:00:00.274)       0:00:33.769 ******** 
2025-07-23 09:02:50,217 p=57437 u=master n=ansible | =============================================================================== 
2025-07-23 09:02:50,218 p=57437 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------ 30.44s
2025-07-23 09:02:50,218 p=57437 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------------------ 1.39s
2025-07-23 09:02:50,218 p=57437 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master --------------------------------------------------------------------------------------------------------- 0.39s
2025-07-23 09:02:50,218 p=57437 u=master n=ansible | slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере ------------------------------------------------------------------------------------------------------ 0.28s
2025-07-23 09:02:50,218 p=57437 u=master n=ansible | slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS ----------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:02:50,218 p=57437 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:02:50,218 p=57437 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 09:02:50,218 p=57437 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание временной директории для распространения -------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 09:02:50,218 p=57437 u=master n=ansible | slurm_build : [SLURM_BUILD] Размер установки Slurm ----------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:02:50,218 p=57437 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:02:50,219 p=57437 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:02:50,219 p=57437 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:04:30,452 p=57610 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:04:30,452 p=57610 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:04:31,806 p=57610 u=master n=ansible | sm01 | CHANGED | rc=0 >>
total 8
drwxr-xr-x  2 root root 4096 Jul 23 12:02 .
drwxr-xr-x 25 root root 4096 Jul 22 16:41 ..
-rw-r--r--  1 root root    0 Jul 23 11:57 test

2025-07-23 09:05:03,495 p=57679 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:05:03,768 p=57679 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:05:04,413 p=57679 u=master n=ansible | sm01 | CHANGED | rc=0 >>
total 11948
drwxr-xr-x 2 root root    4096 Jul 22 18:28 .
drwxr-xr-x 7 root root    4096 Jul 22 18:28 ..
-rwxr-xr-x 1 root root  452744 Jul 22 18:28 sacct
-rwxr-xr-x 1 root root 1370760 Jul 22 18:28 sacctmgr
-rwxr-xr-x 1 root root  415328 Jul 22 18:28 salloc
-rwxr-xr-x 1 root root  325056 Jul 22 18:28 sattach
-rwxr-xr-x 1 root root  457816 Jul 22 18:28 sbatch
-rwxr-xr-x 1 root root  318048 Jul 22 18:28 sbcast
-rwxr-xr-x 1 root root  353088 Jul 22 18:28 scancel
-rwxr-xr-x 1 root root  877576 Jul 22 18:28 scontrol
-rwxr-xr-x 1 root root  342720 Jul 22 18:28 scrontab
-rwxr-xr-x 1 root root  885008 Jul 22 18:28 scrun
-rwxr-xr-x 1 root root  290200 Jul 22 18:28 sdiag
-rwxr-xr-x 1 root root  536432 Jul 22 18:28 sinfo
-rwxr-xr-x 1 root root  366136 Jul 22 18:28 sprio
-rwxr-xr-x 1 root root  699008 Jul 22 18:28 squeue
-rwxr-xr-x 1 root root  508952 Jul 22 18:28 sreport
-rwxr-xr-x 1 root root  908328 Jul 22 18:28 srun
-rwxr-xr-x 1 root root  312408 Jul 22 18:28 sshare
-rwxr-xr-x 1 root root  328920 Jul 22 18:28 sstat
-rwxr-xr-x 1 root root  275904 Jul 22 18:28 strigger
-rwxr-xr-x 1 root root 2160536 Jul 22 18:28 sview

2025-07-23 09:06:06,162 p=57713 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:06:06,162 p=57713 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:06:07,500 p=57713 u=master n=ansible | sm01 | CHANGED | rc=0 >>
total 28
drwxr-xr-x 7 root root 4096 Jul 22 18:28 .
drwxr-xr-x 3 root root 4096 Jul 22 18:27 ..
drwxr-xr-x 2 root root 4096 Jul 22 18:28 bin
drwxr-xr-x 3 root root 4096 Jul 22 18:28 include
drwxr-xr-x 3 root root 4096 Jul 22 18:27 lib
drwxr-xr-x 2 root root 4096 Jul 22 18:28 sbin
drwxr-xr-x 4 root root 4096 Jul 22 18:28 share

2025-07-23 09:07:29,135 p=57810 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:07:29,136 p=57810 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:07:30,488 p=57810 u=master n=ansible | sm01 | CHANGED | rc=0 >>
-rwxr-xr-x 1 root root 6377 Jul 23 11:32 /tmp/slurm-build/slurm-25.05.1/src/slurmctld/slurmctld

2025-07-23 09:08:09,449 p=57851 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:08:09,449 p=57851 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:08:10,076 p=57851 u=master n=ansible | sm01 | CHANGED | rc=0 >>
-rwxr-xr-x 1 root root 536432 Jul 22 18:28 /opt/slurm/bin/sinfo

2025-07-23 09:09:00,702 p=57900 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:09:00,702 p=57900 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:09:01,341 p=57900 u=master n=ansible | sm01 | CHANGED | rc=0 >>
total 532
drwxr-xr-x 2 root root   4096 Jul 23 12:09 .
drwxr-xr-x 3 root root   4096 Jul 23 12:09 ..
-rwxr-xr-x 1 root root 536432 Jul 23 12:09 sinfo

2025-07-23 09:11:05,964 p=57962 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:11:05,964 p=57962 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:11:07,321 p=57962 u=master n=ansible | cn02 | CHANGED | rc=0 >>
-rwxr-xr-x 1 root root 536432 Jul 23 12:09 /sw/slurm-dist/bin/sinfo

2025-07-23 09:11:07,523 p=57962 u=master n=ansible | cn01 | CHANGED | rc=0 >>
-rwxr-xr-x 1 root root 536432 Jul 23 12:09 /sw/slurm-dist/bin/sinfo

2025-07-23 09:11:07,527 p=57962 u=master n=ansible | sm02 | CHANGED | rc=0 >>
-rwxr-xr-x 1 root root 536432 Jul 23 12:09 /sw/slurm-dist/bin/sinfo

2025-07-23 09:11:36,984 p=58046 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:11:36,984 p=58046 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:11:37,462 p=58046 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 09:11:37,502 p=58046 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] ************************************************************************************************************
2025-07-23 09:11:37,502 p=58046 u=master n=ansible | Wednesday 23 July 2025  09:11:37 +0000 (0:00:00.043)       0:00:00.043 ******** 
2025-07-23 09:11:37,905 p=58046 u=master n=ansible | ok: [sm02]
2025-07-23 09:11:37,906 p=58046 u=master n=ansible | ok: [cn02]
2025-07-23 09:11:37,908 p=58046 u=master n=ansible | ok: [cn01]
2025-07-23 09:11:37,912 p=58046 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] *********************************************************************************************************
2025-07-23 09:11:37,912 p=58046 u=master n=ansible | Wednesday 23 July 2025  09:11:37 +0000 (0:00:00.409)       0:00:00.452 ******** 
2025-07-23 09:11:37,936 p=58046 u=master n=ansible | skipping: [sm02]
2025-07-23 09:11:37,937 p=58046 u=master n=ansible | skipping: [cn01]
2025-07-23 09:11:37,945 p=58046 u=master n=ansible | skipping: [cn02]
2025-07-23 09:11:37,949 p=58046 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] *****************************************************************************************************************************
2025-07-23 09:11:37,949 p=58046 u=master n=ansible | Wednesday 23 July 2025  09:11:37 +0000 (0:00:00.037)       0:00:00.490 ******** 
2025-07-23 09:11:37,973 p=58046 u=master n=ansible | skipping: [sm02]
2025-07-23 09:11:37,975 p=58046 u=master n=ansible | skipping: [cn01]
2025-07-23 09:11:37,983 p=58046 u=master n=ansible | skipping: [cn02]
2025-07-23 09:11:37,987 p=58046 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере] ******************************************************************************************************
2025-07-23 09:11:37,987 p=58046 u=master n=ansible | Wednesday 23 July 2025  09:11:37 +0000 (0:00:00.037)       0:00:00.527 ******** 
2025-07-23 09:11:38,013 p=58046 u=master n=ansible | skipping: [sm02]
2025-07-23 09:11:38,015 p=58046 u=master n=ansible | skipping: [cn01]
2025-07-23 09:11:38,023 p=58046 u=master n=ansible | skipping: [cn02]
2025-07-23 09:11:38,027 p=58046 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для распространения] **************************************************************************************************
2025-07-23 09:11:38,028 p=58046 u=master n=ansible | Wednesday 23 July 2025  09:11:38 +0000 (0:00:00.040)       0:00:00.568 ******** 
2025-07-23 09:11:38,053 p=58046 u=master n=ansible | skipping: [sm02]
2025-07-23 09:11:38,055 p=58046 u=master n=ansible | skipping: [cn01]
2025-07-23 09:11:38,064 p=58046 u=master n=ansible | skipping: [cn02]
2025-07-23 09:11:38,068 p=58046 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS] ***********************************************************************************************************
2025-07-23 09:11:38,069 p=58046 u=master n=ansible | Wednesday 23 July 2025  09:11:38 +0000 (0:00:00.040)       0:00:00.609 ******** 
2025-07-23 09:11:38,094 p=58046 u=master n=ansible | skipping: [sm02]
2025-07-23 09:11:38,096 p=58046 u=master n=ansible | skipping: [cn01]
2025-07-23 09:11:38,105 p=58046 u=master n=ansible | skipping: [cn02]
2025-07-23 09:11:38,109 p=58046 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:11:38,109 p=58046 u=master n=ansible | Wednesday 23 July 2025  09:11:38 +0000 (0:00:00.040)       0:00:00.649 ******** 
2025-07-23 09:11:38,488 p=58046 u=master n=ansible | ok: [cn02]
2025-07-23 09:11:38,494 p=58046 u=master n=ansible | ok: [sm02]
2025-07-23 09:11:38,495 p=58046 u=master n=ansible | ok: [cn01]
2025-07-23 09:11:38,499 p=58046 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:11:38,499 p=58046 u=master n=ansible | Wednesday 23 July 2025  09:11:38 +0000 (0:00:00.389)       0:00:01.039 ******** 
2025-07-23 09:11:38,886 p=58046 u=master n=ansible | changed: [cn02]
2025-07-23 09:11:38,887 p=58046 u=master n=ansible | changed: [sm02]
2025-07-23 09:11:38,893 p=58046 u=master n=ansible | changed: [cn01]
2025-07-23 09:11:38,897 p=58046 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:11:38,897 p=58046 u=master n=ansible | Wednesday 23 July 2025  09:11:38 +0000 (0:00:00.397)       0:00:01.437 ******** 
2025-07-23 09:11:38,921 p=58046 u=master n=ansible | skipping: [sm02]
2025-07-23 09:11:38,924 p=58046 u=master n=ansible | skipping: [cn01]
2025-07-23 09:11:38,932 p=58046 u=master n=ansible | skipping: [cn02]
2025-07-23 09:11:38,935 p=58046 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:11:38,936 p=58046 u=master n=ansible | Wednesday 23 July 2025  09:11:38 +0000 (0:00:00.038)       0:00:01.476 ******** 
2025-07-23 09:11:39,199 p=58046 u=master n=ansible | ok: [sm02]
2025-07-23 09:11:39,211 p=58046 u=master n=ansible | ok: [cn01]
2025-07-23 09:11:39,217 p=58046 u=master n=ansible | ok: [cn02]
2025-07-23 09:11:39,221 p=58046 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:11:39,221 p=58046 u=master n=ansible | Wednesday 23 July 2025  09:11:39 +0000 (0:00:00.285)       0:00:01.761 ******** 
2025-07-23 09:11:39,493 p=58046 u=master n=ansible | fatal: [sm02]: FAILED! => changed=true 
  cmd: |-
    cp -r /sw/slurm-dist/* /opt/slurm/ || true
    chown -R root:root /opt/slurm
    chmod -R 755 /opt/slurm/bin /opt/slurm/sbin
  delta: '0:00:00.009214'
  end: '2025-07-23 12:11:39.461851'
  msg: non-zero return code
  rc: 1
  start: '2025-07-23 12:11:39.452637'
  stderr: 'chmod: cannot access ''/opt/slurm/sbin'': No such file or directory'
  stderr_lines: <omitted>
  stdout: ''
  stdout_lines: <omitted>
2025-07-23 09:11:39,511 p=58046 u=master n=ansible | fatal: [cn01]: FAILED! => changed=true 
  cmd: |-
    cp -r /sw/slurm-dist/* /opt/slurm/ || true
    chown -R root:root /opt/slurm
    chmod -R 755 /opt/slurm/bin /opt/slurm/sbin
  delta: '0:00:00.009518'
  end: '2025-07-23 12:11:39.479474'
  msg: non-zero return code
  rc: 1
  start: '2025-07-23 12:11:39.469956'
  stderr: 'chmod: cannot access ''/opt/slurm/sbin'': No such file or directory'
  stderr_lines: <omitted>
  stdout: ''
  stdout_lines: <omitted>
2025-07-23 09:11:39,512 p=58046 u=master n=ansible | fatal: [cn02]: FAILED! => changed=true 
  cmd: |-
    cp -r /sw/slurm-dist/* /opt/slurm/ || true
    chown -R root:root /opt/slurm
    chmod -R 755 /opt/slurm/bin /opt/slurm/sbin
  delta: '0:00:00.009034'
  end: '2025-07-23 12:11:39.487448'
  msg: non-zero return code
  rc: 1
  start: '2025-07-23 12:11:39.478414'
  stderr: 'chmod: cannot access ''/opt/slurm/sbin'': No such file or directory'
  stderr_lines: <omitted>
  stdout: ''
  stdout_lines: <omitted>
2025-07-23 09:11:39,513 p=58046 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 09:11:39,513 p=58046 u=master n=ansible | cn01                       : ok=4    changed=1    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:11:39,513 p=58046 u=master n=ansible | cn02                       : ok=4    changed=1    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:11:39,514 p=58046 u=master n=ansible | sm02                       : ok=4    changed=1    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:11:39,514 p=58046 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 2 seconds
2025-07-23 09:11:39,514 p=58046 u=master n=ansible | Wednesday 23 July 2025  09:11:39 +0000 (0:00:00.293)       0:00:02.054 ******** 
2025-07-23 09:11:39,514 p=58046 u=master n=ansible | =============================================================================== 
2025-07-23 09:11:39,514 p=58046 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------------------ 0.41s
2025-07-23 09:11:39,514 p=58046 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.40s
2025-07-23 09:11:39,514 p=58046 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.39s
2025-07-23 09:11:39,514 p=58046 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.29s
2025-07-23 09:11:39,515 p=58046 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.29s
2025-07-23 09:11:39,515 p=58046 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание временной директории для распространения -------------------------------------------------------------------------------------------------- 0.04s
2025-07-23 09:11:39,515 p=58046 u=master n=ansible | slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере ------------------------------------------------------------------------------------------------------ 0.04s
2025-07-23 09:11:39,515 p=58046 u=master n=ansible | slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS ----------------------------------------------------------------------------------------------------------- 0.04s
2025-07-23 09:11:39,515 p=58046 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.04s
2025-07-23 09:11:39,515 p=58046 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master --------------------------------------------------------------------------------------------------------- 0.04s
2025-07-23 09:11:39,515 p=58046 u=master n=ansible | slurm_build : [SLURM_BUILD] Размер установки Slurm ----------------------------------------------------------------------------------------------------------------------------- 0.04s
2025-07-23 09:13:36,191 p=58141 u=master n=ansible | Using /home/master/22Jul/slurm-hpc-cluster/ansible.cfg as config file
2025-07-23 09:13:36,191 p=58141 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:13:36,191 p=58141 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:13:36,647 p=58141 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 09:13:36,972 p=58141 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] ************************************************************************************************************
2025-07-23 09:13:36,972 p=58141 u=master n=ansible | Wednesday 23 July 2025  09:13:36 +0000 (0:00:00.328)       0:00:00.328 ******** 
2025-07-23 09:13:38,080 p=58141 u=master n=ansible | ok: [cn02] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:13:38,124 p=58141 u=master n=ansible | ok: [sm01] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:13:38,296 p=58141 u=master n=ansible | ok: [cn01] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:13:38,414 p=58141 u=master n=ansible | ok: [sm02] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:13:38,418 p=58141 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] *********************************************************************************************************
2025-07-23 09:13:38,418 p=58141 u=master n=ansible | Wednesday 23 July 2025  09:13:38 +0000 (0:00:01.446)       0:00:01.774 ******** 
2025-07-23 09:13:38,452 p=58141 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:38,455 p=58141 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:38,462 p=58141 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:38,816 p=58141 u=master n=ansible | changed: [sm01] => changed=true 
  cmd: du -sh /opt/slurm
  delta: '0:00:00.005999'
  end: '2025-07-23 12:13:38.830360'
  msg: ''
  rc: 0
  start: '2025-07-23 12:13:38.824361'
  stderr: ''
  stderr_lines: <omitted>
  stdout: "483M\t/opt/slurm"
  stdout_lines: <omitted>
2025-07-23 09:13:38,820 p=58141 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] *****************************************************************************************************************************
2025-07-23 09:13:38,820 p=58141 u=master n=ansible | Wednesday 23 July 2025  09:13:38 +0000 (0:00:00.401)       0:00:02.176 ******** 
2025-07-23 09:13:38,855 p=58141 u=master n=ansible | ok: [sm01] => 
  msg: "Размер установки Slurm на sm01: 483M\t/opt/slurm"
2025-07-23 09:13:38,856 p=58141 u=master n=ansible | skipping: [sm02] => 
  false_condition: inventory_hostname in groups['slurm_master']
2025-07-23 09:13:38,857 p=58141 u=master n=ansible | skipping: [cn01] => 
  false_condition: inventory_hostname in groups['slurm_master']
2025-07-23 09:13:38,865 p=58141 u=master n=ansible | skipping: [cn02] => 
  false_condition: inventory_hostname in groups['slurm_master']
2025-07-23 09:13:38,869 p=58141 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере] ******************************************************************************************************
2025-07-23 09:13:38,869 p=58141 u=master n=ansible | Wednesday 23 July 2025  09:13:38 +0000 (0:00:00.048)       0:00:02.224 ******** 
2025-07-23 09:13:38,905 p=58141 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:38,906 p=58141 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:38,915 p=58141 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:39,135 p=58141 u=master n=ansible | ok: [sm01] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /sw
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:13:39,140 p=58141 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для распространения] **************************************************************************************************
2025-07-23 09:13:39,140 p=58141 u=master n=ansible | Wednesday 23 July 2025  09:13:39 +0000 (0:00:00.270)       0:00:02.495 ******** 
2025-07-23 09:13:39,179 p=58141 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:39,181 p=58141 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:39,191 p=58141 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:39,405 p=58141 u=master n=ansible | ok: [sm01] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /sw/slurm-dist
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:13:39,409 p=58141 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS] ***********************************************************************************************************
2025-07-23 09:13:39,409 p=58141 u=master n=ansible | Wednesday 23 July 2025  09:13:39 +0000 (0:00:00.269)       0:00:02.765 ******** 
2025-07-23 09:13:39,451 p=58141 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:39,452 p=58141 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:39,463 p=58141 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:39,694 p=58141 u=master n=ansible | changed: [sm01] => changed=true 
  cmd: |-
    # Создаем структуру в /sw (исправлены права)
    mkdir -p /sw/slurm-dist/{bin,sbin,lib,share}
    cp -r /opt/slurm/bin/* /sw/slurm-dist/bin/ 2>&1
    cp -r /opt/slurm/sbin/* /sw/slurm-dist/sbin/ 2>&1
    cp -r /opt/slurm/lib/* /sw/slurm-dist/lib/ 2>&1
    cp -r /opt/slurm/share/* /sw/slurm-dist/share/ 2>&1
  
    # Проверяем результат
    ls -la /sw/slurm-dist/bin/sinfo
    echo "Копирование в /sw/slurm-dist завершено"
  delta: '0:00:00.020193'
  end: '2025-07-23 12:13:39.705883'
  msg: ''
  rc: 0
  start: '2025-07-23 12:13:39.685690'
  stderr: ''
  stderr_lines: <omitted>
  stdout: |-
    cp: target '/sw/slurm-dist/sbin/': No such file or directory
    cp: target '/sw/slurm-dist/lib/': No such file or directory
    cp: target '/sw/slurm-dist/share/': No such file or directory
    -rwxr-xr-x 1 root root 536432 Jul 23 12:13 /sw/slurm-dist/bin/sinfo
    Копирование в /sw/slurm-dist завершено
  stdout_lines: <omitted>
2025-07-23 09:13:39,699 p=58141 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:13:39,699 p=58141 u=master n=ansible | Wednesday 23 July 2025  09:13:39 +0000 (0:00:00.289)       0:00:03.054 ******** 
2025-07-23 09:13:39,724 p=58141 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:40,101 p=58141 u=master n=ansible | ok: [sm02] => changed=false 
  elapsed: 0
  gid: 0
  group: root
  match_groupdict: {}
  match_groups: []
  mode: '0755'
  owner: root
  path: /sw/slurm-dist/bin/sinfo
  port: null
  search_regex: null
  size: 536432
  state: file
  uid: 0
2025-07-23 09:13:40,104 p=58141 u=master n=ansible | ok: [cn02] => changed=false 
  elapsed: 0
  gid: 0
  group: root
  match_groupdict: {}
  match_groups: []
  mode: '0755'
  owner: root
  path: /sw/slurm-dist/bin/sinfo
  port: null
  search_regex: null
  size: 536432
  state: file
  uid: 0
2025-07-23 09:13:40,104 p=58141 u=master n=ansible | ok: [cn01] => changed=false 
  elapsed: 0
  gid: 0
  group: root
  match_groupdict: {}
  match_groups: []
  mode: '0755'
  owner: root
  path: /sw/slurm-dist/bin/sinfo
  port: null
  search_regex: null
  size: 536432
  state: file
  uid: 0
2025-07-23 09:13:40,108 p=58141 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:13:40,108 p=58141 u=master n=ansible | Wednesday 23 July 2025  09:13:40 +0000 (0:00:00.409)       0:00:03.464 ******** 
2025-07-23 09:13:40,133 p=58141 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:40,430 p=58141 u=master n=ansible | changed: [sm02] => changed=true 
  cmd: |-
    cp -r /sw/slurm-dist/* /opt/slurm/
    chown -R root:root /opt/slurm
    chmod -R 755 /opt/slurm/bin /opt/slurm/sbin
    echo "Установка Slurm на sm02 завершена"
  delta: '0:00:00.049634'
  end: '2025-07-23 12:13:40.395270'
  msg: ''
  rc: 0
  start: '2025-07-23 12:13:40.345636'
  stderr: 'chmod: cannot access ''/opt/slurm/sbin'': No such file or directory'
  stderr_lines: <omitted>
  stdout: Установка Slurm на sm02 завершена
  stdout_lines: <omitted>
2025-07-23 09:13:40,444 p=58141 u=master n=ansible | changed: [cn01] => changed=true 
  cmd: |-
    cp -r /sw/slurm-dist/* /opt/slurm/
    chown -R root:root /opt/slurm
    chmod -R 755 /opt/slurm/bin /opt/slurm/sbin
    echo "Установка Slurm на cn01 завершена"
  delta: '0:00:00.049435'
  end: '2025-07-23 12:13:40.411654'
  msg: ''
  rc: 0
  start: '2025-07-23 12:13:40.362219'
  stderr: 'chmod: cannot access ''/opt/slurm/sbin'': No such file or directory'
  stderr_lines: <omitted>
  stdout: Установка Slurm на cn01 завершена
  stdout_lines: <omitted>
2025-07-23 09:13:40,445 p=58141 u=master n=ansible | changed: [cn02] => changed=true 
  cmd: |-
    cp -r /sw/slurm-dist/* /opt/slurm/
    chown -R root:root /opt/slurm
    chmod -R 755 /opt/slurm/bin /opt/slurm/sbin
    echo "Установка Slurm на cn02 завершена"
  delta: '0:00:00.047827'
  end: '2025-07-23 12:13:40.418231'
  msg: ''
  rc: 0
  start: '2025-07-23 12:13:40.370404'
  stderr: 'chmod: cannot access ''/opt/slurm/sbin'': No such file or directory'
  stderr_lines: <omitted>
  stdout: Установка Slurm на cn02 завершена
  stdout_lines: <omitted>
2025-07-23 09:13:40,449 p=58141 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:13:40,450 p=58141 u=master n=ansible | Wednesday 23 July 2025  09:13:40 +0000 (0:00:00.341)       0:00:03.805 ******** 
2025-07-23 09:13:40,492 p=58141 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:40,493 p=58141 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:40,505 p=58141 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:13:40,745 p=58141 u=master n=ansible | changed: [sm01] => changed=true 
  path: /sw/slurm-dist
  state: absent
2025-07-23 09:13:40,749 p=58141 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:13:40,750 p=58141 u=master n=ansible | Wednesday 23 July 2025  09:13:40 +0000 (0:00:00.299)       0:00:04.105 ******** 
2025-07-23 09:13:40,783 p=58141 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:14:11,042 p=58141 u=master n=ansible | fatal: [sm02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:14:11,064 p=58141 u=master n=ansible | fatal: [cn01]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:14:11,073 p=58141 u=master n=ansible | fatal: [cn02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:14:11,078 p=58141 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:14:11,078 p=58141 u=master n=ansible | Wednesday 23 July 2025  09:14:11 +0000 (0:00:30.328)       0:00:34.433 ******** 
2025-07-23 09:14:11,100 p=58141 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:14:11,104 p=58141 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:14:11,104 p=58141 u=master n=ansible | Wednesday 23 July 2025  09:14:11 +0000 (0:00:00.026)       0:00:34.460 ******** 
2025-07-23 09:14:11,376 p=58141 u=master n=ansible | ok: [sm01] => changed=false 
  path: /sw/slurm-dist
  state: absent
2025-07-23 09:14:11,389 p=58141 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 09:14:11,389 p=58141 u=master n=ansible | cn01                       : ok=3    changed=1    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:14:11,389 p=58141 u=master n=ansible | cn02                       : ok=3    changed=1    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:14:11,389 p=58141 u=master n=ansible | sm01                       : ok=8    changed=3    unreachable=0    failed=0    skipped=4    rescued=0    ignored=0   
2025-07-23 09:14:11,390 p=58141 u=master n=ansible | sm02                       : ok=3    changed=1    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:14:11,390 p=58141 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 34 seconds
2025-07-23 09:14:11,390 p=58141 u=master n=ansible | Wednesday 23 July 2025  09:14:11 +0000 (0:00:00.285)       0:00:34.745 ******** 
2025-07-23 09:14:11,390 p=58141 u=master n=ansible | =============================================================================== 
2025-07-23 09:14:11,390 p=58141 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------ 30.33s
2025-07-23 09:14:11,390 p=58141 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------------------ 1.45s
2025-07-23 09:14:11,390 p=58141 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.41s
2025-07-23 09:14:11,390 p=58141 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master --------------------------------------------------------------------------------------------------------- 0.40s
2025-07-23 09:14:11,390 p=58141 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.34s
2025-07-23 09:14:11,391 p=58141 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-23 09:14:11,391 p=58141 u=master n=ansible | slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS ----------------------------------------------------------------------------------------------------------- 0.29s
2025-07-23 09:14:11,391 p=58141 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.29s
2025-07-23 09:14:11,391 p=58141 u=master n=ansible | slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере ------------------------------------------------------------------------------------------------------ 0.27s
2025-07-23 09:14:11,391 p=58141 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание временной директории для распространения -------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 09:14:11,391 p=58141 u=master n=ansible | slurm_build : [SLURM_BUILD] Размер установки Slurm ----------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:14:11,391 p=58141 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:21:40,295 p=58366 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:21:40,295 p=58366 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:21:41,690 p=58366 u=master n=ansible | sm01 | CHANGED | rc=0 >>


2025-07-23 09:21:59,097 p=58419 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:21:59,097 p=58419 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:21:59,550 p=58419 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 09:21:59,595 p=58419 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] ************************************************************************************************************
2025-07-23 09:21:59,595 p=58419 u=master n=ansible | Wednesday 23 July 2025  09:21:59 +0000 (0:00:00.048)       0:00:00.048 ******** 
2025-07-23 09:22:00,005 p=58419 u=master n=ansible | ok: [sm01]
2025-07-23 09:22:00,796 p=58419 u=master n=ansible | ok: [cn02]
2025-07-23 09:22:00,887 p=58419 u=master n=ansible | ok: [sm02]
2025-07-23 09:22:00,916 p=58419 u=master n=ansible | ok: [cn01]
2025-07-23 09:22:00,920 p=58419 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] *********************************************************************************************************
2025-07-23 09:22:00,920 p=58419 u=master n=ansible | Wednesday 23 July 2025  09:22:00 +0000 (0:00:01.324)       0:00:01.373 ******** 
2025-07-23 09:22:00,953 p=58419 u=master n=ansible | skipping: [sm02]
2025-07-23 09:22:00,955 p=58419 u=master n=ansible | skipping: [cn01]
2025-07-23 09:22:00,963 p=58419 u=master n=ansible | skipping: [cn02]
2025-07-23 09:22:01,310 p=58419 u=master n=ansible | changed: [sm01]
2025-07-23 09:22:01,315 p=58419 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] *****************************************************************************************************************************
2025-07-23 09:22:01,315 p=58419 u=master n=ansible | Wednesday 23 July 2025  09:22:01 +0000 (0:00:00.394)       0:00:01.767 ******** 
2025-07-23 09:22:01,347 p=58419 u=master n=ansible | ok: [sm01] => 
  msg: "Размер установки Slurm на sm01: 483M\t/opt/slurm"
2025-07-23 09:22:01,349 p=58419 u=master n=ansible | skipping: [sm02]
2025-07-23 09:22:01,349 p=58419 u=master n=ansible | skipping: [cn01]
2025-07-23 09:22:01,357 p=58419 u=master n=ansible | skipping: [cn02]
2025-07-23 09:22:01,361 p=58419 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере] ******************************************************************************************************
2025-07-23 09:22:01,361 p=58419 u=master n=ansible | Wednesday 23 July 2025  09:22:01 +0000 (0:00:00.046)       0:00:01.814 ******** 
2025-07-23 09:22:01,393 p=58419 u=master n=ansible | skipping: [sm02]
2025-07-23 09:22:01,395 p=58419 u=master n=ansible | skipping: [cn01]
2025-07-23 09:22:01,404 p=58419 u=master n=ansible | skipping: [cn02]
2025-07-23 09:22:01,631 p=58419 u=master n=ansible | ok: [sm01]
2025-07-23 09:22:01,636 p=58419 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для распространения] **************************************************************************************************
2025-07-23 09:22:01,636 p=58419 u=master n=ansible | Wednesday 23 July 2025  09:22:01 +0000 (0:00:00.274)       0:00:02.089 ******** 
2025-07-23 09:22:01,672 p=58419 u=master n=ansible | skipping: [sm02]
2025-07-23 09:22:01,673 p=58419 u=master n=ansible | skipping: [cn01]
2025-07-23 09:22:01,682 p=58419 u=master n=ansible | skipping: [cn02]
2025-07-23 09:22:01,902 p=58419 u=master n=ansible | changed: [sm01]
2025-07-23 09:22:01,906 p=58419 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS] ***********************************************************************************************************
2025-07-23 09:22:01,907 p=58419 u=master n=ansible | Wednesday 23 July 2025  09:22:01 +0000 (0:00:00.270)       0:00:02.359 ******** 
2025-07-23 09:22:01,939 p=58419 u=master n=ansible | skipping: [sm02]
2025-07-23 09:22:01,941 p=58419 u=master n=ansible | skipping: [cn01]
2025-07-23 09:22:01,951 p=58419 u=master n=ansible | skipping: [cn02]
2025-07-23 09:22:02,205 p=58419 u=master n=ansible | changed: [sm01]
2025-07-23 09:22:02,224 p=58419 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат копирования на master] ********************************************************************************************************************
2025-07-23 09:22:02,224 p=58419 u=master n=ansible | Wednesday 23 July 2025  09:22:02 +0000 (0:00:00.317)       0:00:02.677 ******** 
2025-07-23 09:22:02,260 p=58419 u=master n=ansible | ok: [sm01] => 
  copy_result.stdout_lines:
  - Скопировано 20 файлов из bin/
  - Скопировано 6 файлов из sbin/
  - Скопировано lib/
  - Скопировано share/
  - === Результат копирования ===
  - total 12
  - drwxr-xr-x 3 root root 4096 Jul 23 12:22 .
  - drwxr-xr-x 3 root root 4096 Jul 23 12:22 ..
  - drwxr-xr-x 2 root root 4096 Jul 23 12:22 {bin,sbin,lib,share}
  - 'Файлов в bin/: 0'
  - 'Файлов в sbin/: 0'
2025-07-23 09:22:02,260 p=58419 u=master n=ansible | skipping: [sm02]
2025-07-23 09:22:02,261 p=58419 u=master n=ansible | skipping: [cn01]
2025-07-23 09:22:02,269 p=58419 u=master n=ansible | skipping: [cn02]
2025-07-23 09:22:02,272 p=58419 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:22:02,272 p=58419 u=master n=ansible | Wednesday 23 July 2025  09:22:02 +0000 (0:00:00.047)       0:00:02.725 ******** 
2025-07-23 09:22:02,295 p=58419 u=master n=ansible | skipping: [sm01]
2025-07-23 09:22:32,684 p=58419 u=master n=ansible | fatal: [cn02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:22:32,686 p=58419 u=master n=ansible | fatal: [sm02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:22:32,695 p=58419 u=master n=ansible | fatal: [cn01]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:22:32,699 p=58419 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:22:32,699 p=58419 u=master n=ansible | Wednesday 23 July 2025  09:22:32 +0000 (0:00:30.426)       0:00:33.152 ******** 
2025-07-23 09:22:32,721 p=58419 u=master n=ansible | skipping: [sm01]
2025-07-23 09:22:32,725 p=58419 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат установки на узлах] ***********************************************************************************************************************
2025-07-23 09:22:32,726 p=58419 u=master n=ansible | Wednesday 23 July 2025  09:22:32 +0000 (0:00:00.026)       0:00:33.178 ******** 
2025-07-23 09:22:32,745 p=58419 u=master n=ansible | skipping: [sm01]
2025-07-23 09:22:32,750 p=58419 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:22:32,750 p=58419 u=master n=ansible | Wednesday 23 July 2025  09:22:32 +0000 (0:00:00.024)       0:00:33.203 ******** 
2025-07-23 09:22:33,049 p=58419 u=master n=ansible | changed: [sm01]
2025-07-23 09:22:33,054 p=58419 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:22:33,054 p=58419 u=master n=ansible | Wednesday 23 July 2025  09:22:33 +0000 (0:00:00.304)       0:00:33.507 ******** 
2025-07-23 09:22:33,074 p=58419 u=master n=ansible | skipping: [sm01]
2025-07-23 09:22:33,078 p=58419 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:22:33,078 p=58419 u=master n=ansible | Wednesday 23 July 2025  09:22:33 +0000 (0:00:00.023)       0:00:33.531 ******** 
2025-07-23 09:22:33,095 p=58419 u=master n=ansible | skipping: [sm01]
2025-07-23 09:22:33,100 p=58419 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:22:33,100 p=58419 u=master n=ansible | Wednesday 23 July 2025  09:22:33 +0000 (0:00:00.021)       0:00:33.553 ******** 
2025-07-23 09:22:33,369 p=58419 u=master n=ansible | ok: [sm01]
2025-07-23 09:22:33,382 p=58419 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 09:22:33,383 p=58419 u=master n=ansible | cn01                       : ok=1    changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:22:33,383 p=58419 u=master n=ansible | cn02                       : ok=1    changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:22:33,383 p=58419 u=master n=ansible | sm01                       : ok=9    changed=4    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
2025-07-23 09:22:33,383 p=58419 u=master n=ansible | sm02                       : ok=1    changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:22:33,383 p=58419 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 33 seconds
2025-07-23 09:22:33,384 p=58419 u=master n=ansible | Wednesday 23 July 2025  09:22:33 +0000 (0:00:00.283)       0:00:33.836 ******** 
2025-07-23 09:22:33,384 p=58419 u=master n=ansible | =============================================================================== 
2025-07-23 09:22:33,384 p=58419 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------ 30.43s
2025-07-23 09:22:33,384 p=58419 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------------------ 1.32s
2025-07-23 09:22:33,384 p=58419 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master --------------------------------------------------------------------------------------------------------- 0.39s
2025-07-23 09:22:33,384 p=58419 u=master n=ansible | slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS ----------------------------------------------------------------------------------------------------------- 0.32s
2025-07-23 09:22:33,385 p=58419 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-23 09:22:33,385 p=58419 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:22:33,385 p=58419 u=master n=ansible | slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере ------------------------------------------------------------------------------------------------------ 0.27s
2025-07-23 09:22:33,385 p=58419 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание временной директории для распространения -------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 09:22:33,385 p=58419 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат копирования на master -------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:22:33,385 p=58419 u=master n=ansible | slurm_build : [SLURM_BUILD] Размер установки Slurm ----------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:22:33,386 p=58419 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:22:33,386 p=58419 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат установки на узлах ----------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:22:33,386 p=58419 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:22:33,386 p=58419 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:26:23,675 p=58618 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:26:23,676 p=58618 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:26:23,930 p=58618 u=master n=ansible | sm01 | SUCCESS => {
    "group_names": [
        "cluster_nodes",
        "jwt_nodes",
        "nfs_server",
        "slurm_cluster",
        "slurm_master"
    ]
}
2025-07-23 09:27:47,387 p=58663 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:27:47,388 p=58663 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:27:47,527 p=58663 u=master n=ansible |   hosts (1):
2025-07-23 09:27:47,527 p=58663 u=master n=ansible |     sm01
2025-07-23 09:28:24,539 p=58704 u=master n=ansible | Using /home/master/22Jul/slurm-hpc-cluster/ansible.cfg as config file
2025-07-23 09:28:24,539 p=58704 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:28:24,539 p=58704 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:28:25,009 p=58704 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 09:28:25,037 p=58704 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] ************************************************************************************************************
2025-07-23 09:28:25,038 p=58704 u=master n=ansible | Wednesday 23 July 2025  09:28:25 +0000 (0:00:00.031)       0:00:00.031 ******** 
2025-07-23 09:28:26,172 p=58704 u=master n=ansible | ok: [sm01] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:28:26,176 p=58704 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] *********************************************************************************************************
2025-07-23 09:28:26,176 p=58704 u=master n=ansible | Wednesday 23 July 2025  09:28:26 +0000 (0:00:01.138)       0:00:01.170 ******** 
2025-07-23 09:28:26,573 p=58704 u=master n=ansible | changed: [sm01] => changed=true 
  cmd: du -sh /opt/slurm
  delta: '0:00:00.006722'
  end: '2025-07-23 12:28:26.606466'
  msg: ''
  rc: 0
  start: '2025-07-23 12:28:26.599744'
  stderr: ''
  stderr_lines: <omitted>
  stdout: "483M\t/opt/slurm"
  stdout_lines: <omitted>
2025-07-23 09:28:26,578 p=58704 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] *****************************************************************************************************************************
2025-07-23 09:28:26,578 p=58704 u=master n=ansible | Wednesday 23 July 2025  09:28:26 +0000 (0:00:00.401)       0:00:01.571 ******** 
2025-07-23 09:28:26,601 p=58704 u=master n=ansible | ok: [sm01] => 
  msg: "Размер установки Slurm на sm01: 483M\t/opt/slurm"
2025-07-23 09:28:26,605 p=58704 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере] ******************************************************************************************************
2025-07-23 09:28:26,605 p=58704 u=master n=ansible | Wednesday 23 July 2025  09:28:26 +0000 (0:00:00.027)       0:00:01.599 ******** 
2025-07-23 09:28:26,889 p=58704 u=master n=ansible | ok: [sm01] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /sw
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:28:26,893 p=58704 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для распространения] **************************************************************************************************
2025-07-23 09:28:26,893 p=58704 u=master n=ansible | Wednesday 23 July 2025  09:28:26 +0000 (0:00:00.287)       0:00:01.886 ******** 
2025-07-23 09:28:27,175 p=58704 u=master n=ansible | changed: [sm01] => changed=true 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /sw/slurm-dist
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:28:27,180 p=58704 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS] ***********************************************************************************************************
2025-07-23 09:28:27,181 p=58704 u=master n=ansible | Wednesday 23 July 2025  09:28:27 +0000 (0:00:00.287)       0:00:02.174 ******** 
2025-07-23 09:28:27,475 p=58704 u=master n=ansible | changed: [sm01] => changed=true 
  cmd: |-
    # Создаем структуру в /sw
    mkdir -p /sw/slurm-dist/{bin,sbin,lib,share}
  
    # Копируем все директории
    if [ -d "/opt/slurm/bin" ]; then
      cp -r /opt/slurm/bin/* /sw/slurm-dist/bin/
      echo "Скопировано $(ls /opt/slurm/bin | wc -l) файлов из bin/"
    fi
  
    if [ -d "/opt/slurm/sbin" ]; then
      cp -r /opt/slurm/sbin/* /sw/slurm-dist/sbin/
      echo "Скопировано $(ls /opt/slurm/sbin | wc -l) файлов из sbin/"
    fi
  
    if [ -d "/opt/slurm/lib" ]; then
      cp -r /opt/slurm/lib/* /sw/slurm-dist/lib/
      echo "Скопировано lib/"
    fi
  
    if [ -d "/opt/slurm/share" ]; then
      cp -r /opt/slurm/share/* /sw/slurm-dist/share/
      echo "Скопировано share/"
    fi
  
    # Проверяем результат
    echo "=== Результат копирования ==="
    ls -la /sw/slurm-dist/
    echo "Файлов в bin/: $(ls /sw/slurm-dist/bin 2>/dev/null | wc -l)"
    echo "Файлов в sbin/: $(ls /sw/slurm-dist/sbin 2>/dev/null | wc -l)"
  delta: '0:00:00.019113'
  end: '2025-07-23 12:28:27.504143'
  msg: ''
  rc: 0
  start: '2025-07-23 12:28:27.485030'
  stderr: |-
    cp: target '/sw/slurm-dist/bin/': No such file or directory
    cp: target '/sw/slurm-dist/sbin/': No such file or directory
    cp: target '/sw/slurm-dist/lib/': No such file or directory
    cp: target '/sw/slurm-dist/share/': No such file or directory
  stderr_lines: <omitted>
  stdout: |-
    Скопировано 20 файлов из bin/
    Скопировано 6 файлов из sbin/
    Скопировано lib/
    Скопировано share/
    === Результат копирования ===
    total 12
    drwxr-xr-x 3 root root 4096 Jul 23 12:28 .
    drwxr-xr-x 3 root root 4096 Jul 23 12:28 ..
    drwxr-xr-x 2 root root 4096 Jul 23 12:28 {bin,sbin,lib,share}
    Файлов в bin/: 0
    Файлов в sbin/: 0
  stdout_lines: <omitted>
2025-07-23 09:28:27,479 p=58704 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат копирования на master] ********************************************************************************************************************
2025-07-23 09:28:27,479 p=58704 u=master n=ansible | Wednesday 23 July 2025  09:28:27 +0000 (0:00:00.298)       0:00:02.472 ******** 
2025-07-23 09:28:27,504 p=58704 u=master n=ansible | ok: [sm01] => 
  copy_result.stdout_lines:
  - Скопировано 20 файлов из bin/
  - Скопировано 6 файлов из sbin/
  - Скопировано lib/
  - Скопировано share/
  - === Результат копирования ===
  - total 12
  - drwxr-xr-x 3 root root 4096 Jul 23 12:28 .
  - drwxr-xr-x 3 root root 4096 Jul 23 12:28 ..
  - drwxr-xr-x 2 root root 4096 Jul 23 12:28 {bin,sbin,lib,share}
  - 'Файлов в bin/: 0'
  - 'Файлов в sbin/: 0'
2025-07-23 09:28:27,508 p=58704 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:28:27,508 p=58704 u=master n=ansible | Wednesday 23 July 2025  09:28:27 +0000 (0:00:00.029)       0:00:02.501 ******** 
2025-07-23 09:28:27,524 p=58704 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:28:27,528 p=58704 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:28:27,528 p=58704 u=master n=ansible | Wednesday 23 July 2025  09:28:27 +0000 (0:00:00.020)       0:00:02.521 ******** 
2025-07-23 09:28:27,545 p=58704 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:28:27,549 p=58704 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат установки на узлах] ***********************************************************************************************************************
2025-07-23 09:28:27,549 p=58704 u=master n=ansible | Wednesday 23 July 2025  09:28:27 +0000 (0:00:00.020)       0:00:02.542 ******** 
2025-07-23 09:28:27,565 p=58704 u=master n=ansible | skipping: [sm01] => 
  false_condition: inventory_hostname not in groups['slurm_master']
2025-07-23 09:28:27,569 p=58704 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:28:27,569 p=58704 u=master n=ansible | Wednesday 23 July 2025  09:28:27 +0000 (0:00:00.019)       0:00:02.562 ******** 
2025-07-23 09:28:27,842 p=58704 u=master n=ansible | changed: [sm01] => changed=true 
  path: /sw/slurm-dist
  state: absent
2025-07-23 09:28:27,847 p=58704 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:28:27,847 p=58704 u=master n=ansible | Wednesday 23 July 2025  09:28:27 +0000 (0:00:00.277)       0:00:02.840 ******** 
2025-07-23 09:28:27,864 p=58704 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:28:27,867 p=58704 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:28:27,868 p=58704 u=master n=ansible | Wednesday 23 July 2025  09:28:27 +0000 (0:00:00.020)       0:00:02.861 ******** 
2025-07-23 09:28:27,885 p=58704 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:28:27,889 p=58704 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:28:27,889 p=58704 u=master n=ansible | Wednesday 23 July 2025  09:28:27 +0000 (0:00:00.021)       0:00:02.883 ******** 
2025-07-23 09:28:28,155 p=58704 u=master n=ansible | ok: [sm01] => changed=false 
  path: /sw/slurm-dist
  state: absent
2025-07-23 09:28:28,167 p=58704 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 09:28:28,167 p=58704 u=master n=ansible | sm01                       : ok=9    changed=4    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
2025-07-23 09:28:28,167 p=58704 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 3 seconds
2025-07-23 09:28:28,168 p=58704 u=master n=ansible | Wednesday 23 July 2025  09:28:28 +0000 (0:00:00.278)       0:00:03.161 ******** 
2025-07-23 09:28:28,168 p=58704 u=master n=ansible | =============================================================================== 
2025-07-23 09:28:28,168 p=58704 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------------------ 1.14s
2025-07-23 09:28:28,168 p=58704 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master --------------------------------------------------------------------------------------------------------- 0.40s
2025-07-23 09:28:28,168 p=58704 u=master n=ansible | slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS ----------------------------------------------------------------------------------------------------------- 0.30s
2025-07-23 09:28:28,168 p=58704 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание временной директории для распространения -------------------------------------------------------------------------------------------------- 0.29s
2025-07-23 09:28:28,168 p=58704 u=master n=ansible | slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере ------------------------------------------------------------------------------------------------------ 0.29s
2025-07-23 09:28:28,168 p=58704 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:28:28,168 p=58704 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:28:28,168 p=58704 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат копирования на master -------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:28:28,169 p=58704 u=master n=ansible | slurm_build : [SLURM_BUILD] Размер установки Slurm ----------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:28:28,169 p=58704 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:28:28,169 p=58704 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:28:28,169 p=58704 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:28:28,169 p=58704 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:28:28,169 p=58704 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат установки на узлах ----------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:33:31,972 p=58791 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:33:31,972 p=58791 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:33:33,336 p=58791 u=master n=ansible | sm01 | CHANGED | rc=0 >>


2025-07-23 09:33:48,599 p=58844 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:33:48,599 p=58844 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:33:49,048 p=58844 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 09:33:49,094 p=58844 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] ************************************************************************************************************
2025-07-23 09:33:49,094 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:33:49 +0000 (0:00:00.048)       0:00:00.048 ******** 
2025-07-23 09:33:49,506 p=58844 u=master n=ansible | ok: [sm01]
2025-07-23 09:33:50,195 p=58844 u=master n=ansible | ok: [cn02]
2025-07-23 09:33:50,399 p=58844 u=master n=ansible | ok: [sm02]
2025-07-23 09:33:50,418 p=58844 u=master n=ansible | ok: [cn01]
2025-07-23 09:33:50,422 p=58844 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] *********************************************************************************************************
2025-07-23 09:33:50,422 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:33:50 +0000 (0:00:01.328)       0:00:01.377 ******** 
2025-07-23 09:33:50,456 p=58844 u=master n=ansible | skipping: [sm02]
2025-07-23 09:33:50,458 p=58844 u=master n=ansible | skipping: [cn01]
2025-07-23 09:33:50,467 p=58844 u=master n=ansible | skipping: [cn02]
2025-07-23 09:33:50,809 p=58844 u=master n=ansible | changed: [sm01]
2025-07-23 09:33:50,814 p=58844 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] *****************************************************************************************************************************
2025-07-23 09:33:50,814 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:33:50 +0000 (0:00:00.391)       0:00:01.768 ******** 
2025-07-23 09:33:50,850 p=58844 u=master n=ansible | ok: [sm01] => 
  msg: "Размер установки Slurm на sm01: 483M\t/opt/slurm"
2025-07-23 09:33:50,851 p=58844 u=master n=ansible | skipping: [sm02]
2025-07-23 09:33:50,851 p=58844 u=master n=ansible | skipping: [cn01]
2025-07-23 09:33:50,859 p=58844 u=master n=ansible | skipping: [cn02]
2025-07-23 09:33:50,863 p=58844 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере] ******************************************************************************************************
2025-07-23 09:33:50,863 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:33:50 +0000 (0:00:00.049)       0:00:01.817 ******** 
2025-07-23 09:33:50,896 p=58844 u=master n=ansible | skipping: [sm02]
2025-07-23 09:33:50,898 p=58844 u=master n=ansible | skipping: [cn01]
2025-07-23 09:33:50,909 p=58844 u=master n=ansible | skipping: [cn02]
2025-07-23 09:33:51,128 p=58844 u=master n=ansible | ok: [sm01]
2025-07-23 09:33:51,133 p=58844 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для распространения] **************************************************************************************************
2025-07-23 09:33:51,133 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:33:51 +0000 (0:00:00.269)       0:00:02.087 ******** 
2025-07-23 09:33:51,170 p=58844 u=master n=ansible | skipping: [sm02]
2025-07-23 09:33:51,172 p=58844 u=master n=ansible | skipping: [cn01]
2025-07-23 09:33:51,182 p=58844 u=master n=ansible | skipping: [cn02]
2025-07-23 09:33:51,396 p=58844 u=master n=ansible | changed: [sm01]
2025-07-23 09:33:51,400 p=58844 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка инвентаря] *********************************************************************************************************************************
2025-07-23 09:33:51,400 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:33:51 +0000 (0:00:00.267)       0:00:02.355 ******** 
2025-07-23 09:33:51,434 p=58844 u=master n=ansible | ok: [sm01] => 
  msg: |-
    Узел: sm01
    Группы: ['cluster_nodes', 'jwt_nodes', 'nfs_server', 'slurm_cluster', 'slurm_master']
    В slurm_master: True
2025-07-23 09:33:51,436 p=58844 u=master n=ansible | ok: [sm02] => 
  msg: |-
    Узел: sm02
    Группы: ['cluster_nodes', 'jwt_nodes', 'nfs_client', 'slurm_cluster', 'slurm_login']
    В slurm_master: False
2025-07-23 09:33:51,442 p=58844 u=master n=ansible | ok: [cn01] => 
  msg: |-
    Узел: cn01
    Группы: ['cluster_nodes', 'gpu_nodes', 'nfs_client', 'slurm_cluster', 'slurm_compute']
    В slurm_master: False
2025-07-23 09:33:51,449 p=58844 u=master n=ansible | ok: [cn02] => 
  msg: |-
    Узел: cn02
    Группы: ['cluster_nodes', 'gpu_nodes', 'nfs_client', 'slurm_cluster', 'slurm_compute']
    В slurm_master: False
2025-07-23 09:33:51,453 p=58844 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01)] ******************************************************************************************
2025-07-23 09:33:51,453 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:33:51 +0000 (0:00:00.052)       0:00:02.407 ******** 
2025-07-23 09:33:51,485 p=58844 u=master n=ansible | skipping: [sm02]
2025-07-23 09:33:51,487 p=58844 u=master n=ansible | skipping: [cn01]
2025-07-23 09:33:51,496 p=58844 u=master n=ansible | skipping: [cn02]
2025-07-23 09:33:51,731 p=58844 u=master n=ansible | changed: [sm01]
2025-07-23 09:33:51,735 p=58844 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат копирования на master] ********************************************************************************************************************
2025-07-23 09:33:51,735 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:33:51 +0000 (0:00:00.282)       0:00:02.690 ******** 
2025-07-23 09:33:51,775 p=58844 u=master n=ansible | ok: [sm01] => 
  copy_result.stdout_lines:
  - Скопировано 20 файлов из bin/
  - Скопировано 6 файлов из sbin/
  - Скопировано lib/
  - Скопировано share/
  - === Результат копирования ===
  - total 12
  - drwxr-xr-x 3 root root 4096 Jul 23 12:33 .
  - drwxr-xr-x 3 root root 4096 Jul 23 12:33 ..
  - drwxr-xr-x 2 root root 4096 Jul 23 12:33 {bin,sbin,lib,share}
  - 'Файлов в bin/: 0'
  - 'Файлов в sbin/: 0'
2025-07-23 09:33:51,776 p=58844 u=master n=ansible | skipping: [sm02]
2025-07-23 09:33:51,777 p=58844 u=master n=ansible | skipping: [cn01]
2025-07-23 09:33:51,784 p=58844 u=master n=ansible | skipping: [cn02]
2025-07-23 09:33:51,788 p=58844 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01)] ************************************************************************************************************
2025-07-23 09:33:51,788 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:33:51 +0000 (0:00:00.052)       0:00:02.742 ******** 
2025-07-23 09:33:51,812 p=58844 u=master n=ansible | skipping: [sm01]
2025-07-23 09:34:22,210 p=58844 u=master n=ansible | fatal: [sm02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:34:22,211 p=58844 u=master n=ansible | fatal: [cn02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:34:22,215 p=58844 u=master n=ansible | fatal: [cn01]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:34:22,219 p=58844 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01)] **************************************************************************************************
2025-07-23 09:34:22,219 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:34:22 +0000 (0:00:30.431)       0:00:33.174 ******** 
2025-07-23 09:34:22,238 p=58844 u=master n=ansible | skipping: [sm01]
2025-07-23 09:34:22,242 p=58844 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат установки на узлах] ***********************************************************************************************************************
2025-07-23 09:34:22,243 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:34:22 +0000 (0:00:00.023)       0:00:33.197 ******** 
2025-07-23 09:34:22,260 p=58844 u=master n=ansible | skipping: [sm01]
2025-07-23 09:34:22,264 p=58844 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:34:22,264 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:34:22 +0000 (0:00:00.021)       0:00:33.219 ******** 
2025-07-23 09:34:22,536 p=58844 u=master n=ansible | changed: [sm01]
2025-07-23 09:34:22,541 p=58844 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:34:22,541 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:34:22 +0000 (0:00:00.277)       0:00:33.496 ******** 
2025-07-23 09:34:22,558 p=58844 u=master n=ansible | skipping: [sm01]
2025-07-23 09:34:22,562 p=58844 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:34:22,562 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:34:22 +0000 (0:00:00.020)       0:00:33.516 ******** 
2025-07-23 09:34:22,578 p=58844 u=master n=ansible | skipping: [sm01]
2025-07-23 09:34:22,582 p=58844 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:34:22,582 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:34:22 +0000 (0:00:00.020)       0:00:33.537 ******** 
2025-07-23 09:34:22,847 p=58844 u=master n=ansible | ok: [sm01]
2025-07-23 09:34:22,860 p=58844 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 09:34:22,860 p=58844 u=master n=ansible | cn01                       : ok=2    changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:34:22,860 p=58844 u=master n=ansible | cn02                       : ok=2    changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:34:22,860 p=58844 u=master n=ansible | sm01                       : ok=10   changed=4    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
2025-07-23 09:34:22,861 p=58844 u=master n=ansible | sm02                       : ok=2    changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:34:22,861 p=58844 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 33 seconds
2025-07-23 09:34:22,861 p=58844 u=master n=ansible | Wednesday 23 July 2025  09:34:22 +0000 (0:00:00.278)       0:00:33.815 ******** 
2025-07-23 09:34:22,861 p=58844 u=master n=ansible | =============================================================================== 
2025-07-23 09:34:22,861 p=58844 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01) ----------------------------------------------------------------------------------------------------------- 30.43s
2025-07-23 09:34:22,861 p=58844 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------------------ 1.33s
2025-07-23 09:34:22,861 p=58844 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master --------------------------------------------------------------------------------------------------------- 0.39s
2025-07-23 09:34:22,861 p=58844 u=master n=ansible | slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01) ------------------------------------------------------------------------------------------ 0.28s
2025-07-23 09:34:22,861 p=58844 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:34:22,861 p=58844 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:34:22,862 p=58844 u=master n=ansible | slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере ------------------------------------------------------------------------------------------------------ 0.27s
2025-07-23 09:34:22,862 p=58844 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание временной директории для распространения -------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 09:34:22,862 p=58844 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка инвентаря --------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:34:22,862 p=58844 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат копирования на master -------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:34:22,862 p=58844 u=master n=ansible | slurm_build : [SLURM_BUILD] Размер установки Slurm ----------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:34:22,862 p=58844 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01) -------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:34:22,862 p=58844 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат установки на узлах ----------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:34:22,862 p=58844 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:34:22,862 p=58844 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:34:46,682 p=59051 u=master n=ansible | Using /home/master/22Jul/slurm-hpc-cluster/ansible.cfg as config file
2025-07-23 09:34:46,683 p=59051 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:34:46,683 p=59051 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:34:47,137 p=59051 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 09:34:47,183 p=59051 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] ************************************************************************************************************
2025-07-23 09:34:47,183 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:34:47 +0000 (0:00:00.048)       0:00:00.048 ******** 
2025-07-23 09:34:47,585 p=59051 u=master n=ansible | ok: [sm02] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:34:47,587 p=59051 u=master n=ansible | ok: [cn02] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:34:47,588 p=59051 u=master n=ansible | ok: [sm01] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:34:47,596 p=59051 u=master n=ansible | ok: [cn01] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:34:47,601 p=59051 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] *********************************************************************************************************
2025-07-23 09:34:47,601 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:34:47 +0000 (0:00:00.417)       0:00:00.466 ******** 
2025-07-23 09:34:47,636 p=59051 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:34:47,638 p=59051 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:34:47,647 p=59051 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:34:47,990 p=59051 u=master n=ansible | changed: [sm01] => changed=true 
  cmd: du -sh /opt/slurm
  delta: '0:00:00.006199'
  end: '2025-07-23 12:34:47.999958'
  msg: ''
  rc: 0
  start: '2025-07-23 12:34:47.993759'
  stderr: ''
  stderr_lines: <omitted>
  stdout: "483M\t/opt/slurm"
  stdout_lines: <omitted>
2025-07-23 09:34:47,995 p=59051 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] *****************************************************************************************************************************
2025-07-23 09:34:47,995 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:34:47 +0000 (0:00:00.394)       0:00:00.860 ******** 
2025-07-23 09:34:48,030 p=59051 u=master n=ansible | ok: [sm01] => 
  msg: "Размер установки Slurm на sm01: 483M\t/opt/slurm"
2025-07-23 09:34:48,031 p=59051 u=master n=ansible | skipping: [sm02] => 
  false_condition: inventory_hostname in groups['slurm_master']
2025-07-23 09:34:48,031 p=59051 u=master n=ansible | skipping: [cn01] => 
  false_condition: inventory_hostname in groups['slurm_master']
2025-07-23 09:34:48,040 p=59051 u=master n=ansible | skipping: [cn02] => 
  false_condition: inventory_hostname in groups['slurm_master']
2025-07-23 09:34:48,043 p=59051 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере] ******************************************************************************************************
2025-07-23 09:34:48,044 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:34:48 +0000 (0:00:00.048)       0:00:00.909 ******** 
2025-07-23 09:34:48,078 p=59051 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:34:48,079 p=59051 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:34:48,089 p=59051 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:34:48,308 p=59051 u=master n=ansible | ok: [sm01] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /sw
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:34:48,312 p=59051 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для распространения] **************************************************************************************************
2025-07-23 09:34:48,312 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:34:48 +0000 (0:00:00.268)       0:00:01.178 ******** 
2025-07-23 09:34:48,353 p=59051 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:34:48,354 p=59051 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:34:48,364 p=59051 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:34:48,581 p=59051 u=master n=ansible | changed: [sm01] => changed=true 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /sw/slurm-dist
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:34:48,585 p=59051 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка инвентаря] *********************************************************************************************************************************
2025-07-23 09:34:48,585 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:34:48 +0000 (0:00:00.272)       0:00:01.450 ******** 
2025-07-23 09:34:48,621 p=59051 u=master n=ansible | ok: [sm01] => 
  msg: |-
    Узел: sm01
    Группы: ['cluster_nodes', 'jwt_nodes', 'nfs_server', 'slurm_cluster', 'slurm_master']
    В slurm_master: True
2025-07-23 09:34:48,623 p=59051 u=master n=ansible | ok: [sm02] => 
  msg: |-
    Узел: sm02
    Группы: ['cluster_nodes', 'jwt_nodes', 'nfs_client', 'slurm_cluster', 'slurm_login']
    В slurm_master: False
2025-07-23 09:34:48,627 p=59051 u=master n=ansible | ok: [cn01] => 
  msg: |-
    Узел: cn01
    Группы: ['cluster_nodes', 'gpu_nodes', 'nfs_client', 'slurm_cluster', 'slurm_compute']
    В slurm_master: False
2025-07-23 09:34:48,636 p=59051 u=master n=ansible | ok: [cn02] => 
  msg: |-
    Узел: cn02
    Группы: ['cluster_nodes', 'gpu_nodes', 'nfs_client', 'slurm_cluster', 'slurm_compute']
    В slurm_master: False
2025-07-23 09:34:48,640 p=59051 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01)] ******************************************************************************************
2025-07-23 09:34:48,641 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:34:48 +0000 (0:00:00.055)       0:00:01.506 ******** 
2025-07-23 09:34:48,678 p=59051 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname == "sm01"
  skip_reason: Conditional result was False
2025-07-23 09:34:48,679 p=59051 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname == "sm01"
  skip_reason: Conditional result was False
2025-07-23 09:34:48,688 p=59051 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname == "sm01"
  skip_reason: Conditional result was False
2025-07-23 09:34:48,921 p=59051 u=master n=ansible | changed: [sm01] => changed=true 
  cmd: |-
    # Создаем структуру в /sw
    mkdir -p /sw/slurm-dist/{bin,sbin,lib,share}
  
    # Копируем все директории
    if [ -d "/opt/slurm/bin" ]; then
      cp -r /opt/slurm/bin/* /sw/slurm-dist/bin/
      echo "Скопировано $(ls /opt/slurm/bin | wc -l) файлов из bin/"
    fi
  
    if [ -d "/opt/slurm/sbin" ]; then
      cp -r /opt/slurm/sbin/* /sw/slurm-dist/sbin/
      echo "Скопировано $(ls /opt/slurm/sbin | wc -l) файлов из sbin/"
    fi
  
    if [ -d "/opt/slurm/lib" ]; then
      cp -r /opt/slurm/lib/* /sw/slurm-dist/lib/
      echo "Скопировано lib/"
    fi
  
    if [ -d "/opt/slurm/share" ]; then
      cp -r /opt/slurm/share/* /sw/slurm-dist/share/
      echo "Скопировано share/"
    fi
  
    # Проверяем результат
    echo "=== Результат копирования ==="
    ls -la /sw/slurm-dist/
    echo "Файлов в bin/: $(ls /sw/slurm-dist/bin 2>/dev/null | wc -l)"
    echo "Файлов в sbin/: $(ls /sw/slurm-dist/sbin 2>/dev/null | wc -l)"
  delta: '0:00:00.019904'
  end: '2025-07-23 12:34:48.930295'
  msg: ''
  rc: 0
  start: '2025-07-23 12:34:48.910391'
  stderr: |-
    cp: target '/sw/slurm-dist/bin/': No such file or directory
    cp: target '/sw/slurm-dist/sbin/': No such file or directory
    cp: target '/sw/slurm-dist/lib/': No such file or directory
    cp: target '/sw/slurm-dist/share/': No such file or directory
  stderr_lines: <omitted>
  stdout: |-
    Скопировано 20 файлов из bin/
    Скопировано 6 файлов из sbin/
    Скопировано lib/
    Скопировано share/
    === Результат копирования ===
    total 12
    drwxr-xr-x 3 root root 4096 Jul 23 12:34 .
    drwxr-xr-x 3 root root 4096 Jul 23 12:34 ..
    drwxr-xr-x 2 root root 4096 Jul 23 12:34 {bin,sbin,lib,share}
    Файлов в bin/: 0
    Файлов в sbin/: 0
  stdout_lines: <omitted>
2025-07-23 09:34:48,925 p=59051 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат копирования на master] ********************************************************************************************************************
2025-07-23 09:34:48,925 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:34:48 +0000 (0:00:00.284)       0:00:01.791 ******** 
2025-07-23 09:34:48,961 p=59051 u=master n=ansible | skipping: [sm02] => 
  false_condition: inventory_hostname == "sm01"
2025-07-23 09:34:48,964 p=59051 u=master n=ansible | ok: [sm01] => 
  copy_result.stdout_lines:
  - Скопировано 20 файлов из bin/
  - Скопировано 6 файлов из sbin/
  - Скопировано lib/
  - Скопировано share/
  - === Результат копирования ===
  - total 12
  - drwxr-xr-x 3 root root 4096 Jul 23 12:34 .
  - drwxr-xr-x 3 root root 4096 Jul 23 12:34 ..
  - drwxr-xr-x 2 root root 4096 Jul 23 12:34 {bin,sbin,lib,share}
  - 'Файлов в bin/: 0'
  - 'Файлов в sbin/: 0'
2025-07-23 09:34:48,964 p=59051 u=master n=ansible | skipping: [cn01] => 
  false_condition: inventory_hostname == "sm01"
2025-07-23 09:34:48,972 p=59051 u=master n=ansible | skipping: [cn02] => 
  false_condition: inventory_hostname == "sm01"
2025-07-23 09:34:48,976 p=59051 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01)] ************************************************************************************************************
2025-07-23 09:34:48,976 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:34:48 +0000 (0:00:00.050)       0:00:01.842 ******** 
2025-07-23 09:34:49,002 p=59051 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname != "sm01"
  skip_reason: Conditional result was False
2025-07-23 09:35:19,395 p=59051 u=master n=ansible | fatal: [cn02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:35:19,396 p=59051 u=master n=ansible | fatal: [sm02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:35:19,405 p=59051 u=master n=ansible | fatal: [cn01]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:35:19,410 p=59051 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01)] **************************************************************************************************
2025-07-23 09:35:19,410 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:35:19 +0000 (0:00:30.433)       0:00:32.275 ******** 
2025-07-23 09:35:19,428 p=59051 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname != "sm01"
  skip_reason: Conditional result was False
2025-07-23 09:35:19,432 p=59051 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат установки на узлах] ***********************************************************************************************************************
2025-07-23 09:35:19,433 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:35:19 +0000 (0:00:00.022)       0:00:32.298 ******** 
2025-07-23 09:35:19,452 p=59051 u=master n=ansible | skipping: [sm01] => 
  false_condition: inventory_hostname != "sm01"
2025-07-23 09:35:19,456 p=59051 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:35:19,456 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:35:19 +0000 (0:00:00.023)       0:00:32.322 ******** 
2025-07-23 09:35:19,728 p=59051 u=master n=ansible | changed: [sm01] => changed=true 
  path: /sw/slurm-dist
  state: absent
2025-07-23 09:35:19,733 p=59051 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:35:19,734 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:35:19 +0000 (0:00:00.277)       0:00:32.599 ******** 
2025-07-23 09:35:19,756 p=59051 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:35:19,760 p=59051 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:35:19,760 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:35:19 +0000 (0:00:00.026)       0:00:32.625 ******** 
2025-07-23 09:35:19,777 p=59051 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:35:19,781 p=59051 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:35:19,781 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:35:19 +0000 (0:00:00.021)       0:00:32.647 ******** 
2025-07-23 09:35:20,050 p=59051 u=master n=ansible | ok: [sm01] => changed=false 
  path: /sw/slurm-dist
  state: absent
2025-07-23 09:35:20,063 p=59051 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 09:35:20,063 p=59051 u=master n=ansible | cn01                       : ok=2    changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:35:20,063 p=59051 u=master n=ansible | cn02                       : ok=2    changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:35:20,063 p=59051 u=master n=ansible | sm01                       : ok=10   changed=4    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
2025-07-23 09:35:20,063 p=59051 u=master n=ansible | sm02                       : ok=2    changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:35:20,063 p=59051 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 32 seconds
2025-07-23 09:35:20,064 p=59051 u=master n=ansible | Wednesday 23 July 2025  09:35:20 +0000 (0:00:00.282)       0:00:32.929 ******** 
2025-07-23 09:35:20,064 p=59051 u=master n=ansible | =============================================================================== 
2025-07-23 09:35:20,064 p=59051 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01) ----------------------------------------------------------------------------------------------------------- 30.43s
2025-07-23 09:35:20,064 p=59051 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------------------ 0.42s
2025-07-23 09:35:20,064 p=59051 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master --------------------------------------------------------------------------------------------------------- 0.39s
2025-07-23 09:35:20,064 p=59051 u=master n=ansible | slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01) ------------------------------------------------------------------------------------------ 0.28s
2025-07-23 09:35:20,064 p=59051 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:35:20,064 p=59051 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:35:20,064 p=59051 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание временной директории для распространения -------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 09:35:20,064 p=59051 u=master n=ansible | slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере ------------------------------------------------------------------------------------------------------ 0.27s
2025-07-23 09:35:20,065 p=59051 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка инвентаря --------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 09:35:20,065 p=59051 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат копирования на master -------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:35:20,065 p=59051 u=master n=ansible | slurm_build : [SLURM_BUILD] Размер установки Slurm ----------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:35:20,065 p=59051 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:35:20,065 p=59051 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат установки на узлах ----------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:35:20,065 p=59051 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01) -------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:35:20,065 p=59051 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:36:11,624 p=59214 u=master n=ansible | Using /home/master/22Jul/slurm-hpc-cluster/ansible.cfg as config file
2025-07-23 09:36:11,624 p=59214 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:36:11,625 p=59214 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:36:12,077 p=59214 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 09:36:12,123 p=59214 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] ************************************************************************************************************
2025-07-23 09:36:12,123 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:12 +0000 (0:00:00.048)       0:00:00.048 ******** 
2025-07-23 09:36:12,529 p=59214 u=master n=ansible | ok: [sm01] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:36:12,533 p=59214 u=master n=ansible | ok: [sm02] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:36:12,537 p=59214 u=master n=ansible | ok: [cn02] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:36:12,538 p=59214 u=master n=ansible | ok: [cn01] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /opt/slurm
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:36:12,542 p=59214 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] *********************************************************************************************************
2025-07-23 09:36:12,542 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:12 +0000 (0:00:00.418)       0:00:00.467 ******** 
2025-07-23 09:36:12,577 p=59214 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:36:12,578 p=59214 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:36:12,585 p=59214 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:36:12,942 p=59214 u=master n=ansible | changed: [sm01] => changed=true 
  cmd: du -sh /opt/slurm
  delta: '0:00:00.005947'
  end: '2025-07-23 12:36:12.949222'
  msg: ''
  rc: 0
  start: '2025-07-23 12:36:12.943275'
  stderr: ''
  stderr_lines: <omitted>
  stdout: "483M\t/opt/slurm"
  stdout_lines: <omitted>
2025-07-23 09:36:12,947 p=59214 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] *****************************************************************************************************************************
2025-07-23 09:36:12,947 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:12 +0000 (0:00:00.405)       0:00:00.872 ******** 
2025-07-23 09:36:12,980 p=59214 u=master n=ansible | ok: [sm01] => 
  msg: "Размер установки Slurm на sm01: 483M\t/opt/slurm"
2025-07-23 09:36:12,982 p=59214 u=master n=ansible | skipping: [sm02] => 
  false_condition: inventory_hostname in groups['slurm_master']
2025-07-23 09:36:12,983 p=59214 u=master n=ansible | skipping: [cn01] => 
  false_condition: inventory_hostname in groups['slurm_master']
2025-07-23 09:36:12,991 p=59214 u=master n=ansible | skipping: [cn02] => 
  false_condition: inventory_hostname in groups['slurm_master']
2025-07-23 09:36:12,995 p=59214 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере] ******************************************************************************************************
2025-07-23 09:36:12,995 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:12 +0000 (0:00:00.047)       0:00:00.920 ******** 
2025-07-23 09:36:13,029 p=59214 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:36:13,031 p=59214 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:36:13,039 p=59214 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:36:13,260 p=59214 u=master n=ansible | ok: [sm01] => changed=false 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /sw
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:36:13,264 p=59214 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для распространения] **************************************************************************************************
2025-07-23 09:36:13,264 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:13 +0000 (0:00:00.269)       0:00:01.190 ******** 
2025-07-23 09:36:13,305 p=59214 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:36:13,306 p=59214 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:36:13,316 p=59214 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:36:13,529 p=59214 u=master n=ansible | changed: [sm01] => changed=true 
  gid: 0
  group: root
  mode: '0755'
  owner: root
  path: /sw/slurm-dist
  size: 4096
  state: directory
  uid: 0
2025-07-23 09:36:13,533 p=59214 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка инвентаря] *********************************************************************************************************************************
2025-07-23 09:36:13,533 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:13 +0000 (0:00:00.268)       0:00:01.459 ******** 
2025-07-23 09:36:13,561 p=59214 u=master n=ansible | ok: [sm01] => 
  msg: |-
    Узел: sm01
    Группы: ['cluster_nodes', 'jwt_nodes', 'nfs_server', 'slurm_cluster', 'slurm_master']
    В slurm_master: True
2025-07-23 09:36:13,573 p=59214 u=master n=ansible | ok: [sm02] => 
  msg: |-
    Узел: sm02
    Группы: ['cluster_nodes', 'jwt_nodes', 'nfs_client', 'slurm_cluster', 'slurm_login']
    В slurm_master: False
2025-07-23 09:36:13,576 p=59214 u=master n=ansible | ok: [cn01] => 
  msg: |-
    Узел: cn01
    Группы: ['cluster_nodes', 'gpu_nodes', 'nfs_client', 'slurm_cluster', 'slurm_compute']
    В slurm_master: False
2025-07-23 09:36:13,589 p=59214 u=master n=ansible | ok: [cn02] => 
  msg: |-
    Узел: cn02
    Группы: ['cluster_nodes', 'gpu_nodes', 'nfs_client', 'slurm_cluster', 'slurm_compute']
    В slurm_master: False
2025-07-23 09:36:13,593 p=59214 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01)] ******************************************************************************************
2025-07-23 09:36:13,593 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:13 +0000 (0:00:00.059)       0:00:01.518 ******** 
2025-07-23 09:36:13,628 p=59214 u=master n=ansible | skipping: [sm02] => changed=false 
  false_condition: inventory_hostname == "sm01"
  skip_reason: Conditional result was False
2025-07-23 09:36:13,630 p=59214 u=master n=ansible | skipping: [cn01] => changed=false 
  false_condition: inventory_hostname == "sm01"
  skip_reason: Conditional result was False
2025-07-23 09:36:13,638 p=59214 u=master n=ansible | skipping: [cn02] => changed=false 
  false_condition: inventory_hostname == "sm01"
  skip_reason: Conditional result was False
2025-07-23 09:36:13,873 p=59214 u=master n=ansible | changed: [sm01] => changed=true 
  cmd: |-
    # Создаем структуру в /sw
    mkdir -p /sw/slurm-dist/{bin,sbin,lib,share}
  
    # Копируем все директории
    if [ -d "/opt/slurm/bin" ]; then
      cp -r /opt/slurm/bin/* /sw/slurm-dist/bin/
      echo "Скопировано $(ls /opt/slurm/bin | wc -l) файлов из bin/"
    fi
  
    if [ -d "/opt/slurm/sbin" ]; then
      cp -r /opt/slurm/sbin/* /sw/slurm-dist/sbin/
      echo "Скопировано $(ls /opt/slurm/sbin | wc -l) файлов из sbin/"
    fi
  
    if [ -d "/opt/slurm/lib" ]; then
      cp -r /opt/slurm/lib/* /sw/slurm-dist/lib/
      echo "Скопировано lib/"
    fi
  
    if [ -d "/opt/slurm/share" ]; then
      cp -r /opt/slurm/share/* /sw/slurm-dist/share/
      echo "Скопировано share/"
    fi
  
    # Проверяем результат
    echo "=== Результат копирования ==="
    ls -la /sw/slurm-dist/
    echo "Файлов в bin/: $(ls /sw/slurm-dist/bin 2>/dev/null | wc -l)"
    echo "Файлов в sbin/: $(ls /sw/slurm-dist/sbin 2>/dev/null | wc -l)"
  delta: '0:00:00.019420'
  end: '2025-07-23 12:36:13.879378'
  msg: ''
  rc: 0
  start: '2025-07-23 12:36:13.859958'
  stderr: |-
    cp: target '/sw/slurm-dist/bin/': No such file or directory
    cp: target '/sw/slurm-dist/sbin/': No such file or directory
    cp: target '/sw/slurm-dist/lib/': No such file or directory
    cp: target '/sw/slurm-dist/share/': No such file or directory
  stderr_lines: <omitted>
  stdout: |-
    Скопировано 20 файлов из bin/
    Скопировано 6 файлов из sbin/
    Скопировано lib/
    Скопировано share/
    === Результат копирования ===
    total 12
    drwxr-xr-x 3 root root 4096 Jul 23 12:36 .
    drwxr-xr-x 3 root root 4096 Jul 23 12:36 ..
    drwxr-xr-x 2 root root 4096 Jul 23 12:36 {bin,sbin,lib,share}
    Файлов в bin/: 0
    Файлов в sbin/: 0
  stdout_lines: <omitted>
2025-07-23 09:36:13,878 p=59214 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат копирования на master] ********************************************************************************************************************
2025-07-23 09:36:13,878 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:13 +0000 (0:00:00.284)       0:00:01.803 ******** 
2025-07-23 09:36:13,914 p=59214 u=master n=ansible | ok: [sm01] => 
  copy_result.stdout_lines:
  - Скопировано 20 файлов из bin/
  - Скопировано 6 файлов из sbin/
  - Скопировано lib/
  - Скопировано share/
  - === Результат копирования ===
  - total 12
  - drwxr-xr-x 3 root root 4096 Jul 23 12:36 .
  - drwxr-xr-x 3 root root 4096 Jul 23 12:36 ..
  - drwxr-xr-x 2 root root 4096 Jul 23 12:36 {bin,sbin,lib,share}
  - 'Файлов в bin/: 0'
  - 'Файлов в sbin/: 0'
2025-07-23 09:36:13,916 p=59214 u=master n=ansible | skipping: [sm02] => 
  false_condition: inventory_hostname == "sm01"
2025-07-23 09:36:13,917 p=59214 u=master n=ansible | skipping: [cn01] => 
  false_condition: inventory_hostname == "sm01"
2025-07-23 09:36:13,924 p=59214 u=master n=ansible | skipping: [cn02] => 
  false_condition: inventory_hostname == "sm01"
2025-07-23 09:36:13,928 p=59214 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01)] ************************************************************************************************************
2025-07-23 09:36:13,928 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:13 +0000 (0:00:00.050)       0:00:01.853 ******** 
2025-07-23 09:36:13,955 p=59214 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname != "sm01"
  skip_reason: Conditional result was False
2025-07-23 09:36:44,348 p=59214 u=master n=ansible | fatal: [sm02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:36:44,349 p=59214 u=master n=ansible | fatal: [cn02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:36:44,351 p=59214 u=master n=ansible | fatal: [cn01]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:36:44,355 p=59214 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01)] **************************************************************************************************
2025-07-23 09:36:44,356 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:44 +0000 (0:00:30.427)       0:00:32.281 ******** 
2025-07-23 09:36:44,375 p=59214 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname != "sm01"
  skip_reason: Conditional result was False
2025-07-23 09:36:44,380 p=59214 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат установки на узлах] ***********************************************************************************************************************
2025-07-23 09:36:44,380 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:44 +0000 (0:00:00.024)       0:00:32.305 ******** 
2025-07-23 09:36:44,398 p=59214 u=master n=ansible | skipping: [sm01] => 
  false_condition: inventory_hostname != "sm01"
2025-07-23 09:36:44,402 p=59214 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:36:44,402 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:44 +0000 (0:00:00.022)       0:00:32.327 ******** 
2025-07-23 09:36:44,683 p=59214 u=master n=ansible | changed: [sm01] => changed=true 
  path: /sw/slurm-dist
  state: absent
2025-07-23 09:36:44,688 p=59214 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:36:44,688 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:44 +0000 (0:00:00.285)       0:00:32.613 ******** 
2025-07-23 09:36:44,706 p=59214 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:36:44,710 p=59214 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:36:44,710 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:44 +0000 (0:00:00.022)       0:00:32.636 ******** 
2025-07-23 09:36:44,728 p=59214 u=master n=ansible | skipping: [sm01] => changed=false 
  false_condition: inventory_hostname not in groups['slurm_master']
  skip_reason: Conditional result was False
2025-07-23 09:36:44,732 p=59214 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:36:44,732 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:44 +0000 (0:00:00.021)       0:00:32.657 ******** 
2025-07-23 09:36:45,002 p=59214 u=master n=ansible | ok: [sm01] => changed=false 
  path: /sw/slurm-dist
  state: absent
2025-07-23 09:36:45,015 p=59214 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 09:36:45,015 p=59214 u=master n=ansible | cn01                       : ok=2    changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:36:45,015 p=59214 u=master n=ansible | cn02                       : ok=2    changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:36:45,015 p=59214 u=master n=ansible | sm01                       : ok=10   changed=4    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
2025-07-23 09:36:45,015 p=59214 u=master n=ansible | sm02                       : ok=2    changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:36:45,015 p=59214 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 32 seconds
2025-07-23 09:36:45,015 p=59214 u=master n=ansible | Wednesday 23 July 2025  09:36:45 +0000 (0:00:00.283)       0:00:32.941 ******** 
2025-07-23 09:36:45,016 p=59214 u=master n=ansible | =============================================================================== 
2025-07-23 09:36:45,016 p=59214 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01) ----------------------------------------------------------------------------------------------------------- 30.43s
2025-07-23 09:36:45,016 p=59214 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------------------ 0.42s
2025-07-23 09:36:45,016 p=59214 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master --------------------------------------------------------------------------------------------------------- 0.41s
2025-07-23 09:36:45,016 p=59214 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.29s
2025-07-23 09:36:45,016 p=59214 u=master n=ansible | slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01) ------------------------------------------------------------------------------------------ 0.28s
2025-07-23 09:36:45,016 p=59214 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:36:45,016 p=59214 u=master n=ansible | slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере ------------------------------------------------------------------------------------------------------ 0.27s
2025-07-23 09:36:45,016 p=59214 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание временной директории для распространения -------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 09:36:45,016 p=59214 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка инвентаря --------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 09:36:45,017 p=59214 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат копирования на master -------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:36:45,017 p=59214 u=master n=ansible | slurm_build : [SLURM_BUILD] Размер установки Slurm ----------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:36:45,017 p=59214 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01) -------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:36:45,017 p=59214 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:36:45,017 p=59214 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат установки на узлах ----------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:36:45,017 p=59214 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:39:03,691 p=59388 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:39:03,692 p=59388 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:39:05,063 p=59388 u=master n=ansible | sm01 | CHANGED | rc=0 >>


2025-07-23 09:39:17,578 p=59444 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:39:17,578 p=59444 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:39:18,025 p=59444 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 09:39:18,071 p=59444 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] ************************************************************************************************************
2025-07-23 09:39:18,071 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:18 +0000 (0:00:00.048)       0:00:00.048 ******** 
2025-07-23 09:39:18,489 p=59444 u=master n=ansible | ok: [sm01]
2025-07-23 09:39:19,189 p=59444 u=master n=ansible | ok: [cn02]
2025-07-23 09:39:19,403 p=59444 u=master n=ansible | ok: [cn01]
2025-07-23 09:39:19,406 p=59444 u=master n=ansible | ok: [sm02]
2025-07-23 09:39:19,410 p=59444 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] *********************************************************************************************************
2025-07-23 09:39:19,410 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:19 +0000 (0:00:01.338)       0:00:01.387 ******** 
2025-07-23 09:39:19,443 p=59444 u=master n=ansible | skipping: [sm02]
2025-07-23 09:39:19,450 p=59444 u=master n=ansible | skipping: [cn01]
2025-07-23 09:39:19,453 p=59444 u=master n=ansible | skipping: [cn02]
2025-07-23 09:39:19,814 p=59444 u=master n=ansible | changed: [sm01]
2025-07-23 09:39:19,818 p=59444 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] *****************************************************************************************************************************
2025-07-23 09:39:19,819 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:19 +0000 (0:00:00.408)       0:00:01.796 ******** 
2025-07-23 09:39:19,853 p=59444 u=master n=ansible | ok: [sm01] => 
  msg: "Размер установки Slurm на sm01: 483M\t/opt/slurm"
2025-07-23 09:39:19,854 p=59444 u=master n=ansible | skipping: [sm02]
2025-07-23 09:39:19,856 p=59444 u=master n=ansible | skipping: [cn01]
2025-07-23 09:39:19,865 p=59444 u=master n=ansible | skipping: [cn02]
2025-07-23 09:39:19,869 p=59444 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере] ******************************************************************************************************
2025-07-23 09:39:19,869 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:19 +0000 (0:00:00.050)       0:00:01.846 ******** 
2025-07-23 09:39:19,903 p=59444 u=master n=ansible | skipping: [sm02]
2025-07-23 09:39:19,905 p=59444 u=master n=ansible | skipping: [cn01]
2025-07-23 09:39:19,912 p=59444 u=master n=ansible | skipping: [cn02]
2025-07-23 09:39:20,150 p=59444 u=master n=ansible | ok: [sm01]
2025-07-23 09:39:20,154 p=59444 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для распространения] **************************************************************************************************
2025-07-23 09:39:20,154 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:20 +0000 (0:00:00.285)       0:00:02.131 ******** 
2025-07-23 09:39:20,191 p=59444 u=master n=ansible | skipping: [sm02]
2025-07-23 09:39:20,192 p=59444 u=master n=ansible | skipping: [cn01]
2025-07-23 09:39:20,202 p=59444 u=master n=ansible | skipping: [cn02]
2025-07-23 09:39:20,429 p=59444 u=master n=ansible | changed: [sm01]
2025-07-23 09:39:20,433 p=59444 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка инвентаря] *********************************************************************************************************************************
2025-07-23 09:39:20,434 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:20 +0000 (0:00:00.279)       0:00:02.411 ******** 
2025-07-23 09:39:20,468 p=59444 u=master n=ansible | ok: [sm01] => 
  msg: |-
    Узел: sm01
    Группы: ['cluster_nodes', 'jwt_nodes', 'nfs_server', 'slurm_cluster', 'slurm_master']
    В slurm_master: True
2025-07-23 09:39:20,472 p=59444 u=master n=ansible | ok: [sm02] => 
  msg: |-
    Узел: sm02
    Группы: ['cluster_nodes', 'jwt_nodes', 'nfs_client', 'slurm_cluster', 'slurm_login']
    В slurm_master: False
2025-07-23 09:39:20,475 p=59444 u=master n=ansible | ok: [cn01] => 
  msg: |-
    Узел: cn01
    Группы: ['cluster_nodes', 'gpu_nodes', 'nfs_client', 'slurm_cluster', 'slurm_compute']
    В slurm_master: False
2025-07-23 09:39:20,487 p=59444 u=master n=ansible | ok: [cn02] => 
  msg: |-
    Узел: cn02
    Группы: ['cluster_nodes', 'gpu_nodes', 'nfs_client', 'slurm_cluster', 'slurm_compute']
    В slurm_master: False
2025-07-23 09:39:20,491 p=59444 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01)] ******************************************************************************************
2025-07-23 09:39:20,492 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:20 +0000 (0:00:00.057)       0:00:02.469 ******** 
2025-07-23 09:39:20,525 p=59444 u=master n=ansible | skipping: [sm02]
2025-07-23 09:39:20,527 p=59444 u=master n=ansible | skipping: [cn01]
2025-07-23 09:39:20,536 p=59444 u=master n=ansible | skipping: [cn02]
2025-07-23 09:39:20,775 p=59444 u=master n=ansible | changed: [sm01]
2025-07-23 09:39:20,779 p=59444 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат копирования на master] ********************************************************************************************************************
2025-07-23 09:39:20,779 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:20 +0000 (0:00:00.287)       0:00:02.756 ******** 
2025-07-23 09:39:20,814 p=59444 u=master n=ansible | ok: [sm01] => 
  copy_result.stdout_lines:
  - Скопировано 20 файлов из bin/
  - Скопировано 6 файлов из sbin/
  - Скопировано lib/
  - Скопировано share/
  - === Результат копирования ===
  - total 12
  - drwxr-xr-x 3 root root 4096 Jul 23 12:39 .
  - drwxr-xr-x 3 root root 4096 Jul 23 12:39 ..
  - drwxr-xr-x 2 root root 4096 Jul 23 12:39 {bin,sbin,lib,share}
  - 'Файлов в bin/: 0'
  - 'Файлов в sbin/: 0'
2025-07-23 09:39:20,815 p=59444 u=master n=ansible | skipping: [sm02]
2025-07-23 09:39:20,815 p=59444 u=master n=ansible | skipping: [cn01]
2025-07-23 09:39:20,822 p=59444 u=master n=ansible | skipping: [cn02]
2025-07-23 09:39:20,826 p=59444 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01)] ************************************************************************************************************
2025-07-23 09:39:20,827 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:20 +0000 (0:00:00.047)       0:00:02.804 ******** 
2025-07-23 09:39:20,850 p=59444 u=master n=ansible | skipping: [sm01]
2025-07-23 09:39:51,241 p=59444 u=master n=ansible | fatal: [cn02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:39:51,245 p=59444 u=master n=ansible | fatal: [sm02]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:39:51,248 p=59444 u=master n=ansible | fatal: [cn01]: FAILED! => changed=false 
  elapsed: 30
  msg: Timeout when waiting for file /sw/slurm-dist/bin/sinfo
2025-07-23 09:39:51,252 p=59444 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01)] **************************************************************************************************
2025-07-23 09:39:51,252 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:51 +0000 (0:00:30.425)       0:00:33.229 ******** 
2025-07-23 09:39:51,272 p=59444 u=master n=ansible | skipping: [sm01]
2025-07-23 09:39:51,276 p=59444 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат установки на узлах] ***********************************************************************************************************************
2025-07-23 09:39:51,276 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:51 +0000 (0:00:00.023)       0:00:33.253 ******** 
2025-07-23 09:39:51,296 p=59444 u=master n=ansible | skipping: [sm01]
2025-07-23 09:39:51,300 p=59444 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:39:51,300 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:51 +0000 (0:00:00.023)       0:00:33.277 ******** 
2025-07-23 09:39:51,575 p=59444 u=master n=ansible | changed: [sm01]
2025-07-23 09:39:51,579 p=59444 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:39:51,579 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:51 +0000 (0:00:00.279)       0:00:33.557 ******** 
2025-07-23 09:39:51,598 p=59444 u=master n=ansible | skipping: [sm01]
2025-07-23 09:39:51,602 p=59444 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:39:51,602 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:51 +0000 (0:00:00.022)       0:00:33.579 ******** 
2025-07-23 09:39:51,620 p=59444 u=master n=ansible | skipping: [sm01]
2025-07-23 09:39:51,623 p=59444 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:39:51,624 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:51 +0000 (0:00:00.021)       0:00:33.601 ******** 
2025-07-23 09:39:51,889 p=59444 u=master n=ansible | ok: [sm01]
2025-07-23 09:39:51,902 p=59444 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 09:39:51,902 p=59444 u=master n=ansible | cn01                       : ok=2    changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:39:51,902 p=59444 u=master n=ansible | cn02                       : ok=2    changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:39:51,902 p=59444 u=master n=ansible | sm01                       : ok=10   changed=4    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
2025-07-23 09:39:51,902 p=59444 u=master n=ansible | sm02                       : ok=2    changed=0    unreachable=0    failed=1    skipped=6    rescued=0    ignored=0   
2025-07-23 09:39:51,903 p=59444 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 33 seconds
2025-07-23 09:39:51,903 p=59444 u=master n=ansible | Wednesday 23 July 2025  09:39:51 +0000 (0:00:00.279)       0:00:33.880 ******** 
2025-07-23 09:39:51,903 p=59444 u=master n=ansible | =============================================================================== 
2025-07-23 09:39:51,903 p=59444 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01) ----------------------------------------------------------------------------------------------------------- 30.43s
2025-07-23 09:39:51,903 p=59444 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------------------ 1.34s
2025-07-23 09:39:51,903 p=59444 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master --------------------------------------------------------------------------------------------------------- 0.41s
2025-07-23 09:39:51,903 p=59444 u=master n=ansible | slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01) ------------------------------------------------------------------------------------------ 0.29s
2025-07-23 09:39:51,903 p=59444 u=master n=ansible | slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере ------------------------------------------------------------------------------------------------------ 0.29s
2025-07-23 09:39:51,903 p=59444 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание временной директории для распространения -------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:39:51,903 p=59444 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:39:51,903 p=59444 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:39:51,904 p=59444 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка инвентаря --------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 09:39:51,904 p=59444 u=master n=ansible | slurm_build : [SLURM_BUILD] Размер установки Slurm ----------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:39:51,904 p=59444 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат копирования на master -------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:39:51,904 p=59444 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01) -------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:39:51,904 p=59444 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат установки на узлах ----------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:39:51,904 p=59444 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:39:51,904 p=59444 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:42:04,532 p=59611 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:42:04,532 p=59611 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:42:05,886 p=59611 u=master n=ansible | sm01 | CHANGED | rc=0 >>


2025-07-23 09:42:15,342 p=59652 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:42:15,342 p=59652 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:42:16,108 p=59652 u=master n=ansible | sm01 | CHANGED | rc=0 >>
total 8
drwxr-xr-x  2 root root 4096 Jul 23 12:39 .
drwxr-xr-x 25 root root 4096 Jul 22 16:41 ..
-rw-r--r--  1 root root    0 Jul 23 11:57 test

2025-07-23 09:42:49,087 p=59700 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:42:49,087 p=59700 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:42:49,530 p=59700 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 09:42:49,557 p=59700 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] ************************************************************************************************************
2025-07-23 09:42:49,557 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:49 +0000 (0:00:00.030)       0:00:00.030 ******** 
2025-07-23 09:42:49,961 p=59700 u=master n=ansible | ok: [sm01]
2025-07-23 09:42:49,965 p=59700 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] *********************************************************************************************************
2025-07-23 09:42:49,965 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:49 +0000 (0:00:00.407)       0:00:00.438 ******** 
2025-07-23 09:42:50,359 p=59700 u=master n=ansible | changed: [sm01]
2025-07-23 09:42:50,364 p=59700 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] *****************************************************************************************************************************
2025-07-23 09:42:50,364 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:50 +0000 (0:00:00.398)       0:00:00.836 ******** 
2025-07-23 09:42:50,389 p=59700 u=master n=ansible | ok: [sm01] => 
  msg: "Размер установки Slurm на sm01: 483M\t/opt/slurm"
2025-07-23 09:42:50,393 p=59700 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере] ******************************************************************************************************
2025-07-23 09:42:50,393 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:50 +0000 (0:00:00.029)       0:00:00.866 ******** 
2025-07-23 09:42:50,664 p=59700 u=master n=ansible | ok: [sm01]
2025-07-23 09:42:50,667 p=59700 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для распространения] **************************************************************************************************
2025-07-23 09:42:50,668 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:50 +0000 (0:00:00.274)       0:00:01.140 ******** 
2025-07-23 09:42:50,935 p=59700 u=master n=ansible | changed: [sm01]
2025-07-23 09:42:50,940 p=59700 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка инвентаря] *********************************************************************************************************************************
2025-07-23 09:42:50,941 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:50 +0000 (0:00:00.273)       0:00:01.413 ******** 
2025-07-23 09:42:50,963 p=59700 u=master n=ansible | ok: [sm01] => 
  msg: |-
    Узел: sm01
    Группы: ['cluster_nodes', 'jwt_nodes', 'nfs_server', 'slurm_cluster', 'slurm_master']
    В slurm_master: True
2025-07-23 09:42:50,967 p=59700 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01)] ******************************************************************************************
2025-07-23 09:42:50,967 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:50 +0000 (0:00:00.026)       0:00:01.440 ******** 
2025-07-23 09:42:51,248 p=59700 u=master n=ansible | changed: [sm01]
2025-07-23 09:42:51,252 p=59700 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат копирования на master] ********************************************************************************************************************
2025-07-23 09:42:51,252 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:51 +0000 (0:00:00.285)       0:00:01.725 ******** 
2025-07-23 09:42:51,276 p=59700 u=master n=ansible | ok: [sm01] => 
  copy_result.stdout_lines:
  - Скопировано 20 файлов из bin/
  - Скопировано 6 файлов из sbin/
  - Скопировано lib/
  - Скопировано share/
  - === Результат копирования ===
  - total 12
  - drwxr-xr-x 3 root root 4096 Jul 23 12:42 .
  - drwxr-xr-x 3 root root 4096 Jul 23 12:42 ..
  - drwxr-xr-x 2 root root 4096 Jul 23 12:42 {bin,sbin,lib,share}
  - 'Файлов в bin/: 0'
  - 'Файлов в sbin/: 0'
2025-07-23 09:42:51,280 p=59700 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01)] ************************************************************************************************************
2025-07-23 09:42:51,280 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:51 +0000 (0:00:00.027)       0:00:01.752 ******** 
2025-07-23 09:42:51,296 p=59700 u=master n=ansible | skipping: [sm01]
2025-07-23 09:42:51,299 p=59700 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01)] **************************************************************************************************
2025-07-23 09:42:51,300 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:51 +0000 (0:00:00.019)       0:00:01.772 ******** 
2025-07-23 09:42:51,315 p=59700 u=master n=ansible | skipping: [sm01]
2025-07-23 09:42:51,318 p=59700 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат установки на узлах] ***********************************************************************************************************************
2025-07-23 09:42:51,318 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:51 +0000 (0:00:00.018)       0:00:01.791 ******** 
2025-07-23 09:42:51,334 p=59700 u=master n=ansible | skipping: [sm01]
2025-07-23 09:42:51,338 p=59700 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:42:51,338 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:51 +0000 (0:00:00.019)       0:00:01.811 ******** 
2025-07-23 09:42:51,603 p=59700 u=master n=ansible | changed: [sm01]
2025-07-23 09:42:51,608 p=59700 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:42:51,608 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:51 +0000 (0:00:00.269)       0:00:02.080 ******** 
2025-07-23 09:42:51,626 p=59700 u=master n=ansible | skipping: [sm01]
2025-07-23 09:42:51,630 p=59700 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:42:51,630 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:51 +0000 (0:00:00.022)       0:00:02.103 ******** 
2025-07-23 09:42:51,647 p=59700 u=master n=ansible | skipping: [sm01]
2025-07-23 09:42:51,651 p=59700 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:42:51,651 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:51 +0000 (0:00:00.020)       0:00:02.124 ******** 
2025-07-23 09:42:51,918 p=59700 u=master n=ansible | ok: [sm01]
2025-07-23 09:42:51,931 p=59700 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 09:42:51,931 p=59700 u=master n=ansible | sm01                       : ok=10   changed=4    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
2025-07-23 09:42:51,931 p=59700 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 2 seconds
2025-07-23 09:42:51,931 p=59700 u=master n=ansible | Wednesday 23 July 2025  09:42:51 +0000 (0:00:00.279)       0:00:02.404 ******** 
2025-07-23 09:42:51,931 p=59700 u=master n=ansible | =============================================================================== 
2025-07-23 09:42:51,932 p=59700 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------------------ 0.41s
2025-07-23 09:42:51,932 p=59700 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master --------------------------------------------------------------------------------------------------------- 0.40s
2025-07-23 09:42:51,932 p=59700 u=master n=ansible | slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01) ------------------------------------------------------------------------------------------ 0.29s
2025-07-23 09:42:51,932 p=59700 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:42:51,932 p=59700 u=master n=ansible | slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере ------------------------------------------------------------------------------------------------------ 0.27s
2025-07-23 09:42:51,932 p=59700 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание временной директории для распространения -------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 09:42:51,932 p=59700 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 09:42:51,932 p=59700 u=master n=ansible | slurm_build : [SLURM_BUILD] Размер установки Slurm ----------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:42:51,932 p=59700 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат копирования на master -------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:42:51,932 p=59700 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка инвентаря --------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:42:51,932 p=59700 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:42:51,933 p=59700 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:42:51,933 p=59700 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат установки на узлах ----------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:42:51,933 p=59700 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01) ------------------------------------------------------------------------------------------------------------ 0.02s
2025-07-23 09:42:51,933 p=59700 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01) -------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:43:44,742 p=59779 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:43:44,742 p=59779 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:43:45,360 p=59779 u=master n=ansible | sm01 | FAILED | rc=2 >>
ls: cannot access '/sw/slurm-dist/': No such file or directorynon-zero return code

2025-07-23 09:48:14,228 p=59855 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:48:14,228 p=59855 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:48:15,592 p=59855 u=master n=ansible | sm01 | CHANGED | rc=0 >>


2025-07-23 09:48:28,612 p=59900 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:48:28,613 p=59900 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:48:29,064 p=59900 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 09:48:29,092 p=59900 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] ************************************************************************************************************
2025-07-23 09:48:29,092 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:29 +0000 (0:00:00.030)       0:00:00.030 ******** 
2025-07-23 09:48:29,506 p=59900 u=master n=ansible | ok: [sm01]
2025-07-23 09:48:29,510 p=59900 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] *********************************************************************************************************
2025-07-23 09:48:29,510 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:29 +0000 (0:00:00.418)       0:00:00.448 ******** 
2025-07-23 09:48:29,905 p=59900 u=master n=ansible | changed: [sm01]
2025-07-23 09:48:29,910 p=59900 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] *****************************************************************************************************************************
2025-07-23 09:48:29,910 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:29 +0000 (0:00:00.399)       0:00:00.848 ******** 
2025-07-23 09:48:29,934 p=59900 u=master n=ansible | ok: [sm01] => 
  msg: "Размер установки Slurm на sm01: 483M\t/opt/slurm"
2025-07-23 09:48:29,938 p=59900 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере] ******************************************************************************************************
2025-07-23 09:48:29,938 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:29 +0000 (0:00:00.027)       0:00:00.876 ******** 
2025-07-23 09:48:30,212 p=59900 u=master n=ansible | ok: [sm01]
2025-07-23 09:48:30,216 p=59900 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для распространения] **************************************************************************************************
2025-07-23 09:48:30,216 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:30 +0000 (0:00:00.277)       0:00:01.154 ******** 
2025-07-23 09:48:30,485 p=59900 u=master n=ansible | changed: [sm01]
2025-07-23 09:48:30,491 p=59900 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка инвентаря] *********************************************************************************************************************************
2025-07-23 09:48:30,491 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:30 +0000 (0:00:00.274)       0:00:01.429 ******** 
2025-07-23 09:48:30,514 p=59900 u=master n=ansible | ok: [sm01] => 
  msg: |-
    Узел: sm01
    Группы: ['cluster_nodes', 'jwt_nodes', 'nfs_server', 'slurm_cluster', 'slurm_master']
    В slurm_master: True
2025-07-23 09:48:30,518 p=59900 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01)] ******************************************************************************************
2025-07-23 09:48:30,518 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:30 +0000 (0:00:00.027)       0:00:01.456 ******** 
2025-07-23 09:48:30,802 p=59900 u=master n=ansible | changed: [sm01]
2025-07-23 09:48:30,806 p=59900 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат копирования на master] ********************************************************************************************************************
2025-07-23 09:48:30,807 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:30 +0000 (0:00:00.288)       0:00:01.745 ******** 
2025-07-23 09:48:30,832 p=59900 u=master n=ansible | ok: [sm01] => 
  copy_result.stdout_lines:
  - Скопировано 20 файлов из bin/
  - Скопировано 6 файлов из sbin/
  - Скопировано lib/
  - Скопировано share/
  - === Результат копирования ===
  - total 12
  - drwxr-xr-x 3 root root 4096 Jul 23 12:48 .
  - drwxr-xr-x 3 root root 4096 Jul 23 12:48 ..
  - drwxr-xr-x 2 root root 4096 Jul 23 12:48 {bin,sbin,lib,share}
  - 'Файлов в bin/: 0'
  - 'Файлов в sbin/: 0'
2025-07-23 09:48:30,836 p=59900 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01)] ************************************************************************************************************
2025-07-23 09:48:30,836 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:30 +0000 (0:00:00.029)       0:00:01.774 ******** 
2025-07-23 09:48:30,854 p=59900 u=master n=ansible | skipping: [sm01]
2025-07-23 09:48:30,858 p=59900 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01)] **************************************************************************************************
2025-07-23 09:48:30,858 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:30 +0000 (0:00:00.021)       0:00:01.796 ******** 
2025-07-23 09:48:30,874 p=59900 u=master n=ansible | skipping: [sm01]
2025-07-23 09:48:30,877 p=59900 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат установки на узлах] ***********************************************************************************************************************
2025-07-23 09:48:30,878 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:30 +0000 (0:00:00.019)       0:00:01.816 ******** 
2025-07-23 09:48:30,893 p=59900 u=master n=ansible | skipping: [sm01]
2025-07-23 09:48:30,898 p=59900 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:48:30,898 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:30 +0000 (0:00:00.020)       0:00:01.836 ******** 
2025-07-23 09:48:31,168 p=59900 u=master n=ansible | changed: [sm01]
2025-07-23 09:48:31,172 p=59900 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:48:31,172 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:31 +0000 (0:00:00.274)       0:00:02.110 ******** 
2025-07-23 09:48:31,190 p=59900 u=master n=ansible | skipping: [sm01]
2025-07-23 09:48:31,194 p=59900 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:48:31,194 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:31 +0000 (0:00:00.022)       0:00:02.133 ******** 
2025-07-23 09:48:31,212 p=59900 u=master n=ansible | skipping: [sm01]
2025-07-23 09:48:31,216 p=59900 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:48:31,216 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:31 +0000 (0:00:00.021)       0:00:02.154 ******** 
2025-07-23 09:48:31,488 p=59900 u=master n=ansible | ok: [sm01]
2025-07-23 09:48:31,501 p=59900 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 09:48:31,502 p=59900 u=master n=ansible | sm01                       : ok=10   changed=4    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
2025-07-23 09:48:31,502 p=59900 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 2 seconds
2025-07-23 09:48:31,502 p=59900 u=master n=ansible | Wednesday 23 July 2025  09:48:31 +0000 (0:00:00.285)       0:00:02.440 ******** 
2025-07-23 09:48:31,502 p=59900 u=master n=ansible | =============================================================================== 
2025-07-23 09:48:31,502 p=59900 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------------------ 0.42s
2025-07-23 09:48:31,502 p=59900 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master --------------------------------------------------------------------------------------------------------- 0.40s
2025-07-23 09:48:31,502 p=59900 u=master n=ansible | slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01) ------------------------------------------------------------------------------------------ 0.29s
2025-07-23 09:48:31,503 p=59900 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.29s
2025-07-23 09:48:31,503 p=59900 u=master n=ansible | slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере ------------------------------------------------------------------------------------------------------ 0.28s
2025-07-23 09:48:31,503 p=59900 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание временной директории для распространения -------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 09:48:31,503 p=59900 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 09:48:31,503 p=59900 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат копирования на master -------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:48:31,503 p=59900 u=master n=ansible | slurm_build : [SLURM_BUILD] Размер установки Slurm ----------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:48:31,503 p=59900 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка инвентаря --------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:48:31,503 p=59900 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:48:31,503 p=59900 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:48:31,503 p=59900 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01) ------------------------------------------------------------------------------------------------------------ 0.02s
2025-07-23 09:48:31,503 p=59900 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат установки на узлах ----------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:48:31,503 p=59900 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01) -------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:49:10,772 p=59964 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:49:10,772 p=59964 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:49:11,409 p=59964 u=master n=ansible | sm01 | FAILED | rc=2 >>
ls: cannot access '/sw/slurm-dist/': No such file or directorynon-zero return code

2025-07-23 09:51:32,449 p=60017 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:51:32,449 p=60017 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:51:33,802 p=60017 u=master n=ansible | sm01 | CHANGED | rc=0 >>


2025-07-23 09:51:52,759 p=60084 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:51:52,759 p=60084 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:51:53,216 p=60084 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 09:51:53,244 p=60084 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] ************************************************************************************************************
2025-07-23 09:51:53,244 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:53 +0000 (0:00:00.031)       0:00:00.031 ******** 
2025-07-23 09:51:53,648 p=60084 u=master n=ansible | ok: [sm01]
2025-07-23 09:51:53,653 p=60084 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] *********************************************************************************************************
2025-07-23 09:51:53,653 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:53 +0000 (0:00:00.408)       0:00:00.439 ******** 
2025-07-23 09:51:54,104 p=60084 u=master n=ansible | changed: [sm01]
2025-07-23 09:51:54,110 p=60084 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] *****************************************************************************************************************************
2025-07-23 09:51:54,110 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:54 +0000 (0:00:00.456)       0:00:00.896 ******** 
2025-07-23 09:51:54,136 p=60084 u=master n=ansible | ok: [sm01] => 
  msg: "Размер установки Slurm на sm01: 483M\t/opt/slurm"
2025-07-23 09:51:54,140 p=60084 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере] ******************************************************************************************************
2025-07-23 09:51:54,141 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:54 +0000 (0:00:00.030)       0:00:00.927 ******** 
2025-07-23 09:51:54,412 p=60084 u=master n=ansible | ok: [sm01]
2025-07-23 09:51:54,416 p=60084 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для распространения] **************************************************************************************************
2025-07-23 09:51:54,416 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:54 +0000 (0:00:00.275)       0:00:01.203 ******** 
2025-07-23 09:51:54,689 p=60084 u=master n=ansible | changed: [sm01]
2025-07-23 09:51:54,695 p=60084 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка инвентаря] *********************************************************************************************************************************
2025-07-23 09:51:54,695 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:54 +0000 (0:00:00.279)       0:00:01.482 ******** 
2025-07-23 09:51:54,720 p=60084 u=master n=ansible | ok: [sm01] => 
  msg: |-
    Узел: sm01
    Группы: ['cluster_nodes', 'jwt_nodes', 'nfs_server', 'slurm_cluster', 'slurm_master']
    В slurm_master: True
2025-07-23 09:51:54,724 p=60084 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01)] ******************************************************************************************
2025-07-23 09:51:54,724 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:54 +0000 (0:00:00.028)       0:00:01.511 ******** 
2025-07-23 09:51:55,019 p=60084 u=master n=ansible | changed: [sm01]
2025-07-23 09:51:55,024 p=60084 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат копирования на master] ********************************************************************************************************************
2025-07-23 09:51:55,024 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:55 +0000 (0:00:00.300)       0:00:01.811 ******** 
2025-07-23 09:51:55,051 p=60084 u=master n=ansible | ok: [sm01] => 
  copy_result.stdout_lines:
  - Скопировано 20 файлов из bin/
  - Скопировано 6 файлов из sbin/
  - Скопировано lib/
  - Скопировано share/
  - === Результат копирования ===
  - total 12
  - drwxr-xr-x 3 root root 4096 Jul 23 12:51 .
  - drwxr-xr-x 3 root root 4096 Jul 23 12:51 ..
  - drwxr-xr-x 2 root root 4096 Jul 23 12:51 {bin,sbin,lib,share}
  - 'Файлов в bin/: 0'
  - 'Файлов в sbin/: 0'
2025-07-23 09:51:55,055 p=60084 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01)] ************************************************************************************************************
2025-07-23 09:51:55,055 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:55 +0000 (0:00:00.030)       0:00:01.842 ******** 
2025-07-23 09:51:55,072 p=60084 u=master n=ansible | skipping: [sm01]
2025-07-23 09:51:55,077 p=60084 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01)] **************************************************************************************************
2025-07-23 09:51:55,077 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:55 +0000 (0:00:00.021)       0:00:01.863 ******** 
2025-07-23 09:51:55,094 p=60084 u=master n=ansible | skipping: [sm01]
2025-07-23 09:51:55,098 p=60084 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат установки на узлах] ***********************************************************************************************************************
2025-07-23 09:51:55,098 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:55 +0000 (0:00:00.021)       0:00:01.885 ******** 
2025-07-23 09:51:55,116 p=60084 u=master n=ansible | skipping: [sm01]
2025-07-23 09:51:55,121 p=60084 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:51:55,121 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:55 +0000 (0:00:00.022)       0:00:01.907 ******** 
2025-07-23 09:51:55,394 p=60084 u=master n=ansible | changed: [sm01]
2025-07-23 09:51:55,399 p=60084 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:51:55,399 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:55 +0000 (0:00:00.278)       0:00:02.186 ******** 
2025-07-23 09:51:55,418 p=60084 u=master n=ansible | skipping: [sm01]
2025-07-23 09:51:55,422 p=60084 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:51:55,422 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:55 +0000 (0:00:00.023)       0:00:02.209 ******** 
2025-07-23 09:51:55,439 p=60084 u=master n=ansible | skipping: [sm01]
2025-07-23 09:51:55,443 p=60084 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:51:55,443 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:55 +0000 (0:00:00.021)       0:00:02.230 ******** 
2025-07-23 09:51:55,731 p=60084 u=master n=ansible | ok: [sm01]
2025-07-23 09:51:55,744 p=60084 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 09:51:55,745 p=60084 u=master n=ansible | sm01                       : ok=10   changed=4    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
2025-07-23 09:51:55,745 p=60084 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 2 seconds
2025-07-23 09:51:55,745 p=60084 u=master n=ansible | Wednesday 23 July 2025  09:51:55 +0000 (0:00:00.301)       0:00:02.532 ******** 
2025-07-23 09:51:55,745 p=60084 u=master n=ansible | =============================================================================== 
2025-07-23 09:51:55,745 p=60084 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master --------------------------------------------------------------------------------------------------------- 0.46s
2025-07-23 09:51:55,745 p=60084 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------------------ 0.41s
2025-07-23 09:51:55,746 p=60084 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-23 09:51:55,746 p=60084 u=master n=ansible | slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01) ------------------------------------------------------------------------------------------ 0.30s
2025-07-23 09:51:55,746 p=60084 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание временной директории для распространения -------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:51:55,746 p=60084 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:51:55,746 p=60084 u=master n=ansible | slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере ------------------------------------------------------------------------------------------------------ 0.28s
2025-07-23 09:51:55,746 p=60084 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат копирования на master -------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:51:55,746 p=60084 u=master n=ansible | slurm_build : [SLURM_BUILD] Размер установки Slurm ----------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:51:55,746 p=60084 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка инвентаря --------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:51:55,746 p=60084 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:51:55,746 p=60084 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат установки на узлах ----------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:51:55,746 p=60084 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01) ------------------------------------------------------------------------------------------------------------ 0.02s
2025-07-23 09:51:55,747 p=60084 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01) -------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:51:55,747 p=60084 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:52:37,233 p=60163 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:52:37,234 p=60163 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:52:37,882 p=60163 u=master n=ansible | sm01 | CHANGED | rc=0 >>
Нет slurm директорий

2025-07-23 09:53:10,893 p=60225 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:53:10,893 p=60225 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:53:11,351 p=60225 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 09:53:11,379 p=60225 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах] ************************************************************************************************************
2025-07-23 09:53:11,379 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:11 +0000 (0:00:00.031)       0:00:00.031 ******** 
2025-07-23 09:53:11,789 p=60225 u=master n=ansible | ok: [sm01]
2025-07-23 09:53:11,793 p=60225 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master] *********************************************************************************************************
2025-07-23 09:53:11,794 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:11 +0000 (0:00:00.414)       0:00:00.445 ******** 
2025-07-23 09:53:12,194 p=60225 u=master n=ansible | changed: [sm01]
2025-07-23 09:53:12,267 p=60225 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Размер установки Slurm] *****************************************************************************************************************************
2025-07-23 09:53:12,267 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:12 +0000 (0:00:00.473)       0:00:00.919 ******** 
2025-07-23 09:53:12,293 p=60225 u=master n=ansible | ok: [sm01] => 
  msg: "Размер установки Slurm на sm01: 483M\t/opt/slurm"
2025-07-23 09:53:12,297 p=60225 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере] ******************************************************************************************************
2025-07-23 09:53:12,297 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:12 +0000 (0:00:00.029)       0:00:00.948 ******** 
2025-07-23 09:53:12,561 p=60225 u=master n=ansible | ok: [sm01]
2025-07-23 09:53:12,565 p=60225 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание временной директории для распространения] **************************************************************************************************
2025-07-23 09:53:12,565 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:12 +0000 (0:00:00.268)       0:00:01.217 ******** 
2025-07-23 09:53:12,831 p=60225 u=master n=ansible | changed: [sm01]
2025-07-23 09:53:12,837 p=60225 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка инвентаря] *********************************************************************************************************************************
2025-07-23 09:53:12,837 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:12 +0000 (0:00:00.271)       0:00:01.488 ******** 
2025-07-23 09:53:12,860 p=60225 u=master n=ansible | ok: [sm01] => 
  msg: |-
    Узел: sm01
    Группы: ['cluster_nodes', 'jwt_nodes', 'nfs_server', 'slurm_cluster', 'slurm_master']
    В slurm_master: True
2025-07-23 09:53:12,864 p=60225 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01)] ******************************************************************************************
2025-07-23 09:53:12,864 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:12 +0000 (0:00:00.027)       0:00:01.515 ******** 
2025-07-23 09:53:13,141 p=60225 u=master n=ansible | changed: [sm01]
2025-07-23 09:53:13,145 p=60225 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат копирования на master] ********************************************************************************************************************
2025-07-23 09:53:13,145 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:13 +0000 (0:00:00.281)       0:00:01.797 ******** 
2025-07-23 09:53:13,170 p=60225 u=master n=ansible | ok: [sm01] => 
  copy_result.stdout_lines:
  - Скопировано 20 файлов из bin/
  - Скопировано 6 файлов из sbin/
  - Скопировано lib/
  - Скопировано share/
  - === Результат копирования ===
  - total 12
  - drwxr-xr-x 3 root root 4096 Jul 23 12:53 .
  - drwxr-xr-x 3 root root 4096 Jul 23 12:53 ..
  - drwxr-xr-x 2 root root 4096 Jul 23 12:53 {bin,sbin,lib,share}
  - 'Файлов в bin/: 0'
  - 'Файлов в sbin/: 0'
2025-07-23 09:53:13,174 p=60225 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01)] ************************************************************************************************************
2025-07-23 09:53:13,174 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:13 +0000 (0:00:00.028)       0:00:01.825 ******** 
2025-07-23 09:53:13,190 p=60225 u=master n=ansible | skipping: [sm01]
2025-07-23 09:53:13,193 p=60225 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01)] **************************************************************************************************
2025-07-23 09:53:13,194 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:13 +0000 (0:00:00.019)       0:00:01.845 ******** 
2025-07-23 09:53:13,209 p=60225 u=master n=ansible | skipping: [sm01]
2025-07-23 09:53:13,213 p=60225 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат установки на узлах] ***********************************************************************************************************************
2025-07-23 09:53:13,213 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:13 +0000 (0:00:00.019)       0:00:01.864 ******** 
2025-07-23 09:53:13,228 p=60225 u=master n=ansible | skipping: [sm01]
2025-07-23 09:53:13,232 p=60225 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:53:13,233 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:13 +0000 (0:00:00.019)       0:00:01.884 ******** 
2025-07-23 09:53:13,500 p=60225 u=master n=ansible | changed: [sm01]
2025-07-23 09:53:13,504 p=60225 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:53:13,504 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:13 +0000 (0:00:00.271)       0:00:02.156 ******** 
2025-07-23 09:53:13,522 p=60225 u=master n=ansible | skipping: [sm01]
2025-07-23 09:53:13,526 p=60225 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:53:13,526 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:13 +0000 (0:00:00.021)       0:00:02.178 ******** 
2025-07-23 09:53:13,542 p=60225 u=master n=ansible | skipping: [sm01]
2025-07-23 09:53:13,546 p=60225 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS] ********************************************************************************************************************
2025-07-23 09:53:13,547 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:13 +0000 (0:00:00.020)       0:00:02.198 ******** 
2025-07-23 09:53:13,811 p=60225 u=master n=ansible | ok: [sm01]
2025-07-23 09:53:13,824 p=60225 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 09:53:13,824 p=60225 u=master n=ansible | sm01                       : ok=10   changed=4    unreachable=0    failed=0    skipped=5    rescued=0    ignored=0   
2025-07-23 09:53:13,824 p=60225 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 2 seconds
2025-07-23 09:53:13,825 p=60225 u=master n=ansible | Wednesday 23 July 2025  09:53:13 +0000 (0:00:00.277)       0:00:02.476 ******** 
2025-07-23 09:53:13,825 p=60225 u=master n=ansible | =============================================================================== 
2025-07-23 09:53:13,825 p=60225 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка размера установки Slurm на master --------------------------------------------------------------------------------------------------------- 0.47s
2025-07-23 09:53:13,825 p=60225 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание директории Slurm на всех узлах ------------------------------------------------------------------------------------------------------------ 0.41s
2025-07-23 09:53:13,825 p=60225 u=master n=ansible | slurm_build : [SLURM_BUILD] Быстрое копирование бинарников через NFS (только на sm01) ------------------------------------------------------------------------------------------ 0.28s
2025-07-23 09:53:13,825 p=60225 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 09:53:13,825 p=60225 u=master n=ansible | slurm_build : [SLURM_BUILD] Очистка временных файлов из NFS -------------------------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 09:53:13,825 p=60225 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание временной директории для распространения -------------------------------------------------------------------------------------------------- 0.27s
2025-07-23 09:53:13,826 p=60225 u=master n=ansible | slurm_build : [SLURM_BUILD] Исправление прав доступа к /sw на NFS сервере ------------------------------------------------------------------------------------------------------ 0.27s
2025-07-23 09:53:13,826 p=60225 u=master n=ansible | slurm_build : [SLURM_BUILD] Размер установки Slurm ----------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:53:13,826 p=60225 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат копирования на master -------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:53:13,826 p=60225 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка инвентаря --------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 09:53:13,826 p=60225 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:53:13,826 p=60225 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:53:13,826 p=60225 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS (не на sm01) ------------------------------------------------------------------------------------------------------------ 0.02s
2025-07-23 09:53:13,826 p=60225 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат установки на узлах ----------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:53:13,826 p=60225 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS (не на sm01) -------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 09:57:21,648 p=60418 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:57:21,649 p=60418 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:57:23,133 p=60418 u=master n=ansible | sm01 | CHANGED | rc=0 >>


2025-07-23 09:57:31,387 p=60463 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:57:31,387 p=60463 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:57:31,818 p=60463 u=master n=ansible | PLAY [Тестирование роли slurm_build] **************************************************************************************************************************************************
2025-07-23 09:57:31,851 p=60463 u=master n=ansible | TASK [common : [COMMON] Проверка работы MUNGE] ****************************************************************************************************************************************
2025-07-23 09:57:31,851 p=60463 u=master n=ansible | Wednesday 23 July 2025  09:57:31 +0000 (0:00:00.035)       0:00:00.035 ******** 
2025-07-23 09:57:32,242 p=60463 u=master n=ansible | ok: [sm01]
2025-07-23 09:57:32,993 p=60463 u=master n=ansible | ok: [cn02]
2025-07-23 09:57:33,170 p=60463 u=master n=ansible | ok: [sm02]
2025-07-23 09:57:33,186 p=60463 u=master n=ansible | ok: [cn01]
2025-07-23 09:57:33,191 p=60463 u=master n=ansible | TASK [common : [COMMON] Результат проверки MUNGE] *************************************************************************************************************************************
2025-07-23 09:57:33,191 p=60463 u=master n=ansible | Wednesday 23 July 2025  09:57:33 +0000 (0:00:01.340)       0:00:01.375 ******** 
2025-07-23 09:57:33,226 p=60463 u=master n=ansible | ok: [sm01] => 
  msg: MUNGE работает корректно на sm01
2025-07-23 09:57:33,227 p=60463 u=master n=ansible | ok: [sm02] => 
  msg: MUNGE работает корректно на sm02
2025-07-23 09:57:33,231 p=60463 u=master n=ansible | ok: [cn01] => 
  msg: MUNGE работает корректно на cn01
2025-07-23 09:57:33,241 p=60463 u=master n=ansible | ok: [cn02] => 
  msg: MUNGE работает корректно на cn02
2025-07-23 09:57:33,245 p=60463 u=master n=ansible | TASK [common : [COMMON] Проверка HWLOC] ***********************************************************************************************************************************************
2025-07-23 09:57:33,245 p=60463 u=master n=ansible | Wednesday 23 July 2025  09:57:33 +0000 (0:00:00.053)       0:00:01.429 ******** 
2025-07-23 09:57:33,519 p=60463 u=master n=ansible | ok: [sm01]
2025-07-23 09:57:33,524 p=60463 u=master n=ansible | ok: [sm02]
2025-07-23 09:57:33,529 p=60463 u=master n=ansible | ok: [cn01]
2025-07-23 09:57:33,537 p=60463 u=master n=ansible | ok: [cn02]
2025-07-23 09:57:33,543 p=60463 u=master n=ansible | TASK [common : [COMMON] Версия HWLOC] *************************************************************************************************************************************************
2025-07-23 09:57:33,543 p=60463 u=master n=ansible | Wednesday 23 July 2025  09:57:33 +0000 (0:00:00.298)       0:00:01.727 ******** 
2025-07-23 09:57:33,575 p=60463 u=master n=ansible | ok: [sm01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 09:57:33,576 p=60463 u=master n=ansible | ok: [sm02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 09:57:33,580 p=60463 u=master n=ansible | ok: [cn01] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 09:57:33,591 p=60463 u=master n=ansible | ok: [cn02] => 
  msg: 'Установлена версия HWLOC: lstopo 2.10.0'
2025-07-23 09:57:33,595 p=60463 u=master n=ansible | TASK [common : [COMMON] Роль common выполнена успешно] ********************************************************************************************************************************
2025-07-23 09:57:33,595 p=60463 u=master n=ansible | Wednesday 23 July 2025  09:57:33 +0000 (0:00:00.051)       0:00:01.779 ******** 
2025-07-23 09:57:33,618 p=60463 u=master n=ansible | ok: [sm01] => 
  msg: ✅ Узел sm01 готов для установки Slurm
2025-07-23 09:57:33,629 p=60463 u=master n=ansible | ok: [sm02] => 
  msg: ✅ Узел sm02 готов для установки Slurm
2025-07-23 09:57:33,633 p=60463 u=master n=ansible | ok: [cn01] => 
  msg: ✅ Узел cn01 готов для установки Slurm
2025-07-23 09:57:33,644 p=60463 u=master n=ansible | ok: [cn02] => 
  msg: ✅ Узел cn02 готов для установки Slurm
2025-07-23 09:57:33,657 p=60463 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] ПРОСТОЕ копирование через NFS] **********************************************************************************************************************
2025-07-23 09:57:33,657 p=60463 u=master n=ansible | Wednesday 23 July 2025  09:57:33 +0000 (0:00:00.062)       0:00:01.841 ******** 
2025-07-23 09:57:33,690 p=60463 u=master n=ansible | skipping: [sm02]
2025-07-23 09:57:33,691 p=60463 u=master n=ansible | skipping: [cn01]
2025-07-23 09:57:33,700 p=60463 u=master n=ansible | skipping: [cn02]
2025-07-23 09:57:35,916 p=60463 u=master n=ansible | changed: [sm01]
2025-07-23 09:57:35,921 p=60463 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Ожидание копирования в NFS] *************************************************************************************************************************
2025-07-23 09:57:35,922 p=60463 u=master n=ansible | Wednesday 23 July 2025  09:57:35 +0000 (0:00:02.264)       0:00:04.106 ******** 
2025-07-23 09:57:35,956 p=60463 u=master n=ansible | skipping: [sm01]
2025-07-23 09:57:36,347 p=60463 u=master n=ansible | ok: [sm02]
2025-07-23 09:57:36,357 p=60463 u=master n=ansible | ok: [cn02]
2025-07-23 09:57:36,358 p=60463 u=master n=ansible | ok: [cn01]
2025-07-23 09:57:36,361 p=60463 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS] ***************************************************************************************************************
2025-07-23 09:57:36,362 p=60463 u=master n=ansible | Wednesday 23 July 2025  09:57:36 +0000 (0:00:00.440)       0:00:04.546 ******** 
2025-07-23 09:57:36,385 p=60463 u=master n=ansible | skipping: [sm01]
2025-07-23 09:57:38,513 p=60463 u=master n=ansible | changed: [sm02]
2025-07-23 09:57:38,883 p=60463 u=master n=ansible | changed: [cn02]
2025-07-23 09:57:39,187 p=60463 u=master n=ansible | changed: [cn01]
2025-07-23 09:57:39,192 p=60463 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Создание символических ссылок] **********************************************************************************************************************
2025-07-23 09:57:39,192 p=60463 u=master n=ansible | Wednesday 23 July 2025  09:57:39 +0000 (0:00:02.830)       0:00:07.376 ******** 
2025-07-23 09:57:39,615 p=60463 u=master n=ansible | ok: [sm01] => (item=sinfo)
2025-07-23 09:57:39,622 p=60463 u=master n=ansible | changed: [cn01] => (item=sinfo)
2025-07-23 09:57:39,634 p=60463 u=master n=ansible | changed: [sm02] => (item=sinfo)
2025-07-23 09:57:39,679 p=60463 u=master n=ansible | changed: [cn02] => (item=sinfo)
2025-07-23 09:57:39,885 p=60463 u=master n=ansible | ok: [sm01] => (item=squeue)
2025-07-23 09:57:39,888 p=60463 u=master n=ansible | changed: [sm02] => (item=squeue)
2025-07-23 09:57:39,912 p=60463 u=master n=ansible | changed: [cn01] => (item=squeue)
2025-07-23 09:57:39,932 p=60463 u=master n=ansible | changed: [cn02] => (item=squeue)
2025-07-23 09:57:40,140 p=60463 u=master n=ansible | changed: [sm02] => (item=sbatch)
2025-07-23 09:57:40,141 p=60463 u=master n=ansible | ok: [sm01] => (item=sbatch)
2025-07-23 09:57:40,177 p=60463 u=master n=ansible | changed: [cn01] => (item=sbatch)
2025-07-23 09:57:40,178 p=60463 u=master n=ansible | changed: [cn02] => (item=sbatch)
2025-07-23 09:57:40,391 p=60463 u=master n=ansible | ok: [sm01] => (item=srun)
2025-07-23 09:57:40,396 p=60463 u=master n=ansible | changed: [sm02] => (item=srun)
2025-07-23 09:57:40,424 p=60463 u=master n=ansible | changed: [cn02] => (item=srun)
2025-07-23 09:57:40,453 p=60463 u=master n=ansible | changed: [cn01] => (item=srun)
2025-07-23 09:57:40,459 p=60463 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Проверка версии Slurm] ******************************************************************************************************************************
2025-07-23 09:57:40,459 p=60463 u=master n=ansible | Wednesday 23 July 2025  09:57:40 +0000 (0:00:01.267)       0:00:08.643 ******** 
2025-07-23 09:57:40,772 p=60463 u=master n=ansible | ok: [sm01]
2025-07-23 09:57:40,782 p=60463 u=master n=ansible | ok: [sm02]
2025-07-23 09:57:40,813 p=60463 u=master n=ansible | ok: [cn01]
2025-07-23 09:57:40,816 p=60463 u=master n=ansible | ok: [cn02]
2025-07-23 09:57:40,820 p=60463 u=master n=ansible | TASK [slurm_build : [SLURM_BUILD] Результат установки] ********************************************************************************************************************************
2025-07-23 09:57:40,820 p=60463 u=master n=ansible | Wednesday 23 July 2025  09:57:40 +0000 (0:00:00.360)       0:00:09.004 ******** 
2025-07-23 09:57:40,873 p=60463 u=master n=ansible | ok: [sm01] => 
  msg: '✅ Slurm установлен: '
2025-07-23 09:57:40,893 p=60463 u=master n=ansible | ok: [cn01] => 
  msg: '✅ Slurm установлен: '
2025-07-23 09:57:40,902 p=60463 u=master n=ansible | ok: [sm02] => 
  msg: '✅ Slurm установлен: '
2025-07-23 09:57:40,931 p=60463 u=master n=ansible | ok: [cn02] => 
  msg: '✅ Slurm установлен: '
2025-07-23 09:57:40,972 p=60463 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 09:57:40,972 p=60463 u=master n=ansible | cn01                       : ok=10   changed=2    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-07-23 09:57:40,972 p=60463 u=master n=ansible | cn02                       : ok=10   changed=2    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-07-23 09:57:40,972 p=60463 u=master n=ansible | sm01                       : ok=9    changed=1    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
2025-07-23 09:57:40,972 p=60463 u=master n=ansible | sm02                       : ok=10   changed=2    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-07-23 09:57:40,973 p=60463 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 9 seconds
2025-07-23 09:57:40,973 p=60463 u=master n=ansible | Wednesday 23 July 2025  09:57:40 +0000 (0:00:00.152)       0:00:09.157 ******** 
2025-07-23 09:57:40,973 p=60463 u=master n=ansible | =============================================================================== 
2025-07-23 09:57:40,973 p=60463 u=master n=ansible | slurm_build : [SLURM_BUILD] Копирование Slurm на все узлы из NFS --------------------------------------------------------------------------------------------------------------- 2.83s
2025-07-23 09:57:40,973 p=60463 u=master n=ansible | slurm_build : [SLURM_BUILD] ПРОСТОЕ копирование через NFS ---------------------------------------------------------------------------------------------------------------------- 2.26s
2025-07-23 09:57:40,973 p=60463 u=master n=ansible | common : [COMMON] Проверка работы MUNGE ---------------------------------------------------------------------------------------------------------------------------------------- 1.34s
2025-07-23 09:57:40,973 p=60463 u=master n=ansible | slurm_build : [SLURM_BUILD] Создание символических ссылок ---------------------------------------------------------------------------------------------------------------------- 1.27s
2025-07-23 09:57:40,973 p=60463 u=master n=ansible | slurm_build : [SLURM_BUILD] Ожидание копирования в NFS ------------------------------------------------------------------------------------------------------------------------- 0.44s
2025-07-23 09:57:40,973 p=60463 u=master n=ansible | slurm_build : [SLURM_BUILD] Проверка версии Slurm ------------------------------------------------------------------------------------------------------------------------------ 0.36s
2025-07-23 09:57:40,974 p=60463 u=master n=ansible | common : [COMMON] Проверка HWLOC ----------------------------------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-23 09:57:40,974 p=60463 u=master n=ansible | slurm_build : [SLURM_BUILD] Результат установки -------------------------------------------------------------------------------------------------------------------------------- 0.15s
2025-07-23 09:57:40,974 p=60463 u=master n=ansible | common : [COMMON] Роль common выполнена успешно -------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 09:57:40,974 p=60463 u=master n=ansible | common : [COMMON] Результат проверки MUNGE ------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:57:40,974 p=60463 u=master n=ansible | common : [COMMON] Версия HWLOC ------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 09:57:53,899 p=60640 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:57:53,900 p=60640 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 09:57:54,582 p=60640 u=master n=ansible | cn01 | CHANGED | rc=0 >>
Slurm не работаетsinfo: error: resolve_ctls_from_dns_srv: res_nsearch error: Unknown host
sinfo: error: fetch_config: DNS SRV lookup failed
sinfo: error: _establish_config_source: failed to fetch config
sinfo: fatal: Could not establish a configuration source

2025-07-23 09:57:54,592 p=60640 u=master n=ansible | cn02 | CHANGED | rc=0 >>
Slurm не работаетsinfo: error: resolve_ctls_from_dns_srv: res_nsearch error: Unknown host
sinfo: error: fetch_config: DNS SRV lookup failed
sinfo: error: _establish_config_source: failed to fetch config
sinfo: fatal: Could not establish a configuration source

2025-07-23 09:57:54,596 p=60640 u=master n=ansible | sm01 | CHANGED | rc=0 >>
Slurm не работаетsinfo: error: resolve_ctls_from_dns_srv: res_nsearch error: Unknown host
sinfo: error: fetch_config: DNS SRV lookup failed
sinfo: error: _establish_config_source: failed to fetch config
sinfo: fatal: Could not establish a configuration source

2025-07-23 09:57:54,596 p=60640 u=master n=ansible | sm02 | CHANGED | rc=0 >>
Slurm не работаетsinfo: error: resolve_ctls_from_dns_srv: res_nsearch error: Unknown host
sinfo: error: fetch_config: DNS SRV lookup failed
sinfo: error: _establish_config_source: failed to fetch config
sinfo: fatal: Could not establish a configuration source

2025-07-23 19:40:07,769 p=62625 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 19:40:07,769 p=62625 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 19:40:09,547 p=62625 u=master n=ansible | cn02 | CHANGED | rc=0 >>
НЕТ КОНФИГАls: cannot access '/etc/slurm/slurm.conf': No such file or directory

2025-07-23 19:40:09,590 p=62625 u=master n=ansible | sm01 | CHANGED | rc=0 >>
НЕТ КОНФИГАls: cannot access '/etc/slurm/slurm.conf': No such file or directory

2025-07-23 19:40:09,680 p=62625 u=master n=ansible | cn01 | CHANGED | rc=0 >>
НЕТ КОНФИГАls: cannot access '/etc/slurm/slurm.conf': No such file or directory

2025-07-23 19:40:09,685 p=62625 u=master n=ansible | sm02 | CHANGED | rc=0 >>
НЕТ КОНФИГАls: cannot access '/etc/slurm/slurm.conf': No such file or directory

2025-07-23 19:40:57,566 p=62751 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 19:40:57,566 p=62751 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 19:40:58,209 p=62751 u=master n=ansible | sm01 | CHANGED | rc=0 >>
sm01
127.0.1.1 sm01
10.20.90.166 sm01
10.20.90.161 sm02

2025-07-23 19:40:58,348 p=62751 u=master n=ansible | sm02 | CHANGED | rc=0 >>
sm02
127.0.1.1 sm02
10.20.90.166 sm01
10.20.90.161 sm02

2025-07-23 19:40:58,349 p=62751 u=master n=ansible | cn01 | CHANGED | rc=0 >>
cn01
10.20.90.166 sm01
10.20.90.161 sm02

2025-07-23 19:40:58,349 p=62751 u=master n=ansible | cn02 | CHANGED | rc=0 >>
cn02
10.20.90.166 sm01
10.20.90.161 sm02

2025-07-23 20:40:23,145 p=63520 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 20:40:23,145 p=63520 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 20:40:23,606 p=63520 u=master n=ansible | PLAY [Тестирование роли common] *******************************************************************************************************************************************************
2025-07-23 20:40:23,621 p=63520 u=master n=ansible | TASK [Gathering Facts] ****************************************************************************************************************************************************************
2025-07-23 20:40:23,621 p=63520 u=master n=ansible | Wednesday 23 July 2025  20:40:23 +0000 (0:00:00.018)       0:00:00.018 ******** 
2025-07-23 20:40:25,191 p=63520 u=master n=ansible | ok: [cn02]
2025-07-23 20:40:25,229 p=63520 u=master n=ansible | ok: [sm01]
2025-07-23 20:40:25,397 p=63520 u=master n=ansible | ok: [sm02]
2025-07-23 20:40:25,577 p=63520 u=master n=ansible | ok: [cn01]
2025-07-23 20:40:25,593 p=63520 u=master n=ansible | TASK [common : [COMMON] Установка MariaDB] ********************************************************************************************************************************************
2025-07-23 20:40:25,593 p=63520 u=master n=ansible | Wednesday 23 July 2025  20:40:25 +0000 (0:00:01.972)       0:00:01.990 ******** 
2025-07-23 20:40:25,630 p=63520 u=master n=ansible | skipping: [sm02]
2025-07-23 20:40:25,632 p=63520 u=master n=ansible | skipping: [cn01]
2025-07-23 20:40:25,640 p=63520 u=master n=ansible | skipping: [cn02]
2025-07-23 20:41:54,893 p=63520 u=master n=ansible | changed: [sm01]
2025-07-23 20:41:54,928 p=63520 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 20:41:54,928 p=63520 u=master n=ansible | cn01                       : ok=1    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-07-23 20:41:54,928 p=63520 u=master n=ansible | cn02                       : ok=1    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-07-23 20:41:54,928 p=63520 u=master n=ansible | sm01                       : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-23 20:41:54,929 p=63520 u=master n=ansible | sm02                       : ok=1    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
2025-07-23 20:41:54,929 p=63520 u=master n=ansible | Playbook run took 0 days, 0 hours, 1 minutes, 31 seconds
2025-07-23 20:41:54,929 p=63520 u=master n=ansible | Wednesday 23 July 2025  20:41:54 +0000 (0:01:29.335)       0:01:31.326 ******** 
2025-07-23 20:41:54,929 p=63520 u=master n=ansible | =============================================================================== 
2025-07-23 20:41:54,929 p=63520 u=master n=ansible | common : [COMMON] Установка MariaDB ------------------------------------------------------------------------------------------------------------------------------------------- 89.34s
2025-07-23 20:41:54,929 p=63520 u=master n=ansible | Gathering Facts ---------------------------------------------------------------------------------------------------------------------------------------------------------------- 1.97s
2025-07-23 20:42:04,773 p=63654 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 20:42:04,773 p=63654 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 20:42:05,418 p=63654 u=master n=ansible | sm01 | CHANGED | rc=0 >>
● mariadb.service - MariaDB 10.11.13 database server
     Loaded: loaded (/usr/lib/systemd/system/mariadb.service; enabled; preset: enabled)
     Active: active (running) since Wed 2025-07-23 23:41:37 MSK; 27s ago
       Docs: man:mariadbd(8)
             https://mariadb.com/kb/en/library/systemd/
   Main PID: 68993 (mariadbd)
     Status: "Taking your SQL requests now..."
      Tasks: 12 (limit: 92231)
     Memory: 81.0M (peak: 84.4M)
        CPU: 471ms
     CGroup: /system.slice/mariadb.service
             └─68993 /usr/sbin/mariadbd

Jul 23 23:41:37 sm01 mariadbd[68993]: 2025-07-23 23:41:37 0 [Note] InnoDB: File './ibtmp1' size is now 12.000MiB.
Jul 23 23:41:37 sm01 mariadbd[68993]: 2025-07-23 23:41:37 0 [Note] InnoDB: log sequence number 46846; transaction id 14
Jul 23 23:41:37 sm01 mariadbd[68993]: 2025-07-23 23:41:37 0 [Note] InnoDB: Loading buffer pool(s) from /var/lib/mysql/ib_buffer_pool
Jul 23 23:41:37 sm01 mariadbd[68993]: 2025-07-23 23:41:37 0 [Note] Plugin 'FEEDBACK' is disabled.
Jul 23 23:41:37 sm01 mariadbd[68993]: 2025-07-23 23:41:37 0 [Warning] You need to use --log-bin to make --expire-logs-days or --binlog-expire-logs-seconds work.
Jul 23 23:41:37 sm01 mariadbd[68993]: 2025-07-23 23:41:37 0 [Note] Server socket created on IP: '127.0.0.1'.
Jul 23 23:41:37 sm01 mariadbd[68993]: 2025-07-23 23:41:37 0 [Note] InnoDB: Buffer pool(s) load completed at 250723 23:41:37
Jul 23 23:41:37 sm01 mariadbd[68993]: 2025-07-23 23:41:37 0 [Note] /usr/sbin/mariadbd: ready for connections.
Jul 23 23:41:37 sm01 mariadbd[68993]: Version: '10.11.13-MariaDB-0ubuntu0.24.04.1'  socket: '/run/mysqld/mysqld.sock'  port: 3306  Ubuntu 24.04
Jul 23 23:41:37 sm01 systemd[1]: Started mariadb.service - MariaDB 10.11.13 database server.

2025-07-23 20:42:35,730 p=63717 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 20:42:35,730 p=63717 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 20:42:36,373 p=63717 u=master n=ansible | sm01 | CHANGED | rc=0 >>
VERSION()
10.11.13-MariaDB-0ubuntu0.24.04.1

2025-07-23 21:09:07,014 p=64130 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:09:07,014 p=64130 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:09:07,422 p=64130 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 21:09:07,436 p=64130 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 21:09:07,436 p=64130 u=master n=ansible | Wednesday 23 July 2025  21:09:07 +0000 (0:00:00.016)       0:00:00.016 ******** 
2025-07-23 21:09:07,459 p=64130 u=master n=ansible | fatal: [sm01]: FAILED! => 
  msg: |-
    The task includes an option with an undefined variable. The error was: 'slurm_install_prefix' is undefined. 'slurm_install_prefix' is undefined
  
    The error appears to be in '/home/master/22Jul/slurm-hpc-cluster/playbooks/test_slurm_master_simple.yml': line 18, column 7, but may
    be elsewhere in the file depending on the exact syntax problem.
  
    The offending line appears to be:
  
      tasks:
        - name: "[TEST] Информация о тестировании"
          ^ here
2025-07-23 21:09:07,460 p=64130 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:09:07,460 p=64130 u=master n=ansible | sm01                       : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 21:09:07,460 p=64130 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 0 seconds
2025-07-23 21:09:07,460 p=64130 u=master n=ansible | Wednesday 23 July 2025  21:09:07 +0000 (0:00:00.024)       0:00:00.040 ******** 
2025-07-23 21:09:07,461 p=64130 u=master n=ansible | =============================================================================== 
2025-07-23 21:09:07,461 p=64130 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 21:10:56,068 p=64200 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:10:56,069 p=64200 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:10:56,466 p=64200 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 21:10:56,480 p=64200 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 21:10:56,480 p=64200 u=master n=ansible | Wednesday 23 July 2025  21:10:56 +0000 (0:00:00.016)       0:00:00.016 ******** 
2025-07-23 21:10:56,503 p=64200 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 21:10:56,507 p=64200 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 21:10:56,507 p=64200 u=master n=ansible | Wednesday 23 July 2025  21:10:56 +0000 (0:00:00.027)       0:00:00.043 ******** 
2025-07-23 21:10:57,776 p=64200 u=master n=ansible | ok: [sm01]
2025-07-23 21:10:57,780 p=64200 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 21:10:57,780 p=64200 u=master n=ansible | Wednesday 23 July 2025  21:10:57 +0000 (0:00:01.272)       0:00:01.316 ******** 
2025-07-23 21:10:57,827 p=64200 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 21:10:57,837 p=64200 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:10:57,837 p=64200 u=master n=ansible | sm01                       : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-23 21:10:57,837 p=64200 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 1 seconds
2025-07-23 21:10:57,837 p=64200 u=master n=ansible | Wednesday 23 July 2025  21:10:57 +0000 (0:00:00.057)       0:00:01.373 ******** 
2025-07-23 21:10:57,838 p=64200 u=master n=ansible | =============================================================================== 
2025-07-23 21:10:57,838 p=64200 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.27s
2025-07-23 21:10:57,838 p=64200 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 21:10:57,838 p=64200 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:11:08,049 p=64262 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:11:08,049 p=64262 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:11:08,440 p=64262 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 21:11:08,454 p=64262 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 21:11:08,454 p=64262 u=master n=ansible | Wednesday 23 July 2025  21:11:08 +0000 (0:00:00.015)       0:00:00.015 ******** 
2025-07-23 21:11:08,477 p=64262 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 21:11:08,481 p=64262 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 21:11:08,481 p=64262 u=master n=ansible | Wednesday 23 July 2025  21:11:08 +0000 (0:00:00.027)       0:00:00.042 ******** 
2025-07-23 21:11:08,520 p=64262 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:11:08,520 p=64262 u=master n=ansible | sm01                       : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-23 21:11:08,520 p=64262 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 0 seconds
2025-07-23 21:11:08,520 p=64262 u=master n=ansible | Wednesday 23 July 2025  21:11:08 +0000 (0:00:00.038)       0:00:00.081 ******** 
2025-07-23 21:11:08,520 p=64262 u=master n=ansible | =============================================================================== 
2025-07-23 21:11:08,520 p=64262 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.04s
2025-07-23 21:11:08,521 p=64262 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:12:34,957 p=64318 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:12:34,957 p=64318 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:12:35,356 p=64318 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 21:12:35,369 p=64318 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 21:12:35,370 p=64318 u=master n=ansible | Wednesday 23 July 2025  21:12:35 +0000 (0:00:00.015)       0:00:00.015 ******** 
2025-07-23 21:12:35,393 p=64318 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 21:12:35,397 p=64318 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 21:12:35,397 p=64318 u=master n=ansible | Wednesday 23 July 2025  21:12:35 +0000 (0:00:00.027)       0:00:00.043 ******** 
2025-07-23 21:12:35,435 p=64318 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:12:35,435 p=64318 u=master n=ansible | sm01                       : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-23 21:12:35,436 p=64318 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 0 seconds
2025-07-23 21:12:35,436 p=64318 u=master n=ansible | Wednesday 23 July 2025  21:12:35 +0000 (0:00:00.039)       0:00:00.082 ******** 
2025-07-23 21:12:35,436 p=64318 u=master n=ansible | =============================================================================== 
2025-07-23 21:12:35,436 p=64318 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.04s
2025-07-23 21:12:35,436 p=64318 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:13:27,905 p=64377 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:13:27,906 p=64377 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:13:28,303 p=64377 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 21:13:28,318 p=64377 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 21:13:28,318 p=64377 u=master n=ansible | Wednesday 23 July 2025  21:13:28 +0000 (0:00:00.017)       0:00:00.017 ******** 
2025-07-23 21:13:28,342 p=64377 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 21:13:28,345 p=64377 u=master n=ansible | TASK [[TEST] Проверка созданных файлов] ***********************************************************************************************************************************************
2025-07-23 21:13:28,346 p=64377 u=master n=ansible | Wednesday 23 July 2025  21:13:28 +0000 (0:00:00.027)       0:00:00.045 ******** 
2025-07-23 21:13:29,456 p=64377 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurm.conf)
2025-07-23 21:13:29,700 p=64377 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurmdbd.conf)
2025-07-23 21:13:29,943 p=64377 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/gres.conf)
2025-07-23 21:13:30,179 p=64377 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmctld.service)
2025-07-23 21:13:30,435 p=64377 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmdbd.service)
2025-07-23 21:13:30,441 p=64377 u=master n=ansible | TASK [[TEST] Результаты проверки файлов] **********************************************************************************************************************************************
2025-07-23 21:13:30,441 p=64377 u=master n=ansible | Wednesday 23 July 2025  21:13:30 +0000 (0:00:02.095)       0:00:02.140 ******** 
2025-07-23 21:13:30,495 p=64377 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': False}, 'invocation': {'module_args': {'path': '/etc/slurm/slurm.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurm.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurm.conf: ❌ отсутствует"
2025-07-23 21:13:30,499 p=64377 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': False}, 'invocation': {'module_args': {'path': '/etc/slurm/slurmdbd.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurmdbd.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurmdbd.conf: ❌ отсутствует"
2025-07-23 21:13:30,505 p=64377 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': False}, 'invocation': {'module_args': {'path': '/etc/slurm/gres.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/gres.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/gres.conf: ❌ отсутствует"
2025-07-23 21:13:30,510 p=64377 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': False}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmctld.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmctld.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmctld.service: ❌ отсутствует"
2025-07-23 21:13:30,516 p=64377 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': False}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmdbd.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmdbd.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmdbd.service: ❌ отсутствует"
2025-07-23 21:13:30,521 p=64377 u=master n=ansible | TASK [[TEST] Проверка сервисов] *******************************************************************************************************************************************************
2025-07-23 21:13:30,521 p=64377 u=master n=ansible | Wednesday 23 July 2025  21:13:30 +0000 (0:00:00.079)       0:00:02.220 ******** 
2025-07-23 21:13:31,252 p=64377 u=master n=ansible | ok: [sm01] => (item=slurmdbd)
2025-07-23 21:13:31,693 p=64377 u=master n=ansible | ok: [sm01] => (item=slurmctld)
2025-07-23 21:13:31,701 p=64377 u=master n=ansible | TASK [[TEST] Статус сервисов] *********************************************************************************************************************************************************
2025-07-23 21:13:31,701 p=64377 u=master n=ansible | Wednesday 23 July 2025  21:13:31 +0000 (0:00:01.179)       0:00:03.400 ******** 
2025-07-23 21:13:31,779 p=64377 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmdbd', 'changed': False, 'status': {'ExitType': 'main', 'Restart': 'no', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '100ms', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '100ms', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': 'infinity', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '0', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '[not set]', 'GID': '[not set]', 'NRestarts': '0', 'ReloadSignal': '1', 'ExecMainStartTimestampMonotonic': '0', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '0', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ControlGroupId': '0', 'MemoryCurrent': '[not set]', 'MemoryPeak': '[not set]', 'MemorySwapCurrent': '[not set]', 'MemorySwapPeak': '[not set]', 'MemoryZSwapCurrent': '[not set]', 'MemoryAvailable': '[not set]', 'CPUUsageNSec': '[not set]', 'TasksCurrent': '[not set]', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': '8388608', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '1048576', 'LimitNOFILESoft': '1048576', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': '1536593920', 'LimitMEMLOCKSoft': '1536593920', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'inherit', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'no', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'no', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'control-group', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmdbd.service', 'Names': 'slurmdbd.service', 'Description': 'slurmdbd.service', 'LoadState': 'not-found', 'ActiveState': 'inactive', 'FreezerState': 'running', 'SubState': 'dead', 'StateChangeTimestampMonotonic': '0', 'InactiveExitTimestampMonotonic': '0', 'ActiveEnterTimestampMonotonic': '0', 'ActiveExitTimestampMonotonic': '0', 'InactiveEnterTimestampMonotonic': '0', 'CanStart': 'no', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'no', 'AssertResult': 'no', 'ConditionTimestampMonotonic': '0', 'AssertTimestampMonotonic': '0', 'LoadError': 'org.freedesktop.systemd1.NoSuchUnit "Unit slurmdbd.service not found."', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '10s', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmdbd', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmdbd', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmdbd: inactive"
2025-07-23 21:13:31,786 p=64377 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmctld', 'changed': False, 'status': {'ExitType': 'main', 'Restart': 'no', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '100ms', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '100ms', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': 'infinity', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '0', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '[not set]', 'GID': '[not set]', 'NRestarts': '0', 'ReloadSignal': '1', 'ExecMainStartTimestampMonotonic': '0', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '0', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ControlGroupId': '0', 'MemoryCurrent': '[not set]', 'MemoryPeak': '[not set]', 'MemorySwapCurrent': '[not set]', 'MemorySwapPeak': '[not set]', 'MemoryZSwapCurrent': '[not set]', 'MemoryAvailable': '[not set]', 'CPUUsageNSec': '[not set]', 'TasksCurrent': '[not set]', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': '8388608', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '1048576', 'LimitNOFILESoft': '1048576', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': '1536593920', 'LimitMEMLOCKSoft': '1536593920', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'inherit', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'no', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'no', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'control-group', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmctld.service', 'Names': 'slurmctld.service', 'Description': 'slurmctld.service', 'LoadState': 'not-found', 'ActiveState': 'inactive', 'FreezerState': 'running', 'SubState': 'dead', 'StateChangeTimestampMonotonic': '0', 'InactiveExitTimestampMonotonic': '0', 'ActiveEnterTimestampMonotonic': '0', 'ActiveExitTimestampMonotonic': '0', 'InactiveEnterTimestampMonotonic': '0', 'CanStart': 'no', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'no', 'AssertResult': 'no', 'ConditionTimestampMonotonic': '0', 'AssertTimestampMonotonic': '0', 'LoadError': 'org.freedesktop.systemd1.NoSuchUnit "Unit slurmctld.service not found."', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '10s', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmctld', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmctld', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmctld: inactive"
2025-07-23 21:13:31,796 p=64377 u=master n=ansible | TASK [[TEST] Тестовая команда scontrol] ***********************************************************************************************************************************************
2025-07-23 21:13:31,797 p=64377 u=master n=ansible | Wednesday 23 July 2025  21:13:31 +0000 (0:00:00.095)       0:00:03.496 ******** 
2025-07-23 21:13:32,181 p=64377 u=master n=ansible | ok: [sm01]
2025-07-23 21:13:32,185 p=64377 u=master n=ansible | TASK [[TEST] Результат scontrol ping] *************************************************************************************************************************************************
2025-07-23 21:13:32,287 p=64377 u=master n=ansible | Wednesday 23 July 2025  21:13:32 +0000 (0:00:00.490)       0:00:03.986 ******** 
2025-07-23 21:13:32,312 p=64377 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 scontrol ping:\n❌ ОШИБКА:"
2025-07-23 21:13:32,322 p=64377 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:13:32,322 p=64377 u=master n=ansible | sm01                       : ok=7    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-23 21:13:32,323 p=64377 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 4 seconds
2025-07-23 21:13:32,323 p=64377 u=master n=ansible | Wednesday 23 July 2025  21:13:32 +0000 (0:00:00.036)       0:00:04.022 ******** 
2025-07-23 21:13:32,323 p=64377 u=master n=ansible | =============================================================================== 
2025-07-23 21:13:32,323 p=64377 u=master n=ansible | [TEST] Проверка созданных файлов ----------------------------------------------------------------------------------------------------------------------------------------------- 2.10s
2025-07-23 21:13:32,323 p=64377 u=master n=ansible | [TEST] Проверка сервисов ------------------------------------------------------------------------------------------------------------------------------------------------------- 1.18s
2025-07-23 21:13:32,323 p=64377 u=master n=ansible | [TEST] Тестовая команда scontrol ----------------------------------------------------------------------------------------------------------------------------------------------- 0.49s
2025-07-23 21:13:32,323 p=64377 u=master n=ansible | [TEST] Статус сервисов --------------------------------------------------------------------------------------------------------------------------------------------------------- 0.10s
2025-07-23 21:13:32,323 p=64377 u=master n=ansible | [TEST] Результаты проверки файлов ---------------------------------------------------------------------------------------------------------------------------------------------- 0.08s
2025-07-23 21:13:32,324 p=64377 u=master n=ansible | [TEST] Результат scontrol ping ------------------------------------------------------------------------------------------------------------------------------------------------- 0.04s
2025-07-23 21:13:32,324 p=64377 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:14:21,791 p=64479 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:14:21,791 p=64479 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:14:22,195 p=64479 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 21:14:22,209 p=64479 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 21:14:22,209 p=64479 u=master n=ansible | Wednesday 23 July 2025  21:14:22 +0000 (0:00:00.016)       0:00:00.016 ******** 
2025-07-23 21:14:22,233 p=64479 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 21:14:22,237 p=64479 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 21:14:22,238 p=64479 u=master n=ansible | Wednesday 23 July 2025  21:14:22 +0000 (0:00:00.028)       0:00:00.044 ******** 
2025-07-23 21:14:22,633 p=64479 u=master n=ansible | ok: [sm01]
2025-07-23 21:14:22,637 p=64479 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 21:14:22,637 p=64479 u=master n=ansible | Wednesday 23 July 2025  21:14:22 +0000 (0:00:00.399)       0:00:00.444 ******** 
2025-07-23 21:14:22,683 p=64479 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 21:14:22,687 p=64479 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 21:14:22,687 p=64479 u=master n=ansible | Wednesday 23 July 2025  21:14:22 +0000 (0:00:00.049)       0:00:00.494 ******** 
2025-07-23 21:14:22,720 p=64479 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 21:14:22,721 p=64479 u=master n=ansible | Wednesday 23 July 2025  21:14:22 +0000 (0:00:00.033)       0:00:00.527 ******** 
2025-07-23 21:14:22,769 p=64479 u=master n=ansible | fatal: [sm01]: FAILED! => 
  msg: |-
    The task includes an option with an undefined variable. The error was: 'ansible_default_ipv4' is undefined. 'ansible_default_ipv4' is undefined
  
    The error appears to be in '/home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/main.yml': line 7, column 3, but may
    be elsewhere in the file depending on the exact syntax problem.
  
    The offending line appears to be:
  
  
    - name: "[SLURM-MASTER] Начало настройки Slurm Master"
      ^ here
2025-07-23 21:14:22,771 p=64479 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:14:22,771 p=64479 u=master n=ansible | sm01                       : ok=3    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 21:14:22,771 p=64479 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 0 seconds
2025-07-23 21:14:22,771 p=64479 u=master n=ansible | Wednesday 23 July 2025  21:14:22 +0000 (0:00:00.050)       0:00:00.578 ******** 
2025-07-23 21:14:22,771 p=64479 u=master n=ansible | =============================================================================== 
2025-07-23 21:14:22,771 p=64479 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 0.40s
2025-07-23 21:14:22,772 p=64479 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:14:22,772 p=64479 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:14:22,772 p=64479 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:14:22,772 p=64479 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:16:20,589 p=64560 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:16:20,590 p=64560 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:16:20,997 p=64560 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 21:16:21,010 p=64560 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 21:16:21,011 p=64560 u=master n=ansible | Wednesday 23 July 2025  21:16:21 +0000 (0:00:00.016)       0:00:00.016 ******** 
2025-07-23 21:16:21,035 p=64560 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 21:16:21,039 p=64560 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 21:16:21,039 p=64560 u=master n=ansible | Wednesday 23 July 2025  21:16:21 +0000 (0:00:00.028)       0:00:00.044 ******** 
2025-07-23 21:16:22,141 p=64560 u=master n=ansible | ok: [sm01]
2025-07-23 21:16:22,145 p=64560 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 21:16:22,145 p=64560 u=master n=ansible | Wednesday 23 July 2025  21:16:22 +0000 (0:00:01.106)       0:00:01.150 ******** 
2025-07-23 21:16:22,191 p=64560 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 21:16:22,195 p=64560 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 21:16:22,195 p=64560 u=master n=ansible | Wednesday 23 July 2025  21:16:22 +0000 (0:00:00.050)       0:00:01.200 ******** 
2025-07-23 21:16:22,228 p=64560 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 21:16:22,228 p=64560 u=master n=ansible | Wednesday 23 July 2025  21:16:22 +0000 (0:00:00.032)       0:00:01.233 ******** 
2025-07-23 21:16:22,277 p=64560 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 21:16:22,282 p=64560 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 21:16:22,282 p=64560 u=master n=ansible | Wednesday 23 July 2025  21:16:22 +0000 (0:00:00.053)       0:00:01.287 ******** 
2025-07-23 21:16:22,337 p=64560 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 21:16:22,342 p=64560 u=master n=ansible | TASK [slurm_master : [MARIADB] Установка root пароля MariaDB] *************************************************************************************************************************
2025-07-23 21:16:22,343 p=64560 u=master n=ansible | Wednesday 23 July 2025  21:16:22 +0000 (0:00:00.060)       0:00:01.348 ******** 
2025-07-23 21:16:23,139 p=64560 u=master n=ansible | [WARNING]: Option column_case_sensitive is not provided. The default is now false, so the column's name will be uppercased. The default will be changed to true in community.mysql
4.0.0.

2025-07-23 21:16:23,140 p=64560 u=master n=ansible | changed: [sm01]
2025-07-23 21:16:23,144 p=64560 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание базы данных Slurm] ****************************************************************************************************************************
2025-07-23 21:16:23,145 p=64560 u=master n=ansible | Wednesday 23 July 2025  21:16:23 +0000 (0:00:00.802)       0:00:02.150 ******** 
2025-07-23 21:16:23,724 p=64560 u=master n=ansible | changed: [sm01]
2025-07-23 21:16:23,728 p=64560 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя Slurm] ***************************************************************************************************************************
2025-07-23 21:16:23,729 p=64560 u=master n=ansible | Wednesday 23 July 2025  21:16:23 +0000 (0:00:00.583)       0:00:02.734 ******** 
2025-07-23 21:16:23,747 p=64560 u=master n=ansible | fatal: [sm01]: FAILED! => 
  msg: '''ansible_default_ipv4'' is undefined. ''ansible_default_ipv4'' is undefined'
2025-07-23 21:16:23,749 p=64560 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:16:23,749 p=64560 u=master n=ansible | sm01                       : ok=7    changed=2    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 21:16:23,749 p=64560 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 2 seconds
2025-07-23 21:16:23,749 p=64560 u=master n=ansible | Wednesday 23 July 2025  21:16:23 +0000 (0:00:00.020)       0:00:02.755 ******** 
2025-07-23 21:16:23,750 p=64560 u=master n=ansible | =============================================================================== 
2025-07-23 21:16:23,750 p=64560 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.11s
2025-07-23 21:16:23,750 p=64560 u=master n=ansible | slurm_master : [MARIADB] Установка root пароля MariaDB ------------------------------------------------------------------------------------------------------------------------- 0.80s
2025-07-23 21:16:23,750 p=64560 u=master n=ansible | slurm_master : [MARIADB] Создание базы данных Slurm ---------------------------------------------------------------------------------------------------------------------------- 0.58s
2025-07-23 21:16:23,750 p=64560 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 21:16:23,750 p=64560 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:16:23,750 p=64560 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:16:23,750 p=64560 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:16:23,750 p=64560 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:16:23,750 p=64560 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя Slurm --------------------------------------------------------------------------------------------------------------------------- 0.02s
2025-07-23 21:19:57,618 p=64711 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:19:57,618 p=64711 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:19:58,012 p=64711 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 21:19:58,025 p=64711 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 21:19:58,026 p=64711 u=master n=ansible | Wednesday 23 July 2025  21:19:58 +0000 (0:00:00.015)       0:00:00.015 ******** 
2025-07-23 21:19:58,049 p=64711 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 21:19:58,053 p=64711 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 21:19:58,053 p=64711 u=master n=ansible | Wednesday 23 July 2025  21:19:58 +0000 (0:00:00.027)       0:00:00.042 ******** 
2025-07-23 21:19:59,176 p=64711 u=master n=ansible | ok: [sm01]
2025-07-23 21:19:59,180 p=64711 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 21:19:59,180 p=64711 u=master n=ansible | Wednesday 23 July 2025  21:19:59 +0000 (0:00:01.126)       0:00:01.169 ******** 
2025-07-23 21:19:59,227 p=64711 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 21:19:59,231 p=64711 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 21:19:59,231 p=64711 u=master n=ansible | Wednesday 23 July 2025  21:19:59 +0000 (0:00:00.051)       0:00:01.221 ******** 
2025-07-23 21:19:59,264 p=64711 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 21:19:59,264 p=64711 u=master n=ansible | Wednesday 23 July 2025  21:19:59 +0000 (0:00:00.033)       0:00:01.254 ******** 
2025-07-23 21:19:59,314 p=64711 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 21:19:59,318 p=64711 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 21:19:59,318 p=64711 u=master n=ansible | Wednesday 23 July 2025  21:19:59 +0000 (0:00:00.053)       0:00:01.308 ******** 
2025-07-23 21:19:59,373 p=64711 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 21:19:59,378 p=64711 u=master n=ansible | TASK [slurm_master : [MARIADB] Установка root пароля MariaDB] *************************************************************************************************************************
2025-07-23 21:19:59,379 p=64711 u=master n=ansible | Wednesday 23 July 2025  21:19:59 +0000 (0:00:00.060)       0:00:01.368 ******** 
2025-07-23 21:19:59,864 p=64711 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  msg: 'unable to connect to database, check login_user and login_password are correct or /root/.my.cnf has the credentials. Exception message: (1045, "Access denied for user ''root''@''localhost'' (using password: NO)")'
2025-07-23 21:19:59,864 p=64711 u=master n=ansible | ...ignoring
2025-07-23 21:19:59,868 p=64711 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание базы данных Slurm] ****************************************************************************************************************************
2025-07-23 21:19:59,868 p=64711 u=master n=ansible | Wednesday 23 July 2025  21:19:59 +0000 (0:00:00.489)       0:00:01.858 ******** 
2025-07-23 21:20:00,329 p=64711 u=master n=ansible | ok: [sm01]
2025-07-23 21:20:00,334 p=64711 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя Slurm] ***************************************************************************************************************************
2025-07-23 21:20:00,334 p=64711 u=master n=ansible | Wednesday 23 July 2025  21:20:00 +0000 (0:00:00.465)       0:00:02.324 ******** 
2025-07-23 21:20:00,940 p=64711 u=master n=ansible | changed: [sm01] => (item=localhost)
2025-07-23 21:20:01,522 p=64711 u=master n=ansible | changed: [sm01] => (item=sm01)
2025-07-23 21:20:02,003 p=64711 u=master n=ansible | changed: [sm01] => (item=%)
2025-07-23 21:20:02,005 p=64711 u=master n=ansible | [WARNING]: Option column_case_sensitive is not provided. The default is now false, so the column's name will be uppercased. The default will be changed to true in community.mysql
4.0.0.

2025-07-23 21:20:02,009 p=64711 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат настройки базы] ******************************************************************************************************************************
2025-07-23 21:20:02,009 p=64711 u=master n=ansible | Wednesday 23 July 2025  21:20:02 +0000 (0:00:01.675)       0:00:03.999 ******** 
2025-07-23 21:20:02,057 p=64711 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB для Slurm:\n\U0001F4CA База: slurm_acct_db (уже существует)\n\U0001F464 Пользователь: slurm\n\U0001F510 Пароль: [установлен]"
2025-07-23 21:20:02,061 p=64711 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-23 21:20:02,061 p=64711 u=master n=ansible | Wednesday 23 July 2025  21:20:02 +0000 (0:00:00.051)       0:00:04.050 ******** 
2025-07-23 21:20:02,081 p=64711 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-23 21:20:02,089 p=64711 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-23 21:20:02,089 p=64711 u=master n=ansible | Wednesday 23 July 2025  21:20:02 +0000 (0:00:00.028)       0:00:04.079 ******** 
2025-07-23 21:20:02,216 p=64711 u=master n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'jwt_enabled' is undefined. 'jwt_enabled' is undefined
2025-07-23 21:20:02,217 p=64711 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  msg: 'AnsibleUndefinedVariable: ''jwt_enabled'' is undefined. ''jwt_enabled'' is undefined'
2025-07-23 21:20:02,218 p=64711 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:20:02,218 p=64711 u=master n=ansible | sm01                       : ok=10   changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=1   
2025-07-23 21:20:02,219 p=64711 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 4 seconds
2025-07-23 21:20:02,219 p=64711 u=master n=ansible | Wednesday 23 July 2025  21:20:02 +0000 (0:00:00.129)       0:00:04.208 ******** 
2025-07-23 21:20:02,219 p=64711 u=master n=ansible | =============================================================================== 
2025-07-23 21:20:02,219 p=64711 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя Slurm --------------------------------------------------------------------------------------------------------------------------- 1.68s
2025-07-23 21:20:02,219 p=64711 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.13s
2025-07-23 21:20:02,219 p=64711 u=master n=ansible | slurm_master : [MARIADB] Установка root пароля MariaDB ------------------------------------------------------------------------------------------------------------------------- 0.49s
2025-07-23 21:20:02,219 p=64711 u=master n=ansible | slurm_master : [MARIADB] Создание базы данных Slurm ---------------------------------------------------------------------------------------------------------------------------- 0.47s
2025-07-23 21:20:02,219 p=64711 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.13s
2025-07-23 21:20:02,220 p=64711 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 21:20:02,220 p=64711 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:20:02,220 p=64711 u=master n=ansible | slurm_master : [MARIADB] Результат настройки базы ------------------------------------------------------------------------------------------------------------------------------ 0.05s
2025-07-23 21:20:02,220 p=64711 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:20:02,220 p=64711 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:20:02,220 p=64711 u=master n=ansible | slurm_master : [SLURM-MASTER] Создание конфигурации Slurm ---------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:20:02,220 p=64711 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:22:23,938 p=64813 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:22:23,939 p=64813 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:22:24,333 p=64813 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 21:22:24,347 p=64813 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 21:22:24,347 p=64813 u=master n=ansible | Wednesday 23 July 2025  21:22:24 +0000 (0:00:00.016)       0:00:00.016 ******** 
2025-07-23 21:22:24,371 p=64813 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 21:22:24,375 p=64813 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 21:22:24,375 p=64813 u=master n=ansible | Wednesday 23 July 2025  21:22:24 +0000 (0:00:00.027)       0:00:00.044 ******** 
2025-07-23 21:22:25,493 p=64813 u=master n=ansible | ok: [sm01]
2025-07-23 21:22:25,497 p=64813 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 21:22:25,497 p=64813 u=master n=ansible | Wednesday 23 July 2025  21:22:25 +0000 (0:00:01.122)       0:00:01.166 ******** 
2025-07-23 21:22:25,543 p=64813 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 21:22:25,546 p=64813 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 21:22:25,546 p=64813 u=master n=ansible | Wednesday 23 July 2025  21:22:25 +0000 (0:00:00.049)       0:00:01.215 ******** 
2025-07-23 21:22:25,579 p=64813 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 21:22:25,579 p=64813 u=master n=ansible | Wednesday 23 July 2025  21:22:25 +0000 (0:00:00.032)       0:00:01.248 ******** 
2025-07-23 21:22:25,630 p=64813 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 21:22:25,634 p=64813 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 21:22:25,634 p=64813 u=master n=ansible | Wednesday 23 July 2025  21:22:25 +0000 (0:00:00.055)       0:00:01.303 ******** 
2025-07-23 21:22:25,686 p=64813 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 21:22:25,692 p=64813 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка подключения к MariaDB с sudo] *****************************************************************************************************************
2025-07-23 21:22:25,692 p=64813 u=master n=ansible | Wednesday 23 July 2025  21:22:25 +0000 (0:00:00.057)       0:00:01.361 ******** 
2025-07-23 21:22:25,967 p=64813 u=master n=ansible | ok: [sm01]
2025-07-23 21:22:25,971 p=64813 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание базы данных Slurm (через sudo)] ***************************************************************************************************************
2025-07-23 21:22:25,971 p=64813 u=master n=ansible | Wednesday 23 July 2025  21:22:25 +0000 (0:00:00.278)       0:00:01.640 ******** 
2025-07-23 21:22:26,250 p=64813 u=master n=ansible | fatal: [sm01]: FAILED! => changed=true 
  cmd: |-
    sudo mysql -e "CREATE DATABASE IF NOT EXISTS slurm_acct_db CHARACTER SET utf8 COLLATE utf8_general_ci;"
  delta: '0:00:00.018427'
  end: '2025-07-24 00:22:26.227233'
  msg: non-zero return code
  rc: 1
  start: '2025-07-24 00:22:26.208806'
  stderr: 'ERROR 1045 (28000): Access denied for user ''root''@''localhost'' (using password: NO)'
  stderr_lines: <omitted>
  stdout: ''
  stdout_lines: <omitted>
2025-07-23 21:22:26,251 p=64813 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:22:26,252 p=64813 u=master n=ansible | sm01                       : ok=6    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 21:22:26,252 p=64813 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 1 seconds
2025-07-23 21:22:26,252 p=64813 u=master n=ansible | Wednesday 23 July 2025  21:22:26 +0000 (0:00:00.280)       0:00:01.921 ******** 
2025-07-23 21:22:26,252 p=64813 u=master n=ansible | =============================================================================== 
2025-07-23 21:22:26,252 p=64813 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.12s
2025-07-23 21:22:26,252 p=64813 u=master n=ansible | slurm_master : [MARIADB] Создание базы данных Slurm (через sudo) --------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 21:22:26,253 p=64813 u=master n=ansible | slurm_master : [MARIADB] Проверка подключения к MariaDB с sudo ----------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 21:22:26,253 p=64813 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 21:22:26,253 p=64813 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 21:22:26,253 p=64813 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:22:26,253 p=64813 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:22:26,253 p=64813 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:25:02,963 p=64895 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:25:02,963 p=64895 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:25:03,373 p=64895 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 21:25:03,389 p=64895 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 21:25:03,389 p=64895 u=master n=ansible | Wednesday 23 July 2025  21:25:03 +0000 (0:00:00.018)       0:00:00.018 ******** 
2025-07-23 21:25:03,414 p=64895 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 21:25:03,418 p=64895 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 21:25:03,418 p=64895 u=master n=ansible | Wednesday 23 July 2025  21:25:03 +0000 (0:00:00.028)       0:00:00.047 ******** 
2025-07-23 21:25:04,522 p=64895 u=master n=ansible | ok: [sm01]
2025-07-23 21:25:04,526 p=64895 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 21:25:04,526 p=64895 u=master n=ansible | Wednesday 23 July 2025  21:25:04 +0000 (0:00:01.107)       0:00:01.155 ******** 
2025-07-23 21:25:04,572 p=64895 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 21:25:04,576 p=64895 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 21:25:04,576 p=64895 u=master n=ansible | Wednesday 23 July 2025  21:25:04 +0000 (0:00:00.050)       0:00:01.205 ******** 
2025-07-23 21:25:04,610 p=64895 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 21:25:04,610 p=64895 u=master n=ansible | Wednesday 23 July 2025  21:25:04 +0000 (0:00:00.033)       0:00:01.239 ******** 
2025-07-23 21:25:04,660 p=64895 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 21:25:04,664 p=64895 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 21:25:04,664 p=64895 u=master n=ansible | Wednesday 23 July 2025  21:25:04 +0000 (0:00:00.054)       0:00:01.293 ******** 
2025-07-23 21:25:04,717 p=64895 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 21:25:04,723 p=64895 u=master n=ansible | TASK [slurm_master : [MARIADB] Диагностика MariaDB root пользователя] *****************************************************************************************************************
2025-07-23 21:25:04,723 p=64895 u=master n=ansible | Wednesday 23 July 2025  21:25:04 +0000 (0:00:00.058)       0:00:01.352 ******** 
2025-07-23 21:25:04,996 p=64895 u=master n=ansible | ok: [sm01]
2025-07-23 21:25:05,000 p=64895 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат диагностики] *********************************************************************************************************************************
2025-07-23 21:25:05,001 p=64895 u=master n=ansible | Wednesday 23 July 2025  21:25:05 +0000 (0:00:00.277)       0:00:01.630 ******** 
2025-07-23 21:25:05,026 p=64895 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F50D MariaDB root info:"
2025-07-23 21:25:05,032 p=64895 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание базы данных Slurm (правильный способ)] ********************************************************************************************************
2025-07-23 21:25:05,032 p=64895 u=master n=ansible | Wednesday 23 July 2025  21:25:05 +0000 (0:00:00.031)       0:00:01.661 ******** 
2025-07-23 21:25:05,308 p=64895 u=master n=ansible | fatal: [sm01]: FAILED! => changed=true 
  cmd: sudo -u root mysql -e "CREATE DATABASE IF NOT EXISTS slurm_acct_db CHARACTER SET utf8 COLLATE utf8_general_ci;"
  delta: '0:00:00.017682'
  end: '2025-07-24 00:25:05.285330'
  msg: non-zero return code
  rc: 1
  start: '2025-07-24 00:25:05.267648'
  stderr: 'ERROR 1045 (28000): Access denied for user ''root''@''localhost'' (using password: NO)'
  stderr_lines: <omitted>
  stdout: ''
  stdout_lines: <omitted>
2025-07-23 21:25:05,310 p=64895 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:25:05,310 p=64895 u=master n=ansible | sm01                       : ok=7    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 21:25:05,310 p=64895 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 1 seconds
2025-07-23 21:25:05,311 p=64895 u=master n=ansible | Wednesday 23 July 2025  21:25:05 +0000 (0:00:00.278)       0:00:01.940 ******** 
2025-07-23 21:25:05,311 p=64895 u=master n=ansible | =============================================================================== 
2025-07-23 21:25:05,311 p=64895 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.11s
2025-07-23 21:25:05,311 p=64895 u=master n=ansible | slurm_master : [MARIADB] Создание базы данных Slurm (правильный способ) -------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 21:25:05,311 p=64895 u=master n=ansible | slurm_master : [MARIADB] Диагностика MariaDB root пользователя ----------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-23 21:25:05,311 p=64895 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 21:25:05,311 p=64895 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:25:05,311 p=64895 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:25:05,311 p=64895 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:25:05,311 p=64895 u=master n=ansible | slurm_master : [MARIADB] Результат диагностики --------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:25:05,312 p=64895 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:25:47,446 p=64960 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:25:47,446 p=64960 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:25:48,103 p=64960 u=master n=ansible | sm01 | FAILED | rc=1 >>
ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: NO)non-zero return code

2025-07-23 21:26:47,693 p=65026 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:26:47,694 p=65026 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:26:49,045 p=65026 u=master n=ansible | sm01 | FAILED | rc=1 >>
ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: NO)non-zero return code

2025-07-23 21:34:07,340 p=65150 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:34:07,341 p=65150 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:34:07,767 p=65150 u=master n=ansible | PLAY [Тестирование роли common] *******************************************************************************************************************************************************
2025-07-23 21:34:07,798 p=65150 u=master n=ansible | TASK [common : [COMMON] Установка MariaDB] ********************************************************************************************************************************************
2025-07-23 21:34:07,799 p=65150 u=master n=ansible | Wednesday 23 July 2025  21:34:07 +0000 (0:00:00.034)       0:00:00.034 ******** 
2025-07-23 21:34:07,831 p=65150 u=master n=ansible | skipping: [sm02]
2025-07-23 21:34:07,833 p=65150 u=master n=ansible | skipping: [cn01]
2025-07-23 21:34:07,841 p=65150 u=master n=ansible | skipping: [cn02]
2025-07-23 21:34:09,659 p=65150 u=master n=ansible | ok: [sm01]
2025-07-23 21:34:09,663 p=65150 u=master n=ansible | TASK [common : [COMMON] Установка python3-pymysql для Ansible mysql модулей] **********************************************************************************************************
2025-07-23 21:34:09,663 p=65150 u=master n=ansible | Wednesday 23 July 2025  21:34:09 +0000 (0:00:01.864)       0:00:01.898 ******** 
2025-07-23 21:34:09,695 p=65150 u=master n=ansible | skipping: [sm02]
2025-07-23 21:34:09,697 p=65150 u=master n=ansible | skipping: [cn01]
2025-07-23 21:34:09,705 p=65150 u=master n=ansible | skipping: [cn02]
2025-07-23 21:34:10,595 p=65150 u=master n=ansible | ok: [sm01]
2025-07-23 21:34:10,635 p=65150 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:34:10,635 p=65150 u=master n=ansible | cn01                       : ok=0    changed=0    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
2025-07-23 21:34:10,636 p=65150 u=master n=ansible | cn02                       : ok=0    changed=0    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
2025-07-23 21:34:10,636 p=65150 u=master n=ansible | sm01                       : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-23 21:34:10,636 p=65150 u=master n=ansible | sm02                       : ok=0    changed=0    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
2025-07-23 21:34:10,636 p=65150 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 2 seconds
2025-07-23 21:34:10,636 p=65150 u=master n=ansible | Wednesday 23 July 2025  21:34:10 +0000 (0:00:00.973)       0:00:02.872 ******** 
2025-07-23 21:34:10,636 p=65150 u=master n=ansible | =============================================================================== 
2025-07-23 21:34:10,636 p=65150 u=master n=ansible | common : [COMMON] Установка MariaDB -------------------------------------------------------------------------------------------------------------------------------------------- 1.86s
2025-07-23 21:34:10,637 p=65150 u=master n=ansible | common : [COMMON] Установка python3-pymysql для Ansible mysql модулей ---------------------------------------------------------------------------------------------------------- 0.97s
2025-07-23 21:35:27,666 p=65244 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:35:27,666 p=65244 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:35:28,062 p=65244 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 21:35:28,076 p=65244 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 21:35:28,076 p=65244 u=master n=ansible | Wednesday 23 July 2025  21:35:28 +0000 (0:00:00.016)       0:00:00.016 ******** 
2025-07-23 21:35:28,100 p=65244 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 21:35:28,104 p=65244 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 21:35:28,104 p=65244 u=master n=ansible | Wednesday 23 July 2025  21:35:28 +0000 (0:00:00.027)       0:00:00.043 ******** 
2025-07-23 21:35:29,220 p=65244 u=master n=ansible | ok: [sm01]
2025-07-23 21:35:29,224 p=65244 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 21:35:29,224 p=65244 u=master n=ansible | Wednesday 23 July 2025  21:35:29 +0000 (0:00:01.119)       0:00:01.163 ******** 
2025-07-23 21:35:29,271 p=65244 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 21:35:29,275 p=65244 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 21:35:29,275 p=65244 u=master n=ansible | Wednesday 23 July 2025  21:35:29 +0000 (0:00:00.050)       0:00:01.214 ******** 
2025-07-23 21:35:29,307 p=65244 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 21:35:29,308 p=65244 u=master n=ansible | Wednesday 23 July 2025  21:35:29 +0000 (0:00:00.032)       0:00:01.247 ******** 
2025-07-23 21:35:29,358 p=65244 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 21:35:29,363 p=65244 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 21:35:29,363 p=65244 u=master n=ansible | Wednesday 23 July 2025  21:35:29 +0000 (0:00:00.055)       0:00:01.302 ******** 
2025-07-23 21:35:29,418 p=65244 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 21:35:29,423 p=65244 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка статуса MariaDB] ******************************************************************************************************************************
2025-07-23 21:35:29,424 p=65244 u=master n=ansible | Wednesday 23 July 2025  21:35:29 +0000 (0:00:00.060)       0:00:01.363 ******** 
2025-07-23 21:35:30,171 p=65244 u=master n=ansible | ok: [sm01]
2025-07-23 21:35:30,175 p=65244 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя Slurm (способ DeepOps)] **********************************************************************************************************
2025-07-23 21:35:30,175 p=65244 u=master n=ansible | Wednesday 23 July 2025  21:35:30 +0000 (0:00:00.751)       0:00:02.115 ******** 
2025-07-23 21:35:30,692 p=65244 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  msg: 'unable to connect to database, check login_user and login_password are correct or /root/.my.cnf has the credentials. Exception message: (1045, "Access denied for user ''root''@''localhost'' (using password: NO)")'
2025-07-23 21:35:30,694 p=65244 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:35:30,694 p=65244 u=master n=ansible | sm01                       : ok=6    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 21:35:30,694 p=65244 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 2 seconds
2025-07-23 21:35:30,695 p=65244 u=master n=ansible | Wednesday 23 July 2025  21:35:30 +0000 (0:00:00.519)       0:00:02.634 ******** 
2025-07-23 21:35:30,695 p=65244 u=master n=ansible | =============================================================================== 
2025-07-23 21:35:30,695 p=65244 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.12s
2025-07-23 21:35:30,695 p=65244 u=master n=ansible | slurm_master : [MARIADB] Проверка статуса MariaDB ------------------------------------------------------------------------------------------------------------------------------ 0.75s
2025-07-23 21:35:30,695 p=65244 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя Slurm (способ DeepOps) ---------------------------------------------------------------------------------------------------------- 0.52s
2025-07-23 21:35:30,695 p=65244 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 21:35:30,695 p=65244 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 21:35:30,695 p=65244 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:35:30,695 p=65244 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:35:30,696 p=65244 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:37:45,944 p=65347 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:37:45,944 p=65347 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:37:48,204 p=65347 u=master n=ansible | sm01 | CHANGED => {
    "changed": true,
    "name": "mariadb",
    "state": "stopped",
    "status": {
        "ActiveEnterTimestamp": "Wed 2025-07-23 23:41:37 MSK",
        "ActiveEnterTimestampMonotonic": "44528762551",
        "ActiveExitTimestampMonotonic": "0",
        "ActiveState": "active",
        "After": "system.slice network.target systemd-journald.socket sysinit.target basic.target",
        "AllowIsolate": "no",
        "AmbientCapabilities": "cap_ipc_lock",
        "AssertResult": "yes",
        "AssertTimestamp": "Wed 2025-07-23 23:41:37 MSK",
        "AssertTimestampMonotonic": "44528093018",
        "Before": "shutdown.target multi-user.target",
        "BlockIOAccounting": "no",
        "BlockIOWeight": "[not set]",
        "CPUAccounting": "yes",
        "CPUAffinityFromNUMA": "no",
        "CPUQuotaPerSecUSec": "infinity",
        "CPUQuotaPeriodUSec": "infinity",
        "CPUSchedulingPolicy": "0",
        "CPUSchedulingPriority": "0",
        "CPUSchedulingResetOnFork": "no",
        "CPUShares": "[not set]",
        "CPUUsageNSec": "1053206000",
        "CPUWeight": "[not set]",
        "CacheDirectoryMode": "0755",
        "CanFreeze": "yes",
        "CanIsolate": "no",
        "CanReload": "no",
        "CanStart": "yes",
        "CanStop": "yes",
        "CapabilityBoundingSet": "cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore",
        "CleanResult": "success",
        "CollectMode": "inactive",
        "ConditionResult": "yes",
        "ConditionTimestamp": "Wed 2025-07-23 23:41:37 MSK",
        "ConditionTimestampMonotonic": "44528093016",
        "ConfigurationDirectoryMode": "0755",
        "Conflicts": "shutdown.target",
        "ControlGroup": "/system.slice/mariadb.service",
        "ControlGroupId": "9391",
        "ControlPID": "0",
        "CoredumpFilter": "0x33",
        "CoredumpReceive": "no",
        "DefaultDependencies": "yes",
        "DefaultMemoryLow": "0",
        "DefaultMemoryMin": "0",
        "DefaultStartupMemoryLow": "0",
        "Delegate": "no",
        "Description": "MariaDB 10.11.13 database server",
        "DevicePolicy": "auto",
        "Documentation": "\"man:mariadbd(8)\" https://mariadb.com/kb/en/library/systemd/",
        "DynamicUser": "no",
        "ExecMainCode": "0",
        "ExecMainExitTimestampMonotonic": "0",
        "ExecMainPID": "68993",
        "ExecMainStartTimestamp": "Wed 2025-07-23 23:41:37 MSK",
        "ExecMainStartTimestampMonotonic": "44528172142",
        "ExecMainStatus": "0",
        "ExecStart": "{ path=/usr/sbin/mariadbd ; argv[]=/usr/sbin/mariadbd $MYSQLD_OPTS $_WSREP_NEW_CLUSTER $_WSREP_START_POSITION ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }",
        "ExecStartEx": "{ path=/usr/sbin/mariadbd ; argv[]=/usr/sbin/mariadbd $MYSQLD_OPTS $_WSREP_NEW_CLUSTER $_WSREP_START_POSITION ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }",
        "ExecStartPost": "{ path=/etc/mysql/debian-start ; argv[]=/etc/mysql/debian-start ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }",
        "ExecStartPostEx": "{ path=/etc/mysql/debian-start ; argv[]=/etc/mysql/debian-start ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }",
        "ExecStartPre": "{ path=/bin/sh ; argv[]=/bin/sh -c [ ! -e /usr/bin/galera_recovery ] && VAR= ||   VAR=`/usr/bin/galera_recovery`; [ $? -eq 0 ]   && systemctl set-environment _WSREP_START_POSITION=$VAR || exit 1 ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }",
        "ExecStartPreEx": "{ path=/bin/sh ; argv[]=/bin/sh -c [ ! -e /usr/bin/galera_recovery ] && VAR= ||   VAR=`/usr/bin/galera_recovery`; [ $? -eq 0 ]   && systemctl set-environment _WSREP_START_POSITION=$VAR || exit 1 ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }",
        "ExitType": "main",
        "ExtensionImagePolicy": "root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent",
        "FailureAction": "none",
        "FileDescriptorStoreMax": "0",
        "FileDescriptorStorePreserve": "restart",
        "FinalKillSignal": "9",
        "FragmentPath": "/usr/lib/systemd/system/mariadb.service",
        "FreezerState": "running",
        "GID": "111",
        "Group": "mysql",
        "GuessMainPID": "yes",
        "IOAccounting": "no",
        "IOReadBytes": "[not set]",
        "IOReadOperations": "[not set]",
        "IOSchedulingClass": "2",
        "IOSchedulingPriority": "4",
        "IOWeight": "[not set]",
        "IOWriteBytes": "[not set]",
        "IOWriteOperations": "[not set]",
        "IPAccounting": "no",
        "IPEgressBytes": "[no data]",
        "IPEgressPackets": "[no data]",
        "IPIngressBytes": "[no data]",
        "IPIngressPackets": "[no data]",
        "Id": "mariadb.service",
        "IgnoreOnIsolate": "no",
        "IgnoreSIGPIPE": "yes",
        "InactiveEnterTimestampMonotonic": "0",
        "InactiveExitTimestamp": "Wed 2025-07-23 23:41:37 MSK",
        "InactiveExitTimestampMonotonic": "44528111239",
        "InvocationID": "4df632a9acc44ec7acb14d93b4e6048c",
        "JobRunningTimeoutUSec": "infinity",
        "JobTimeoutAction": "none",
        "JobTimeoutUSec": "infinity",
        "KeyringMode": "private",
        "KillMode": "control-group",
        "KillSignal": "15",
        "LimitAS": "infinity",
        "LimitASSoft": "infinity",
        "LimitCORE": "infinity",
        "LimitCORESoft": "0",
        "LimitCPU": "infinity",
        "LimitCPUSoft": "infinity",
        "LimitDATA": "infinity",
        "LimitDATASoft": "infinity",
        "LimitFSIZE": "infinity",
        "LimitFSIZESoft": "infinity",
        "LimitLOCKS": "infinity",
        "LimitLOCKSSoft": "infinity",
        "LimitMEMLOCK": "524288",
        "LimitMEMLOCKSoft": "524288",
        "LimitMSGQUEUE": "819200",
        "LimitMSGQUEUESoft": "819200",
        "LimitNICE": "0",
        "LimitNICESoft": "0",
        "LimitNOFILE": "32768",
        "LimitNOFILESoft": "32768",
        "LimitNPROC": "46581",
        "LimitNPROCSoft": "46581",
        "LimitRSS": "infinity",
        "LimitRSSSoft": "infinity",
        "LimitRTPRIO": "0",
        "LimitRTPRIOSoft": "0",
        "LimitRTTIME": "infinity",
        "LimitRTTIMESoft": "infinity",
        "LimitSIGPENDING": "46581",
        "LimitSIGPENDINGSoft": "46581",
        "LimitSTACK": "infinity",
        "LimitSTACKSoft": "8388608",
        "LoadState": "loaded",
        "LockPersonality": "no",
        "LogLevelMax": "-1",
        "LogRateLimitBurst": "0",
        "LogRateLimitIntervalUSec": "0",
        "LogsDirectoryMode": "0755",
        "MainPID": "68993",
        "ManagedOOMMemoryPressure": "auto",
        "ManagedOOMMemoryPressureLimit": "0",
        "ManagedOOMPreference": "none",
        "ManagedOOMSwap": "auto",
        "MemoryAccounting": "yes",
        "MemoryAvailable": "11635965952",
        "MemoryCurrent": "85422080",
        "MemoryDenyWriteExecute": "no",
        "MemoryHigh": "infinity",
        "MemoryKSM": "no",
        "MemoryLimit": "infinity",
        "MemoryLow": "0",
        "MemoryMax": "infinity",
        "MemoryMin": "0",
        "MemoryPeak": "88543232",
        "MemoryPressureThresholdUSec": "200ms",
        "MemoryPressureWatch": "auto",
        "MemorySwapCurrent": "0",
        "MemorySwapMax": "infinity",
        "MemorySwapPeak": "0",
        "MemoryZSwapCurrent": "0",
        "MemoryZSwapMax": "infinity",
        "MountAPIVFS": "no",
        "MountImagePolicy": "root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent",
        "NFileDescriptorStore": "0",
        "NRestarts": "0",
        "NUMAPolicy": "n/a",
        "Names": "mariadb.service mysql.service mysqld.service",
        "NeedDaemonReload": "no",
        "Nice": "0",
        "NoNewPrivileges": "no",
        "NonBlocking": "no",
        "NotifyAccess": "main",
        "OOMPolicy": "stop",
        "OOMScoreAdjust": "0",
        "OnFailureJobMode": "replace",
        "OnSuccessJobMode": "fail",
        "Perpetual": "no",
        "PrivateDevices": "no",
        "PrivateIPC": "no",
        "PrivateMounts": "no",
        "PrivateNetwork": "no",
        "PrivateTmp": "no",
        "PrivateUsers": "no",
        "ProcSubset": "all",
        "ProtectClock": "no",
        "ProtectControlGroups": "no",
        "ProtectHome": "yes",
        "ProtectHostname": "no",
        "ProtectKernelLogs": "no",
        "ProtectKernelModules": "no",
        "ProtectKernelTunables": "no",
        "ProtectProc": "default",
        "ProtectSystem": "full",
        "RefuseManualStart": "no",
        "RefuseManualStop": "no",
        "ReloadResult": "success",
        "ReloadSignal": "1",
        "RemainAfterExit": "no",
        "RemoveIPC": "no",
        "Requires": "system.slice sysinit.target",
        "Restart": "on-abnormal",
        "RestartKillSignal": "15",
        "RestartMaxDelayUSec": "infinity",
        "RestartMode": "normal",
        "RestartSteps": "0",
        "RestartUSec": "5s",
        "RestartUSecNext": "5s",
        "RestrictNamespaces": "no",
        "RestrictRealtime": "no",
        "RestrictSUIDSGID": "no",
        "Result": "success",
        "RootDirectoryStartOnly": "no",
        "RootEphemeral": "no",
        "RootImagePolicy": "root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent",
        "RuntimeDirectoryMode": "0755",
        "RuntimeDirectoryPreserve": "no",
        "RuntimeMaxUSec": "infinity",
        "RuntimeRandomizedExtraUSec": "0",
        "SameProcessGroup": "no",
        "SecureBits": "0",
        "SendSIGHUP": "no",
        "SendSIGKILL": "no",
        "SetLoginEnvironment": "no",
        "Slice": "system.slice",
        "StandardError": "inherit",
        "StandardInput": "null",
        "StandardOutput": "journal",
        "StartLimitAction": "none",
        "StartLimitBurst": "5",
        "StartLimitIntervalUSec": "10s",
        "StartupBlockIOWeight": "[not set]",
        "StartupCPUShares": "[not set]",
        "StartupCPUWeight": "[not set]",
        "StartupIOWeight": "[not set]",
        "StartupMemoryHigh": "infinity",
        "StartupMemoryLow": "0",
        "StartupMemoryMax": "infinity",
        "StartupMemorySwapMax": "infinity",
        "StartupMemoryZSwapMax": "infinity",
        "StateChangeTimestamp": "Wed 2025-07-23 23:41:37 MSK",
        "StateChangeTimestampMonotonic": "44528762551",
        "StateDirectoryMode": "0755",
        "StatusErrno": "0",
        "StatusText": "Taking your SQL requests now...",
        "StopWhenUnneeded": "no",
        "SubState": "running",
        "SuccessAction": "none",
        "SurviveFinalKillSignal": "no",
        "SyslogFacility": "3",
        "SyslogLevel": "6",
        "SyslogLevelPrefix": "yes",
        "SyslogPriority": "30",
        "SystemCallErrorNumber": "2147483646",
        "TTYReset": "no",
        "TTYVHangup": "no",
        "TTYVTDisallocate": "no",
        "TasksAccounting": "yes",
        "TasksCurrent": "10",
        "TasksMax": "92231",
        "TimeoutAbortUSec": "15min",
        "TimeoutCleanUSec": "infinity",
        "TimeoutStartFailureMode": "terminate",
        "TimeoutStartUSec": "15min",
        "TimeoutStopFailureMode": "terminate",
        "TimeoutStopUSec": "15min",
        "TimerSlackNSec": "50000",
        "Transient": "no",
        "Type": "notify",
        "UID": "114",
        "UMask": "0007",
        "UnitFilePreset": "enabled",
        "UnitFileState": "enabled",
        "User": "mysql",
        "UtmpMode": "init",
        "WantedBy": "multi-user.target",
        "WatchdogSignal": "6",
        "WatchdogTimestampMonotonic": "0",
        "WatchdogUSec": "0"
    }
}
2025-07-23 21:37:48,689 p=65384 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:37:48,696 p=65384 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:38:48,163 p=65384 u=master n=ansible | sm01 | CHANGED => {
    "changed": true,
    "stderr": "",
    "stderr_lines": [],
    "stdout": "Reading package lists...\nBuilding dependency tree...\nReading state information...\nThe following packages will be REMOVED:\n  galera-4* libcgi-fast-perl* libcgi-pm-perl* libclone-perl*\n  libconfig-inifiles-perl* libdbd-mysql-perl* libdbi-perl*\n  libencode-locale-perl* libfcgi-bin* libfcgi-perl* libfcgi0t64*\n  libhtml-parser-perl* libhtml-tagset-perl* libhtml-template-perl*\n  libhttp-date-perl* libhttp-message-perl* libio-html-perl*\n  liblwp-mediatypes-perl* libmariadb-dev* libmariadb3* libmysqlclient21*\n  libsnappy1v5* libtimedate-perl* liburi-perl* liburing2* mariadb-client*\n  mariadb-client-core* mariadb-common* mariadb-plugin-provider-bzip2*\n  mariadb-plugin-provider-lz4* mariadb-plugin-provider-lzma*\n  mariadb-plugin-provider-lzo* mariadb-plugin-provider-snappy* mariadb-server*\n  mariadb-server-core* mysql-common* pv* socat*\n0 upgraded, 0 newly installed, 38 to remove and 1 not upgraded.\nAfter this operation, 202 MB disk space will be freed.\n(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 130437 files and directories currently installed.)\r\nRemoving mariadb-plugin-provider-snappy (1:10.11.13-0ubuntu0.24.04.1) ...\r\nRemoving mariadb-plugin-provider-lzo (1:10.11.13-0ubuntu0.24.04.1) ...\r\nRemoving libcgi-fast-perl (1:2.17-1) ...\r\nRemoving libhtml-template-perl (2.97-2) ...\r\nRemoving libcgi-pm-perl (4.63-1) ...\r\nRemoving libhttp-message-perl (6.45-1ubuntu1) ...\r\nRemoving libclone-perl:amd64 (0.46-1build3) ...\r\nRemoving libdbd-mysql-perl:amd64 (4.052-1ubuntu3) ...\r\nRemoving libencode-locale-perl (1.05-3) ...\r\nRemoving libfcgi-bin (2.4.2-2.1ubuntu0.24.04.1) ...\r\nRemoving libfcgi-perl (0.82+ds-3build2) ...\r\nRemoving libfcgi0t64:amd64 (2.4.2-2.1ubuntu0.24.04.1) ...\r\nRemoving libhtml-parser-perl:amd64 (3.81-1build3) ...\r\nRemoving libhtml-tagset-perl (3.20-6) ...\r\nRemoving libhttp-date-perl (6.06-1) ...\r\nRemoving libio-html-perl (1.004-3) ...\r\nRemoving liblwp-mediatypes-perl (6.04-2) ...\r\nRemoving libmariadb-dev (1:10.11.13-0ubuntu0.24.04.1) ...\r\nRemoving libmysqlclient21:amd64 (8.0.42-0ubuntu0.24.04.2) ...\r\nRemoving libsnappy1v5:amd64 (1.1.10-1build1) ...\r\nRemoving libtimedate-perl (2.3300-2) ...\r\nRemoving liburi-perl (5.27-1) ...\r\nRemoving mariadb-plugin-provider-bzip2 (1:10.11.13-0ubuntu0.24.04.1) ...\r\nRemoving mariadb-plugin-provider-lz4 (1:10.11.13-0ubuntu0.24.04.1) ...\r\nRemoving mariadb-plugin-provider-lzma (1:10.11.13-0ubuntu0.24.04.1) ...\r\nRemoving pv (1.8.5-2build1) ...\r\nRemoving mariadb-server (1:10.11.13-0ubuntu0.24.04.1) ...\r\nRemoving galera-4 (26.4.16-2build4) ...\r\nRemoving mariadb-client (1:10.11.13-0ubuntu0.24.04.1) ...\r\nRemoving libconfig-inifiles-perl (3.000003-2) ...\r\nRemoving libdbi-perl:amd64 (1.643-4build3) ...\r\nRemoving mariadb-client-core (1:10.11.13-0ubuntu0.24.04.1) ...\r\nRemoving libmariadb3:amd64 (1:10.11.13-0ubuntu0.24.04.1) ...\r\nRemoving mariadb-server-core (1:10.11.13-0ubuntu0.24.04.1) ...\r\nRemoving liburing2:amd64 (2.5-1build1) ...\r\nRemoving mariadb-common (1:10.11.13-0ubuntu0.24.04.1) ...\r\nupdate-alternatives: using /etc/mysql/my.cnf.fallback to provide /etc/mysql/my.cnf (my.cnf) in auto mode\r\nRemoving mysql-common (5.8+1.1.0build1) ...\r\nRemoving socat (1.8.0.0-4build3) ...\r\nProcessing triggers for man-db (2.12.0-4build2) ...\r\nProcessing triggers for libc-bin (2.39-0ubuntu8.5) ...\r\n(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 129347 files and directories currently installed.)\r\nPurging configuration files for mysql-common (5.8+1.1.0build1) ...\r\nPurging configuration files for mariadb-client (1:10.11.13-0ubuntu0.24.04.1) ...\r\nPurging configuration files for mariadb-plugin-provider-lz4 (1:10.11.13-0ubuntu0.24.04.1) ...\r\nPurging configuration files for mariadb-plugin-provider-snappy (1:10.11.13-0ubuntu0.24.04.1) ...\r\nPurging configuration files for mariadb-server (1:10.11.13-0ubuntu0.24.04.1) ...\r\nPurging configuration files for mariadb-common (1:10.11.13-0ubuntu0.24.04.1) ...\r\nPurging configuration files for mariadb-plugin-provider-bzip2 (1:10.11.13-0ubuntu0.24.04.1) ...\r\nPurging configuration files for mariadb-plugin-provider-lzma (1:10.11.13-0ubuntu0.24.04.1) ...\r\nPurging configuration files for mariadb-plugin-provider-lzo (1:10.11.13-0ubuntu0.24.04.1) ...\r\ndpkg: warning: while removing mariadb-plugin-provider-lzo, directory '/etc/mysql' not empty so not removed\r\n",
    "stdout_lines": [
        "Reading package lists...",
        "Building dependency tree...",
        "Reading state information...",
        "The following packages will be REMOVED:",
        "  galera-4* libcgi-fast-perl* libcgi-pm-perl* libclone-perl*",
        "  libconfig-inifiles-perl* libdbd-mysql-perl* libdbi-perl*",
        "  libencode-locale-perl* libfcgi-bin* libfcgi-perl* libfcgi0t64*",
        "  libhtml-parser-perl* libhtml-tagset-perl* libhtml-template-perl*",
        "  libhttp-date-perl* libhttp-message-perl* libio-html-perl*",
        "  liblwp-mediatypes-perl* libmariadb-dev* libmariadb3* libmysqlclient21*",
        "  libsnappy1v5* libtimedate-perl* liburi-perl* liburing2* mariadb-client*",
        "  mariadb-client-core* mariadb-common* mariadb-plugin-provider-bzip2*",
        "  mariadb-plugin-provider-lz4* mariadb-plugin-provider-lzma*",
        "  mariadb-plugin-provider-lzo* mariadb-plugin-provider-snappy* mariadb-server*",
        "  mariadb-server-core* mysql-common* pv* socat*",
        "0 upgraded, 0 newly installed, 38 to remove and 1 not upgraded.",
        "After this operation, 202 MB disk space will be freed.",
        "(Reading database ... ",
        "(Reading database ... 5%",
        "(Reading database ... 10%",
        "(Reading database ... 15%",
        "(Reading database ... 20%",
        "(Reading database ... 25%",
        "(Reading database ... 30%",
        "(Reading database ... 35%",
        "(Reading database ... 40%",
        "(Reading database ... 45%",
        "(Reading database ... 50%",
        "(Reading database ... 55%",
        "(Reading database ... 60%",
        "(Reading database ... 65%",
        "(Reading database ... 70%",
        "(Reading database ... 75%",
        "(Reading database ... 80%",
        "(Reading database ... 85%",
        "(Reading database ... 90%",
        "(Reading database ... 95%",
        "(Reading database ... 100%",
        "(Reading database ... 130437 files and directories currently installed.)",
        "Removing mariadb-plugin-provider-snappy (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Removing mariadb-plugin-provider-lzo (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Removing libcgi-fast-perl (1:2.17-1) ...",
        "Removing libhtml-template-perl (2.97-2) ...",
        "Removing libcgi-pm-perl (4.63-1) ...",
        "Removing libhttp-message-perl (6.45-1ubuntu1) ...",
        "Removing libclone-perl:amd64 (0.46-1build3) ...",
        "Removing libdbd-mysql-perl:amd64 (4.052-1ubuntu3) ...",
        "Removing libencode-locale-perl (1.05-3) ...",
        "Removing libfcgi-bin (2.4.2-2.1ubuntu0.24.04.1) ...",
        "Removing libfcgi-perl (0.82+ds-3build2) ...",
        "Removing libfcgi0t64:amd64 (2.4.2-2.1ubuntu0.24.04.1) ...",
        "Removing libhtml-parser-perl:amd64 (3.81-1build3) ...",
        "Removing libhtml-tagset-perl (3.20-6) ...",
        "Removing libhttp-date-perl (6.06-1) ...",
        "Removing libio-html-perl (1.004-3) ...",
        "Removing liblwp-mediatypes-perl (6.04-2) ...",
        "Removing libmariadb-dev (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Removing libmysqlclient21:amd64 (8.0.42-0ubuntu0.24.04.2) ...",
        "Removing libsnappy1v5:amd64 (1.1.10-1build1) ...",
        "Removing libtimedate-perl (2.3300-2) ...",
        "Removing liburi-perl (5.27-1) ...",
        "Removing mariadb-plugin-provider-bzip2 (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Removing mariadb-plugin-provider-lz4 (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Removing mariadb-plugin-provider-lzma (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Removing pv (1.8.5-2build1) ...",
        "Removing mariadb-server (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Removing galera-4 (26.4.16-2build4) ...",
        "Removing mariadb-client (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Removing libconfig-inifiles-perl (3.000003-2) ...",
        "Removing libdbi-perl:amd64 (1.643-4build3) ...",
        "Removing mariadb-client-core (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Removing libmariadb3:amd64 (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Removing mariadb-server-core (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Removing liburing2:amd64 (2.5-1build1) ...",
        "Removing mariadb-common (1:10.11.13-0ubuntu0.24.04.1) ...",
        "update-alternatives: using /etc/mysql/my.cnf.fallback to provide /etc/mysql/my.cnf (my.cnf) in auto mode",
        "Removing mysql-common (5.8+1.1.0build1) ...",
        "Removing socat (1.8.0.0-4build3) ...",
        "Processing triggers for man-db (2.12.0-4build2) ...",
        "Processing triggers for libc-bin (2.39-0ubuntu8.5) ...",
        "(Reading database ... ",
        "(Reading database ... 5%",
        "(Reading database ... 10%",
        "(Reading database ... 15%",
        "(Reading database ... 20%",
        "(Reading database ... 25%",
        "(Reading database ... 30%",
        "(Reading database ... 35%",
        "(Reading database ... 40%",
        "(Reading database ... 45%",
        "(Reading database ... 50%",
        "(Reading database ... 55%",
        "(Reading database ... 60%",
        "(Reading database ... 65%",
        "(Reading database ... 70%",
        "(Reading database ... 75%",
        "(Reading database ... 80%",
        "(Reading database ... 85%",
        "(Reading database ... 90%",
        "(Reading database ... 95%",
        "(Reading database ... 100%",
        "(Reading database ... 129347 files and directories currently installed.)",
        "Purging configuration files for mysql-common (5.8+1.1.0build1) ...",
        "Purging configuration files for mariadb-client (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Purging configuration files for mariadb-plugin-provider-lz4 (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Purging configuration files for mariadb-plugin-provider-snappy (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Purging configuration files for mariadb-server (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Purging configuration files for mariadb-common (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Purging configuration files for mariadb-plugin-provider-bzip2 (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Purging configuration files for mariadb-plugin-provider-lzma (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Purging configuration files for mariadb-plugin-provider-lzo (1:10.11.13-0ubuntu0.24.04.1) ...",
        "dpkg: warning: while removing mariadb-plugin-provider-lzo, directory '/etc/mysql' not empty so not removed"
    ]
}
2025-07-23 21:38:48,608 p=65415 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:38:48,609 p=65415 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:38:49,256 p=65415 u=master n=ansible | sm01 | CHANGED | rc=0 >>


2025-07-23 21:38:55,425 p=65454 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:38:55,425 p=65454 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:40:39,466 p=65454 u=master n=ansible | sm01 | CHANGED => {
    "cache_update_time": 1753306737,
    "cache_updated": true,
    "changed": true,
    "stderr": "\nRunning kernel seems to be up-to-date.\n\nNo services need to be restarted.\n\nNo containers need to be restarted.\n\nNo user sessions are running outdated binaries.\n\nNo VM guests are running outdated hypervisor (qemu) binaries on this host.\n",
    "stderr_lines": [
        "",
        "Running kernel seems to be up-to-date.",
        "",
        "No services need to be restarted.",
        "",
        "No containers need to be restarted.",
        "",
        "No user sessions are running outdated binaries.",
        "",
        "No VM guests are running outdated hypervisor (qemu) binaries on this host."
    ],
    "stdout": "Reading package lists...\nBuilding dependency tree...\nReading state information...\nThe following additional packages will be installed:\n  galera-4 libcgi-fast-perl libcgi-pm-perl libclone-perl\n  libconfig-inifiles-perl libdbd-mysql-perl libdbi-perl libencode-locale-perl\n  libfcgi-bin libfcgi-perl libfcgi0t64 libhtml-parser-perl libhtml-tagset-perl\n  libhtml-template-perl libhttp-date-perl libhttp-message-perl libio-html-perl\n  liblwp-mediatypes-perl libmariadb3 libmysqlclient21 libsnappy1v5\n  libtimedate-perl liburi-perl liburing2 mariadb-client-core mariadb-common\n  mariadb-plugin-provider-bzip2 mariadb-plugin-provider-lz4\n  mariadb-plugin-provider-lzma mariadb-plugin-provider-lzo\n  mariadb-plugin-provider-snappy mariadb-server-core mysql-common pv socat\nSuggested packages:\n  libmldbm-perl libnet-daemon-perl libsql-statement-perl libdata-dump-perl\n  libipc-sharedcache-perl libio-compress-brotli-perl libbusiness-isbn-perl\n  libregexp-ipv6-perl libwww-perl mailx mariadb-test doc-base\nThe following NEW packages will be installed:\n  galera-4 libcgi-fast-perl libcgi-pm-perl libclone-perl\n  libconfig-inifiles-perl libdbd-mysql-perl libdbi-perl libencode-locale-perl\n  libfcgi-bin libfcgi-perl libfcgi0t64 libhtml-parser-perl libhtml-tagset-perl\n  libhtml-template-perl libhttp-date-perl libhttp-message-perl libio-html-perl\n  liblwp-mediatypes-perl libmariadb3 libmysqlclient21 libsnappy1v5\n  libtimedate-perl liburi-perl liburing2 mariadb-client mariadb-client-core\n  mariadb-common mariadb-plugin-provider-bzip2 mariadb-plugin-provider-lz4\n  mariadb-plugin-provider-lzma mariadb-plugin-provider-lzo\n  mariadb-plugin-provider-snappy mariadb-server mariadb-server-core\n  mysql-common pv socat\nPreconfiguring packages ...\n0 upgraded, 37 newly installed, 0 to remove and 1 not upgraded.\nNeed to get 0 B/19.7 MB of archives.\nAfter this operation, 201 MB of additional disk space will be used.\nSelecting previously unselected package galera-4.\r\n(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 129320 files and directories currently installed.)\r\nPreparing to unpack .../00-galera-4_26.4.16-2build4_amd64.deb ...\r\nUnpacking galera-4 (26.4.16-2build4) ...\r\nSelecting previously unselected package mysql-common.\r\nPreparing to unpack .../01-mysql-common_5.8+1.1.0build1_all.deb ...\r\nUnpacking mysql-common (5.8+1.1.0build1) ...\r\nSelecting previously unselected package mariadb-common.\r\nPreparing to unpack .../02-mariadb-common_1%3a10.11.13-0ubuntu0.24.04.1_all.deb ...\r\nUnpacking mariadb-common (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSelecting previously unselected package libdbi-perl:amd64.\r\nPreparing to unpack .../03-libdbi-perl_1.643-4build3_amd64.deb ...\r\nUnpacking libdbi-perl:amd64 (1.643-4build3) ...\r\nSelecting previously unselected package libconfig-inifiles-perl.\r\nPreparing to unpack .../04-libconfig-inifiles-perl_3.000003-2_all.deb ...\r\nUnpacking libconfig-inifiles-perl (3.000003-2) ...\r\nSelecting previously unselected package libmariadb3:amd64.\r\nPreparing to unpack .../05-libmariadb3_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...\r\nUnpacking libmariadb3:amd64 (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSelecting previously unselected package mariadb-client-core.\r\nPreparing to unpack .../06-mariadb-client-core_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...\r\nUnpacking mariadb-client-core (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSelecting previously unselected package mariadb-client.\r\nPreparing to unpack .../07-mariadb-client_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...\r\nUnpacking mariadb-client (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSelecting previously unselected package liburing2:amd64.\r\nPreparing to unpack .../08-liburing2_2.5-1build1_amd64.deb ...\r\nUnpacking liburing2:amd64 (2.5-1build1) ...\r\nSelecting previously unselected package mariadb-server-core.\r\nPreparing to unpack .../09-mariadb-server-core_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...\r\nUnpacking mariadb-server-core (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSelecting previously unselected package socat.\r\nPreparing to unpack .../10-socat_1.8.0.0-4build3_amd64.deb ...\r\nUnpacking socat (1.8.0.0-4build3) ...\r\nSetting up mysql-common (5.8+1.1.0build1) ...\r\nupdate-alternatives: using /etc/mysql/my.cnf.fallback to provide /etc/mysql/my.cnf (my.cnf) in auto mode\r\nSetting up mariadb-common (1:10.11.13-0ubuntu0.24.04.1) ...\r\nupdate-alternatives: using /etc/mysql/mariadb.cnf to provide /etc/mysql/my.cnf (my.cnf) in auto mode\r\nSelecting previously unselected package mariadb-server.\r\n(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 129794 files and directories currently installed.)\r\nPreparing to unpack .../00-mariadb-server_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...\r\nUnpacking mariadb-server (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSelecting previously unselected package libhtml-tagset-perl.\r\nPreparing to unpack .../01-libhtml-tagset-perl_3.20-6_all.deb ...\r\nUnpacking libhtml-tagset-perl (3.20-6) ...\r\nSelecting previously unselected package liburi-perl.\r\nPreparing to unpack .../02-liburi-perl_5.27-1_all.deb ...\r\nUnpacking liburi-perl (5.27-1) ...\r\nSelecting previously unselected package libhtml-parser-perl:amd64.\r\nPreparing to unpack .../03-libhtml-parser-perl_3.81-1build3_amd64.deb ...\r\nUnpacking libhtml-parser-perl:amd64 (3.81-1build3) ...\r\nSelecting previously unselected package libcgi-pm-perl.\r\nPreparing to unpack .../04-libcgi-pm-perl_4.63-1_all.deb ...\r\nUnpacking libcgi-pm-perl (4.63-1) ...\r\nSelecting previously unselected package libfcgi0t64:amd64.\r\nPreparing to unpack .../05-libfcgi0t64_2.4.2-2.1ubuntu0.24.04.1_amd64.deb ...\r\nUnpacking libfcgi0t64:amd64 (2.4.2-2.1ubuntu0.24.04.1) ...\r\nSelecting previously unselected package libfcgi-perl.\r\nPreparing to unpack .../06-libfcgi-perl_0.82+ds-3build2_amd64.deb ...\r\nUnpacking libfcgi-perl (0.82+ds-3build2) ...\r\nSelecting previously unselected package libcgi-fast-perl.\r\nPreparing to unpack .../07-libcgi-fast-perl_1%3a2.17-1_all.deb ...\r\nUnpacking libcgi-fast-perl (1:2.17-1) ...\r\nSelecting previously unselected package libclone-perl:amd64.\r\nPreparing to unpack .../08-libclone-perl_0.46-1build3_amd64.deb ...\r\nUnpacking libclone-perl:amd64 (0.46-1build3) ...\r\nSelecting previously unselected package libmysqlclient21:amd64.\r\nPreparing to unpack .../09-libmysqlclient21_8.0.42-0ubuntu0.24.04.2_amd64.deb ...\r\nUnpacking libmysqlclient21:amd64 (8.0.42-0ubuntu0.24.04.2) ...\r\nSelecting previously unselected package libdbd-mysql-perl:amd64.\r\nPreparing to unpack .../10-libdbd-mysql-perl_4.052-1ubuntu3_amd64.deb ...\r\nUnpacking libdbd-mysql-perl:amd64 (4.052-1ubuntu3) ...\r\nSelecting previously unselected package libencode-locale-perl.\r\nPreparing to unpack .../11-libencode-locale-perl_1.05-3_all.deb ...\r\nUnpacking libencode-locale-perl (1.05-3) ...\r\nSelecting previously unselected package libfcgi-bin.\r\nPreparing to unpack .../12-libfcgi-bin_2.4.2-2.1ubuntu0.24.04.1_amd64.deb ...\r\nUnpacking libfcgi-bin (2.4.2-2.1ubuntu0.24.04.1) ...\r\nSelecting previously unselected package libhtml-template-perl.\r\nPreparing to unpack .../13-libhtml-template-perl_2.97-2_all.deb ...\r\nUnpacking libhtml-template-perl (2.97-2) ...\r\nSelecting previously unselected package libtimedate-perl.\r\nPreparing to unpack .../14-libtimedate-perl_2.3300-2_all.deb ...\r\nUnpacking libtimedate-perl (2.3300-2) ...\r\nSelecting previously unselected package libhttp-date-perl.\r\nPreparing to unpack .../15-libhttp-date-perl_6.06-1_all.deb ...\r\nUnpacking libhttp-date-perl (6.06-1) ...\r\nSelecting previously unselected package libio-html-perl.\r\nPreparing to unpack .../16-libio-html-perl_1.004-3_all.deb ...\r\nUnpacking libio-html-perl (1.004-3) ...\r\nSelecting previously unselected package liblwp-mediatypes-perl.\r\nPreparing to unpack .../17-liblwp-mediatypes-perl_6.04-2_all.deb ...\r\nUnpacking liblwp-mediatypes-perl (6.04-2) ...\r\nSelecting previously unselected package libhttp-message-perl.\r\nPreparing to unpack .../18-libhttp-message-perl_6.45-1ubuntu1_all.deb ...\r\nUnpacking libhttp-message-perl (6.45-1ubuntu1) ...\r\nSelecting previously unselected package mariadb-plugin-provider-bzip2.\r\nPreparing to unpack .../19-mariadb-plugin-provider-bzip2_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...\r\nUnpacking mariadb-plugin-provider-bzip2 (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSelecting previously unselected package mariadb-plugin-provider-lz4.\r\nPreparing to unpack .../20-mariadb-plugin-provider-lz4_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...\r\nUnpacking mariadb-plugin-provider-lz4 (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSelecting previously unselected package mariadb-plugin-provider-lzma.\r\nPreparing to unpack .../21-mariadb-plugin-provider-lzma_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...\r\nUnpacking mariadb-plugin-provider-lzma (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSelecting previously unselected package mariadb-plugin-provider-lzo.\r\nPreparing to unpack .../22-mariadb-plugin-provider-lzo_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...\r\nUnpacking mariadb-plugin-provider-lzo (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSelecting previously unselected package libsnappy1v5:amd64.\r\nPreparing to unpack .../23-libsnappy1v5_1.1.10-1build1_amd64.deb ...\r\nUnpacking libsnappy1v5:amd64 (1.1.10-1build1) ...\r\nSelecting previously unselected package mariadb-plugin-provider-snappy.\r\nPreparing to unpack .../24-mariadb-plugin-provider-snappy_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...\r\nUnpacking mariadb-plugin-provider-snappy (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSelecting previously unselected package pv.\r\nPreparing to unpack .../25-pv_1.8.5-2build1_amd64.deb ...\r\nUnpacking pv (1.8.5-2build1) ...\r\nSetting up libconfig-inifiles-perl (3.000003-2) ...\r\nSetting up galera-4 (26.4.16-2build4) ...\r\nSetting up libmysqlclient21:amd64 (8.0.42-0ubuntu0.24.04.2) ...\r\nSetting up libclone-perl:amd64 (0.46-1build3) ...\r\nSetting up libfcgi0t64:amd64 (2.4.2-2.1ubuntu0.24.04.1) ...\r\nSetting up libhtml-tagset-perl (3.20-6) ...\r\nSetting up liblwp-mediatypes-perl (6.04-2) ...\r\nSetting up libfcgi-bin (2.4.2-2.1ubuntu0.24.04.1) ...\r\nSetting up libencode-locale-perl (1.05-3) ...\r\nSetting up libsnappy1v5:amd64 (1.1.10-1build1) ...\r\nSetting up socat (1.8.0.0-4build3) ...\r\nSetting up libio-html-perl (1.004-3) ...\r\nSetting up libmariadb3:amd64 (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSetting up libtimedate-perl (2.3300-2) ...\r\nSetting up pv (1.8.5-2build1) ...\r\nSetting up libfcgi-perl (0.82+ds-3build2) ...\r\nSetting up liburing2:amd64 (2.5-1build1) ...\r\nSetting up liburi-perl (5.27-1) ...\r\nSetting up libdbi-perl:amd64 (1.643-4build3) ...\r\nSetting up libhttp-date-perl (6.06-1) ...\r\nSetting up mariadb-client-core (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSetting up libdbd-mysql-perl:amd64 (4.052-1ubuntu3) ...\r\nSetting up libhtml-parser-perl:amd64 (3.81-1build3) ...\r\nSetting up mariadb-server-core (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSetting up libhttp-message-perl (6.45-1ubuntu1) ...\r\nSetting up mariadb-client (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSetting up libcgi-pm-perl (4.63-1) ...\r\nSetting up libhtml-template-perl (2.97-2) ...\r\nSetting up mariadb-server (1:10.11.13-0ubuntu0.24.04.1) ...\r\nCreated symlink /etc/systemd/system/multi-user.target.wants/mariadb.service → /usr/lib/systemd/system/mariadb.service.\r\r\nSetting up mariadb-plugin-provider-bzip2 (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSetting up mariadb-plugin-provider-lzma (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSetting up mariadb-plugin-provider-lzo (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSetting up mariadb-plugin-provider-lz4 (1:10.11.13-0ubuntu0.24.04.1) ...\r\nSetting up libcgi-fast-perl (1:2.17-1) ...\r\nSetting up mariadb-plugin-provider-snappy (1:10.11.13-0ubuntu0.24.04.1) ...\r\nProcessing triggers for man-db (2.12.0-4build2) ...\r\nProcessing triggers for libc-bin (2.39-0ubuntu8.5) ...\r\nProcessing triggers for mariadb-server (1:10.11.13-0ubuntu0.24.04.1) ...\r\n",
    "stdout_lines": [
        "Reading package lists...",
        "Building dependency tree...",
        "Reading state information...",
        "The following additional packages will be installed:",
        "  galera-4 libcgi-fast-perl libcgi-pm-perl libclone-perl",
        "  libconfig-inifiles-perl libdbd-mysql-perl libdbi-perl libencode-locale-perl",
        "  libfcgi-bin libfcgi-perl libfcgi0t64 libhtml-parser-perl libhtml-tagset-perl",
        "  libhtml-template-perl libhttp-date-perl libhttp-message-perl libio-html-perl",
        "  liblwp-mediatypes-perl libmariadb3 libmysqlclient21 libsnappy1v5",
        "  libtimedate-perl liburi-perl liburing2 mariadb-client-core mariadb-common",
        "  mariadb-plugin-provider-bzip2 mariadb-plugin-provider-lz4",
        "  mariadb-plugin-provider-lzma mariadb-plugin-provider-lzo",
        "  mariadb-plugin-provider-snappy mariadb-server-core mysql-common pv socat",
        "Suggested packages:",
        "  libmldbm-perl libnet-daemon-perl libsql-statement-perl libdata-dump-perl",
        "  libipc-sharedcache-perl libio-compress-brotli-perl libbusiness-isbn-perl",
        "  libregexp-ipv6-perl libwww-perl mailx mariadb-test doc-base",
        "The following NEW packages will be installed:",
        "  galera-4 libcgi-fast-perl libcgi-pm-perl libclone-perl",
        "  libconfig-inifiles-perl libdbd-mysql-perl libdbi-perl libencode-locale-perl",
        "  libfcgi-bin libfcgi-perl libfcgi0t64 libhtml-parser-perl libhtml-tagset-perl",
        "  libhtml-template-perl libhttp-date-perl libhttp-message-perl libio-html-perl",
        "  liblwp-mediatypes-perl libmariadb3 libmysqlclient21 libsnappy1v5",
        "  libtimedate-perl liburi-perl liburing2 mariadb-client mariadb-client-core",
        "  mariadb-common mariadb-plugin-provider-bzip2 mariadb-plugin-provider-lz4",
        "  mariadb-plugin-provider-lzma mariadb-plugin-provider-lzo",
        "  mariadb-plugin-provider-snappy mariadb-server mariadb-server-core",
        "  mysql-common pv socat",
        "Preconfiguring packages ...",
        "0 upgraded, 37 newly installed, 0 to remove and 1 not upgraded.",
        "Need to get 0 B/19.7 MB of archives.",
        "After this operation, 201 MB of additional disk space will be used.",
        "Selecting previously unselected package galera-4.",
        "(Reading database ... ",
        "(Reading database ... 5%",
        "(Reading database ... 10%",
        "(Reading database ... 15%",
        "(Reading database ... 20%",
        "(Reading database ... 25%",
        "(Reading database ... 30%",
        "(Reading database ... 35%",
        "(Reading database ... 40%",
        "(Reading database ... 45%",
        "(Reading database ... 50%",
        "(Reading database ... 55%",
        "(Reading database ... 60%",
        "(Reading database ... 65%",
        "(Reading database ... 70%",
        "(Reading database ... 75%",
        "(Reading database ... 80%",
        "(Reading database ... 85%",
        "(Reading database ... 90%",
        "(Reading database ... 95%",
        "(Reading database ... 100%",
        "(Reading database ... 129320 files and directories currently installed.)",
        "Preparing to unpack .../00-galera-4_26.4.16-2build4_amd64.deb ...",
        "Unpacking galera-4 (26.4.16-2build4) ...",
        "Selecting previously unselected package mysql-common.",
        "Preparing to unpack .../01-mysql-common_5.8+1.1.0build1_all.deb ...",
        "Unpacking mysql-common (5.8+1.1.0build1) ...",
        "Selecting previously unselected package mariadb-common.",
        "Preparing to unpack .../02-mariadb-common_1%3a10.11.13-0ubuntu0.24.04.1_all.deb ...",
        "Unpacking mariadb-common (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Selecting previously unselected package libdbi-perl:amd64.",
        "Preparing to unpack .../03-libdbi-perl_1.643-4build3_amd64.deb ...",
        "Unpacking libdbi-perl:amd64 (1.643-4build3) ...",
        "Selecting previously unselected package libconfig-inifiles-perl.",
        "Preparing to unpack .../04-libconfig-inifiles-perl_3.000003-2_all.deb ...",
        "Unpacking libconfig-inifiles-perl (3.000003-2) ...",
        "Selecting previously unselected package libmariadb3:amd64.",
        "Preparing to unpack .../05-libmariadb3_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...",
        "Unpacking libmariadb3:amd64 (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Selecting previously unselected package mariadb-client-core.",
        "Preparing to unpack .../06-mariadb-client-core_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...",
        "Unpacking mariadb-client-core (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Selecting previously unselected package mariadb-client.",
        "Preparing to unpack .../07-mariadb-client_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...",
        "Unpacking mariadb-client (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Selecting previously unselected package liburing2:amd64.",
        "Preparing to unpack .../08-liburing2_2.5-1build1_amd64.deb ...",
        "Unpacking liburing2:amd64 (2.5-1build1) ...",
        "Selecting previously unselected package mariadb-server-core.",
        "Preparing to unpack .../09-mariadb-server-core_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...",
        "Unpacking mariadb-server-core (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Selecting previously unselected package socat.",
        "Preparing to unpack .../10-socat_1.8.0.0-4build3_amd64.deb ...",
        "Unpacking socat (1.8.0.0-4build3) ...",
        "Setting up mysql-common (5.8+1.1.0build1) ...",
        "update-alternatives: using /etc/mysql/my.cnf.fallback to provide /etc/mysql/my.cnf (my.cnf) in auto mode",
        "Setting up mariadb-common (1:10.11.13-0ubuntu0.24.04.1) ...",
        "update-alternatives: using /etc/mysql/mariadb.cnf to provide /etc/mysql/my.cnf (my.cnf) in auto mode",
        "Selecting previously unselected package mariadb-server.",
        "(Reading database ... ",
        "(Reading database ... 5%",
        "(Reading database ... 10%",
        "(Reading database ... 15%",
        "(Reading database ... 20%",
        "(Reading database ... 25%",
        "(Reading database ... 30%",
        "(Reading database ... 35%",
        "(Reading database ... 40%",
        "(Reading database ... 45%",
        "(Reading database ... 50%",
        "(Reading database ... 55%",
        "(Reading database ... 60%",
        "(Reading database ... 65%",
        "(Reading database ... 70%",
        "(Reading database ... 75%",
        "(Reading database ... 80%",
        "(Reading database ... 85%",
        "(Reading database ... 90%",
        "(Reading database ... 95%",
        "(Reading database ... 100%",
        "(Reading database ... 129794 files and directories currently installed.)",
        "Preparing to unpack .../00-mariadb-server_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...",
        "Unpacking mariadb-server (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Selecting previously unselected package libhtml-tagset-perl.",
        "Preparing to unpack .../01-libhtml-tagset-perl_3.20-6_all.deb ...",
        "Unpacking libhtml-tagset-perl (3.20-6) ...",
        "Selecting previously unselected package liburi-perl.",
        "Preparing to unpack .../02-liburi-perl_5.27-1_all.deb ...",
        "Unpacking liburi-perl (5.27-1) ...",
        "Selecting previously unselected package libhtml-parser-perl:amd64.",
        "Preparing to unpack .../03-libhtml-parser-perl_3.81-1build3_amd64.deb ...",
        "Unpacking libhtml-parser-perl:amd64 (3.81-1build3) ...",
        "Selecting previously unselected package libcgi-pm-perl.",
        "Preparing to unpack .../04-libcgi-pm-perl_4.63-1_all.deb ...",
        "Unpacking libcgi-pm-perl (4.63-1) ...",
        "Selecting previously unselected package libfcgi0t64:amd64.",
        "Preparing to unpack .../05-libfcgi0t64_2.4.2-2.1ubuntu0.24.04.1_amd64.deb ...",
        "Unpacking libfcgi0t64:amd64 (2.4.2-2.1ubuntu0.24.04.1) ...",
        "Selecting previously unselected package libfcgi-perl.",
        "Preparing to unpack .../06-libfcgi-perl_0.82+ds-3build2_amd64.deb ...",
        "Unpacking libfcgi-perl (0.82+ds-3build2) ...",
        "Selecting previously unselected package libcgi-fast-perl.",
        "Preparing to unpack .../07-libcgi-fast-perl_1%3a2.17-1_all.deb ...",
        "Unpacking libcgi-fast-perl (1:2.17-1) ...",
        "Selecting previously unselected package libclone-perl:amd64.",
        "Preparing to unpack .../08-libclone-perl_0.46-1build3_amd64.deb ...",
        "Unpacking libclone-perl:amd64 (0.46-1build3) ...",
        "Selecting previously unselected package libmysqlclient21:amd64.",
        "Preparing to unpack .../09-libmysqlclient21_8.0.42-0ubuntu0.24.04.2_amd64.deb ...",
        "Unpacking libmysqlclient21:amd64 (8.0.42-0ubuntu0.24.04.2) ...",
        "Selecting previously unselected package libdbd-mysql-perl:amd64.",
        "Preparing to unpack .../10-libdbd-mysql-perl_4.052-1ubuntu3_amd64.deb ...",
        "Unpacking libdbd-mysql-perl:amd64 (4.052-1ubuntu3) ...",
        "Selecting previously unselected package libencode-locale-perl.",
        "Preparing to unpack .../11-libencode-locale-perl_1.05-3_all.deb ...",
        "Unpacking libencode-locale-perl (1.05-3) ...",
        "Selecting previously unselected package libfcgi-bin.",
        "Preparing to unpack .../12-libfcgi-bin_2.4.2-2.1ubuntu0.24.04.1_amd64.deb ...",
        "Unpacking libfcgi-bin (2.4.2-2.1ubuntu0.24.04.1) ...",
        "Selecting previously unselected package libhtml-template-perl.",
        "Preparing to unpack .../13-libhtml-template-perl_2.97-2_all.deb ...",
        "Unpacking libhtml-template-perl (2.97-2) ...",
        "Selecting previously unselected package libtimedate-perl.",
        "Preparing to unpack .../14-libtimedate-perl_2.3300-2_all.deb ...",
        "Unpacking libtimedate-perl (2.3300-2) ...",
        "Selecting previously unselected package libhttp-date-perl.",
        "Preparing to unpack .../15-libhttp-date-perl_6.06-1_all.deb ...",
        "Unpacking libhttp-date-perl (6.06-1) ...",
        "Selecting previously unselected package libio-html-perl.",
        "Preparing to unpack .../16-libio-html-perl_1.004-3_all.deb ...",
        "Unpacking libio-html-perl (1.004-3) ...",
        "Selecting previously unselected package liblwp-mediatypes-perl.",
        "Preparing to unpack .../17-liblwp-mediatypes-perl_6.04-2_all.deb ...",
        "Unpacking liblwp-mediatypes-perl (6.04-2) ...",
        "Selecting previously unselected package libhttp-message-perl.",
        "Preparing to unpack .../18-libhttp-message-perl_6.45-1ubuntu1_all.deb ...",
        "Unpacking libhttp-message-perl (6.45-1ubuntu1) ...",
        "Selecting previously unselected package mariadb-plugin-provider-bzip2.",
        "Preparing to unpack .../19-mariadb-plugin-provider-bzip2_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...",
        "Unpacking mariadb-plugin-provider-bzip2 (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Selecting previously unselected package mariadb-plugin-provider-lz4.",
        "Preparing to unpack .../20-mariadb-plugin-provider-lz4_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...",
        "Unpacking mariadb-plugin-provider-lz4 (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Selecting previously unselected package mariadb-plugin-provider-lzma.",
        "Preparing to unpack .../21-mariadb-plugin-provider-lzma_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...",
        "Unpacking mariadb-plugin-provider-lzma (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Selecting previously unselected package mariadb-plugin-provider-lzo.",
        "Preparing to unpack .../22-mariadb-plugin-provider-lzo_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...",
        "Unpacking mariadb-plugin-provider-lzo (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Selecting previously unselected package libsnappy1v5:amd64.",
        "Preparing to unpack .../23-libsnappy1v5_1.1.10-1build1_amd64.deb ...",
        "Unpacking libsnappy1v5:amd64 (1.1.10-1build1) ...",
        "Selecting previously unselected package mariadb-plugin-provider-snappy.",
        "Preparing to unpack .../24-mariadb-plugin-provider-snappy_1%3a10.11.13-0ubuntu0.24.04.1_amd64.deb ...",
        "Unpacking mariadb-plugin-provider-snappy (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Selecting previously unselected package pv.",
        "Preparing to unpack .../25-pv_1.8.5-2build1_amd64.deb ...",
        "Unpacking pv (1.8.5-2build1) ...",
        "Setting up libconfig-inifiles-perl (3.000003-2) ...",
        "Setting up galera-4 (26.4.16-2build4) ...",
        "Setting up libmysqlclient21:amd64 (8.0.42-0ubuntu0.24.04.2) ...",
        "Setting up libclone-perl:amd64 (0.46-1build3) ...",
        "Setting up libfcgi0t64:amd64 (2.4.2-2.1ubuntu0.24.04.1) ...",
        "Setting up libhtml-tagset-perl (3.20-6) ...",
        "Setting up liblwp-mediatypes-perl (6.04-2) ...",
        "Setting up libfcgi-bin (2.4.2-2.1ubuntu0.24.04.1) ...",
        "Setting up libencode-locale-perl (1.05-3) ...",
        "Setting up libsnappy1v5:amd64 (1.1.10-1build1) ...",
        "Setting up socat (1.8.0.0-4build3) ...",
        "Setting up libio-html-perl (1.004-3) ...",
        "Setting up libmariadb3:amd64 (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Setting up libtimedate-perl (2.3300-2) ...",
        "Setting up pv (1.8.5-2build1) ...",
        "Setting up libfcgi-perl (0.82+ds-3build2) ...",
        "Setting up liburing2:amd64 (2.5-1build1) ...",
        "Setting up liburi-perl (5.27-1) ...",
        "Setting up libdbi-perl:amd64 (1.643-4build3) ...",
        "Setting up libhttp-date-perl (6.06-1) ...",
        "Setting up mariadb-client-core (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Setting up libdbd-mysql-perl:amd64 (4.052-1ubuntu3) ...",
        "Setting up libhtml-parser-perl:amd64 (3.81-1build3) ...",
        "Setting up mariadb-server-core (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Setting up libhttp-message-perl (6.45-1ubuntu1) ...",
        "Setting up mariadb-client (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Setting up libcgi-pm-perl (4.63-1) ...",
        "Setting up libhtml-template-perl (2.97-2) ...",
        "Setting up mariadb-server (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Created symlink /etc/systemd/system/multi-user.target.wants/mariadb.service → /usr/lib/systemd/system/mariadb.service.",
        "",
        "Setting up mariadb-plugin-provider-bzip2 (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Setting up mariadb-plugin-provider-lzma (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Setting up mariadb-plugin-provider-lzo (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Setting up mariadb-plugin-provider-lz4 (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Setting up libcgi-fast-perl (1:2.17-1) ...",
        "Setting up mariadb-plugin-provider-snappy (1:10.11.13-0ubuntu0.24.04.1) ...",
        "Processing triggers for man-db (2.12.0-4build2) ...",
        "Processing triggers for libc-bin (2.39-0ubuntu8.5) ...",
        "Processing triggers for mariadb-server (1:10.11.13-0ubuntu0.24.04.1) ..."
    ]
}
2025-07-23 21:40:39,933 p=65515 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:40:39,934 p=65515 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:40:40,972 p=65515 u=master n=ansible | sm01 | SUCCESS => {
    "changed": false,
    "enabled": true,
    "name": "mariadb",
    "state": "started",
    "status": {
        "ActiveEnterTimestamp": "Thu 2025-07-24 00:40:28 MSK",
        "ActiveEnterTimestampMonotonic": "48059557896",
        "ActiveExitTimestampMonotonic": "0",
        "ActiveState": "active",
        "After": "sysinit.target system.slice systemd-journald.socket network.target basic.target",
        "AllowIsolate": "no",
        "AmbientCapabilities": "cap_ipc_lock",
        "AssertResult": "yes",
        "AssertTimestamp": "Thu 2025-07-24 00:40:28 MSK",
        "AssertTimestampMonotonic": "48059062269",
        "Before": "shutdown.target multi-user.target",
        "BlockIOAccounting": "no",
        "BlockIOWeight": "[not set]",
        "CPUAccounting": "yes",
        "CPUAffinityFromNUMA": "no",
        "CPUQuotaPerSecUSec": "infinity",
        "CPUQuotaPeriodUSec": "infinity",
        "CPUSchedulingPolicy": "0",
        "CPUSchedulingPriority": "0",
        "CPUSchedulingResetOnFork": "no",
        "CPUShares": "[not set]",
        "CPUUsageNSec": "433384000",
        "CPUWeight": "[not set]",
        "CacheDirectoryMode": "0755",
        "CanFreeze": "yes",
        "CanIsolate": "no",
        "CanReload": "no",
        "CanStart": "yes",
        "CanStop": "yes",
        "CapabilityBoundingSet": "cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore",
        "CleanResult": "success",
        "CollectMode": "inactive",
        "ConditionResult": "yes",
        "ConditionTimestamp": "Thu 2025-07-24 00:40:28 MSK",
        "ConditionTimestampMonotonic": "48059062266",
        "ConfigurationDirectoryMode": "0755",
        "Conflicts": "shutdown.target",
        "ControlGroup": "/system.slice/mariadb.service",
        "ControlGroupId": "10553",
        "ControlPID": "0",
        "CoredumpFilter": "0x33",
        "CoredumpReceive": "no",
        "DefaultDependencies": "yes",
        "DefaultMemoryLow": "0",
        "DefaultMemoryMin": "0",
        "DefaultStartupMemoryLow": "0",
        "Delegate": "no",
        "Description": "MariaDB 10.11.13 database server",
        "DevicePolicy": "auto",
        "Documentation": "\"man:mariadbd(8)\" https://mariadb.com/kb/en/library/systemd/",
        "DynamicUser": "no",
        "ExecMainCode": "0",
        "ExecMainExitTimestampMonotonic": "0",
        "ExecMainPID": "71376",
        "ExecMainStartTimestamp": "Thu 2025-07-24 00:40:28 MSK",
        "ExecMainStartTimestampMonotonic": "48059132069",
        "ExecMainStatus": "0",
        "ExecStart": "{ path=/usr/sbin/mariadbd ; argv[]=/usr/sbin/mariadbd $MYSQLD_OPTS $_WSREP_NEW_CLUSTER $_WSREP_START_POSITION ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }",
        "ExecStartEx": "{ path=/usr/sbin/mariadbd ; argv[]=/usr/sbin/mariadbd $MYSQLD_OPTS $_WSREP_NEW_CLUSTER $_WSREP_START_POSITION ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }",
        "ExecStartPost": "{ path=/etc/mysql/debian-start ; argv[]=/etc/mysql/debian-start ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }",
        "ExecStartPostEx": "{ path=/etc/mysql/debian-start ; argv[]=/etc/mysql/debian-start ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }",
        "ExecStartPre": "{ path=/bin/sh ; argv[]=/bin/sh -c [ ! -e /usr/bin/galera_recovery ] && VAR= ||   VAR=`/usr/bin/galera_recovery`; [ $? -eq 0 ]   && systemctl set-environment _WSREP_START_POSITION=$VAR || exit 1 ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }",
        "ExecStartPreEx": "{ path=/bin/sh ; argv[]=/bin/sh -c [ ! -e /usr/bin/galera_recovery ] && VAR= ||   VAR=`/usr/bin/galera_recovery`; [ $? -eq 0 ]   && systemctl set-environment _WSREP_START_POSITION=$VAR || exit 1 ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }",
        "ExitType": "main",
        "ExtensionImagePolicy": "root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent",
        "FailureAction": "none",
        "FileDescriptorStoreMax": "0",
        "FileDescriptorStorePreserve": "restart",
        "FinalKillSignal": "9",
        "FragmentPath": "/usr/lib/systemd/system/mariadb.service",
        "FreezerState": "running",
        "GID": "111",
        "Group": "mysql",
        "GuessMainPID": "yes",
        "IOAccounting": "no",
        "IOReadBytes": "[not set]",
        "IOReadOperations": "[not set]",
        "IOSchedulingClass": "2",
        "IOSchedulingPriority": "4",
        "IOWeight": "[not set]",
        "IOWriteBytes": "[not set]",
        "IOWriteOperations": "[not set]",
        "IPAccounting": "no",
        "IPEgressBytes": "[no data]",
        "IPEgressPackets": "[no data]",
        "IPIngressBytes": "[no data]",
        "IPIngressPackets": "[no data]",
        "Id": "mariadb.service",
        "IgnoreOnIsolate": "no",
        "IgnoreSIGPIPE": "yes",
        "InactiveEnterTimestampMonotonic": "0",
        "InactiveExitTimestamp": "Thu 2025-07-24 00:40:28 MSK",
        "InactiveExitTimestampMonotonic": "48059069231",
        "InvocationID": "4fa4c18d83b64dbfafdedfe767d30e1e",
        "JobRunningTimeoutUSec": "infinity",
        "JobTimeoutAction": "none",
        "JobTimeoutUSec": "infinity",
        "KeyringMode": "private",
        "KillMode": "control-group",
        "KillSignal": "15",
        "LimitAS": "infinity",
        "LimitASSoft": "infinity",
        "LimitCORE": "infinity",
        "LimitCORESoft": "0",
        "LimitCPU": "infinity",
        "LimitCPUSoft": "infinity",
        "LimitDATA": "infinity",
        "LimitDATASoft": "infinity",
        "LimitFSIZE": "infinity",
        "LimitFSIZESoft": "infinity",
        "LimitLOCKS": "infinity",
        "LimitLOCKSSoft": "infinity",
        "LimitMEMLOCK": "524288",
        "LimitMEMLOCKSoft": "524288",
        "LimitMSGQUEUE": "819200",
        "LimitMSGQUEUESoft": "819200",
        "LimitNICE": "0",
        "LimitNICESoft": "0",
        "LimitNOFILE": "32768",
        "LimitNOFILESoft": "32768",
        "LimitNPROC": "46581",
        "LimitNPROCSoft": "46581",
        "LimitRSS": "infinity",
        "LimitRSSSoft": "infinity",
        "LimitRTPRIO": "0",
        "LimitRTPRIOSoft": "0",
        "LimitRTTIME": "infinity",
        "LimitRTTIMESoft": "infinity",
        "LimitSIGPENDING": "46581",
        "LimitSIGPENDINGSoft": "46581",
        "LimitSTACK": "infinity",
        "LimitSTACKSoft": "8388608",
        "LoadState": "loaded",
        "LockPersonality": "no",
        "LogLevelMax": "-1",
        "LogRateLimitBurst": "0",
        "LogRateLimitIntervalUSec": "0",
        "LogsDirectoryMode": "0755",
        "MainPID": "71376",
        "ManagedOOMMemoryPressure": "auto",
        "ManagedOOMMemoryPressureLimit": "0",
        "ManagedOOMPreference": "none",
        "ManagedOOMSwap": "auto",
        "MemoryAccounting": "yes",
        "MemoryAvailable": "11515457536",
        "MemoryCurrent": "82329600",
        "MemoryDenyWriteExecute": "no",
        "MemoryHigh": "infinity",
        "MemoryKSM": "no",
        "MemoryLimit": "infinity",
        "MemoryLow": "0",
        "MemoryMax": "infinity",
        "MemoryMin": "0",
        "MemoryPeak": "85819392",
        "MemoryPressureThresholdUSec": "200ms",
        "MemoryPressureWatch": "auto",
        "MemorySwapCurrent": "0",
        "MemorySwapMax": "infinity",
        "MemorySwapPeak": "0",
        "MemoryZSwapCurrent": "0",
        "MemoryZSwapMax": "infinity",
        "MountAPIVFS": "no",
        "MountImagePolicy": "root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent",
        "NFileDescriptorStore": "0",
        "NRestarts": "0",
        "NUMAPolicy": "n/a",
        "Names": "mariadb.service mysql.service mysqld.service",
        "NeedDaemonReload": "no",
        "Nice": "0",
        "NoNewPrivileges": "no",
        "NonBlocking": "no",
        "NotifyAccess": "main",
        "OOMPolicy": "stop",
        "OOMScoreAdjust": "0",
        "OnFailureJobMode": "replace",
        "OnSuccessJobMode": "fail",
        "Perpetual": "no",
        "PrivateDevices": "no",
        "PrivateIPC": "no",
        "PrivateMounts": "no",
        "PrivateNetwork": "no",
        "PrivateTmp": "no",
        "PrivateUsers": "no",
        "ProcSubset": "all",
        "ProtectClock": "no",
        "ProtectControlGroups": "no",
        "ProtectHome": "yes",
        "ProtectHostname": "no",
        "ProtectKernelLogs": "no",
        "ProtectKernelModules": "no",
        "ProtectKernelTunables": "no",
        "ProtectProc": "default",
        "ProtectSystem": "full",
        "RefuseManualStart": "no",
        "RefuseManualStop": "no",
        "ReloadResult": "success",
        "ReloadSignal": "1",
        "RemainAfterExit": "no",
        "RemoveIPC": "no",
        "Requires": "system.slice sysinit.target",
        "Restart": "on-abnormal",
        "RestartKillSignal": "15",
        "RestartMaxDelayUSec": "infinity",
        "RestartMode": "normal",
        "RestartSteps": "0",
        "RestartUSec": "5s",
        "RestartUSecNext": "5s",
        "RestrictNamespaces": "no",
        "RestrictRealtime": "no",
        "RestrictSUIDSGID": "no",
        "Result": "success",
        "RootDirectoryStartOnly": "no",
        "RootEphemeral": "no",
        "RootImagePolicy": "root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent",
        "RuntimeDirectoryMode": "0755",
        "RuntimeDirectoryPreserve": "no",
        "RuntimeMaxUSec": "infinity",
        "RuntimeRandomizedExtraUSec": "0",
        "SameProcessGroup": "no",
        "SecureBits": "0",
        "SendSIGHUP": "no",
        "SendSIGKILL": "no",
        "SetLoginEnvironment": "no",
        "Slice": "system.slice",
        "StandardError": "inherit",
        "StandardInput": "null",
        "StandardOutput": "journal",
        "StartLimitAction": "none",
        "StartLimitBurst": "5",
        "StartLimitIntervalUSec": "10s",
        "StartupBlockIOWeight": "[not set]",
        "StartupCPUShares": "[not set]",
        "StartupCPUWeight": "[not set]",
        "StartupIOWeight": "[not set]",
        "StartupMemoryHigh": "infinity",
        "StartupMemoryLow": "0",
        "StartupMemoryMax": "infinity",
        "StartupMemorySwapMax": "infinity",
        "StartupMemoryZSwapMax": "infinity",
        "StateChangeTimestamp": "Thu 2025-07-24 00:40:28 MSK",
        "StateChangeTimestampMonotonic": "48059557896",
        "StateDirectoryMode": "0755",
        "StatusErrno": "0",
        "StatusText": "Taking your SQL requests now...",
        "StopWhenUnneeded": "no",
        "SubState": "running",
        "SuccessAction": "none",
        "SurviveFinalKillSignal": "no",
        "SyslogFacility": "3",
        "SyslogLevel": "6",
        "SyslogLevelPrefix": "yes",
        "SyslogPriority": "30",
        "SystemCallErrorNumber": "2147483646",
        "TTYReset": "no",
        "TTYVHangup": "no",
        "TTYVTDisallocate": "no",
        "TasksAccounting": "yes",
        "TasksCurrent": "12",
        "TasksMax": "92231",
        "TimeoutAbortUSec": "15min",
        "TimeoutCleanUSec": "infinity",
        "TimeoutStartFailureMode": "terminate",
        "TimeoutStartUSec": "15min",
        "TimeoutStopFailureMode": "terminate",
        "TimeoutStopUSec": "15min",
        "TimerSlackNSec": "50000",
        "Transient": "no",
        "Type": "notify",
        "UID": "114",
        "UMask": "0007",
        "UnitFilePreset": "enabled",
        "UnitFileState": "enabled",
        "User": "mysql",
        "UtmpMode": "init",
        "WantedBy": "multi-user.target",
        "WatchdogSignal": "6",
        "WatchdogTimestampMonotonic": "0",
        "WatchdogUSec": "0"
    }
}
2025-07-23 21:41:04,438 p=65579 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:41:04,438 p=65579 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:41:05,111 p=65579 u=master n=ansible | sm01 | CHANGED | rc=0 >>
VERSION()
10.11.13-MariaDB-0ubuntu0.24.04.1

2025-07-23 21:41:28,108 p=65633 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:41:28,108 p=65633 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:41:28,506 p=65633 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 21:41:28,515 p=65633 u=master n=ansible | TASK [Gathering Facts] ****************************************************************************************************************************************************************
2025-07-23 21:41:28,515 p=65633 u=master n=ansible | Wednesday 23 July 2025  21:41:28 +0000 (0:00:00.011)       0:00:00.011 ******** 
2025-07-23 21:41:29,269 p=65633 u=master n=ansible | ok: [sm01]
2025-07-23 21:41:29,277 p=65633 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 21:41:29,277 p=65633 u=master n=ansible | Wednesday 23 July 2025  21:41:29 +0000 (0:00:00.762)       0:00:00.773 ******** 
2025-07-23 21:41:29,299 p=65633 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 21:41:29,303 p=65633 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 21:41:29,303 p=65633 u=master n=ansible | Wednesday 23 July 2025  21:41:29 +0000 (0:00:00.026)       0:00:00.799 ******** 
2025-07-23 21:41:29,692 p=65633 u=master n=ansible | ok: [sm01]
2025-07-23 21:41:29,695 p=65633 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 21:41:29,695 p=65633 u=master n=ansible | Wednesday 23 July 2025  21:41:29 +0000 (0:00:00.392)       0:00:01.191 ******** 
2025-07-23 21:41:29,742 p=65633 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 21:41:29,745 p=65633 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 21:41:29,745 p=65633 u=master n=ansible | Wednesday 23 July 2025  21:41:29 +0000 (0:00:00.049)       0:00:01.241 ******** 
2025-07-23 21:41:29,779 p=65633 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 21:41:29,779 p=65633 u=master n=ansible | Wednesday 23 July 2025  21:41:29 +0000 (0:00:00.034)       0:00:01.275 ******** 
2025-07-23 21:41:29,827 p=65633 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 21:41:29,831 p=65633 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 21:41:29,831 p=65633 u=master n=ansible | Wednesday 23 July 2025  21:41:29 +0000 (0:00:00.051)       0:00:01.327 ******** 
2025-07-23 21:41:29,885 p=65633 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 21:41:29,890 p=65633 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка статуса MariaDB] ******************************************************************************************************************************
2025-07-23 21:41:29,890 p=65633 u=master n=ansible | Wednesday 23 July 2025  21:41:29 +0000 (0:00:00.058)       0:00:01.386 ******** 
2025-07-23 21:41:30,628 p=65633 u=master n=ansible | ok: [sm01]
2025-07-23 21:41:30,632 p=65633 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя Slurm (способ DeepOps)] **********************************************************************************************************
2025-07-23 21:41:30,632 p=65633 u=master n=ansible | Wednesday 23 July 2025  21:41:30 +0000 (0:00:00.742)       0:00:02.128 ******** 
2025-07-23 21:41:31,130 p=65633 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  msg: 'unable to connect to database, check login_user and login_password are correct or /root/.my.cnf has the credentials. Exception message: (1698, "Access denied for user ''root''@''localhost''")'
2025-07-23 21:41:31,132 p=65633 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:41:31,132 p=65633 u=master n=ansible | sm01                       : ok=7    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 21:41:31,132 p=65633 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 2 seconds
2025-07-23 21:41:31,132 p=65633 u=master n=ansible | Wednesday 23 July 2025  21:41:31 +0000 (0:00:00.499)       0:00:02.628 ******** 
2025-07-23 21:41:31,133 p=65633 u=master n=ansible | =============================================================================== 
2025-07-23 21:41:31,133 p=65633 u=master n=ansible | Gathering Facts ---------------------------------------------------------------------------------------------------------------------------------------------------------------- 0.76s
2025-07-23 21:41:31,133 p=65633 u=master n=ansible | slurm_master : [MARIADB] Проверка статуса MariaDB ------------------------------------------------------------------------------------------------------------------------------ 0.74s
2025-07-23 21:41:31,133 p=65633 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя Slurm (способ DeepOps) ---------------------------------------------------------------------------------------------------------- 0.50s
2025-07-23 21:41:31,133 p=65633 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 0.39s
2025-07-23 21:41:31,133 p=65633 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 21:41:31,133 p=65633 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:41:31,133 p=65633 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:41:31,133 p=65633 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:41:31,133 p=65633 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:43:17,661 p=65716 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:43:17,661 p=65716 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:43:18,073 p=65716 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 21:43:18,087 p=65716 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 21:43:18,087 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:18 +0000 (0:00:00.016)       0:00:00.016 ******** 
2025-07-23 21:43:18,110 p=65716 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 21:43:18,114 p=65716 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 21:43:18,114 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:18 +0000 (0:00:00.026)       0:00:00.043 ******** 
2025-07-23 21:43:19,267 p=65716 u=master n=ansible | ok: [sm01]
2025-07-23 21:43:19,271 p=65716 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 21:43:19,271 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:19 +0000 (0:00:01.156)       0:00:01.200 ******** 
2025-07-23 21:43:19,316 p=65716 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 21:43:19,319 p=65716 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 21:43:19,319 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:19 +0000 (0:00:00.048)       0:00:01.248 ******** 
2025-07-23 21:43:19,351 p=65716 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 21:43:19,352 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:19 +0000 (0:00:00.032)       0:00:01.281 ******** 
2025-07-23 21:43:19,400 p=65716 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 21:43:19,404 p=65716 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 21:43:19,405 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:19 +0000 (0:00:00.052)       0:00:01.333 ******** 
2025-07-23 21:43:19,457 p=65716 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 21:43:19,463 p=65716 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-23 21:43:19,463 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:19 +0000 (0:00:00.058)       0:00:01.392 ******** 
2025-07-23 21:43:19,736 p=65716 u=master n=ansible | ok: [sm01]
2025-07-23 21:43:19,740 p=65716 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-23 21:43:19,740 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:19 +0000 (0:00:00.276)       0:00:01.669 ******** 
2025-07-23 21:43:19,790 p=65716 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-23 21:43:19,794 p=65716 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (через shell)] ******************************************************************************************************
2025-07-23 21:43:19,794 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:19 +0000 (0:00:00.053)       0:00:01.723 ******** 
2025-07-23 21:43:20,162 p=65716 u=master n=ansible | changed: [sm01]
2025-07-23 21:43:20,167 p=65716 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-23 21:43:20,168 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:20 +0000 (0:00:00.373)       0:00:02.096 ******** 
2025-07-23 21:43:20,215 p=65716 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-23 21:43:20,219 p=65716 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-23 21:43:20,219 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:20 +0000 (0:00:00.051)       0:00:02.148 ******** 
2025-07-23 21:43:20,515 p=65716 u=master n=ansible | ok: [sm01]
2025-07-23 21:43:20,519 p=65716 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-23 21:43:20,520 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:20 +0000 (0:00:00.300)       0:00:02.448 ******** 
2025-07-23 21:43:20,818 p=65716 u=master n=ansible | ok: [sm01]
2025-07-23 21:43:20,822 p=65716 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-23 21:43:20,823 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:20 +0000 (0:00:00.302)       0:00:02.751 ******** 
2025-07-23 21:43:20,873 p=65716 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-23 21:43:20,877 p=65716 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-23 21:43:20,877 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:20 +0000 (0:00:00.054)       0:00:02.806 ******** 
2025-07-23 21:43:20,897 p=65716 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-23 21:43:20,907 p=65716 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-23 21:43:20,908 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:20 +0000 (0:00:00.030)       0:00:02.836 ******** 
2025-07-23 21:43:21,033 p=65716 u=master n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'jwt_enabled' is undefined. 'jwt_enabled' is undefined
2025-07-23 21:43:21,034 p=65716 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  msg: 'AnsibleUndefinedVariable: ''jwt_enabled'' is undefined. ''jwt_enabled'' is undefined'
2025-07-23 21:43:21,035 p=65716 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:43:21,035 p=65716 u=master n=ansible | sm01                       : ok=13   changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 21:43:21,035 p=65716 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 2 seconds
2025-07-23 21:43:21,035 p=65716 u=master n=ansible | Wednesday 23 July 2025  21:43:21 +0000 (0:00:00.127)       0:00:02.964 ******** 
2025-07-23 21:43:21,035 p=65716 u=master n=ansible | =============================================================================== 
2025-07-23 21:43:21,036 p=65716 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.16s
2025-07-23 21:43:21,036 p=65716 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (через shell) ------------------------------------------------------------------------------------------------------ 0.37s
2025-07-23 21:43:21,036 p=65716 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-23 21:43:21,036 p=65716 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-23 21:43:21,036 p=65716 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.28s
2025-07-23 21:43:21,036 p=65716 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.13s
2025-07-23 21:43:21,036 p=65716 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 21:43:21,036 p=65716 u=master n=ansible | slurm_master : [MARIADB] Финальный результат ----------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:43:21,036 p=65716 u=master n=ansible | slurm_master : [MARIADB] Показать версию MariaDB ------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:43:21,036 p=65716 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:43:21,037 p=65716 u=master n=ansible | slurm_master : [MARIADB] Результат создания пользователя ----------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:43:21,037 p=65716 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:43:21,037 p=65716 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:43:21,037 p=65716 u=master n=ansible | slurm_master : [SLURM-MASTER] Создание конфигурации Slurm ---------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:43:21,037 p=65716 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:44:32,101 p=65813 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:44:32,101 p=65813 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:44:32,497 p=65813 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 21:44:32,511 p=65813 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 21:44:32,511 p=65813 u=master n=ansible | Wednesday 23 July 2025  21:44:32 +0000 (0:00:00.016)       0:00:00.016 ******** 
2025-07-23 21:44:32,534 p=65813 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 21:44:32,538 p=65813 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 21:44:32,538 p=65813 u=master n=ansible | Wednesday 23 July 2025  21:44:32 +0000 (0:00:00.026)       0:00:00.042 ******** 
2025-07-23 21:44:32,576 p=65813 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:44:32,576 p=65813 u=master n=ansible | sm01                       : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-23 21:44:32,577 p=65813 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 0 seconds
2025-07-23 21:44:32,577 p=65813 u=master n=ansible | Wednesday 23 July 2025  21:44:32 +0000 (0:00:00.038)       0:00:00.081 ******** 
2025-07-23 21:44:32,577 p=65813 u=master n=ansible | =============================================================================== 
2025-07-23 21:44:32,577 p=65813 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.04s
2025-07-23 21:44:32,577 p=65813 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:46:19,566 p=65866 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:46:19,566 p=65866 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:46:19,798 p=65866 u=master n=ansible | sm01 | SUCCESS => {
    "changed": false,
    "include_args": {
        "name": "slurm_master",
        "tasks_from": "mariadb"
    }
}
2025-07-23 21:46:21,015 p=65866 u=master n=ansible | sm01 | SUCCESS | rc=0 >>
VERSION()
10.11.13-MariaDB-0ubuntu0.24.04.1

2025-07-23 21:46:21,110 p=65866 u=master n=ansible | sm01 | SUCCESS => {
    "msg": "🐬 MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
}
2025-07-23 21:46:21,469 p=65866 u=master n=ansible | sm01 | CHANGED | rc=0 >>


2025-07-23 21:46:21,558 p=65866 u=master n=ansible | sm01 | SUCCESS => {
    "msg": "📝 Создание пользователя: False\n"
}
2025-07-23 21:46:21,897 p=65866 u=master n=ansible | sm01 | SUCCESS | rc=1 >>
ERROR 1045 (28000): Access denied for user 'slurm'@'localhost' (using password: YES)non-zero return code

2025-07-23 21:46:22,232 p=65866 u=master n=ansible | sm01 | SUCCESS | rc=1 >>
ERROR 1045 (28000): Access denied for user 'slurm'@'localhost' (using password: YES)non-zero return code

2025-07-23 21:46:22,341 p=65866 u=master n=ansible | sm01 | SUCCESS => {
    "msg": "🐬 MariaDB настройка завершена:\n👤 Пользователь: slurm\n📊 База: slurm_acct_db\n✅ Подключение: False\n\n📋 Доступные базы:\n\n\n❌ Проблема: ERROR 1045 (28000): Access denied for user 'slurm'@'localhost' (using password: YES)\n"
}
2025-07-23 21:49:10,016 p=65997 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:49:10,017 p=65997 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:49:10,423 p=65997 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 21:49:10,437 p=65997 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 21:49:10,437 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:10 +0000 (0:00:00.016)       0:00:00.016 ******** 
2025-07-23 21:49:10,463 p=65997 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 21:49:10,467 p=65997 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 21:49:10,468 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:10 +0000 (0:00:00.030)       0:00:00.046 ******** 
2025-07-23 21:49:11,585 p=65997 u=master n=ansible | ok: [sm01]
2025-07-23 21:49:11,590 p=65997 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 21:49:11,590 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:11 +0000 (0:00:01.122)       0:00:01.168 ******** 
2025-07-23 21:49:11,640 p=65997 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 21:49:11,644 p=65997 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 21:49:11,644 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:11 +0000 (0:00:00.054)       0:00:01.222 ******** 
2025-07-23 21:49:11,678 p=65997 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 21:49:11,678 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:11 +0000 (0:00:00.034)       0:00:01.257 ******** 
2025-07-23 21:49:11,729 p=65997 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 21:49:11,733 p=65997 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 21:49:11,733 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:11 +0000 (0:00:00.054)       0:00:01.312 ******** 
2025-07-23 21:49:11,789 p=65997 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 21:49:11,796 p=65997 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-23 21:49:11,796 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:11 +0000 (0:00:00.063)       0:00:01.375 ******** 
2025-07-23 21:49:12,089 p=65997 u=master n=ansible | ok: [sm01]
2025-07-23 21:49:12,093 p=65997 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-23 21:49:12,093 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:12 +0000 (0:00:00.296)       0:00:01.672 ******** 
2025-07-23 21:49:12,145 p=65997 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-23 21:49:12,149 p=65997 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-23 21:49:12,149 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:12 +0000 (0:00:00.056)       0:00:01.728 ******** 
2025-07-23 21:49:12,553 p=65997 u=master n=ansible | changed: [sm01]
2025-07-23 21:49:12,558 p=65997 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-23 21:49:12,558 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:12 +0000 (0:00:00.408)       0:00:02.136 ******** 
2025-07-23 21:49:12,613 p=65997 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-23 21:49:12,617 p=65997 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-23 21:49:12,617 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:12 +0000 (0:00:00.059)       0:00:02.195 ******** 
2025-07-23 21:49:12,920 p=65997 u=master n=ansible | ok: [sm01]
2025-07-23 21:49:12,924 p=65997 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-23 21:49:12,925 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:12 +0000 (0:00:00.307)       0:00:02.503 ******** 
2025-07-23 21:49:13,232 p=65997 u=master n=ansible | ok: [sm01]
2025-07-23 21:49:13,237 p=65997 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-23 21:49:13,237 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:13 +0000 (0:00:00.312)       0:00:02.816 ******** 
2025-07-23 21:49:13,289 p=65997 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-23 21:49:13,294 p=65997 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-23 21:49:13,294 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:13 +0000 (0:00:00.056)       0:00:02.873 ******** 
2025-07-23 21:49:13,318 p=65997 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-23 21:49:13,338 p=65997 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-23 21:49:13,339 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:13 +0000 (0:00:00.044)       0:00:02.917 ******** 
2025-07-23 21:49:13,477 p=65997 u=master n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'jwt_enabled' is undefined. 'jwt_enabled' is undefined
2025-07-23 21:49:13,477 p=65997 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  msg: 'AnsibleUndefinedVariable: ''jwt_enabled'' is undefined. ''jwt_enabled'' is undefined'
2025-07-23 21:49:13,479 p=65997 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 21:49:13,479 p=65997 u=master n=ansible | sm01                       : ok=13   changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 21:49:13,479 p=65997 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 3 seconds
2025-07-23 21:49:13,479 p=65997 u=master n=ansible | Wednesday 23 July 2025  21:49:13 +0000 (0:00:00.140)       0:00:03.058 ******** 
2025-07-23 21:49:13,479 p=65997 u=master n=ansible | =============================================================================== 
2025-07-23 21:49:13,479 p=65997 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.12s
2025-07-23 21:49:13,480 p=65997 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.41s
2025-07-23 21:49:13,480 p=65997 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-23 21:49:13,480 p=65997 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-23 21:49:13,480 p=65997 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.30s
2025-07-23 21:49:13,480 p=65997 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.14s
2025-07-23 21:49:13,480 p=65997 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 21:49:13,480 p=65997 u=master n=ansible | slurm_master : [MARIADB] Результат создания пользователя ----------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 21:49:13,480 p=65997 u=master n=ansible | slurm_master : [MARIADB] Финальный результат ----------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 21:49:13,480 p=65997 u=master n=ansible | slurm_master : [MARIADB] Показать версию MariaDB ------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 21:49:13,480 p=65997 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:49:13,480 p=65997 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 21:49:13,480 p=65997 u=master n=ansible | slurm_master : [SLURM-MASTER] Создание конфигурации Slurm ---------------------------------------------------------------------------------------------------------------------- 0.04s
2025-07-23 21:49:13,481 p=65997 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:49:13,481 p=65997 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 21:50:48,241 p=66082 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:50:48,241 p=66082 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:50:49,621 p=66082 u=master n=ansible | sm01 | CHANGED | rc=0 >>
User	Host
slurm	%
slurm	localhost

2025-07-23 21:51:25,133 p=66157 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:51:25,133 p=66157 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:51:25,781 p=66157 u=master n=ansible | sm01 | CHANGED | rc=0 >>
User	Host	authentication_string
mariadb.sys	localhost	
root	localhost	invalid
mysql	localhost	invalid
slurm	localhost	*25CC6EB9620934A46146BC4E56332FE2FD8AC058
slurm	%	*25CC6EB9620934A46146BC4E56332FE2FD8AC058

2025-07-23 21:58:25,192 p=66247 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:58:25,192 p=66247 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:58:25,447 p=66247 u=master n=ansible | sm01 | SUCCESS => {
    "slurm_db_password": "testslurm123"
}
2025-07-23 21:59:34,193 p=66285 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:59:34,194 p=66285 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 21:59:34,445 p=66285 u=master n=ansible | sm01 | SUCCESS => {
    "slurm_db_password": "testslurm123"
}
2025-07-23 22:01:33,871 p=66348 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:01:33,872 p=66348 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:01:34,272 p=66348 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 22:01:34,286 p=66348 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 22:01:34,286 p=66348 u=master n=ansible | Wednesday 23 July 2025  22:01:34 +0000 (0:00:00.015)       0:00:00.016 ******** 
2025-07-23 22:01:34,310 p=66348 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 22:01:34,314 p=66348 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 22:01:34,314 p=66348 u=master n=ansible | Wednesday 23 July 2025  22:01:34 +0000 (0:00:00.027)       0:00:00.043 ******** 
2025-07-23 22:01:34,354 p=66348 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 22:01:34,355 p=66348 u=master n=ansible | sm01                       : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-23 22:01:34,355 p=66348 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 0 seconds
2025-07-23 22:01:34,355 p=66348 u=master n=ansible | Wednesday 23 July 2025  22:01:34 +0000 (0:00:00.040)       0:00:00.084 ******** 
2025-07-23 22:01:34,355 p=66348 u=master n=ansible | =============================================================================== 
2025-07-23 22:01:34,355 p=66348 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.04s
2025-07-23 22:01:34,355 p=66348 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:01:41,873 p=66387 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:01:41,873 p=66387 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:01:42,264 p=66387 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 22:01:42,278 p=66387 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 22:01:42,278 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:42 +0000 (0:00:00.016)       0:00:00.016 ******** 
2025-07-23 22:01:42,301 p=66387 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 22:01:42,304 p=66387 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 22:01:42,305 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:42 +0000 (0:00:00.026)       0:00:00.042 ******** 
2025-07-23 22:01:43,400 p=66387 u=master n=ansible | ok: [sm01]
2025-07-23 22:01:43,405 p=66387 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 22:01:43,405 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:43 +0000 (0:00:01.100)       0:00:01.142 ******** 
2025-07-23 22:01:43,450 p=66387 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 22:01:43,454 p=66387 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 22:01:43,454 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:43 +0000 (0:00:00.049)       0:00:01.192 ******** 
2025-07-23 22:01:43,488 p=66387 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 22:01:43,488 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:43 +0000 (0:00:00.033)       0:00:01.225 ******** 
2025-07-23 22:01:43,538 p=66387 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 22:01:43,542 p=66387 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 22:01:43,542 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:43 +0000 (0:00:00.054)       0:00:01.280 ******** 
2025-07-23 22:01:43,595 p=66387 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 22:01:43,601 p=66387 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-23 22:01:43,601 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:43 +0000 (0:00:00.058)       0:00:01.339 ******** 
2025-07-23 22:01:43,878 p=66387 u=master n=ansible | ok: [sm01]
2025-07-23 22:01:43,882 p=66387 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-23 22:01:43,882 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:43 +0000 (0:00:00.280)       0:00:01.620 ******** 
2025-07-23 22:01:43,934 p=66387 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-23 22:01:43,937 p=66387 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-23 22:01:43,938 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:43 +0000 (0:00:00.055)       0:00:01.675 ******** 
2025-07-23 22:01:44,329 p=66387 u=master n=ansible | changed: [sm01]
2025-07-23 22:01:44,333 p=66387 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-23 22:01:44,333 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:44 +0000 (0:00:00.395)       0:00:02.071 ******** 
2025-07-23 22:01:44,380 p=66387 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-23 22:01:44,384 p=66387 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-23 22:01:44,384 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:44 +0000 (0:00:00.050)       0:00:02.122 ******** 
2025-07-23 22:01:44,694 p=66387 u=master n=ansible | ok: [sm01]
2025-07-23 22:01:44,698 p=66387 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-23 22:01:44,699 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:44 +0000 (0:00:00.314)       0:00:02.436 ******** 
2025-07-23 22:01:44,995 p=66387 u=master n=ansible | ok: [sm01]
2025-07-23 22:01:44,999 p=66387 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-23 22:01:44,999 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:44 +0000 (0:00:00.300)       0:00:02.737 ******** 
2025-07-23 22:01:45,050 p=66387 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-23 22:01:45,054 p=66387 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-23 22:01:45,054 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:45 +0000 (0:00:00.055)       0:00:02.792 ******** 
2025-07-23 22:01:45,075 p=66387 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-23 22:01:45,085 p=66387 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-23 22:01:45,085 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:45 +0000 (0:00:00.030)       0:00:02.822 ******** 
2025-07-23 22:01:45,212 p=66387 u=master n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'jwt_enabled' is undefined. 'jwt_enabled' is undefined
2025-07-23 22:01:45,212 p=66387 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  msg: 'AnsibleUndefinedVariable: ''jwt_enabled'' is undefined. ''jwt_enabled'' is undefined'
2025-07-23 22:01:45,214 p=66387 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 22:01:45,214 p=66387 u=master n=ansible | sm01                       : ok=13   changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 22:01:45,214 p=66387 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 2 seconds
2025-07-23 22:01:45,214 p=66387 u=master n=ansible | Wednesday 23 July 2025  22:01:45 +0000 (0:00:00.129)       0:00:02.952 ******** 
2025-07-23 22:01:45,214 p=66387 u=master n=ansible | =============================================================================== 
2025-07-23 22:01:45,215 p=66387 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.10s
2025-07-23 22:01:45,215 p=66387 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.40s
2025-07-23 22:01:45,215 p=66387 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-23 22:01:45,215 p=66387 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-23 22:01:45,215 p=66387 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.28s
2025-07-23 22:01:45,215 p=66387 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.13s
2025-07-23 22:01:45,215 p=66387 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:01:45,215 p=66387 u=master n=ansible | slurm_master : [MARIADB] Показать версию MariaDB ------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:01:45,215 p=66387 u=master n=ansible | slurm_master : [MARIADB] Финальный результат ----------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:01:45,215 p=66387 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:01:45,216 p=66387 u=master n=ansible | slurm_master : [MARIADB] Результат создания пользователя ----------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:01:45,216 p=66387 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:01:45,216 p=66387 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:01:45,216 p=66387 u=master n=ansible | slurm_master : [SLURM-MASTER] Создание конфигурации Slurm ---------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:01:45,216 p=66387 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:06:24,072 p=66502 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:06:24,073 p=66502 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:06:24,467 p=66502 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 22:06:24,480 p=66502 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 22:06:24,480 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:24 +0000 (0:00:00.015)       0:00:00.015 ******** 
2025-07-23 22:06:24,504 p=66502 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 22:06:24,508 p=66502 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 22:06:24,508 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:24 +0000 (0:00:00.027)       0:00:00.043 ******** 
2025-07-23 22:06:25,600 p=66502 u=master n=ansible | ok: [sm01]
2025-07-23 22:06:25,605 p=66502 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 22:06:25,605 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:25 +0000 (0:00:01.096)       0:00:01.140 ******** 
2025-07-23 22:06:25,654 p=66502 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 22:06:25,658 p=66502 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 22:06:25,658 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:25 +0000 (0:00:00.053)       0:00:01.193 ******** 
2025-07-23 22:06:25,691 p=66502 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 22:06:25,691 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:25 +0000 (0:00:00.033)       0:00:01.226 ******** 
2025-07-23 22:06:25,742 p=66502 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 22:06:25,746 p=66502 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 22:06:25,747 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:25 +0000 (0:00:00.055)       0:00:01.281 ******** 
2025-07-23 22:06:25,799 p=66502 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 22:06:25,807 p=66502 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-23 22:06:25,807 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:25 +0000 (0:00:00.060)       0:00:01.342 ******** 
2025-07-23 22:06:26,086 p=66502 u=master n=ansible | ok: [sm01]
2025-07-23 22:06:26,090 p=66502 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-23 22:06:26,091 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:26 +0000 (0:00:00.283)       0:00:01.625 ******** 
2025-07-23 22:06:26,140 p=66502 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-23 22:06:26,144 p=66502 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-23 22:06:26,144 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:26 +0000 (0:00:00.053)       0:00:01.679 ******** 
2025-07-23 22:06:26,548 p=66502 u=master n=ansible | changed: [sm01]
2025-07-23 22:06:26,553 p=66502 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-23 22:06:26,553 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:26 +0000 (0:00:00.408)       0:00:02.088 ******** 
2025-07-23 22:06:26,606 p=66502 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-23 22:06:26,610 p=66502 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-23 22:06:26,610 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:26 +0000 (0:00:00.056)       0:00:02.145 ******** 
2025-07-23 22:06:26,918 p=66502 u=master n=ansible | ok: [sm01]
2025-07-23 22:06:26,922 p=66502 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-23 22:06:26,922 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:26 +0000 (0:00:00.312)       0:00:02.457 ******** 
2025-07-23 22:06:27,225 p=66502 u=master n=ansible | ok: [sm01]
2025-07-23 22:06:27,230 p=66502 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-23 22:06:27,230 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:27 +0000 (0:00:00.307)       0:00:02.765 ******** 
2025-07-23 22:06:27,283 p=66502 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-23 22:06:27,287 p=66502 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-23 22:06:27,287 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:27 +0000 (0:00:00.057)       0:00:02.822 ******** 
2025-07-23 22:06:27,308 p=66502 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-23 22:06:27,318 p=66502 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-23 22:06:27,318 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:27 +0000 (0:00:00.030)       0:00:02.853 ******** 
2025-07-23 22:06:27,447 p=66502 u=master n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'slurm_spool_dir' is undefined. 'slurm_spool_dir' is undefined
2025-07-23 22:06:27,447 p=66502 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  msg: 'AnsibleUndefinedVariable: ''slurm_spool_dir'' is undefined. ''slurm_spool_dir'' is undefined'
2025-07-23 22:06:27,449 p=66502 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 22:06:27,449 p=66502 u=master n=ansible | sm01                       : ok=13   changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 22:06:27,449 p=66502 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 2 seconds
2025-07-23 22:06:27,450 p=66502 u=master n=ansible | Wednesday 23 July 2025  22:06:27 +0000 (0:00:00.131)       0:00:02.984 ******** 
2025-07-23 22:06:27,450 p=66502 u=master n=ansible | =============================================================================== 
2025-07-23 22:06:27,450 p=66502 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.10s
2025-07-23 22:06:27,450 p=66502 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.41s
2025-07-23 22:06:27,450 p=66502 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-23 22:06:27,451 p=66502 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-23 22:06:27,451 p=66502 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.28s
2025-07-23 22:06:27,451 p=66502 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.13s
2025-07-23 22:06:27,451 p=66502 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:06:27,451 p=66502 u=master n=ansible | slurm_master : [MARIADB] Финальный результат ----------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:06:27,451 p=66502 u=master n=ansible | slurm_master : [MARIADB] Результат создания пользователя ----------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:06:27,451 p=66502 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:06:27,452 p=66502 u=master n=ansible | slurm_master : [MARIADB] Показать версию MariaDB ------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:06:27,452 p=66502 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:06:27,452 p=66502 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:06:27,452 p=66502 u=master n=ansible | slurm_master : [SLURM-MASTER] Создание конфигурации Slurm ---------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:06:27,452 p=66502 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:06:42,789 p=66584 u=master n=ansible | ansible-playbook [core 2.16.3]
  config file = /home/master/22Jul/slurm-hpc-cluster/ansible.cfg
  configured module search path = ['/home/master/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python3/dist-packages/ansible
  ansible collection location = /home/master/.ansible/collections:/usr/share/ansible/collections
  executable location = /usr/bin/ansible-playbook
  python version = 3.12.3 (main, Jun 18 2025, 17:59:45) [GCC 13.3.0] (/usr/bin/python3)
  jinja version = 3.1.2
  libyaml = True
2025-07-23 22:06:42,789 p=66584 u=master n=ansible | Using /home/master/22Jul/slurm-hpc-cluster/ansible.cfg as config file
2025-07-23 22:06:42,789 p=66584 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:06:42,790 p=66584 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:06:42,920 p=66584 u=master n=ansible | host_list declined parsing /home/master/22Jul/slurm-hpc-cluster/inventory as it did not pass its verify_file() method
2025-07-23 22:06:42,920 p=66584 u=master n=ansible | script declined parsing /home/master/22Jul/slurm-hpc-cluster/inventory as it did not pass its verify_file() method
2025-07-23 22:06:42,920 p=66584 u=master n=ansible | auto declined parsing /home/master/22Jul/slurm-hpc-cluster/inventory as it did not pass its verify_file() method
2025-07-23 22:06:42,924 p=66584 u=master n=ansible | Parsed /home/master/22Jul/slurm-hpc-cluster/inventory inventory source with ini plugin
2025-07-23 22:06:43,126 p=66584 u=master n=ansible | redirecting (type: callback) ansible.builtin.yaml to community.general.yaml
2025-07-23 22:06:43,168 p=66584 u=master n=ansible | redirecting (type: callback) ansible.builtin.yaml to community.general.yaml
2025-07-23 22:06:43,184 p=66584 u=master n=ansible | redirecting (type: callback) ansible.builtin.timer to ansible.posix.timer
2025-07-23 22:06:43,185 p=66584 u=master n=ansible | redirecting (type: callback) ansible.builtin.profile_tasks to ansible.posix.profile_tasks
2025-07-23 22:06:43,186 p=66584 u=master n=ansible | Skipping callback 'default', as we already have a stdout callback.
2025-07-23 22:06:43,186 p=66584 u=master n=ansible | Skipping callback 'minimal', as we already have a stdout callback.
2025-07-23 22:06:43,186 p=66584 u=master n=ansible | Skipping callback 'oneline', as we already have a stdout callback.
2025-07-23 22:06:43,187 p=66584 u=master n=ansible | PLAYBOOK: test_slurm_master_simple.yml ************************************************************************************************************************************************
2025-07-23 22:06:43,187 p=66584 u=master n=ansible | 1 plays in playbooks/test_slurm_master_simple.yml
2025-07-23 22:06:43,188 p=66584 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 22:06:43,202 p=66584 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 22:06:43,202 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:43 +0000 (0:00:00.016)       0:00:00.016 ******** 
2025-07-23 22:06:43,227 p=66584 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 22:06:43,230 p=66584 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 22:06:43,231 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:43 +0000 (0:00:00.028)       0:00:00.045 ******** 
2025-07-23 22:06:43,372 p=66584 u=master n=ansible | Using module file /usr/lib/python3/dist-packages/ansible/modules/command.py
2025-07-23 22:06:43,373 p=66584 u=master n=ansible | Pipelining is enabled.
2025-07-23 22:06:43,373 p=66584 u=master n=ansible | <sm01> ESTABLISH SSH CONNECTION FOR USER: master
2025-07-23 22:06:43,373 p=66584 u=master n=ansible | <sm01> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="master"' -o ConnectTimeout=30 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o 'ControlPath="./tmp/ansible-ssh-%h-%p-%r"' sm01 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-lfpqjixdnmfzgxqyscapwzyiwvyxkfty ; /usr/bin/python3'"'"'"'"'"'"'"'"' && sleep 0'"'"''
2025-07-23 22:06:43,393 p=66584 u=master n=ansible | Escalation succeeded
2025-07-23 22:06:43,617 p=66584 u=master n=ansible | <sm01> (0, b'\n{"changed": true, "stdout": "\\u25cf mariadb.service - MariaDB 10.11.13 database server\\n     Loaded: loaded (/usr/lib/systemd/system/mariadb.service; enabled; preset: enabled)\\n     Active: active (running) since Thu 2025-07-24 00:40:28 MSK; 26min ago\\n       Docs: man:mariadbd(8)\\n             https://mariadb.com/kb/en/library/systemd/\\n   Main PID: 71376 (mariadbd)\\n     Status: \\"Taking your SQL requests now...\\"\\n      Tasks: 10 (limit: 92231)\\n     Memory: 78.8M (peak: 81.8M)\\n        CPU: 729ms\\n     CGroup: /system.slice/mariadb.service\\n             \\u2514\\u250071376 /usr/sbin/mariadbd\\n\\nJul 24 00:40:28 sm01 mariadbd[71376]: 2025-07-24  0:40:28 0 [Note] InnoDB: Loading buffer pool(s) from /var/lib/mysql/ib_buffer_pool\\nJul 24 00:40:28 sm01 mariadbd[71376]: 2025-07-24  0:40:28 0 [Warning] You need to use --log-bin to make --expire-logs-days or --binlog-expire-logs-seconds work.\\nJul 24 00:40:28 sm01 mariadbd[71376]: 2025-07-24  0:40:28 0 [Note] Server socket created on IP: \'127.0.0.1\'.\\nJul 24 00:40:28 sm01 mariadbd[71376]: 2025-07-24  0:40:28 0 [Note] InnoDB: Buffer pool(s) load completed at 250724  0:40:28\\nJul 24 00:40:28 sm01 mariadbd[71376]: 2025-07-24  0:40:28 0 [Note] /usr/sbin/mariadbd: ready for connections.\\nJul 24 00:40:28 sm01 mariadbd[71376]: Version: \'10.11.13-MariaDB-0ubuntu0.24.04.1\'  socket: \'/run/mysqld/mysqld.sock\'  port: 3306  Ubuntu 24.04\\nJul 24 00:40:28 sm01 systemd[1]: Started mariadb.service - MariaDB 10.11.13 database server.\\nJul 24 00:41:31 sm01 mariadbd[71376]: 2025-07-24  0:41:31 32 [Warning] Access denied for user \'root\'@\'localhost\'\\nJul 24 00:46:21 sm01 mariadbd[71376]: 2025-07-24  0:46:21 39 [Warning] Access denied for user \'slurm\'@\'localhost\' (using password: YES)\\nJul 24 00:46:22 sm01 mariadbd[71376]: 2025-07-24  0:46:22 40 [Warning] Access denied for user \'slurm\'@\'localhost\' (using password: YES)", "stderr": "", "rc": 0, "cmd": ["systemctl", "status", "mariadb"], "start": "2025-07-24 01:06:43.585346", "end": "2025-07-24 01:06:43.596338", "delta": "0:00:00.010992", "msg": "", "invocation": {"module_args": {"_raw_params": "systemctl status mariadb", "_uses_shell": false, "expand_argument_vars": true, "stdin_add_newline": true, "strip_empty_ends": true, "argv": null, "chdir": null, "executable": null, "creates": null, "removes": null, "stdin": null}}}\n', b'')
2025-07-23 22:06:43,622 p=66584 u=master n=ansible | ok: [sm01] => changed=false 
  cmd:
  - systemctl
  - status
  - mariadb
  delta: '0:00:00.010992'
  end: '2025-07-24 01:06:43.596338'
  invocation:
    module_args:
      _raw_params: systemctl status mariadb
      _uses_shell: false
      argv: null
      chdir: null
      creates: null
      executable: null
      expand_argument_vars: true
      removes: null
      stdin: null
      stdin_add_newline: true
      strip_empty_ends: true
  msg: ''
  rc: 0
  start: '2025-07-24 01:06:43.585346'
  stderr: ''
  stderr_lines: <omitted>
  stdout: |-
    ● mariadb.service - MariaDB 10.11.13 database server
         Loaded: loaded (/usr/lib/systemd/system/mariadb.service; enabled; preset: enabled)
         Active: active (running) since Thu 2025-07-24 00:40:28 MSK; 26min ago
           Docs: man:mariadbd(8)
                 https://mariadb.com/kb/en/library/systemd/
       Main PID: 71376 (mariadbd)
         Status: "Taking your SQL requests now..."
          Tasks: 10 (limit: 92231)
         Memory: 78.8M (peak: 81.8M)
            CPU: 729ms
         CGroup: /system.slice/mariadb.service
                 └─71376 /usr/sbin/mariadbd
  
    Jul 24 00:40:28 sm01 mariadbd[71376]: 2025-07-24  0:40:28 0 [Note] InnoDB: Loading buffer pool(s) from /var/lib/mysql/ib_buffer_pool
    Jul 24 00:40:28 sm01 mariadbd[71376]: 2025-07-24  0:40:28 0 [Warning] You need to use --log-bin to make --expire-logs-days or --binlog-expire-logs-seconds work.
    Jul 24 00:40:28 sm01 mariadbd[71376]: 2025-07-24  0:40:28 0 [Note] Server socket created on IP: '127.0.0.1'.
    Jul 24 00:40:28 sm01 mariadbd[71376]: 2025-07-24  0:40:28 0 [Note] InnoDB: Buffer pool(s) load completed at 250724  0:40:28
    Jul 24 00:40:28 sm01 mariadbd[71376]: 2025-07-24  0:40:28 0 [Note] /usr/sbin/mariadbd: ready for connections.
    Jul 24 00:40:28 sm01 mariadbd[71376]: Version: '10.11.13-MariaDB-0ubuntu0.24.04.1'  socket: '/run/mysqld/mysqld.sock'  port: 3306  Ubuntu 24.04
    Jul 24 00:40:28 sm01 systemd[1]: Started mariadb.service - MariaDB 10.11.13 database server.
    Jul 24 00:41:31 sm01 mariadbd[71376]: 2025-07-24  0:41:31 32 [Warning] Access denied for user 'root'@'localhost'
    Jul 24 00:46:21 sm01 mariadbd[71376]: 2025-07-24  0:46:21 39 [Warning] Access denied for user 'slurm'@'localhost' (using password: YES)
    Jul 24 00:46:22 sm01 mariadbd[71376]: 2025-07-24  0:46:22 40 [Warning] Access denied for user 'slurm'@'localhost' (using password: YES)
  stdout_lines: <omitted>
2025-07-23 22:06:43,625 p=66584 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 22:06:43,626 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:43 +0000 (0:00:00.394)       0:00:00.439 ******** 
2025-07-23 22:06:43,673 p=66584 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 22:06:43,676 p=66584 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 22:06:43,677 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:43 +0000 (0:00:00.050)       0:00:00.490 ******** 
2025-07-23 22:06:43,710 p=66584 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 22:06:43,710 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:43 +0000 (0:00:00.033)       0:00:00.524 ******** 
2025-07-23 22:06:43,760 p=66584 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 22:06:43,764 p=66584 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 22:06:43,765 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:43 +0000 (0:00:00.054)       0:00:00.579 ******** 
2025-07-23 22:06:43,818 p=66584 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 22:06:43,825 p=66584 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-23 22:06:43,825 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:43 +0000 (0:00:00.060)       0:00:00.639 ******** 
2025-07-23 22:06:43,844 p=66584 u=master n=ansible | Using module file /usr/lib/python3/dist-packages/ansible/modules/command.py
2025-07-23 22:06:43,845 p=66584 u=master n=ansible | Pipelining is enabled.
2025-07-23 22:06:43,845 p=66584 u=master n=ansible | <sm01> ESTABLISH SSH CONNECTION FOR USER: master
2025-07-23 22:06:43,845 p=66584 u=master n=ansible | <sm01> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="master"' -o ConnectTimeout=30 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o 'ControlPath="./tmp/ansible-ssh-%h-%p-%r"' sm01 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-fcysvguzdzziicbrdsedorqiyukyiorp ; /usr/bin/python3'"'"'"'"'"'"'"'"' && sleep 0'"'"''
2025-07-23 22:06:43,865 p=66584 u=master n=ansible | Escalation succeeded
2025-07-23 22:06:44,098 p=66584 u=master n=ansible | <sm01> (0, b'\n{"changed": true, "stdout": "VERSION()\\n10.11.13-MariaDB-0ubuntu0.24.04.1", "stderr": "", "rc": 0, "cmd": "sudo mysql -e \\"SELECT VERSION();\\"", "start": "2025-07-24 01:06:44.055896", "end": "2025-07-24 01:06:44.077124", "delta": "0:00:00.021228", "msg": "", "invocation": {"module_args": {"_raw_params": "sudo mysql -e \\"SELECT VERSION();\\"", "_uses_shell": true, "expand_argument_vars": true, "stdin_add_newline": true, "strip_empty_ends": true, "argv": null, "chdir": null, "executable": null, "creates": null, "removes": null, "stdin": null}}}\n', b'')
2025-07-23 22:06:44,102 p=66584 u=master n=ansible | ok: [sm01] => changed=false 
  cmd: sudo mysql -e "SELECT VERSION();"
  delta: '0:00:00.021228'
  end: '2025-07-24 01:06:44.077124'
  invocation:
    module_args:
      _raw_params: sudo mysql -e "SELECT VERSION();"
      _uses_shell: true
      argv: null
      chdir: null
      creates: null
      executable: null
      expand_argument_vars: true
      removes: null
      stdin: null
      stdin_add_newline: true
      strip_empty_ends: true
  msg: ''
  rc: 0
  start: '2025-07-24 01:06:44.055896'
  stderr: ''
  stderr_lines: <omitted>
  stdout: |-
    VERSION()
    10.11.13-MariaDB-0ubuntu0.24.04.1
  stdout_lines: <omitted>
2025-07-23 22:06:44,106 p=66584 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-23 22:06:44,107 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:44 +0000 (0:00:00.281)       0:00:00.920 ******** 
2025-07-23 22:06:44,157 p=66584 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-23 22:06:44,161 p=66584 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-23 22:06:44,161 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:44 +0000 (0:00:00.054)       0:00:00.975 ******** 
2025-07-23 22:06:44,212 p=66584 u=master n=ansible | Using module file /usr/lib/python3/dist-packages/ansible/modules/command.py
2025-07-23 22:06:44,212 p=66584 u=master n=ansible | Pipelining is enabled.
2025-07-23 22:06:44,213 p=66584 u=master n=ansible | <sm01> ESTABLISH SSH CONNECTION FOR USER: master
2025-07-23 22:06:44,213 p=66584 u=master n=ansible | <sm01> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="master"' -o ConnectTimeout=30 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o 'ControlPath="./tmp/ansible-ssh-%h-%p-%r"' sm01 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-amanppaxajnnyfmzaxfoljmsbbcuvxuo ; /usr/bin/python3'"'"'"'"'"'"'"'"' && sleep 0'"'"''
2025-07-23 22:06:44,232 p=66584 u=master n=ansible | Escalation succeeded
2025-07-23 22:06:44,557 p=66584 u=master n=ansible | <sm01> (0, b'\n{"changed": true, "stdout": "", "stderr": "", "rc": 0, "cmd": "sudo mysql -e \\"CREATE USER IF NOT EXISTS \'slurm\'@\'localhost\' IDENTIFIED BY \'testslurm123\';\\"\\nsudo mysql -e \\"CREATE USER IF NOT EXISTS \'slurm\'@\'%\' IDENTIFIED BY \'testslurm123\';\\"\\nsudo mysql -e \\"CREATE DATABASE IF NOT EXISTS slurm_acct_db;\\"\\nsudo mysql -e \\"GRANT ALL PRIVILEGES ON slurm_acct_db.* TO \'slurm\'@\'localhost\';\\"\\nsudo mysql -e \\"GRANT ALL PRIVILEGES ON slurm_acct_db.* TO \'slurm\'@\'%\';\\"\\nsudo mysql -e \\"FLUSH PRIVILEGES;\\"\\n", "start": "2025-07-24 01:06:44.425539", "end": "2025-07-24 01:06:44.534082", "delta": "0:00:00.108543", "msg": "", "invocation": {"module_args": {"_raw_params": "sudo mysql -e \\"CREATE USER IF NOT EXISTS \'slurm\'@\'localhost\' IDENTIFIED BY \'testslurm123\';\\"\\nsudo mysql -e \\"CREATE USER IF NOT EXISTS \'slurm\'@\'%\' IDENTIFIED BY \'testslurm123\';\\"\\nsudo mysql -e \\"CREATE DATABASE IF NOT EXISTS slurm_acct_db;\\"\\nsudo mysql -e \\"GRANT ALL PRIVILEGES ON slurm_acct_db.* TO \'slurm\'@\'localhost\';\\"\\nsudo mysql -e \\"GRANT ALL PRIVILEGES ON slurm_acct_db.* TO \'slurm\'@\'%\';\\"\\nsudo mysql -e \\"FLUSH PRIVILEGES;\\"\\n", "_uses_shell": true, "expand_argument_vars": true, "stdin_add_newline": true, "strip_empty_ends": true, "argv": null, "chdir": null, "executable": null, "creates": null, "removes": null, "stdin": null}}}\n', b'')
2025-07-23 22:06:44,561 p=66584 u=master n=ansible | changed: [sm01] => changed=true 
  cmd: |-
    sudo mysql -e "CREATE USER IF NOT EXISTS 'slurm'@'localhost' IDENTIFIED BY 'testslurm123';"
    sudo mysql -e "CREATE USER IF NOT EXISTS 'slurm'@'%' IDENTIFIED BY 'testslurm123';"
    sudo mysql -e "CREATE DATABASE IF NOT EXISTS slurm_acct_db;"
    sudo mysql -e "GRANT ALL PRIVILEGES ON slurm_acct_db.* TO 'slurm'@'localhost';"
    sudo mysql -e "GRANT ALL PRIVILEGES ON slurm_acct_db.* TO 'slurm'@'%';"
    sudo mysql -e "FLUSH PRIVILEGES;"
  delta: '0:00:00.108543'
  end: '2025-07-24 01:06:44.534082'
  invocation:
    module_args:
      _raw_params: |-
        sudo mysql -e "CREATE USER IF NOT EXISTS 'slurm'@'localhost' IDENTIFIED BY 'testslurm123';"
        sudo mysql -e "CREATE USER IF NOT EXISTS 'slurm'@'%' IDENTIFIED BY 'testslurm123';"
        sudo mysql -e "CREATE DATABASE IF NOT EXISTS slurm_acct_db;"
        sudo mysql -e "GRANT ALL PRIVILEGES ON slurm_acct_db.* TO 'slurm'@'localhost';"
        sudo mysql -e "GRANT ALL PRIVILEGES ON slurm_acct_db.* TO 'slurm'@'%';"
        sudo mysql -e "FLUSH PRIVILEGES;"
      _uses_shell: true
      argv: null
      chdir: null
      creates: null
      executable: null
      expand_argument_vars: true
      removes: null
      stdin: null
      stdin_add_newline: true
      strip_empty_ends: true
  msg: ''
  rc: 0
  start: '2025-07-24 01:06:44.425539'
  stderr: ''
  stderr_lines: <omitted>
  stdout: ''
  stdout_lines: <omitted>
2025-07-23 22:06:44,565 p=66584 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-23 22:06:44,565 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:44 +0000 (0:00:00.403)       0:00:01.379 ******** 
2025-07-23 22:06:44,613 p=66584 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-23 22:06:44,617 p=66584 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-23 22:06:44,617 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:44 +0000 (0:00:00.051)       0:00:01.431 ******** 
2025-07-23 22:06:44,664 p=66584 u=master n=ansible | Using module file /usr/lib/python3/dist-packages/ansible/modules/command.py
2025-07-23 22:06:44,664 p=66584 u=master n=ansible | Pipelining is enabled.
2025-07-23 22:06:44,665 p=66584 u=master n=ansible | <sm01> ESTABLISH SSH CONNECTION FOR USER: master
2025-07-23 22:06:44,665 p=66584 u=master n=ansible | <sm01> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="master"' -o ConnectTimeout=30 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o 'ControlPath="./tmp/ansible-ssh-%h-%p-%r"' sm01 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-qnkmjigxjrkbozmnfazzlvtartsmeuth ; /usr/bin/python3'"'"'"'"'"'"'"'"' && sleep 0'"'"''
2025-07-23 22:06:44,684 p=66584 u=master n=ansible | Escalation succeeded
2025-07-23 22:06:44,910 p=66584 u=master n=ansible | <sm01> (0, b'\n{"changed": true, "stdout": "test\\n1", "stderr": "", "rc": 0, "cmd": "mysql -uslurm -ptestslurm123 -e \\"USE slurm_acct_db; SELECT 1 AS test;\\"", "start": "2025-07-24 01:06:44.876387", "end": "2025-07-24 01:06:44.888456", "delta": "0:00:00.012069", "msg": "", "invocation": {"module_args": {"_raw_params": "mysql -uslurm -ptestslurm123 -e \\"USE slurm_acct_db; SELECT 1 AS test;\\"", "_uses_shell": true, "expand_argument_vars": true, "stdin_add_newline": true, "strip_empty_ends": true, "argv": null, "chdir": null, "executable": null, "creates": null, "removes": null, "stdin": null}}}\n', b'')
2025-07-23 22:06:44,914 p=66584 u=master n=ansible | ok: [sm01] => changed=false 
  cmd: mysql -uslurm -ptestslurm123 -e "USE slurm_acct_db; SELECT 1 AS test;"
  delta: '0:00:00.012069'
  end: '2025-07-24 01:06:44.888456'
  failed_when_result: false
  invocation:
    module_args:
      _raw_params: mysql -uslurm -ptestslurm123 -e "USE slurm_acct_db; SELECT 1 AS test;"
      _uses_shell: true
      argv: null
      chdir: null
      creates: null
      executable: null
      expand_argument_vars: true
      removes: null
      stdin: null
      stdin_add_newline: true
      strip_empty_ends: true
  msg: ''
  rc: 0
  start: '2025-07-24 01:06:44.876387'
  stderr: ''
  stderr_lines: <omitted>
  stdout: |-
    test
    1
  stdout_lines: <omitted>
2025-07-23 22:06:44,918 p=66584 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-23 22:06:44,918 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:44 +0000 (0:00:00.301)       0:00:01.732 ******** 
2025-07-23 22:06:44,967 p=66584 u=master n=ansible | Using module file /usr/lib/python3/dist-packages/ansible/modules/command.py
2025-07-23 22:06:44,968 p=66584 u=master n=ansible | Pipelining is enabled.
2025-07-23 22:06:44,968 p=66584 u=master n=ansible | <sm01> ESTABLISH SSH CONNECTION FOR USER: master
2025-07-23 22:06:44,968 p=66584 u=master n=ansible | <sm01> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="master"' -o ConnectTimeout=30 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o 'ControlPath="./tmp/ansible-ssh-%h-%p-%r"' sm01 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-terlcidmhyxowjisnpwdclwmaqzzxbrw ; /usr/bin/python3'"'"'"'"'"'"'"'"' && sleep 0'"'"''
2025-07-23 22:06:44,987 p=66584 u=master n=ansible | Escalation succeeded
2025-07-23 22:06:45,213 p=66584 u=master n=ansible | <sm01> (0, b'\n{"changed": true, "stdout": "Database\\ninformation_schema\\nslurm_acct_db", "stderr": "", "rc": 0, "cmd": "mysql -uslurm -ptestslurm123 -e \\"SHOW DATABASES;\\"", "start": "2025-07-24 01:06:45.179111", "end": "2025-07-24 01:06:45.191160", "delta": "0:00:00.012049", "msg": "", "invocation": {"module_args": {"_raw_params": "mysql -uslurm -ptestslurm123 -e \\"SHOW DATABASES;\\"", "_uses_shell": true, "expand_argument_vars": true, "stdin_add_newline": true, "strip_empty_ends": true, "argv": null, "chdir": null, "executable": null, "creates": null, "removes": null, "stdin": null}}}\n', b'')
2025-07-23 22:06:45,217 p=66584 u=master n=ansible | ok: [sm01] => changed=false 
  cmd: mysql -uslurm -ptestslurm123 -e "SHOW DATABASES;"
  delta: '0:00:00.012049'
  end: '2025-07-24 01:06:45.191160'
  failed_when_result: false
  invocation:
    module_args:
      _raw_params: mysql -uslurm -ptestslurm123 -e "SHOW DATABASES;"
      _uses_shell: true
      argv: null
      chdir: null
      creates: null
      executable: null
      expand_argument_vars: true
      removes: null
      stdin: null
      stdin_add_newline: true
      strip_empty_ends: true
  msg: ''
  rc: 0
  start: '2025-07-24 01:06:45.179111'
  stderr: ''
  stderr_lines: <omitted>
  stdout: |-
    Database
    information_schema
    slurm_acct_db
  stdout_lines: <omitted>
2025-07-23 22:06:45,222 p=66584 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-23 22:06:45,222 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:45 +0000 (0:00:00.303)       0:00:02.036 ******** 
2025-07-23 22:06:45,276 p=66584 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-23 22:06:45,280 p=66584 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-23 22:06:45,281 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:45 +0000 (0:00:00.058)       0:00:02.094 ******** 
2025-07-23 22:06:45,301 p=66584 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-23 22:06:45,310 p=66584 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-23 22:06:45,311 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:45 +0000 (0:00:00.030)       0:00:02.125 ******** 
2025-07-23 22:06:45,326 p=66584 u=master n=ansible | <sm01> ESTABLISH SSH CONNECTION FOR USER: master
2025-07-23 22:06:45,327 p=66584 u=master n=ansible | <sm01> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="master"' -o ConnectTimeout=30 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o 'ControlPath="./tmp/ansible-ssh-%h-%p-%r"' sm01 '/bin/sh -c '"'"'echo ~master && sleep 0'"'"''
2025-07-23 22:06:45,341 p=66584 u=master n=ansible | <sm01> (0, b'/home/master\n', b'')
2025-07-23 22:06:45,341 p=66584 u=master n=ansible | <sm01> ESTABLISH SSH CONNECTION FOR USER: master
2025-07-23 22:06:45,341 p=66584 u=master n=ansible | <sm01> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="master"' -o ConnectTimeout=30 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o 'ControlPath="./tmp/ansible-ssh-%h-%p-%r"' sm01 '/bin/sh -c '"'"'( umask 77 && mkdir -p "` echo /home/master/.ansible/tmp `"&& mkdir "` echo /home/master/.ansible/tmp/ansible-tmp-1753308405.3411367-66636-251883208868745 `" && echo ansible-tmp-1753308405.3411367-66636-251883208868745="` echo /home/master/.ansible/tmp/ansible-tmp-1753308405.3411367-66636-251883208868745 `" ) && sleep 0'"'"''
2025-07-23 22:06:45,356 p=66584 u=master n=ansible | <sm01> (0, b'ansible-tmp-1753308405.3411367-66636-251883208868745=/home/master/.ansible/tmp/ansible-tmp-1753308405.3411367-66636-251883208868745\n', b'')
2025-07-23 22:06:45,421 p=66584 u=master n=ansible | <sm01> ESTABLISH SSH CONNECTION FOR USER: master
2025-07-23 22:06:45,422 p=66584 u=master n=ansible | <sm01> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o StrictHostKeyChecking=no -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="master"' -o ConnectTimeout=30 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o 'ControlPath="./tmp/ansible-ssh-%h-%p-%r"' sm01 '/bin/sh -c '"'"'rm -f -r /home/master/.ansible/tmp/ansible-tmp-1753308405.3411367-66636-251883208868745/ > /dev/null 2>&1 && sleep 0'"'"''
2025-07-23 22:06:45,434 p=66584 u=master n=ansible | <sm01> (0, b'', b'')
2025-07-23 22:06:45,436 p=66584 u=master n=ansible | The full traceback is:
Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/ansible/template/__init__.py", line 1010, in do_template
    res = myenv.concat(rf)
          ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/ansible/template/native_helpers.py", line 83, in ansible_concat
    return ''.join([to_text(v) for v in nodes])
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 85, in root
  File "/usr/lib/python3/dist-packages/ansible/template/__init__.py", line 295, in wrapper
    ret = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/ansible/template/__init__.py", line 558, in _ansible_finalize
    return thing if _fail_on_undefined(thing) is not None else ''
                    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/ansible/template/__init__.py", line 530, in _fail_on_undefined
    elif is_sequence(data):
         ^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/ansible/module_utils/common/collections.py", line 94, in is_sequence
    if not include_strings and is_string(seq):
                               ^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/jinja2/runtime.py", line 852, in _fail_with_undefined_error
    raise self._undefined_exception(self._undefined_message)
jinja2.exceptions.UndefinedError: 'slurm_spool_dir' is undefined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib/python3/dist-packages/ansible/plugins/action/template.py", line 152, in run
    resultant = templar.do_template(template_data, preserve_trailing_newlines=True, escape_backslashes=False, overrides=overrides)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/ansible/template/__init__.py", line 1044, in do_template
    raise AnsibleUndefinedVariable(e, orig_exc=e)
ansible.errors.AnsibleUndefinedVariable: 'slurm_spool_dir' is undefined. 'slurm_spool_dir' is undefined

2025-07-23 22:06:45,437 p=66584 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  msg: 'AnsibleUndefinedVariable: ''slurm_spool_dir'' is undefined. ''slurm_spool_dir'' is undefined'
2025-07-23 22:06:45,438 p=66584 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 22:06:45,438 p=66584 u=master n=ansible | sm01                       : ok=13   changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 22:06:45,439 p=66584 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 2 seconds
2025-07-23 22:06:45,439 p=66584 u=master n=ansible | Wednesday 23 July 2025  22:06:45 +0000 (0:00:00.128)       0:00:02.253 ******** 
2025-07-23 22:06:45,439 p=66584 u=master n=ansible | =============================================================================== 
2025-07-23 22:06:45,439 p=66584 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.40s
/home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml:18 ---------------------------------------------------------------------------------------------------------
2025-07-23 22:06:45,439 p=66584 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 0.39s
/home/master/22Jul/slurm-hpc-cluster/playbooks/test_slurm_master_simple.yml:28 -------------------------------------------------------------------------------------------------------
2025-07-23 22:06:45,439 p=66584 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.30s
/home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml:45 ---------------------------------------------------------------------------------------------------------
2025-07-23 22:06:45,439 p=66584 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.30s
/home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml:38 ---------------------------------------------------------------------------------------------------------
2025-07-23 22:06:45,440 p=66584 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.28s
/home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml:7 ----------------------------------------------------------------------------------------------------------
2025-07-23 22:06:45,440 p=66584 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.13s
/home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml:7 -----------------------------------------------------------------------------------------------------------
2025-07-23 22:06:45,440 p=66584 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
/home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/main.yml:18 ------------------------------------------------------------------------------------------------------------
2025-07-23 22:06:45,440 p=66584 u=master n=ansible | slurm_master : [MARIADB] Финальный результат ----------------------------------------------------------------------------------------------------------------------------------- 0.06s
/home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml:52 ---------------------------------------------------------------------------------------------------------
2025-07-23 22:06:45,440 p=66584 u=master n=ansible | slurm_master : [MARIADB] Показать версию MariaDB ------------------------------------------------------------------------------------------------------------------------------- 0.05s
/home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml:13 ---------------------------------------------------------------------------------------------------------
2025-07-23 22:06:45,440 p=66584 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.05s
/home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/main.yml:7 -------------------------------------------------------------------------------------------------------------
2025-07-23 22:06:45,440 p=66584 u=master n=ansible | slurm_master : [MARIADB] Результат создания пользователя ----------------------------------------------------------------------------------------------------------------------- 0.05s
/home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml:29 ---------------------------------------------------------------------------------------------------------
2025-07-23 22:06:45,440 p=66584 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
/home/master/22Jul/slurm-hpc-cluster/playbooks/test_slurm_master_simple.yml:34 -------------------------------------------------------------------------------------------------------
2025-07-23 22:06:45,440 p=66584 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
/home/master/22Jul/slurm-hpc-cluster/playbooks/test_slurm_master_simple.yml:39 -------------------------------------------------------------------------------------------------------
2025-07-23 22:06:45,440 p=66584 u=master n=ansible | slurm_master : [SLURM-MASTER] Создание конфигурации Slurm ---------------------------------------------------------------------------------------------------------------------- 0.03s
/home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/main.yml:26 ------------------------------------------------------------------------------------------------------------
2025-07-23 22:06:45,441 p=66584 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
/home/master/22Jul/slurm-hpc-cluster/playbooks/test_slurm_master_simple.yml:20 -------------------------------------------------------------------------------------------------------
2025-07-23 22:09:43,025 p=66812 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:09:43,025 p=66812 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:09:43,421 p=66812 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 22:09:43,435 p=66812 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 22:09:43,435 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:43 +0000 (0:00:00.015)       0:00:00.015 ******** 
2025-07-23 22:09:43,459 p=66812 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 22:09:43,463 p=66812 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 22:09:43,463 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:43 +0000 (0:00:00.028)       0:00:00.043 ******** 
2025-07-23 22:09:44,566 p=66812 u=master n=ansible | ok: [sm01]
2025-07-23 22:09:44,570 p=66812 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 22:09:44,570 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:44 +0000 (0:00:01.106)       0:00:01.150 ******** 
2025-07-23 22:09:44,617 p=66812 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 22:09:44,621 p=66812 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 22:09:44,621 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:44 +0000 (0:00:00.050)       0:00:01.201 ******** 
2025-07-23 22:09:44,654 p=66812 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 22:09:44,655 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:44 +0000 (0:00:00.033)       0:00:01.235 ******** 
2025-07-23 22:09:44,705 p=66812 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 22:09:44,710 p=66812 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 22:09:44,710 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:44 +0000 (0:00:00.055)       0:00:01.290 ******** 
2025-07-23 22:09:44,763 p=66812 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 22:09:44,770 p=66812 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-23 22:09:44,770 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:44 +0000 (0:00:00.060)       0:00:01.351 ******** 
2025-07-23 22:09:45,050 p=66812 u=master n=ansible | ok: [sm01]
2025-07-23 22:09:45,054 p=66812 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-23 22:09:45,054 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:45 +0000 (0:00:00.283)       0:00:01.634 ******** 
2025-07-23 22:09:45,104 p=66812 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-23 22:09:45,108 p=66812 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-23 22:09:45,108 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:45 +0000 (0:00:00.054)       0:00:01.688 ******** 
2025-07-23 22:09:45,613 p=66812 u=master n=ansible | changed: [sm01]
2025-07-23 22:09:45,617 p=66812 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-23 22:09:45,618 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:45 +0000 (0:00:00.509)       0:00:02.198 ******** 
2025-07-23 22:09:45,668 p=66812 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-23 22:09:45,671 p=66812 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-23 22:09:45,672 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:45 +0000 (0:00:00.053)       0:00:02.252 ******** 
2025-07-23 22:09:45,975 p=66812 u=master n=ansible | ok: [sm01]
2025-07-23 22:09:45,979 p=66812 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-23 22:09:45,979 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:45 +0000 (0:00:00.307)       0:00:02.560 ******** 
2025-07-23 22:09:46,283 p=66812 u=master n=ansible | ok: [sm01]
2025-07-23 22:09:46,287 p=66812 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-23 22:09:46,287 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:46 +0000 (0:00:00.307)       0:00:02.868 ******** 
2025-07-23 22:09:46,339 p=66812 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-23 22:09:46,344 p=66812 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-23 22:09:46,344 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:46 +0000 (0:00:00.056)       0:00:02.924 ******** 
2025-07-23 22:09:46,365 p=66812 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-23 22:09:46,375 p=66812 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-23 22:09:46,375 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:46 +0000 (0:00:00.031)       0:00:02.955 ******** 
2025-07-23 22:09:46,510 p=66812 u=master n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'slurm_spool_dir' is undefined. 'slurm_spool_dir' is undefined
2025-07-23 22:09:46,511 p=66812 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  msg: 'AnsibleUndefinedVariable: ''slurm_spool_dir'' is undefined. ''slurm_spool_dir'' is undefined'
2025-07-23 22:09:46,512 p=66812 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 22:09:46,513 p=66812 u=master n=ansible | sm01                       : ok=13   changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 22:09:46,513 p=66812 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 3 seconds
2025-07-23 22:09:46,513 p=66812 u=master n=ansible | Wednesday 23 July 2025  22:09:46 +0000 (0:00:00.137)       0:00:03.093 ******** 
2025-07-23 22:09:46,513 p=66812 u=master n=ansible | =============================================================================== 
2025-07-23 22:09:46,513 p=66812 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.11s
2025-07-23 22:09:46,513 p=66812 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.51s
2025-07-23 22:09:46,513 p=66812 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-23 22:09:46,513 p=66812 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-23 22:09:46,514 p=66812 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.28s
2025-07-23 22:09:46,514 p=66812 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.14s
2025-07-23 22:09:46,514 p=66812 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:09:46,514 p=66812 u=master n=ansible | slurm_master : [MARIADB] Финальный результат ----------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:09:46,514 p=66812 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:09:46,514 p=66812 u=master n=ansible | slurm_master : [MARIADB] Показать версию MariaDB ------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:09:46,514 p=66812 u=master n=ansible | slurm_master : [MARIADB] Результат создания пользователя ----------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:09:46,514 p=66812 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:09:46,514 p=66812 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:09:46,514 p=66812 u=master n=ansible | slurm_master : [SLURM-MASTER] Создание конфигурации Slurm ---------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:09:46,514 p=66812 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:11:53,138 p=67019 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:11:53,138 p=67019 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:11:53,537 p=67019 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 22:11:53,551 p=67019 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 22:11:53,551 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:53 +0000 (0:00:00.015)       0:00:00.015 ******** 
2025-07-23 22:11:53,577 p=67019 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 22:11:53,581 p=67019 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 22:11:53,581 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:53 +0000 (0:00:00.030)       0:00:00.045 ******** 
2025-07-23 22:11:54,697 p=67019 u=master n=ansible | ok: [sm01]
2025-07-23 22:11:54,701 p=67019 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 22:11:54,701 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:54 +0000 (0:00:01.119)       0:00:01.165 ******** 
2025-07-23 22:11:54,748 p=67019 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 22:11:54,752 p=67019 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 22:11:54,752 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:54 +0000 (0:00:00.050)       0:00:01.216 ******** 
2025-07-23 22:11:54,785 p=67019 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 22:11:54,785 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:54 +0000 (0:00:00.033)       0:00:01.250 ******** 
2025-07-23 22:11:54,837 p=67019 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 22:11:54,841 p=67019 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 22:11:54,841 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:54 +0000 (0:00:00.055)       0:00:01.305 ******** 
2025-07-23 22:11:54,894 p=67019 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 22:11:54,901 p=67019 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-23 22:11:54,902 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:54 +0000 (0:00:00.060)       0:00:01.366 ******** 
2025-07-23 22:11:55,178 p=67019 u=master n=ansible | ok: [sm01]
2025-07-23 22:11:55,183 p=67019 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-23 22:11:55,183 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:55 +0000 (0:00:00.281)       0:00:01.647 ******** 
2025-07-23 22:11:55,234 p=67019 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-23 22:11:55,238 p=67019 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-23 22:11:55,238 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:55 +0000 (0:00:00.054)       0:00:01.702 ******** 
2025-07-23 22:11:55,642 p=67019 u=master n=ansible | changed: [sm01]
2025-07-23 22:11:55,646 p=67019 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-23 22:11:55,646 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:55 +0000 (0:00:00.408)       0:00:02.110 ******** 
2025-07-23 22:11:55,699 p=67019 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-23 22:11:55,702 p=67019 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-23 22:11:55,703 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:55 +0000 (0:00:00.056)       0:00:02.167 ******** 
2025-07-23 22:11:56,003 p=67019 u=master n=ansible | ok: [sm01]
2025-07-23 22:11:56,008 p=67019 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-23 22:11:56,008 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:56 +0000 (0:00:00.305)       0:00:02.472 ******** 
2025-07-23 22:11:56,309 p=67019 u=master n=ansible | ok: [sm01]
2025-07-23 22:11:56,313 p=67019 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-23 22:11:56,313 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:56 +0000 (0:00:00.305)       0:00:02.777 ******** 
2025-07-23 22:11:56,365 p=67019 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-23 22:11:56,370 p=67019 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-23 22:11:56,370 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:56 +0000 (0:00:00.057)       0:00:02.834 ******** 
2025-07-23 22:11:56,390 p=67019 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-23 22:11:56,400 p=67019 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-23 22:11:56,400 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:56 +0000 (0:00:00.029)       0:00:02.864 ******** 
2025-07-23 22:11:56,530 p=67019 u=master n=ansible | An exception occurred during task execution. To see the full traceback, use -vvv. The error was: ansible.errors.AnsibleUndefinedVariable: 'ansible.vars.hostvars.HostVarsVars object' has no attribute 'ansible_memtotal_mb'. 'ansible.vars.hostvars.HostVarsVars object' has no attribute 'ansible_memtotal_mb'
2025-07-23 22:11:56,531 p=67019 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  msg: 'AnsibleUndefinedVariable: ''ansible.vars.hostvars.HostVarsVars object'' has no attribute ''ansible_memtotal_mb''. ''ansible.vars.hostvars.HostVarsVars object'' has no attribute ''ansible_memtotal_mb'''
2025-07-23 22:11:56,532 p=67019 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 22:11:56,532 p=67019 u=master n=ansible | sm01                       : ok=13   changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 22:11:56,532 p=67019 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 2 seconds
2025-07-23 22:11:56,533 p=67019 u=master n=ansible | Wednesday 23 July 2025  22:11:56 +0000 (0:00:00.132)       0:00:02.997 ******** 
2025-07-23 22:11:56,533 p=67019 u=master n=ansible | =============================================================================== 
2025-07-23 22:11:56,533 p=67019 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.12s
2025-07-23 22:11:56,533 p=67019 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.41s
2025-07-23 22:11:56,533 p=67019 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-23 22:11:56,533 p=67019 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-23 22:11:56,533 p=67019 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.28s
2025-07-23 22:11:56,533 p=67019 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.13s
2025-07-23 22:11:56,533 p=67019 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:11:56,534 p=67019 u=master n=ansible | slurm_master : [MARIADB] Финальный результат ----------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:11:56,534 p=67019 u=master n=ansible | slurm_master : [MARIADB] Результат создания пользователя ----------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:11:56,534 p=67019 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:11:56,534 p=67019 u=master n=ansible | slurm_master : [MARIADB] Показать версию MariaDB ------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:11:56,534 p=67019 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:11:56,534 p=67019 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:11:56,534 p=67019 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:11:56,534 p=67019 u=master n=ansible | slurm_master : [SLURM-MASTER] Создание конфигурации Slurm ---------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:14:47,000 p=67140 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:14:47,000 p=67140 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:14:47,399 p=67140 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 22:14:47,413 p=67140 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 22:14:47,413 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:47 +0000 (0:00:00.015)       0:00:00.015 ******** 
2025-07-23 22:14:47,437 p=67140 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 22:14:47,441 p=67140 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 22:14:47,441 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:47 +0000 (0:00:00.028)       0:00:00.044 ******** 
2025-07-23 22:14:48,583 p=67140 u=master n=ansible | ok: [sm01]
2025-07-23 22:14:48,587 p=67140 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 22:14:48,587 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:48 +0000 (0:00:01.145)       0:00:01.190 ******** 
2025-07-23 22:14:48,633 p=67140 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 22:14:48,637 p=67140 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 22:14:48,637 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:48 +0000 (0:00:00.050)       0:00:01.240 ******** 
2025-07-23 22:14:48,671 p=67140 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 22:14:48,671 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:48 +0000 (0:00:00.033)       0:00:01.274 ******** 
2025-07-23 22:14:48,720 p=67140 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 22:14:48,724 p=67140 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 22:14:48,725 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:48 +0000 (0:00:00.053)       0:00:01.327 ******** 
2025-07-23 22:14:48,777 p=67140 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 22:14:48,785 p=67140 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-23 22:14:48,785 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:48 +0000 (0:00:00.060)       0:00:01.388 ******** 
2025-07-23 22:14:49,065 p=67140 u=master n=ansible | ok: [sm01]
2025-07-23 22:14:49,069 p=67140 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-23 22:14:49,069 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:49 +0000 (0:00:00.284)       0:00:01.672 ******** 
2025-07-23 22:14:49,119 p=67140 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-23 22:14:49,123 p=67140 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-23 22:14:49,124 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:49 +0000 (0:00:00.054)       0:00:01.726 ******** 
2025-07-23 22:14:49,536 p=67140 u=master n=ansible | changed: [sm01]
2025-07-23 22:14:49,541 p=67140 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-23 22:14:49,541 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:49 +0000 (0:00:00.417)       0:00:02.144 ******** 
2025-07-23 22:14:49,589 p=67140 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-23 22:14:49,593 p=67140 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-23 22:14:49,593 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:49 +0000 (0:00:00.051)       0:00:02.196 ******** 
2025-07-23 22:14:49,892 p=67140 u=master n=ansible | ok: [sm01]
2025-07-23 22:14:49,897 p=67140 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-23 22:14:49,897 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:49 +0000 (0:00:00.304)       0:00:02.500 ******** 
2025-07-23 22:14:50,196 p=67140 u=master n=ansible | ok: [sm01]
2025-07-23 22:14:50,201 p=67140 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-23 22:14:50,201 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:50 +0000 (0:00:00.304)       0:00:02.804 ******** 
2025-07-23 22:14:50,252 p=67140 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-23 22:14:50,257 p=67140 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-23 22:14:50,257 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:50 +0000 (0:00:00.055)       0:00:02.860 ******** 
2025-07-23 22:14:50,277 p=67140 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-23 22:14:50,287 p=67140 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-23 22:14:50,287 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:50 +0000 (0:00:00.030)       0:00:02.890 ******** 
2025-07-23 22:14:51,202 p=67140 u=master n=ansible | changed: [sm01]
2025-07-23 22:14:51,206 p=67140 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание конфига slurmdbd.conf] *************************************************************************************************************************
2025-07-23 22:14:51,207 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:51 +0000 (0:00:00.919)       0:00:03.809 ******** 
2025-07-23 22:14:51,810 p=67140 u=master n=ansible | changed: [sm01]
2025-07-23 22:14:51,814 p=67140 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание gres.conf для GPU] *****************************************************************************************************************************
2025-07-23 22:14:51,815 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:51 +0000 (0:00:00.607)       0:00:04.417 ******** 
2025-07-23 22:14:52,437 p=67140 u=master n=ansible | changed: [sm01]
2025-07-23 22:14:52,441 p=67140 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание cgroup.conf] ***********************************************************************************************************************************
2025-07-23 22:14:52,441 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:52 +0000 (0:00:00.626)       0:00:05.044 ******** 
2025-07-23 22:14:53,207 p=67140 u=master n=ansible | changed: [sm01]
2025-07-23 22:14:53,213 p=67140 u=master n=ansible | TASK [slurm_master : [CONFIG] Копирование конфигов на NFS для распространения] ********************************************************************************************************
2025-07-23 22:14:53,213 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:53 +0000 (0:00:00.772)       0:00:05.816 ******** 
2025-07-23 22:14:53,536 p=67140 u=master n=ansible | failed: [sm01] (item=slurm.conf) => changed=false 
  ansible_loop_var: item
  item: slurm.conf
  msg: Destination directory /sw/config does not exist
2025-07-23 22:14:53,820 p=67140 u=master n=ansible | failed: [sm01] (item=cgroup.conf) => changed=false 
  ansible_loop_var: item
  item: cgroup.conf
  msg: Destination directory /sw/config does not exist
2025-07-23 22:14:54,112 p=67140 u=master n=ansible | failed: [sm01] (item=gres.conf) => changed=false 
  ansible_loop_var: item
  item: gres.conf
  msg: Destination directory /sw/config does not exist
2025-07-23 22:14:54,115 p=67140 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 22:14:54,115 p=67140 u=master n=ansible | sm01                       : ok=17   changed=5    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 22:14:54,115 p=67140 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 6 seconds
2025-07-23 22:14:54,116 p=67140 u=master n=ansible | Wednesday 23 July 2025  22:14:54 +0000 (0:00:00.902)       0:00:06.718 ******** 
2025-07-23 22:14:54,116 p=67140 u=master n=ansible | =============================================================================== 
2025-07-23 22:14:54,116 p=67140 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.15s
2025-07-23 22:14:54,116 p=67140 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.92s
2025-07-23 22:14:54,116 p=67140 u=master n=ansible | slurm_master : [CONFIG] Копирование конфигов на NFS для распространения -------------------------------------------------------------------------------------------------------- 0.90s
2025-07-23 22:14:54,116 p=67140 u=master n=ansible | slurm_master : [CONFIG] Создание cgroup.conf ----------------------------------------------------------------------------------------------------------------------------------- 0.77s
2025-07-23 22:14:54,116 p=67140 u=master n=ansible | slurm_master : [CONFIG] Создание gres.conf для GPU ----------------------------------------------------------------------------------------------------------------------------- 0.63s
2025-07-23 22:14:54,116 p=67140 u=master n=ansible | slurm_master : [CONFIG] Создание конфига slurmdbd.conf ------------------------------------------------------------------------------------------------------------------------- 0.61s
2025-07-23 22:14:54,116 p=67140 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.42s
2025-07-23 22:14:54,117 p=67140 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-23 22:14:54,117 p=67140 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-23 22:14:54,117 p=67140 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.28s
2025-07-23 22:14:54,117 p=67140 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:14:54,117 p=67140 u=master n=ansible | slurm_master : [MARIADB] Финальный результат ----------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:14:54,117 p=67140 u=master n=ansible | slurm_master : [MARIADB] Показать версию MariaDB ------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:14:54,117 p=67140 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:14:54,117 p=67140 u=master n=ansible | slurm_master : [MARIADB] Результат создания пользователя ----------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:14:54,117 p=67140 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:14:54,117 p=67140 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:14:54,117 p=67140 u=master n=ansible | slurm_master : [SLURM-MASTER] Создание конфигурации Slurm ---------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:14:54,118 p=67140 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:16:33,956 p=67293 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:16:33,957 p=67293 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:16:34,373 p=67293 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 22:16:34,386 p=67293 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 22:16:34,387 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:34 +0000 (0:00:00.016)       0:00:00.016 ******** 
2025-07-23 22:16:34,409 p=67293 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 22:16:34,413 p=67293 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 22:16:34,413 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:34 +0000 (0:00:00.026)       0:00:00.042 ******** 
2025-07-23 22:16:35,528 p=67293 u=master n=ansible | ok: [sm01]
2025-07-23 22:16:35,532 p=67293 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 22:16:35,532 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:35 +0000 (0:00:01.118)       0:00:01.161 ******** 
2025-07-23 22:16:35,579 p=67293 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 22:16:35,583 p=67293 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 22:16:35,583 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:35 +0000 (0:00:00.050)       0:00:01.212 ******** 
2025-07-23 22:16:35,616 p=67293 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 22:16:35,616 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:35 +0000 (0:00:00.033)       0:00:01.245 ******** 
2025-07-23 22:16:35,667 p=67293 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 22:16:35,671 p=67293 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 22:16:35,671 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:35 +0000 (0:00:00.054)       0:00:01.300 ******** 
2025-07-23 22:16:35,724 p=67293 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 22:16:35,732 p=67293 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-23 22:16:35,732 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:35 +0000 (0:00:00.060)       0:00:01.361 ******** 
2025-07-23 22:16:36,014 p=67293 u=master n=ansible | ok: [sm01]
2025-07-23 22:16:36,018 p=67293 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-23 22:16:36,018 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:36 +0000 (0:00:00.286)       0:00:01.647 ******** 
2025-07-23 22:16:36,067 p=67293 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-23 22:16:36,072 p=67293 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-23 22:16:36,072 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:36 +0000 (0:00:00.053)       0:00:01.701 ******** 
2025-07-23 22:16:36,502 p=67293 u=master n=ansible | changed: [sm01]
2025-07-23 22:16:36,506 p=67293 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-23 22:16:36,506 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:36 +0000 (0:00:00.434)       0:00:02.135 ******** 
2025-07-23 22:16:36,555 p=67293 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-23 22:16:36,558 p=67293 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-23 22:16:36,559 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:36 +0000 (0:00:00.052)       0:00:02.188 ******** 
2025-07-23 22:16:36,863 p=67293 u=master n=ansible | ok: [sm01]
2025-07-23 22:16:36,868 p=67293 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-23 22:16:36,868 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:36 +0000 (0:00:00.309)       0:00:02.497 ******** 
2025-07-23 22:16:37,173 p=67293 u=master n=ansible | ok: [sm01]
2025-07-23 22:16:37,177 p=67293 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-23 22:16:37,177 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:37 +0000 (0:00:00.309)       0:00:02.806 ******** 
2025-07-23 22:16:37,229 p=67293 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-23 22:16:37,233 p=67293 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-23 22:16:37,233 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:37 +0000 (0:00:00.056)       0:00:02.862 ******** 
2025-07-23 22:16:37,255 p=67293 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-23 22:16:37,265 p=67293 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-23 22:16:37,265 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:37 +0000 (0:00:00.031)       0:00:02.894 ******** 
2025-07-23 22:16:38,216 p=67293 u=master n=ansible | ok: [sm01]
2025-07-23 22:16:38,221 p=67293 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание конфига slurmdbd.conf] *************************************************************************************************************************
2025-07-23 22:16:38,221 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:38 +0000 (0:00:00.956)       0:00:03.850 ******** 
2025-07-23 22:16:38,823 p=67293 u=master n=ansible | ok: [sm01]
2025-07-23 22:16:38,827 p=67293 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание gres.conf для GPU] *****************************************************************************************************************************
2025-07-23 22:16:38,827 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:38 +0000 (0:00:00.605)       0:00:04.456 ******** 
2025-07-23 22:16:39,444 p=67293 u=master n=ansible | ok: [sm01]
2025-07-23 22:16:39,448 p=67293 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание cgroup.conf] ***********************************************************************************************************************************
2025-07-23 22:16:39,448 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:39 +0000 (0:00:00.621)       0:00:05.077 ******** 
2025-07-23 22:16:40,171 p=67293 u=master n=ansible | ok: [sm01]
2025-07-23 22:16:40,177 p=67293 u=master n=ansible | TASK [slurm_master : [CONFIG] Копирование конфигов на NFS для распространения] ********************************************************************************************************
2025-07-23 22:16:40,177 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:40 +0000 (0:00:00.728)       0:00:05.806 ******** 
2025-07-23 22:16:40,618 p=67293 u=master n=ansible | failed: [sm01] (item=slurm.conf) => changed=false 
  ansible_loop_var: item
  item: slurm.conf
  msg: Destination directory /sw/config does not exist
2025-07-23 22:16:40,896 p=67293 u=master n=ansible | failed: [sm01] (item=cgroup.conf) => changed=false 
  ansible_loop_var: item
  item: cgroup.conf
  msg: Destination directory /sw/config does not exist
2025-07-23 22:16:41,180 p=67293 u=master n=ansible | failed: [sm01] (item=gres.conf) => changed=false 
  ansible_loop_var: item
  item: gres.conf
  msg: Destination directory /sw/config does not exist
2025-07-23 22:16:41,184 p=67293 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 22:16:41,184 p=67293 u=master n=ansible | sm01                       : ok=17   changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 22:16:41,184 p=67293 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 6 seconds
2025-07-23 22:16:41,185 p=67293 u=master n=ansible | Wednesday 23 July 2025  22:16:41 +0000 (0:00:01.007)       0:00:06.814 ******** 
2025-07-23 22:16:41,185 p=67293 u=master n=ansible | =============================================================================== 
2025-07-23 22:16:41,185 p=67293 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.12s
2025-07-23 22:16:41,185 p=67293 u=master n=ansible | slurm_master : [CONFIG] Копирование конфигов на NFS для распространения -------------------------------------------------------------------------------------------------------- 1.01s
2025-07-23 22:16:41,185 p=67293 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.96s
2025-07-23 22:16:41,185 p=67293 u=master n=ansible | slurm_master : [CONFIG] Создание cgroup.conf ----------------------------------------------------------------------------------------------------------------------------------- 0.73s
2025-07-23 22:16:41,185 p=67293 u=master n=ansible | slurm_master : [CONFIG] Создание gres.conf для GPU ----------------------------------------------------------------------------------------------------------------------------- 0.62s
2025-07-23 22:16:41,185 p=67293 u=master n=ansible | slurm_master : [CONFIG] Создание конфига slurmdbd.conf ------------------------------------------------------------------------------------------------------------------------- 0.61s
2025-07-23 22:16:41,186 p=67293 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.43s
2025-07-23 22:16:41,186 p=67293 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-23 22:16:41,186 p=67293 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-23 22:16:41,186 p=67293 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.29s
2025-07-23 22:16:41,186 p=67293 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:16:41,186 p=67293 u=master n=ansible | slurm_master : [MARIADB] Финальный результат ----------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:16:41,186 p=67293 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:16:41,186 p=67293 u=master n=ansible | slurm_master : [MARIADB] Показать версию MariaDB ------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:16:41,186 p=67293 u=master n=ansible | slurm_master : [MARIADB] Результат создания пользователя ----------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:16:41,187 p=67293 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:16:41,187 p=67293 u=master n=ansible | [TEST] Выполнение роли slurm_master -------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:16:41,187 p=67293 u=master n=ansible | slurm_master : [SLURM-MASTER] Создание конфигурации Slurm ---------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:16:41,187 p=67293 u=master n=ansible | [TEST] Информация о тестировании ----------------------------------------------------------------------------------------------------------------------------------------------- 0.03s
2025-07-23 22:20:57,836 p=67450 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:20:57,836 p=67450 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:20:58,254 p=67450 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-23 22:20:58,268 p=67450 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-23 22:20:58,268 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:20:58 +0000 (0:00:00.016)       0:00:00.016 ******** 
2025-07-23 22:20:58,295 p=67450 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-23 22:20:58,299 p=67450 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-23 22:20:58,299 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:20:58 +0000 (0:00:00.030)       0:00:00.046 ******** 
2025-07-23 22:20:59,436 p=67450 u=master n=ansible | ok: [sm01]
2025-07-23 22:20:59,439 p=67450 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-23 22:20:59,440 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:20:59 +0000 (0:00:01.140)       0:00:01.187 ******** 
2025-07-23 22:20:59,494 p=67450 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-23 22:20:59,498 p=67450 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-23 22:20:59,498 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:20:59 +0000 (0:00:00.058)       0:00:01.245 ******** 
2025-07-23 22:20:59,532 p=67450 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-23 22:20:59,532 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:20:59 +0000 (0:00:00.034)       0:00:01.280 ******** 
2025-07-23 22:20:59,584 p=67450 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-23 22:20:59,588 p=67450 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-23 22:20:59,588 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:20:59 +0000 (0:00:00.055)       0:00:01.335 ******** 
2025-07-23 22:20:59,642 p=67450 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-23 22:20:59,650 p=67450 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-23 22:20:59,650 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:20:59 +0000 (0:00:00.062)       0:00:01.398 ******** 
2025-07-23 22:20:59,938 p=67450 u=master n=ansible | ok: [sm01]
2025-07-23 22:20:59,942 p=67450 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-23 22:20:59,943 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:20:59 +0000 (0:00:00.292)       0:00:01.690 ******** 
2025-07-23 22:20:59,993 p=67450 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-23 22:20:59,997 p=67450 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-23 22:20:59,998 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:20:59 +0000 (0:00:00.054)       0:00:01.745 ******** 
2025-07-23 22:21:00,406 p=67450 u=master n=ansible | changed: [sm01]
2025-07-23 22:21:00,410 p=67450 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-23 22:21:00,410 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:00 +0000 (0:00:00.412)       0:00:02.158 ******** 
2025-07-23 22:21:00,460 p=67450 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-23 22:21:00,464 p=67450 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-23 22:21:00,464 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:00 +0000 (0:00:00.054)       0:00:02.212 ******** 
2025-07-23 22:21:00,773 p=67450 u=master n=ansible | ok: [sm01]
2025-07-23 22:21:00,778 p=67450 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-23 22:21:00,778 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:00 +0000 (0:00:00.313)       0:00:02.525 ******** 
2025-07-23 22:21:01,092 p=67450 u=master n=ansible | ok: [sm01]
2025-07-23 22:21:01,096 p=67450 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-23 22:21:01,096 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:01 +0000 (0:00:00.318)       0:00:02.844 ******** 
2025-07-23 22:21:01,149 p=67450 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-23 22:21:01,154 p=67450 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-23 22:21:01,155 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:01 +0000 (0:00:00.058)       0:00:02.902 ******** 
2025-07-23 22:21:01,178 p=67450 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-23 22:21:01,188 p=67450 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-23 22:21:01,188 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:01 +0000 (0:00:00.033)       0:00:02.936 ******** 
2025-07-23 22:21:02,086 p=67450 u=master n=ansible | ok: [sm01]
2025-07-23 22:21:02,091 p=67450 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание конфига slurmdbd.conf] *************************************************************************************************************************
2025-07-23 22:21:02,091 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:02 +0000 (0:00:00.903)       0:00:03.839 ******** 
2025-07-23 22:21:02,693 p=67450 u=master n=ansible | ok: [sm01]
2025-07-23 22:21:02,697 p=67450 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание gres.conf для GPU] *****************************************************************************************************************************
2025-07-23 22:21:02,697 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:02 +0000 (0:00:00.606)       0:00:04.445 ******** 
2025-07-23 22:21:03,318 p=67450 u=master n=ansible | ok: [sm01]
2025-07-23 22:21:03,323 p=67450 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание cgroup.conf] ***********************************************************************************************************************************
2025-07-23 22:21:03,323 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:03 +0000 (0:00:00.625)       0:00:05.070 ******** 
2025-07-23 22:21:03,925 p=67450 u=master n=ansible | ok: [sm01]
2025-07-23 22:21:03,929 p=67450 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание директории для конфигов на NFS] ****************************************************************************************************************
2025-07-23 22:21:03,930 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:03 +0000 (0:00:00.606)       0:00:05.677 ******** 
2025-07-23 22:21:04,189 p=67450 u=master n=ansible | changed: [sm01]
2025-07-23 22:21:04,193 p=67450 u=master n=ansible | TASK [slurm_master : [CONFIG] Копирование конфигов на NFS для распространения] ********************************************************************************************************
2025-07-23 22:21:04,194 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:04 +0000 (0:00:00.264)       0:00:05.941 ******** 
2025-07-23 22:21:04,736 p=67450 u=master n=ansible | changed: [sm01] => (item=slurm.conf)
2025-07-23 22:21:05,021 p=67450 u=master n=ansible | changed: [sm01] => (item=cgroup.conf)
2025-07-23 22:21:05,301 p=67450 u=master n=ansible | changed: [sm01] => (item=gres.conf)
2025-07-23 22:21:05,307 p=67450 u=master n=ansible | TASK [slurm_master : [CONFIG] Конфигурация создана] ***********************************************************************************************************************************
2025-07-23 22:21:05,307 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:05 +0000 (0:00:01.113)       0:00:07.054 ******** 
2025-07-23 22:21:05,327 p=67450 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Конфигурация Slurm:\n✅ slurm.conf создан\n✅ gres.conf создан (AutoDetect=nvml)\n✅ cgroup.conf создан\n✅ slurmdbd.conf создан\n\U0001F4E4 Файлы скопированы в /sw/config/ для распространения"
2025-07-23 22:21:05,331 p=67450 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка systemd сервисов] ***********************************************************************************************************************
2025-07-23 22:21:05,331 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:05 +0000 (0:00:00.024)       0:00:07.079 ******** 
2025-07-23 22:21:05,355 p=67450 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/services.yml for sm01
2025-07-23 22:21:05,368 p=67450 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmctld] ******************************************************************************************************************
2025-07-23 22:21:05,368 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:05 +0000 (0:00:00.036)       0:00:07.115 ******** 
2025-07-23 22:21:05,944 p=67450 u=master n=ansible | changed: [sm01]
2025-07-23 22:21:05,948 p=67450 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmdbd] *******************************************************************************************************************
2025-07-23 22:21:05,948 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:05 +0000 (0:00:00.579)       0:00:07.695 ******** 
2025-07-23 22:21:06,543 p=67450 u=master n=ansible | changed: [sm01]
2025-07-23 22:21:06,547 p=67450 u=master n=ansible | TASK [slurm_master : [SERVICES] Перезагрузка systemd daemon] **************************************************************************************************************************
2025-07-23 22:21:06,547 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:06 +0000 (0:00:00.598)       0:00:08.294 ******** 
2025-07-23 22:21:07,637 p=67450 u=master n=ansible | ok: [sm01]
2025-07-23 22:21:07,641 p=67450 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmdbd (сначала база)] ***********************************************************************************************************************
2025-07-23 22:21:07,642 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:07 +0000 (0:00:01.094)       0:00:09.389 ******** 
2025-07-23 22:21:08,513 p=67450 u=master n=ansible | fatal: [sm01]: FAILED! => changed=false 
  msg: |-
    Unable to start service slurmdbd: Job for slurmdbd.service failed because the control process exited with error code.
    See "systemctl status slurmdbd.service" and "journalctl -xeu slurmdbd.service" for details.
2025-07-23 22:21:08,515 p=67450 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-23 22:21:08,515 p=67450 u=master n=ansible | sm01                       : ok=24   changed=5    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
2025-07-23 22:21:08,515 p=67450 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 10 seconds
2025-07-23 22:21:08,515 p=67450 u=master n=ansible | Wednesday 23 July 2025  22:21:08 +0000 (0:00:00.873)       0:00:10.263 ******** 
2025-07-23 22:21:08,516 p=67450 u=master n=ansible | =============================================================================== 
2025-07-23 22:21:08,516 p=67450 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.14s
2025-07-23 22:21:08,516 p=67450 u=master n=ansible | slurm_master : [CONFIG] Копирование конфигов на NFS для распространения -------------------------------------------------------------------------------------------------------- 1.11s
2025-07-23 22:21:08,516 p=67450 u=master n=ansible | slurm_master : [SERVICES] Перезагрузка systemd daemon -------------------------------------------------------------------------------------------------------------------------- 1.09s
2025-07-23 22:21:08,516 p=67450 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.90s
2025-07-23 22:21:08,516 p=67450 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmdbd (сначала база) ----------------------------------------------------------------------------------------------------------------------- 0.87s
2025-07-23 22:21:08,516 p=67450 u=master n=ansible | slurm_master : [CONFIG] Создание gres.conf для GPU ----------------------------------------------------------------------------------------------------------------------------- 0.63s
2025-07-23 22:21:08,516 p=67450 u=master n=ansible | slurm_master : [CONFIG] Создание cgroup.conf ----------------------------------------------------------------------------------------------------------------------------------- 0.61s
2025-07-23 22:21:08,516 p=67450 u=master n=ansible | slurm_master : [CONFIG] Создание конфига slurmdbd.conf ------------------------------------------------------------------------------------------------------------------------- 0.61s
2025-07-23 22:21:08,517 p=67450 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmdbd ------------------------------------------------------------------------------------------------------------------- 0.60s
2025-07-23 22:21:08,517 p=67450 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmctld ------------------------------------------------------------------------------------------------------------------ 0.58s
2025-07-23 22:21:08,517 p=67450 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.41s
2025-07-23 22:21:08,517 p=67450 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.32s
2025-07-23 22:21:08,517 p=67450 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-23 22:21:08,517 p=67450 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.29s
2025-07-23 22:21:08,517 p=67450 u=master n=ansible | slurm_master : [CONFIG] Создание директории для конфигов на NFS ---------------------------------------------------------------------------------------------------------------- 0.26s
2025-07-23 22:21:08,517 p=67450 u=master n=ansible | slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm ---------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:21:08,517 p=67450 u=master n=ansible | slurm_master : [MARIADB] Финальный результат ----------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:21:08,517 p=67450 u=master n=ansible | [TEST] Статус MariaDB ---------------------------------------------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:21:08,517 p=67450 u=master n=ansible | slurm_master : [SLURM-MASTER] Начало настройки Slurm Master -------------------------------------------------------------------------------------------------------------------- 0.06s
2025-07-23 22:21:08,518 p=67450 u=master n=ansible | slurm_master : [MARIADB] Показать версию MariaDB ------------------------------------------------------------------------------------------------------------------------------- 0.05s
2025-07-23 22:25:30,555 p=67657 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:25:30,556 p=67657 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:25:31,927 p=67657 u=master n=ansible | sm01 | CHANGED | rc=0 >>
Jul 24 01:21:08 sm01 systemd[1]: /etc/systemd/system/slurmdbd.service:13: PIDFile= references a path below legacy directory /var/run/, updating /var/run/slurmdbd.pid → /run/slurmdbd.pid; please update the unit file accordingly.
Jul 24 01:21:08 sm01 systemd[1]: /etc/systemd/system/slurmdbd.service:13: PIDFile= references a path below legacy directory /var/run/, updating /var/run/slurmdbd.pid → /run/slurmdbd.pid; please update the unit file accordingly.
Jul 24 01:21:08 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:21:08 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:21:08 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:21:08 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:21:13 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 1.
Jul 24 01:21:13 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:21:13 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:21:13 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:21:13 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:21:18 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 2.
Jul 24 01:21:18 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:21:18 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:21:18 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:21:18 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:21:24 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 3.
Jul 24 01:21:24 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:21:24 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:21:24 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:21:24 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:21:29 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 4.
Jul 24 01:21:29 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:21:29 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:21:29 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:21:29 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:21:34 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 5.
Jul 24 01:21:34 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:21:34 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:21:34 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:21:34 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:21:39 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 6.
Jul 24 01:21:39 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:21:39 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:21:39 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:21:39 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:21:45 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 7.
Jul 24 01:21:45 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:21:45 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:21:45 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:21:45 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:21:50 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 8.
Jul 24 01:21:50 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:21:50 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:21:50 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:21:50 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:21:55 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 9.
Jul 24 01:21:55 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:21:55 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:21:55 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:21:55 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:22:00 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 10.
Jul 24 01:22:00 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:22:00 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:22:00 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:22:00 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:22:06 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 11.
Jul 24 01:22:06 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:22:06 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:22:06 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:22:06 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:22:11 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 12.
Jul 24 01:22:11 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:22:11 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:22:11 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:22:11 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:22:16 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 13.
Jul 24 01:22:16 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:22:16 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:22:16 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:22:16 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:22:21 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 14.
Jul 24 01:22:21 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:22:21 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:22:21 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:22:21 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:22:27 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 15.
Jul 24 01:22:27 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:22:27 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:22:27 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:22:27 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:22:32 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 16.
Jul 24 01:22:32 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:22:32 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:22:32 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:22:32 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:22:37 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 17.
Jul 24 01:22:37 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:22:37 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:22:37 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:22:37 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:22:42 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 18.
Jul 24 01:22:43 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:22:43 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:22:43 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:22:43 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:22:48 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 19.
Jul 24 01:22:48 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:22:48 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:22:48 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:22:48 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:22:53 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 20.
Jul 24 01:22:53 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:22:53 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:22:53 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:22:53 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:22:58 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 21.
Jul 24 01:22:58 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:22:58 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:22:58 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:22:58 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:23:03 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 22.
Jul 24 01:23:03 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:23:03 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:23:03 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:23:03 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:23:09 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 23.
Jul 24 01:23:09 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:23:09 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:23:09 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:23:09 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:23:14 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 24.
Jul 24 01:23:14 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:23:14 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:23:14 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:23:14 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:23:19 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 25.
Jul 24 01:23:19 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:23:19 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:23:19 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:23:19 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:23:24 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 26.
Jul 24 01:23:24 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:23:24 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:23:24 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:23:24 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:23:30 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 27.
Jul 24 01:23:30 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:23:30 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:23:30 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:23:30 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:23:35 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 28.
Jul 24 01:23:35 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:23:35 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:23:35 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:23:35 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:23:40 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 29.
Jul 24 01:23:40 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:23:40 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:23:40 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:23:40 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:23:45 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 30.
Jul 24 01:23:45 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:23:45 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:23:45 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:23:45 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:23:51 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 31.
Jul 24 01:23:51 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:23:51 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:23:51 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:23:51 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:23:56 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 32.
Jul 24 01:23:56 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:23:56 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:23:56 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:23:56 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:24:01 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 33.
Jul 24 01:24:01 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:24:01 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:24:01 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:24:01 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:24:04 sm01 systemd[1]: Stopped slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:24:04 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:24:04 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:24:04 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:24:04 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:24:09 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 34.
Jul 24 01:24:09 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:24:09 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:24:09 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:24:09 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:24:14 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 35.
Jul 24 01:24:14 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:24:14 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:24:14 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:24:14 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:24:19 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 36.
Jul 24 01:24:20 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:24:20 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:24:20 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:24:20 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:24:25 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 37.
Jul 24 01:24:25 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:24:25 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:24:25 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:24:25 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:24:30 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 38.
Jul 24 01:24:30 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:24:30 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:24:30 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:24:30 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:24:35 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 39.
Jul 24 01:24:35 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:24:35 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:24:35 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:24:35 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:24:40 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 40.
Jul 24 01:24:41 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:24:41 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:24:41 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:24:41 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:24:46 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 41.
Jul 24 01:24:46 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:24:46 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:24:46 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:24:46 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:24:51 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 42.
Jul 24 01:24:51 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:24:51 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:24:51 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:24:51 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:24:56 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 43.
Jul 24 01:24:56 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:24:56 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:24:56 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:24:56 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:25:01 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 44.
Jul 24 01:25:01 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:25:01 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:25:01 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:25:01 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:25:07 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 45.
Jul 24 01:25:07 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:25:07 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:25:07 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:25:07 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:25:12 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 46.
Jul 24 01:25:12 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:25:12 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:25:12 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:25:12 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:25:17 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 47.
Jul 24 01:25:17 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:25:17 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:25:17 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:25:17 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:25:22 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 48.
Jul 24 01:25:23 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:25:23 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:25:23 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:25:23 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.
Jul 24 01:25:28 sm01 systemd[1]: slurmdbd.service: Scheduled restart job, restart counter is at 49.
Jul 24 01:25:28 sm01 systemd[1]: Starting slurmdbd.service - Slurm DBD accounting daemon...
Jul 24 01:25:28 sm01 systemd[1]: slurmdbd.service: Control process exited, code=exited, status=203/EXEC
Jul 24 01:25:28 sm01 systemd[1]: slurmdbd.service: Failed with result 'exit-code'.
Jul 24 01:25:28 sm01 systemd[1]: Failed to start slurmdbd.service - Slurm DBD accounting daemon.

2025-07-23 22:26:41,513 p=67715 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:26:41,513 p=67715 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-23 22:26:42,859 p=67715 u=master n=ansible | sm01 | FAILED | rc=2 >>
ls: cannot access '/usr/local/slurm/bin/': No such file or directory
ls: cannot access '/usr/local/slurm/sbin/': No such file or directorynon-zero return code

2025-07-24 04:29:55,129 p=68668 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:29:55,130 p=68668 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:29:56,466 p=68668 u=master n=ansible | sm01 | FAILED | rc=1 >>
tail: cannot open '/var/log/slurm/slurmdbd.log' for reading: Permission deniednon-zero return code

2025-07-24 04:30:10,247 p=68734 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:30:10,247 p=68734 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:30:10,873 p=68734 u=master n=ansible | sm01 | CHANGED | rc=0 >>
[2025-07-24T07:29:52.318] error: mysql_real_connect failed: 2002 Can't connect to server on 'sm01' (111)
[2025-07-24T07:29:52.318] error: The database must be up when starting the MYSQL plugin.  Trying again in 5 seconds.
[2025-07-24T07:29:56.876] error: mysql_real_connect failed: 2002 Can't connect to server on 'sm01' (111)
[2025-07-24T07:29:56.876] error: The database must be up when starting the MYSQL plugin.  Trying again in 5 seconds.
[2025-07-24T07:29:57.175] error: mysql_real_connect failed: 2002 Can't connect to server on 'sm01' (111)
[2025-07-24T07:29:57.175] error: The database must be up when starting the MYSQL plugin.  Trying again in 5 seconds.
[2025-07-24T07:29:57.319] error: mysql_real_connect failed: 2002 Can't connect to server on 'sm01' (111)
[2025-07-24T07:29:57.319] error: The database must be up when starting the MYSQL plugin.  Trying again in 5 seconds.
[2025-07-24T07:30:01.877] error: mysql_real_connect failed: 2002 Can't connect to server on 'sm01' (111)
[2025-07-24T07:30:01.877] error: The database must be up when starting the MYSQL plugin.  Trying again in 5 seconds.
[2025-07-24T07:30:02.176] error: mysql_real_connect failed: 2002 Can't connect to server on 'sm01' (111)
[2025-07-24T07:30:02.176] error: The database must be up when starting the MYSQL plugin.  Trying again in 5 seconds.
[2025-07-24T07:30:02.319] error: mysql_real_connect failed: 2002 Can't connect to server on 'sm01' (111)
[2025-07-24T07:30:02.319] error: The database must be up when starting the MYSQL plugin.  Trying again in 5 seconds.
[2025-07-24T07:30:06.878] error: mysql_real_connect failed: 2002 Can't connect to server on 'sm01' (111)
[2025-07-24T07:30:06.878] error: The database must be up when starting the MYSQL plugin.  Trying again in 5 seconds.
[2025-07-24T07:30:07.176] error: mysql_real_connect failed: 2002 Can't connect to server on 'sm01' (111)
[2025-07-24T07:30:07.176] error: The database must be up when starting the MYSQL plugin.  Trying again in 5 seconds.
[2025-07-24T07:30:07.320] error: mysql_real_connect failed: 2002 Can't connect to server on 'sm01' (111)
[2025-07-24T07:30:07.320] error: The database must be up when starting the MYSQL plugin.  Trying again in 5 seconds.

2025-07-24 04:34:20,336 p=68865 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:34:20,336 p=68865 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:34:20,738 p=68865 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-24 04:34:20,746 p=68865 u=master n=ansible | TASK [Gathering Facts] ****************************************************************************************************************************************************************
2025-07-24 04:34:20,746 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:20 +0000 (0:00:00.010)       0:00:00.010 ********* 
2025-07-24 04:34:22,187 p=68865 u=master n=ansible | ok: [sm01]
2025-07-24 04:34:22,194 p=68865 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-24 04:34:22,194 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:22 +0000 (0:00:01.448)       0:00:01.458 ********* 
2025-07-24 04:34:22,218 p=68865 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-24 04:34:22,222 p=68865 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-24 04:34:22,222 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:22 +0000 (0:00:00.027)       0:00:01.486 ********* 
2025-07-24 04:34:22,615 p=68865 u=master n=ansible | ok: [sm01]
2025-07-24 04:34:22,618 p=68865 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-24 04:34:22,618 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:22 +0000 (0:00:00.396)       0:00:01.882 ********* 
2025-07-24 04:34:22,668 p=68865 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-24 04:34:22,671 p=68865 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-24 04:34:22,671 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:22 +0000 (0:00:00.052)       0:00:01.935 ********* 
2025-07-24 04:34:22,704 p=68865 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-24 04:34:22,704 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:22 +0000 (0:00:00.032)       0:00:01.968 ********* 
2025-07-24 04:34:22,751 p=68865 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-24 04:34:22,755 p=68865 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-24 04:34:22,755 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:22 +0000 (0:00:00.050)       0:00:02.019 ********* 
2025-07-24 04:34:22,809 p=68865 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-24 04:34:22,815 p=68865 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-24 04:34:22,815 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:22 +0000 (0:00:00.059)       0:00:02.079 ********* 
2025-07-24 04:34:23,089 p=68865 u=master n=ansible | ok: [sm01]
2025-07-24 04:34:23,093 p=68865 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-24 04:34:23,093 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:23 +0000 (0:00:00.278)       0:00:02.357 ********* 
2025-07-24 04:34:23,146 p=68865 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-24 04:34:23,150 p=68865 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-24 04:34:23,150 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:23 +0000 (0:00:00.056)       0:00:02.414 ********* 
2025-07-24 04:34:23,544 p=68865 u=master n=ansible | changed: [sm01]
2025-07-24 04:34:23,547 p=68865 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-24 04:34:23,548 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:23 +0000 (0:00:00.397)       0:00:02.811 ********* 
2025-07-24 04:34:23,602 p=68865 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-24 04:34:23,606 p=68865 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-24 04:34:23,607 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:23 +0000 (0:00:00.058)       0:00:02.870 ********* 
2025-07-24 04:34:23,905 p=68865 u=master n=ansible | ok: [sm01]
2025-07-24 04:34:23,909 p=68865 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-24 04:34:23,909 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:23 +0000 (0:00:00.302)       0:00:03.173 ********* 
2025-07-24 04:34:24,208 p=68865 u=master n=ansible | ok: [sm01]
2025-07-24 04:34:24,211 p=68865 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-24 04:34:24,212 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:24 +0000 (0:00:00.302)       0:00:03.475 ********* 
2025-07-24 04:34:24,263 p=68865 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-24 04:34:24,267 p=68865 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-24 04:34:24,267 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:24 +0000 (0:00:00.055)       0:00:03.531 ********* 
2025-07-24 04:34:24,292 p=68865 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-24 04:34:24,301 p=68865 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-24 04:34:24,301 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:24 +0000 (0:00:00.034)       0:00:03.565 ********* 
2025-07-24 04:34:25,253 p=68865 u=master n=ansible | changed: [sm01]
2025-07-24 04:34:25,257 p=68865 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание конфига slurmdbd.conf] *************************************************************************************************************************
2025-07-24 04:34:25,258 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:25 +0000 (0:00:00.956)       0:00:04.521 ********* 
2025-07-24 04:34:25,886 p=68865 u=master n=ansible | changed: [sm01]
2025-07-24 04:34:25,890 p=68865 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание gres.conf для GPU] *****************************************************************************************************************************
2025-07-24 04:34:25,890 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:25 +0000 (0:00:00.632)       0:00:05.154 ********* 
2025-07-24 04:34:26,531 p=68865 u=master n=ansible | changed: [sm01]
2025-07-24 04:34:26,535 p=68865 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание cgroup.conf] ***********************************************************************************************************************************
2025-07-24 04:34:26,535 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:26 +0000 (0:00:00.644)       0:00:05.799 ********* 
2025-07-24 04:34:27,203 p=68865 u=master n=ansible | changed: [sm01]
2025-07-24 04:34:27,208 p=68865 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание директории для конфигов на NFS] ****************************************************************************************************************
2025-07-24 04:34:27,208 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:27 +0000 (0:00:00.673)       0:00:06.472 ********* 
2025-07-24 04:34:27,609 p=68865 u=master n=ansible | ok: [sm01]
2025-07-24 04:34:27,613 p=68865 u=master n=ansible | TASK [slurm_master : [CONFIG] Копирование конфигов на NFS для распространения] ********************************************************************************************************
2025-07-24 04:34:27,614 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:27 +0000 (0:00:00.405)       0:00:06.877 ********* 
2025-07-24 04:34:27,912 p=68865 u=master n=ansible | changed: [sm01] => (item=slurm.conf)
2025-07-24 04:34:28,198 p=68865 u=master n=ansible | changed: [sm01] => (item=cgroup.conf)
2025-07-24 04:34:28,478 p=68865 u=master n=ansible | changed: [sm01] => (item=gres.conf)
2025-07-24 04:34:28,483 p=68865 u=master n=ansible | TASK [slurm_master : [CONFIG] Конфигурация создана] ***********************************************************************************************************************************
2025-07-24 04:34:28,483 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:28 +0000 (0:00:00.869)       0:00:07.747 ********* 
2025-07-24 04:34:28,504 p=68865 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Конфигурация Slurm:\n✅ slurm.conf создан\n✅ gres.conf создан (AutoDetect=nvml)\n✅ cgroup.conf создан\n✅ slurmdbd.conf создан\n\U0001F4E4 Файлы скопированы в /sw/config/ для распространения"
2025-07-24 04:34:28,508 p=68865 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка systemd сервисов] ***********************************************************************************************************************
2025-07-24 04:34:28,508 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:28 +0000 (0:00:00.025)       0:00:07.772 ********* 
2025-07-24 04:34:28,531 p=68865 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/services.yml for sm01
2025-07-24 04:34:28,543 p=68865 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmctld] ******************************************************************************************************************
2025-07-24 04:34:28,543 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:28 +0000 (0:00:00.034)       0:00:07.807 ********* 
2025-07-24 04:34:29,124 p=68865 u=master n=ansible | changed: [sm01]
2025-07-24 04:34:29,128 p=68865 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmdbd] *******************************************************************************************************************
2025-07-24 04:34:29,128 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:29 +0000 (0:00:00.585)       0:00:08.392 ********* 
2025-07-24 04:34:29,736 p=68865 u=master n=ansible | changed: [sm01]
2025-07-24 04:34:29,740 p=68865 u=master n=ansible | TASK [slurm_master : [SERVICES] Перезагрузка systemd daemon] **************************************************************************************************************************
2025-07-24 04:34:29,740 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:29 +0000 (0:00:00.611)       0:00:09.004 ********* 
2025-07-24 04:34:30,779 p=68865 u=master n=ansible | ok: [sm01]
2025-07-24 04:34:30,783 p=68865 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmdbd (сначала база)] ***********************************************************************************************************************
2025-07-24 04:34:30,783 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:30 +0000 (0:00:01.043)       0:00:10.047 ********* 
2025-07-24 04:34:31,308 p=68865 u=master n=ansible | changed: [sm01]
2025-07-24 04:34:31,313 p=68865 u=master n=ansible | TASK [slurm_master : [SERVICES] Пауза после запуска slurmdbd] *************************************************************************************************************************
2025-07-24 04:34:31,313 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:31 +0000 (0:00:00.530)       0:00:10.577 ********* 
2025-07-24 04:34:31,360 p=68865 u=master n=ansible | Pausing for 3 seconds
2025-07-24 04:34:31,361 p=68865 u=master n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-24 04:34:34,365 p=68865 u=master n=ansible | ok: [sm01]
2025-07-24 04:34:34,369 p=68865 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmctld (после базы)] ************************************************************************************************************************
2025-07-24 04:34:34,369 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:34 +0000 (0:00:03.055)       0:00:13.633 ********* 
2025-07-24 04:34:35,343 p=68865 u=master n=ansible | changed: [sm01]
2025-07-24 04:34:35,347 p=68865 u=master n=ansible | TASK [slurm_master : [SERVICES] Сервисы запущены] *************************************************************************************************************************************
2025-07-24 04:34:35,347 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:35 +0000 (0:00:00.978)       0:00:14.611 ********* 
2025-07-24 04:34:35,368 p=68865 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F39B️ Slurm сервисы:\n✅ slurmdbd запущен\n✅ slurmctld запущен\n\U0001F527 Проверьте: systemctl status slurmctld slurmdbd"
2025-07-24 04:34:35,371 p=68865 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Завершение настройки] *****************************************************************************************************************************
2025-07-24 04:34:35,371 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:35 +0000 (0:00:00.024)       0:00:14.635 ********* 
2025-07-24 04:34:35,425 p=68865 u=master n=ansible | ok: [sm01] => 
  msg: "✅ Slurm Master настроен!\n\U0001F527 Кластер: hpc-cluster\n\U0001F39B️ Controller: sm01:6817\n\U0001F4BE Database: включена"
2025-07-24 04:34:35,430 p=68865 u=master n=ansible | TASK [[TEST] Проверка созданных файлов] ***********************************************************************************************************************************************
2025-07-24 04:34:35,430 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:35 +0000 (0:00:00.059)       0:00:14.694 ********* 
2025-07-24 04:34:35,703 p=68865 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurm.conf)
2025-07-24 04:34:35,951 p=68865 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurmdbd.conf)
2025-07-24 04:34:36,200 p=68865 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/gres.conf)
2025-07-24 04:34:36,452 p=68865 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmctld.service)
2025-07-24 04:34:36,752 p=68865 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmdbd.service)
2025-07-24 04:34:36,759 p=68865 u=master n=ansible | TASK [[TEST] Результаты проверки файлов] **********************************************************************************************************************************************
2025-07-24 04:34:36,759 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:36 +0000 (0:00:01.328)       0:00:16.023 ********* 
2025-07-24 04:34:36,821 p=68865 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurm.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 5873, 'inode': 1835037, 'dev': 2050, 'nlink': 1, 'atime': 1753331667.876395, 'mtime': 1753331664.8334444, 'ctime': 1753331665.2114382, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 16, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '1f0876b813cccfedd27ffcf08baac3e0143db670', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '3911866346', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurm.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurm.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurm.conf: ✅ создан"
2025-07-24 04:34:36,825 p=68865 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurmdbd.conf', 'mode': '0600', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2313, 'inode': 1835036, 'dev': 2050, 'nlink': 1, 'atime': 1753331671.2723396, 'mtime': 1753331665.6084318, 'ctime': 1753331665.846428, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': False, 'xgrp': False, 'woth': False, 'roth': False, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '3e7539ff84481d1c96a9fac0fe09ead3ad6fe909', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '1709022112', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurmdbd.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurmdbd.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurmdbd.conf: ✅ создан"
2025-07-24 04:34:36,831 p=68865 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/gres.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2225, 'inode': 1835031, 'dev': 2050, 'nlink': 1, 'atime': 1753331668.4423857, 'mtime': 1753331666.2524214, 'ctime': 1753331666.4904175, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '9c4de4a563fafe257ea173d75e4b265f37f70c7e', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '1956799153', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/gres.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/gres.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/gres.conf: ✅ создан"
2025-07-24 04:34:36,837 p=68865 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmctld.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 587, 'inode': 1835033, 'dev': 2050, 'nlink': 1, 'atime': 1753331674.9132805, 'mtime': 1753331668.8643787, 'ctime': 1753331669.0903752, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': '46eb21197027702db250059307749d445a8cbfc1', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '968271735', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmctld.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmctld.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmctld.service: ✅ создан"
2025-07-24 04:34:36,845 p=68865 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmdbd.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 576, 'inode': 1835034, 'dev': 2050, 'nlink': 1, 'atime': 1753331670.5493515, 'mtime': 1753331669.466369, 'ctime': 1753331669.6973653, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': '42a33bfff18cc793b0f69e7e066f6cf8944622b0', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '1016490732', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmdbd.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmdbd.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmdbd.service: ✅ создан"
2025-07-24 04:34:36,854 p=68865 u=master n=ansible | TASK [[TEST] Проверка сервисов] *******************************************************************************************************************************************************
2025-07-24 04:34:36,855 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:36 +0000 (0:00:00.095)       0:00:16.119 ********* 
2025-07-24 04:34:37,304 p=68865 u=master n=ansible | ok: [sm01] => (item=slurmdbd)
2025-07-24 04:34:37,852 p=68865 u=master n=ansible | ok: [sm01] => (item=slurmctld)
2025-07-24 04:34:37,860 p=68865 u=master n=ansible | TASK [[TEST] Статус сервисов] *********************************************************************************************************************************************************
2025-07-24 04:34:37,860 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:37 +0000 (0:00:01.005)       0:00:17.124 ********* 
2025-07-24 04:34:37,941 p=68865 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmdbd', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '92057', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '1001', 'GID': '988', 'NRestarts': '0', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 07:34:31 MSK', 'ExecMainStartTimestampMonotonic': '72902283067', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '92057', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmdbd.service', 'ControlGroupId': '186372', 'MemoryCurrent': '6541312', 'MemoryPeak': '6549504', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11488833536', 'CPUUsageNSec': '11134000', 'TasksCurrent': '36', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmdbd.service', 'Names': 'slurmdbd.service', 'Requires': '-.mount system.slice sysinit.target', 'Wants': 'tmp.mount munge.service mariadb.service', 'WantedBy': 'multi-user.target slurmctld.service', 'Conflicts': 'shutdown.target', 'Before': 'multi-user.target shutdown.target slurmctld.service', 'After': '-.mount munge.service tmp.mount network.target systemd-tmpfiles-setup.service sysinit.target system.slice systemd-journald.socket basic.target mariadb.service', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm DBD accounting daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmdbd.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 07:34:31 MSK', 'StateChangeTimestampMonotonic': '72902283284', 'InactiveExitTimestamp': 'Thu 2025-07-24 07:34:31 MSK', 'InactiveExitTimestampMonotonic': '72902283284', 'ActiveEnterTimestamp': 'Thu 2025-07-24 07:34:31 MSK', 'ActiveEnterTimestampMonotonic': '72902283284', 'ActiveExitTimestamp': 'Thu 2025-07-24 07:22:52 MSK', 'ActiveExitTimestampMonotonic': '72203109935', 'InactiveEnterTimestamp': 'Thu 2025-07-24 07:22:52 MSK', 'InactiveEnterTimestampMonotonic': '72203109935', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 07:34:31 MSK', 'ConditionTimestampMonotonic': '72902270496', 'AssertTimestamp': 'Thu 2025-07-24 07:34:31 MSK', 'AssertTimestampMonotonic': '72902270503', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': 'b71d0729e62144b7a622ea3b268547d3', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmdbd', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmdbd', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmdbd: active"
2025-07-24 04:34:37,953 p=68865 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmctld', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '0', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'exit-code', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '[not set]', 'GID': '[not set]', 'NRestarts': '0', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 07:34:35 MSK', 'ExecMainStartTimestampMonotonic': '72906320072', 'ExecMainExitTimestamp': 'Thu 2025-07-24 07:34:35 MSK', 'ExecMainExitTimestampMonotonic': '72906327786', 'ExecMainPID': '92387', 'ExecMainCode': '1', 'ExecMainStatus': '1', 'ExecStart': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D ; ignore_errors=no ; start_time=[Thu 2025-07-24 07:34:35 MSK] ; stop_time=[Thu 2025-07-24 07:34:35 MSK] ; pid=92387 ; code=exited ; status=1 }', 'ExecStartEx': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D ; flags= ; start_time=[Thu 2025-07-24 07:34:35 MSK] ; stop_time=[Thu 2025-07-24 07:34:35 MSK] ; pid=92387 ; code=exited ; status=1 }', 'Slice': 'system.slice', 'ControlGroupId': '186771', 'MemoryCurrent': '[not set]', 'MemoryPeak': '[not set]', 'MemorySwapCurrent': '[not set]', 'MemorySwapPeak': '[not set]', 'MemoryZSwapCurrent': '[not set]', 'MemoryAvailable': '11488800768', 'CPUUsageNSec': '6173000', 'TasksCurrent': '[not set]', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmctld.service', 'Names': 'slurmctld.service', 'Requires': 'sysinit.target system.slice -.mount', 'Wants': 'tmp.mount munge.service slurmdbd.service', 'WantedBy': 'multi-user.target', 'Conflicts': 'shutdown.target', 'Before': 'multi-user.target shutdown.target', 'After': 'basic.target -.mount slurmdbd.service systemd-tmpfiles-setup.service tmp.mount network.target systemd-journald.socket system.slice munge.service sysinit.target', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm controller daemon', 'LoadState': 'loaded', 'ActiveState': 'activating', 'FreezerState': 'running', 'SubState': 'auto-restart', 'FragmentPath': '/etc/systemd/system/slurmctld.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 07:34:35 MSK', 'StateChangeTimestampMonotonic': '72906328350', 'InactiveExitTimestamp': 'Thu 2025-07-24 07:34:35 MSK', 'InactiveExitTimestampMonotonic': '72906328350', 'ActiveEnterTimestamp': 'Thu 2025-07-24 07:34:35 MSK', 'ActiveEnterTimestampMonotonic': '72906320285', 'ActiveExitTimestamp': 'Thu 2025-07-24 07:34:35 MSK', 'ActiveExitTimestampMonotonic': '72906328063', 'InactiveEnterTimestamp': 'Thu 2025-07-24 07:34:35 MSK', 'InactiveEnterTimestampMonotonic': '72906328063', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 07:34:35 MSK', 'ConditionTimestampMonotonic': '72906308246', 'AssertTimestamp': 'Thu 2025-07-24 07:34:35 MSK', 'AssertTimestampMonotonic': '72906308253', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': 'cc81b002e51a4f148d0d7fe350b16e3f', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmctld', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmctld', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmctld: activating"
2025-07-24 04:34:37,963 p=68865 u=master n=ansible | TASK [[TEST] Тестовая команда scontrol] ***********************************************************************************************************************************************
2025-07-24 04:34:37,964 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:37 +0000 (0:00:00.103)       0:00:17.227 ********* 
2025-07-24 04:34:38,226 p=68865 u=master n=ansible | ok: [sm01]
2025-07-24 04:34:38,230 p=68865 u=master n=ansible | TASK [[TEST] Результат scontrol ping] *************************************************************************************************************************************************
2025-07-24 04:34:38,230 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:38 +0000 (0:00:00.266)       0:00:17.494 ********* 
2025-07-24 04:34:38,255 p=68865 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 scontrol ping:\n❌ ОШИБКА:"
2025-07-24 04:34:38,263 p=68865 u=master n=ansible | RUNNING HANDLER [slurm_master : restart slurmctld] ************************************************************************************************************************************
2025-07-24 04:34:38,263 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:38 +0000 (0:00:00.033)       0:00:17.527 ********* 
2025-07-24 04:34:39,094 p=68865 u=master n=ansible | changed: [sm01]
2025-07-24 04:34:39,098 p=68865 u=master n=ansible | RUNNING HANDLER [slurm_master : restart slurmdbd] *************************************************************************************************************************************
2025-07-24 04:34:39,098 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:39 +0000 (0:00:00.835)       0:00:18.362 ********* 
2025-07-24 04:34:40,035 p=68865 u=master n=ansible | changed: [sm01]
2025-07-24 04:34:40,042 p=68865 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-24 04:34:40,042 p=68865 u=master n=ansible | sm01                       : ok=38   changed=12   unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-24 04:34:40,043 p=68865 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 19 seconds
2025-07-24 04:34:40,043 p=68865 u=master n=ansible | Thursday 24 July 2025  04:34:40 +0000 (0:00:00.944)       0:00:19.307 ********* 
2025-07-24 04:34:40,043 p=68865 u=master n=ansible | =============================================================================== 
2025-07-24 04:34:40,043 p=68865 u=master n=ansible | slurm_master : [SERVICES] Пауза после запуска slurmdbd ------------------------------------------------------------------------------------------------------------------------- 3.06s
2025-07-24 04:34:40,043 p=68865 u=master n=ansible | Gathering Facts ---------------------------------------------------------------------------------------------------------------------------------------------------------------- 1.45s
2025-07-24 04:34:40,043 p=68865 u=master n=ansible | [TEST] Проверка созданных файлов ----------------------------------------------------------------------------------------------------------------------------------------------- 1.33s
2025-07-24 04:34:40,043 p=68865 u=master n=ansible | slurm_master : [SERVICES] Перезагрузка systemd daemon -------------------------------------------------------------------------------------------------------------------------- 1.04s
2025-07-24 04:34:40,044 p=68865 u=master n=ansible | [TEST] Проверка сервисов ------------------------------------------------------------------------------------------------------------------------------------------------------- 1.01s
2025-07-24 04:34:40,044 p=68865 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmctld (после базы) ------------------------------------------------------------------------------------------------------------------------ 0.98s
2025-07-24 04:34:40,044 p=68865 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.96s
2025-07-24 04:34:40,044 p=68865 u=master n=ansible | slurm_master : restart slurmdbd ------------------------------------------------------------------------------------------------------------------------------------------------ 0.94s
2025-07-24 04:34:40,044 p=68865 u=master n=ansible | slurm_master : [CONFIG] Копирование конфигов на NFS для распространения -------------------------------------------------------------------------------------------------------- 0.87s
2025-07-24 04:34:40,044 p=68865 u=master n=ansible | slurm_master : restart slurmctld ----------------------------------------------------------------------------------------------------------------------------------------------- 0.84s
2025-07-24 04:34:40,044 p=68865 u=master n=ansible | slurm_master : [CONFIG] Создание cgroup.conf ----------------------------------------------------------------------------------------------------------------------------------- 0.67s
2025-07-24 04:34:40,044 p=68865 u=master n=ansible | slurm_master : [CONFIG] Создание gres.conf для GPU ----------------------------------------------------------------------------------------------------------------------------- 0.64s
2025-07-24 04:34:40,044 p=68865 u=master n=ansible | slurm_master : [CONFIG] Создание конфига slurmdbd.conf ------------------------------------------------------------------------------------------------------------------------- 0.63s
2025-07-24 04:34:40,044 p=68865 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmdbd ------------------------------------------------------------------------------------------------------------------- 0.61s
2025-07-24 04:34:40,044 p=68865 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmctld ------------------------------------------------------------------------------------------------------------------ 0.59s
2025-07-24 04:34:40,045 p=68865 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmdbd (сначала база) ----------------------------------------------------------------------------------------------------------------------- 0.53s
2025-07-24 04:34:40,045 p=68865 u=master n=ansible | slurm_master : [CONFIG] Создание директории для конфигов на NFS ---------------------------------------------------------------------------------------------------------------- 0.41s
2025-07-24 04:34:40,045 p=68865 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.40s
2025-07-24 04:34:40,045 p=68865 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 0.40s
2025-07-24 04:34:40,045 p=68865 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-24 04:41:20,513 p=69136 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:41:20,513 p=69136 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:41:20,911 p=69136 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-24 04:41:20,925 p=69136 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-24 04:41:20,925 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:20 +0000 (0:00:00.016)       0:00:00.016 ********* 
2025-07-24 04:41:20,948 p=69136 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-24 04:41:20,951 p=69136 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-24 04:41:20,952 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:20 +0000 (0:00:00.026)       0:00:00.042 ********* 
2025-07-24 04:41:22,051 p=69136 u=master n=ansible | ok: [sm01]
2025-07-24 04:41:22,055 p=69136 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-24 04:41:22,055 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:22 +0000 (0:00:01.103)       0:00:01.145 ********* 
2025-07-24 04:41:22,102 p=69136 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-24 04:41:22,105 p=69136 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-24 04:41:22,105 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:22 +0000 (0:00:00.050)       0:00:01.195 ********* 
2025-07-24 04:41:22,137 p=69136 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-24 04:41:22,138 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:22 +0000 (0:00:00.032)       0:00:01.228 ********* 
2025-07-24 04:41:22,188 p=69136 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-24 04:41:22,192 p=69136 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-24 04:41:22,192 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:22 +0000 (0:00:00.054)       0:00:01.283 ********* 
2025-07-24 04:41:22,246 p=69136 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-24 04:41:22,254 p=69136 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-24 04:41:22,254 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:22 +0000 (0:00:00.061)       0:00:01.345 ********* 
2025-07-24 04:41:22,528 p=69136 u=master n=ansible | ok: [sm01]
2025-07-24 04:41:22,532 p=69136 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-24 04:41:22,532 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:22 +0000 (0:00:00.278)       0:00:01.623 ********* 
2025-07-24 04:41:22,580 p=69136 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-24 04:41:22,584 p=69136 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-24 04:41:22,584 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:22 +0000 (0:00:00.051)       0:00:01.674 ********* 
2025-07-24 04:41:22,979 p=69136 u=master n=ansible | changed: [sm01]
2025-07-24 04:41:22,983 p=69136 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-24 04:41:22,983 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:22 +0000 (0:00:00.398)       0:00:02.073 ********* 
2025-07-24 04:41:23,030 p=69136 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-24 04:41:23,034 p=69136 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-24 04:41:23,034 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:23 +0000 (0:00:00.051)       0:00:02.124 ********* 
2025-07-24 04:41:23,332 p=69136 u=master n=ansible | ok: [sm01]
2025-07-24 04:41:23,336 p=69136 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-24 04:41:23,337 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:23 +0000 (0:00:00.302)       0:00:02.427 ********* 
2025-07-24 04:41:23,633 p=69136 u=master n=ansible | ok: [sm01]
2025-07-24 04:41:23,637 p=69136 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-24 04:41:23,638 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:23 +0000 (0:00:00.300)       0:00:02.728 ********* 
2025-07-24 04:41:23,688 p=69136 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-24 04:41:23,692 p=69136 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-24 04:41:23,692 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:23 +0000 (0:00:00.054)       0:00:02.783 ********* 
2025-07-24 04:41:23,713 p=69136 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-24 04:41:23,722 p=69136 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-24 04:41:23,722 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:23 +0000 (0:00:00.030)       0:00:02.813 ********* 
2025-07-24 04:41:24,607 p=69136 u=master n=ansible | ok: [sm01]
2025-07-24 04:41:24,612 p=69136 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание конфига slurmdbd.conf] *************************************************************************************************************************
2025-07-24 04:41:24,612 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:24 +0000 (0:00:00.889)       0:00:03.702 ********* 
2025-07-24 04:41:25,374 p=69136 u=master n=ansible | changed: [sm01]
2025-07-24 04:41:25,378 p=69136 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание gres.conf для GPU] *****************************************************************************************************************************
2025-07-24 04:41:25,378 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:25 +0000 (0:00:00.766)       0:00:04.469 ********* 
2025-07-24 04:41:25,982 p=69136 u=master n=ansible | ok: [sm01]
2025-07-24 04:41:25,986 p=69136 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание cgroup.conf] ***********************************************************************************************************************************
2025-07-24 04:41:25,986 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:25 +0000 (0:00:00.607)       0:00:05.076 ********* 
2025-07-24 04:41:26,577 p=69136 u=master n=ansible | ok: [sm01]
2025-07-24 04:41:26,582 p=69136 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание директории для конфигов на NFS] ****************************************************************************************************************
2025-07-24 04:41:26,582 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:26 +0000 (0:00:00.595)       0:00:05.672 ********* 
2025-07-24 04:41:26,842 p=69136 u=master n=ansible | ok: [sm01]
2025-07-24 04:41:26,847 p=69136 u=master n=ansible | TASK [slurm_master : [CONFIG] Копирование конфигов на NFS для распространения] ********************************************************************************************************
2025-07-24 04:41:26,847 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:26 +0000 (0:00:00.265)       0:00:05.937 ********* 
2025-07-24 04:41:27,150 p=69136 u=master n=ansible | ok: [sm01] => (item=slurm.conf)
2025-07-24 04:41:27,431 p=69136 u=master n=ansible | ok: [sm01] => (item=cgroup.conf)
2025-07-24 04:41:27,722 p=69136 u=master n=ansible | ok: [sm01] => (item=gres.conf)
2025-07-24 04:41:27,728 p=69136 u=master n=ansible | TASK [slurm_master : [CONFIG] Конфигурация создана] ***********************************************************************************************************************************
2025-07-24 04:41:27,728 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:27 +0000 (0:00:00.881)       0:00:06.819 ********* 
2025-07-24 04:41:27,747 p=69136 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Конфигурация Slurm:\n✅ slurm.conf создан\n✅ gres.conf создан (AutoDetect=nvml)\n✅ cgroup.conf создан\n✅ slurmdbd.conf создан\n\U0001F4E4 Файлы скопированы в /sw/config/ для распространения"
2025-07-24 04:41:27,750 p=69136 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка systemd сервисов] ***********************************************************************************************************************
2025-07-24 04:41:27,751 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:27 +0000 (0:00:00.022)       0:00:06.841 ********* 
2025-07-24 04:41:27,775 p=69136 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/services.yml for sm01
2025-07-24 04:41:27,789 p=69136 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmctld] ******************************************************************************************************************
2025-07-24 04:41:27,790 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:27 +0000 (0:00:00.038)       0:00:06.880 ********* 
2025-07-24 04:41:28,364 p=69136 u=master n=ansible | ok: [sm01]
2025-07-24 04:41:28,368 p=69136 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmdbd] *******************************************************************************************************************
2025-07-24 04:41:28,368 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:28 +0000 (0:00:00.578)       0:00:07.459 ********* 
2025-07-24 04:41:28,953 p=69136 u=master n=ansible | ok: [sm01]
2025-07-24 04:41:28,957 p=69136 u=master n=ansible | TASK [slurm_master : [SERVICES] Перезагрузка systemd daemon] **************************************************************************************************************************
2025-07-24 04:41:28,957 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:28 +0000 (0:00:00.588)       0:00:08.047 ********* 
2025-07-24 04:41:30,046 p=69136 u=master n=ansible | ok: [sm01]
2025-07-24 04:41:30,050 p=69136 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmdbd (сначала база)] ***********************************************************************************************************************
2025-07-24 04:41:30,051 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:30 +0000 (0:00:01.093)       0:00:09.141 ********* 
2025-07-24 04:41:30,550 p=69136 u=master n=ansible | ok: [sm01]
2025-07-24 04:41:30,555 p=69136 u=master n=ansible | TASK [slurm_master : [SERVICES] Пауза после запуска slurmdbd] *************************************************************************************************************************
2025-07-24 04:41:30,555 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:30 +0000 (0:00:00.504)       0:00:09.645 ********* 
2025-07-24 04:41:30,601 p=69136 u=master n=ansible | Pausing for 3 seconds
2025-07-24 04:41:30,602 p=69136 u=master n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-24 04:41:33,606 p=69136 u=master n=ansible | ok: [sm01]
2025-07-24 04:41:33,611 p=69136 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmctld (после базы)] ************************************************************************************************************************
2025-07-24 04:41:33,611 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:33 +0000 (0:00:03.056)       0:00:12.701 ********* 
2025-07-24 04:41:34,096 p=69136 u=master n=ansible | ok: [sm01]
2025-07-24 04:41:34,101 p=69136 u=master n=ansible | TASK [slurm_master : [SERVICES] Сервисы запущены] *************************************************************************************************************************************
2025-07-24 04:41:34,101 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:34 +0000 (0:00:00.489)       0:00:13.191 ********* 
2025-07-24 04:41:34,120 p=69136 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F39B️ Slurm сервисы:\n✅ slurmdbd запущен\n✅ slurmctld запущен\n\U0001F527 Проверьте: systemctl status slurmctld slurmdbd"
2025-07-24 04:41:34,123 p=69136 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Завершение настройки] *****************************************************************************************************************************
2025-07-24 04:41:34,124 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:34 +0000 (0:00:00.022)       0:00:13.214 ********* 
2025-07-24 04:41:34,172 p=69136 u=master n=ansible | ok: [sm01] => 
  msg: "✅ Slurm Master настроен!\n\U0001F527 Кластер: hpc-cluster\n\U0001F39B️ Controller: sm01:6817\n\U0001F4BE Database: включена"
2025-07-24 04:41:34,178 p=69136 u=master n=ansible | TASK [[TEST] Проверка созданных файлов] ***********************************************************************************************************************************************
2025-07-24 04:41:34,178 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:34 +0000 (0:00:00.054)       0:00:13.268 ********* 
2025-07-24 04:41:34,458 p=69136 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurm.conf)
2025-07-24 04:41:34,708 p=69136 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurmdbd.conf)
2025-07-24 04:41:34,959 p=69136 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/gres.conf)
2025-07-24 04:41:35,213 p=69136 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmctld.service)
2025-07-24 04:41:35,467 p=69136 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmdbd.service)
2025-07-24 04:41:35,474 p=69136 u=master n=ansible | TASK [[TEST] Результаты проверки файлов] **********************************************************************************************************************************************
2025-07-24 04:41:35,474 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:35 +0000 (0:00:01.295)       0:00:14.564 ********* 
2025-07-24 04:41:35,535 p=69136 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurm.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 5873, 'inode': 1835037, 'dev': 2050, 'nlink': 1, 'atime': 1753331667.876395, 'mtime': 1753331664.8334444, 'ctime': 1753331665.2114382, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 16, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '1f0876b813cccfedd27ffcf08baac3e0143db670', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '3911866346', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurm.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurm.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurm.conf: ✅ создан"
2025-07-24 04:41:35,541 p=69136 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurmdbd.conf', 'mode': '0600', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2318, 'inode': 1835035, 'dev': 2050, 'nlink': 1, 'atime': 1753332085.3245773, 'mtime': 1753332084.9605834, 'ctime': 1753332085.3325772, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': False, 'xgrp': False, 'woth': False, 'roth': False, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '379c00da27c17c640f268d909eb3fcca82934d56', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '3854950354', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurmdbd.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurmdbd.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurmdbd.conf: ✅ создан"
2025-07-24 04:41:35,546 p=69136 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/gres.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2225, 'inode': 1835031, 'dev': 2050, 'nlink': 1, 'atime': 1753331668.4423857, 'mtime': 1753331666.2524214, 'ctime': 1753331666.4904175, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '9c4de4a563fafe257ea173d75e4b265f37f70c7e', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '1956799153', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/gres.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/gres.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/gres.conf: ✅ создан"
2025-07-24 04:41:35,553 p=69136 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmctld.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 587, 'inode': 1835033, 'dev': 2050, 'nlink': 1, 'atime': 1753331674.9132805, 'mtime': 1753331668.8643787, 'ctime': 1753331669.0903752, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': '46eb21197027702db250059307749d445a8cbfc1', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '968271735', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmctld.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmctld.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmctld.service: ✅ создан"
2025-07-24 04:41:35,559 p=69136 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmdbd.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 576, 'inode': 1835034, 'dev': 2050, 'nlink': 1, 'atime': 1753331670.5493515, 'mtime': 1753331669.466369, 'ctime': 1753331669.6973653, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': '42a33bfff18cc793b0f69e7e066f6cf8944622b0', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '1016490732', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmdbd.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmdbd.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmdbd.service: ✅ создан"
2025-07-24 04:41:35,566 p=69136 u=master n=ansible | TASK [[TEST] Проверка сервисов] *******************************************************************************************************************************************************
2025-07-24 04:41:35,566 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:35 +0000 (0:00:00.092)       0:00:14.657 ********* 
2025-07-24 04:41:36,030 p=69136 u=master n=ansible | ok: [sm01] => (item=slurmdbd)
2025-07-24 04:41:36,456 p=69136 u=master n=ansible | ok: [sm01] => (item=slurmctld)
2025-07-24 04:41:36,464 p=69136 u=master n=ansible | TASK [[TEST] Статус сервисов] *********************************************************************************************************************************************************
2025-07-24 04:41:36,464 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:36 +0000 (0:00:00.897)       0:00:15.554 ********* 
2025-07-24 04:41:36,539 p=69136 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmdbd', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '92576', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '1001', 'GID': '988', 'NRestarts': '0', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 07:34:39 MSK', 'ExecMainStartTimestampMonotonic': '72911013078', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '92576', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmdbd.service', 'ControlGroupId': '186372', 'MemoryCurrent': '6352896', 'MemoryPeak': '6877184', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11589050368', 'CPUUsageNSec': '217266000', 'TasksCurrent': '36', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmdbd.service', 'Names': 'slurmdbd.service', 'Requires': 'system.slice -.mount sysinit.target', 'Wants': 'mariadb.service tmp.mount munge.service', 'WantedBy': 'multi-user.target slurmctld.service', 'Conflicts': 'shutdown.target', 'Before': 'shutdown.target slurmctld.service multi-user.target', 'After': 'munge.service systemd-journald.socket sysinit.target -.mount mariadb.service tmp.mount systemd-tmpfiles-setup.service basic.target system.slice network.target', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm DBD accounting daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmdbd.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 07:34:39 MSK', 'StateChangeTimestampMonotonic': '72911013387', 'InactiveExitTimestamp': 'Thu 2025-07-24 07:34:39 MSK', 'InactiveExitTimestampMonotonic': '72911013387', 'ActiveEnterTimestamp': 'Thu 2025-07-24 07:34:39 MSK', 'ActiveEnterTimestampMonotonic': '72911013387', 'ActiveExitTimestamp': 'Thu 2025-07-24 07:34:39 MSK', 'ActiveExitTimestampMonotonic': '72910912464', 'InactiveEnterTimestamp': 'Thu 2025-07-24 07:34:39 MSK', 'InactiveEnterTimestampMonotonic': '72910913306', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 07:34:39 MSK', 'ConditionTimestampMonotonic': '72910915263', 'AssertTimestamp': 'Thu 2025-07-24 07:34:39 MSK', 'AssertTimestampMonotonic': '72910915289', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': 'c81ce828ef84491d8f54fbb4c6e43718', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmdbd', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmdbd', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmdbd: active"
2025-07-24 04:41:36,550 p=69136 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmctld', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '0', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'exit-code', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '[not set]', 'GID': '[not set]', 'NRestarts': '79', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 07:41:33 MSK', 'ExecMainStartTimestampMonotonic': '73324219177', 'ExecMainExitTimestamp': 'Thu 2025-07-24 07:41:33 MSK', 'ExecMainExitTimestampMonotonic': '73324227850', 'ExecMainPID': '93412', 'ExecMainCode': '1', 'ExecMainStatus': '1', 'ExecStart': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D ; ignore_errors=no ; start_time=[Thu 2025-07-24 07:41:33 MSK] ; stop_time=[Thu 2025-07-24 07:41:33 MSK] ; pid=93412 ; code=exited ; status=1 }', 'ExecStartEx': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D ; flags= ; start_time=[Thu 2025-07-24 07:41:33 MSK] ; stop_time=[Thu 2025-07-24 07:41:33 MSK] ; pid=93412 ; code=exited ; status=1 }', 'Slice': 'system.slice', 'ControlGroupId': '190222', 'MemoryCurrent': '[not set]', 'MemoryPeak': '[not set]', 'MemorySwapCurrent': '[not set]', 'MemorySwapPeak': '[not set]', 'MemoryZSwapCurrent': '[not set]', 'MemoryAvailable': '11603251200', 'CPUUsageNSec': '7013000', 'TasksCurrent': '[not set]', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmctld.service', 'Names': 'slurmctld.service', 'Requires': 'sysinit.target -.mount system.slice', 'Wants': 'munge.service slurmdbd.service tmp.mount', 'WantedBy': 'multi-user.target', 'Conflicts': 'shutdown.target', 'Before': 'multi-user.target shutdown.target', 'After': 'basic.target -.mount network.target systemd-tmpfiles-setup.service systemd-journald.socket slurmdbd.service system.slice sysinit.target munge.service tmp.mount', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm controller daemon', 'LoadState': 'loaded', 'ActiveState': 'activating', 'FreezerState': 'running', 'SubState': 'auto-restart', 'FragmentPath': '/etc/systemd/system/slurmctld.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 07:41:33 MSK', 'StateChangeTimestampMonotonic': '73324228486', 'InactiveExitTimestamp': 'Thu 2025-07-24 07:41:33 MSK', 'InactiveExitTimestampMonotonic': '73324228486', 'ActiveEnterTimestamp': 'Thu 2025-07-24 07:41:33 MSK', 'ActiveEnterTimestampMonotonic': '73324219457', 'ActiveExitTimestamp': 'Thu 2025-07-24 07:41:33 MSK', 'ActiveExitTimestampMonotonic': '73324227997', 'InactiveEnterTimestamp': 'Thu 2025-07-24 07:41:33 MSK', 'InactiveEnterTimestampMonotonic': '73324227997', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 07:34:39 MSK', 'ConditionTimestampMonotonic': '72910064638', 'AssertTimestamp': 'Thu 2025-07-24 07:34:39 MSK', 'AssertTimestampMonotonic': '72910064646', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': '4ba6323cd3774bbd814207c1146ef0c8', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmctld', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmctld', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmctld: activating"
2025-07-24 04:41:36,561 p=69136 u=master n=ansible | TASK [[TEST] Тестовая команда scontrol] ***********************************************************************************************************************************************
2025-07-24 04:41:36,561 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:36 +0000 (0:00:00.097)       0:00:15.651 ********* 
2025-07-24 04:41:36,819 p=69136 u=master n=ansible | ok: [sm01]
2025-07-24 04:41:36,823 p=69136 u=master n=ansible | TASK [[TEST] Результат scontrol ping] *************************************************************************************************************************************************
2025-07-24 04:41:36,823 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:36 +0000 (0:00:00.261)       0:00:15.913 ********* 
2025-07-24 04:41:36,846 p=69136 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 scontrol ping:\n❌ ОШИБКА:"
2025-07-24 04:41:36,855 p=69136 u=master n=ansible | RUNNING HANDLER [slurm_master : restart slurmdbd] *************************************************************************************************************************************
2025-07-24 04:41:36,855 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:36 +0000 (0:00:00.031)       0:00:15.945 ********* 
2025-07-24 04:41:37,695 p=69136 u=master n=ansible | changed: [sm01]
2025-07-24 04:41:37,702 p=69136 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-24 04:41:37,703 p=69136 u=master n=ansible | sm01                       : ok=36   changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-24 04:41:37,703 p=69136 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 16 seconds
2025-07-24 04:41:37,703 p=69136 u=master n=ansible | Thursday 24 July 2025  04:41:37 +0000 (0:00:00.847)       0:00:16.793 ********* 
2025-07-24 04:41:37,703 p=69136 u=master n=ansible | =============================================================================== 
2025-07-24 04:41:37,703 p=69136 u=master n=ansible | slurm_master : [SERVICES] Пауза после запуска slurmdbd ------------------------------------------------------------------------------------------------------------------------- 3.06s
2025-07-24 04:41:37,703 p=69136 u=master n=ansible | [TEST] Проверка созданных файлов ----------------------------------------------------------------------------------------------------------------------------------------------- 1.30s
2025-07-24 04:41:37,703 p=69136 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.10s
2025-07-24 04:41:37,704 p=69136 u=master n=ansible | slurm_master : [SERVICES] Перезагрузка systemd daemon -------------------------------------------------------------------------------------------------------------------------- 1.09s
2025-07-24 04:41:37,704 p=69136 u=master n=ansible | [TEST] Проверка сервисов ------------------------------------------------------------------------------------------------------------------------------------------------------- 0.90s
2025-07-24 04:41:37,704 p=69136 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.89s
2025-07-24 04:41:37,704 p=69136 u=master n=ansible | slurm_master : [CONFIG] Копирование конфигов на NFS для распространения -------------------------------------------------------------------------------------------------------- 0.88s
2025-07-24 04:41:37,704 p=69136 u=master n=ansible | slurm_master : restart slurmdbd ------------------------------------------------------------------------------------------------------------------------------------------------ 0.85s
2025-07-24 04:41:37,704 p=69136 u=master n=ansible | slurm_master : [CONFIG] Создание конфига slurmdbd.conf ------------------------------------------------------------------------------------------------------------------------- 0.77s
2025-07-24 04:41:37,704 p=69136 u=master n=ansible | slurm_master : [CONFIG] Создание gres.conf для GPU ----------------------------------------------------------------------------------------------------------------------------- 0.61s
2025-07-24 04:41:37,704 p=69136 u=master n=ansible | slurm_master : [CONFIG] Создание cgroup.conf ----------------------------------------------------------------------------------------------------------------------------------- 0.60s
2025-07-24 04:41:37,704 p=69136 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmdbd ------------------------------------------------------------------------------------------------------------------- 0.59s
2025-07-24 04:41:37,704 p=69136 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmctld ------------------------------------------------------------------------------------------------------------------ 0.58s
2025-07-24 04:41:37,704 p=69136 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmdbd (сначала база) ----------------------------------------------------------------------------------------------------------------------- 0.50s
2025-07-24 04:41:37,705 p=69136 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmctld (после базы) ------------------------------------------------------------------------------------------------------------------------ 0.49s
2025-07-24 04:41:37,705 p=69136 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.40s
2025-07-24 04:41:37,705 p=69136 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-24 04:41:37,705 p=69136 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-24 04:41:37,705 p=69136 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.28s
2025-07-24 04:41:37,706 p=69136 u=master n=ansible | slurm_master : [CONFIG] Создание директории для конфигов на NFS ---------------------------------------------------------------------------------------------------------------- 0.27s
2025-07-24 04:46:57,572 p=69418 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:46:57,572 p=69418 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:46:57,991 p=69418 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-24 04:46:58,005 p=69418 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-24 04:46:58,005 p=69418 u=master n=ansible | Thursday 24 July 2025  04:46:58 +0000 (0:00:00.016)       0:00:00.016 ********* 
2025-07-24 04:46:58,029 p=69418 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-24 04:46:58,033 p=69418 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-24 04:46:58,033 p=69418 u=master n=ansible | Thursday 24 July 2025  04:46:58 +0000 (0:00:00.028)       0:00:00.044 ********* 
2025-07-24 04:46:59,166 p=69418 u=master n=ansible | ok: [sm01]
2025-07-24 04:46:59,170 p=69418 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-24 04:46:59,170 p=69418 u=master n=ansible | Thursday 24 July 2025  04:46:59 +0000 (0:00:01.136)       0:00:01.181 ********* 
2025-07-24 04:46:59,216 p=69418 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-24 04:46:59,220 p=69418 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-24 04:46:59,220 p=69418 u=master n=ansible | Thursday 24 July 2025  04:46:59 +0000 (0:00:00.050)       0:00:01.231 ********* 
2025-07-24 04:46:59,254 p=69418 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-24 04:46:59,254 p=69418 u=master n=ansible | Thursday 24 July 2025  04:46:59 +0000 (0:00:00.033)       0:00:01.265 ********* 
2025-07-24 04:46:59,303 p=69418 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-24 04:46:59,308 p=69418 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-24 04:46:59,308 p=69418 u=master n=ansible | Thursday 24 July 2025  04:46:59 +0000 (0:00:00.053)       0:00:01.319 ********* 
2025-07-24 04:46:59,360 p=69418 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-24 04:46:59,368 p=69418 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-24 04:46:59,368 p=69418 u=master n=ansible | Thursday 24 July 2025  04:46:59 +0000 (0:00:00.060)       0:00:01.379 ********* 
2025-07-24 04:46:59,650 p=69418 u=master n=ansible | ok: [sm01]
2025-07-24 04:46:59,654 p=69418 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-24 04:46:59,655 p=69418 u=master n=ansible | Thursday 24 July 2025  04:46:59 +0000 (0:00:00.286)       0:00:01.665 ********* 
2025-07-24 04:46:59,705 p=69418 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-24 04:46:59,709 p=69418 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-24 04:46:59,709 p=69418 u=master n=ansible | Thursday 24 July 2025  04:46:59 +0000 (0:00:00.054)       0:00:01.720 ********* 
2025-07-24 04:47:00,115 p=69418 u=master n=ansible | changed: [sm01]
2025-07-24 04:47:00,120 p=69418 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-24 04:47:00,120 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:00 +0000 (0:00:00.410)       0:00:02.131 ********* 
2025-07-24 04:47:00,168 p=69418 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-24 04:47:00,172 p=69418 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-24 04:47:00,172 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:00 +0000 (0:00:00.051)       0:00:02.183 ********* 
2025-07-24 04:47:00,471 p=69418 u=master n=ansible | ok: [sm01]
2025-07-24 04:47:00,476 p=69418 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-24 04:47:00,476 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:00 +0000 (0:00:00.304)       0:00:02.487 ********* 
2025-07-24 04:47:00,780 p=69418 u=master n=ansible | ok: [sm01]
2025-07-24 04:47:00,785 p=69418 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-24 04:47:00,785 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:00 +0000 (0:00:00.308)       0:00:02.796 ********* 
2025-07-24 04:47:00,836 p=69418 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-24 04:47:00,840 p=69418 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-24 04:47:00,841 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:00 +0000 (0:00:00.055)       0:00:02.851 ********* 
2025-07-24 04:47:00,861 p=69418 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-24 04:47:00,871 p=69418 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-24 04:47:00,871 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:00 +0000 (0:00:00.030)       0:00:02.882 ********* 
2025-07-24 04:47:01,740 p=69418 u=master n=ansible | ok: [sm01]
2025-07-24 04:47:01,745 p=69418 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание конфига slurmdbd.conf] *************************************************************************************************************************
2025-07-24 04:47:01,745 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:01 +0000 (0:00:00.874)       0:00:03.756 ********* 
2025-07-24 04:47:02,340 p=69418 u=master n=ansible | ok: [sm01]
2025-07-24 04:47:02,345 p=69418 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание gres.conf для GPU] *****************************************************************************************************************************
2025-07-24 04:47:02,345 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:02 +0000 (0:00:00.599)       0:00:04.356 ********* 
2025-07-24 04:47:02,961 p=69418 u=master n=ansible | ok: [sm01]
2025-07-24 04:47:02,965 p=69418 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание cgroup.conf] ***********************************************************************************************************************************
2025-07-24 04:47:02,965 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:02 +0000 (0:00:00.619)       0:00:04.976 ********* 
2025-07-24 04:47:03,569 p=69418 u=master n=ansible | ok: [sm01]
2025-07-24 04:47:03,574 p=69418 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание директории для конфигов на NFS] ****************************************************************************************************************
2025-07-24 04:47:03,574 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:03 +0000 (0:00:00.608)       0:00:05.585 ********* 
2025-07-24 04:47:03,837 p=69418 u=master n=ansible | ok: [sm01]
2025-07-24 04:47:03,842 p=69418 u=master n=ansible | TASK [slurm_master : [CONFIG] Копирование конфигов на NFS для распространения] ********************************************************************************************************
2025-07-24 04:47:03,842 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:03 +0000 (0:00:00.268)       0:00:05.853 ********* 
2025-07-24 04:47:04,287 p=69418 u=master n=ansible | ok: [sm01] => (item=slurm.conf)
2025-07-24 04:47:04,571 p=69418 u=master n=ansible | ok: [sm01] => (item=cgroup.conf)
2025-07-24 04:47:04,854 p=69418 u=master n=ansible | ok: [sm01] => (item=gres.conf)
2025-07-24 04:47:04,860 p=69418 u=master n=ansible | TASK [slurm_master : [CONFIG] Конфигурация создана] ***********************************************************************************************************************************
2025-07-24 04:47:04,860 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:04 +0000 (0:00:01.017)       0:00:06.871 ********* 
2025-07-24 04:47:04,881 p=69418 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Конфигурация Slurm:\n✅ slurm.conf создан\n✅ gres.conf создан (AutoDetect=nvml)\n✅ cgroup.conf создан\n✅ slurmdbd.conf создан\n\U0001F4E4 Файлы скопированы в /sw/config/ для распространения"
2025-07-24 04:47:04,885 p=69418 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка systemd сервисов] ***********************************************************************************************************************
2025-07-24 04:47:04,885 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:04 +0000 (0:00:00.024)       0:00:06.896 ********* 
2025-07-24 04:47:04,909 p=69418 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/services.yml for sm01
2025-07-24 04:47:04,920 p=69418 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmctld] ******************************************************************************************************************
2025-07-24 04:47:04,921 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:04 +0000 (0:00:00.035)       0:00:06.931 ********* 
2025-07-24 04:47:05,493 p=69418 u=master n=ansible | ok: [sm01]
2025-07-24 04:47:05,497 p=69418 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmdbd] *******************************************************************************************************************
2025-07-24 04:47:05,498 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:05 +0000 (0:00:00.576)       0:00:07.508 ********* 
2025-07-24 04:47:06,114 p=69418 u=master n=ansible | changed: [sm01]
2025-07-24 04:47:06,118 p=69418 u=master n=ansible | TASK [slurm_master : [SERVICES] Перезагрузка systemd daemon] **************************************************************************************************************************
2025-07-24 04:47:06,118 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:06 +0000 (0:00:00.620)       0:00:08.129 ********* 
2025-07-24 04:47:07,211 p=69418 u=master n=ansible | ok: [sm01]
2025-07-24 04:47:07,215 p=69418 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmdbd (сначала база)] ***********************************************************************************************************************
2025-07-24 04:47:07,216 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:07 +0000 (0:00:01.097)       0:00:09.226 ********* 
2025-07-24 04:47:07,716 p=69418 u=master n=ansible | ok: [sm01]
2025-07-24 04:47:07,722 p=69418 u=master n=ansible | TASK [slurm_master : [SERVICES] Пауза после запуска slurmdbd] *************************************************************************************************************************
2025-07-24 04:47:07,722 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:07 +0000 (0:00:00.506)       0:00:09.733 ********* 
2025-07-24 04:47:07,771 p=69418 u=master n=ansible | Pausing for 3 seconds
2025-07-24 04:47:07,771 p=69418 u=master n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-24 04:47:10,777 p=69418 u=master n=ansible | ok: [sm01]
2025-07-24 04:47:10,782 p=69418 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmctld (после базы)] ************************************************************************************************************************
2025-07-24 04:47:10,782 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:10 +0000 (0:00:03.060)       0:00:12.793 ********* 
2025-07-24 04:47:11,272 p=69418 u=master n=ansible | ok: [sm01]
2025-07-24 04:47:11,277 p=69418 u=master n=ansible | TASK [slurm_master : [SERVICES] Сервисы запущены] *************************************************************************************************************************************
2025-07-24 04:47:11,277 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:11 +0000 (0:00:00.495)       0:00:13.288 ********* 
2025-07-24 04:47:11,297 p=69418 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F39B️ Slurm сервисы:\n✅ slurmdbd запущен\n✅ slurmctld запущен\n\U0001F527 Проверьте: systemctl status slurmctld slurmdbd"
2025-07-24 04:47:11,301 p=69418 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Завершение настройки] *****************************************************************************************************************************
2025-07-24 04:47:11,302 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:11 +0000 (0:00:00.024)       0:00:13.312 ********* 
2025-07-24 04:47:11,351 p=69418 u=master n=ansible | ok: [sm01] => 
  msg: "✅ Slurm Master настроен!\n\U0001F527 Кластер: hpc-cluster\n\U0001F39B️ Controller: sm01:6817\n\U0001F4BE Database: включена"
2025-07-24 04:47:11,357 p=69418 u=master n=ansible | TASK [[TEST] Проверка созданных файлов] ***********************************************************************************************************************************************
2025-07-24 04:47:11,357 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:11 +0000 (0:00:00.055)       0:00:13.368 ********* 
2025-07-24 04:47:11,637 p=69418 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurm.conf)
2025-07-24 04:47:11,889 p=69418 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurmdbd.conf)
2025-07-24 04:47:12,141 p=69418 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/gres.conf)
2025-07-24 04:47:12,395 p=69418 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmctld.service)
2025-07-24 04:47:12,648 p=69418 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmdbd.service)
2025-07-24 04:47:12,655 p=69418 u=master n=ansible | TASK [[TEST] Результаты проверки файлов] **********************************************************************************************************************************************
2025-07-24 04:47:12,655 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:12 +0000 (0:00:01.297)       0:00:14.666 ********* 
2025-07-24 04:47:12,716 p=69418 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurm.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 5873, 'inode': 1835037, 'dev': 2050, 'nlink': 1, 'atime': 1753331667.876395, 'mtime': 1753331664.8334444, 'ctime': 1753331665.2114382, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 16, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '1f0876b813cccfedd27ffcf08baac3e0143db670', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '3911866346', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurm.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurm.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurm.conf: ✅ создан"
2025-07-24 04:47:12,721 p=69418 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurmdbd.conf', 'mode': '0600', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2318, 'inode': 1835035, 'dev': 2050, 'nlink': 1, 'atime': 1753332094.6684244, 'mtime': 1753332084.9605834, 'ctime': 1753332085.3325772, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': False, 'xgrp': False, 'woth': False, 'roth': False, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '379c00da27c17c640f268d909eb3fcca82934d56', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '3854950354', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurmdbd.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurmdbd.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurmdbd.conf: ✅ создан"
2025-07-24 04:47:12,727 p=69418 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/gres.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2225, 'inode': 1835031, 'dev': 2050, 'nlink': 1, 'atime': 1753331668.4423857, 'mtime': 1753331666.2524214, 'ctime': 1753331666.4904175, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '9c4de4a563fafe257ea173d75e4b265f37f70c7e', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '1956799153', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/gres.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/gres.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/gres.conf: ✅ создан"
2025-07-24 04:47:12,733 p=69418 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmctld.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 587, 'inode': 1835033, 'dev': 2050, 'nlink': 1, 'atime': 1753331674.9132805, 'mtime': 1753331668.8643787, 'ctime': 1753331669.0903752, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': '46eb21197027702db250059307749d445a8cbfc1', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '968271735', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmctld.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmctld.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmctld.service: ✅ создан"
2025-07-24 04:47:12,740 p=69418 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmdbd.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 690, 'inode': 1835036, 'dev': 2050, 'nlink': 1, 'atime': 1753332426.971969, 'mtime': 1753332425.8459873, 'ctime': 1753332426.0779836, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': '33d45fae188dc48fbaa9cc10e6db19a4d355f02b', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '3262396044', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmdbd.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmdbd.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmdbd.service: ✅ создан"
2025-07-24 04:47:12,747 p=69418 u=master n=ansible | TASK [[TEST] Проверка сервисов] *******************************************************************************************************************************************************
2025-07-24 04:47:12,748 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:12 +0000 (0:00:00.092)       0:00:14.758 ********* 
2025-07-24 04:47:13,205 p=69418 u=master n=ansible | ok: [sm01] => (item=slurmdbd)
2025-07-24 04:47:13,634 p=69418 u=master n=ansible | ok: [sm01] => (item=slurmctld)
2025-07-24 04:47:13,642 p=69418 u=master n=ansible | TASK [[TEST] Статус сервисов] *********************************************************************************************************************************************************
2025-07-24 04:47:13,642 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:13 +0000 (0:00:00.894)       0:00:15.653 ********* 
2025-07-24 04:47:13,718 p=69418 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmdbd', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '93532', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '1001', 'GID': '988', 'NRestarts': '0', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 07:41:37 MSK', 'ExecMainStartTimestampMonotonic': '73328672132', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '93532', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmdbd.service', 'ControlGroupId': '186372', 'MemoryCurrent': '6795264', 'MemoryPeak': '7577600', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11602395136', 'CPUUsageNSec': '149680000', 'TasksCurrent': '40', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmdbd.service', 'Names': 'slurmdbd.service', 'Requires': 'system.slice sysinit.target -.mount', 'Wants': 'munge.service mariadb.service tmp.mount', 'WantedBy': 'slurmctld.service multi-user.target', 'Conflicts': 'shutdown.target', 'Before': 'shutdown.target slurmctld.service multi-user.target', 'After': 'sysinit.target system.slice -.mount systemd-tmpfiles-setup.service systemd-journald.socket tmp.mount mariadb.service network.target basic.target munge.service', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm DBD accounting daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmdbd.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 07:41:37 MSK', 'StateChangeTimestampMonotonic': '73328672410', 'InactiveExitTimestamp': 'Thu 2025-07-24 07:41:37 MSK', 'InactiveExitTimestampMonotonic': '73328672410', 'ActiveEnterTimestamp': 'Thu 2025-07-24 07:41:37 MSK', 'ActiveEnterTimestampMonotonic': '73328672410', 'ActiveExitTimestamp': 'Thu 2025-07-24 07:41:37 MSK', 'ActiveExitTimestampMonotonic': '73328659057', 'InactiveEnterTimestamp': 'Thu 2025-07-24 07:41:37 MSK', 'InactiveEnterTimestampMonotonic': '73328659814', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 07:41:37 MSK', 'ConditionTimestampMonotonic': '73328661939', 'AssertTimestamp': 'Thu 2025-07-24 07:41:37 MSK', 'AssertTimestampMonotonic': '73328661965', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': '6e8f8a26a2e645a9ba26327bd1073666', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmdbd', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmdbd', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmdbd: active"
2025-07-24 04:47:13,729 p=69418 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmctld', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '0', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'exit-code', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '[not set]', 'GID': '[not set]', 'NRestarts': '143', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 07:47:09 MSK', 'ExecMainStartTimestampMonotonic': '73660215172', 'ExecMainExitTimestamp': 'Thu 2025-07-24 07:47:09 MSK', 'ExecMainExitTimestampMonotonic': '73660224733', 'ExecMainPID': '94197', 'ExecMainCode': '1', 'ExecMainStatus': '1', 'ExecStart': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D ; ignore_errors=no ; start_time=[Thu 2025-07-24 07:47:09 MSK] ; stop_time=[Thu 2025-07-24 07:47:09 MSK] ; pid=94197 ; code=exited ; status=1 }', 'ExecStartEx': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D ; flags= ; start_time=[Thu 2025-07-24 07:47:09 MSK] ; stop_time=[Thu 2025-07-24 07:47:09 MSK] ; pid=94197 ; code=exited ; status=1 }', 'Slice': 'system.slice', 'ControlGroupId': '192959', 'MemoryCurrent': '[not set]', 'MemoryPeak': '[not set]', 'MemorySwapCurrent': '[not set]', 'MemorySwapPeak': '[not set]', 'MemoryZSwapCurrent': '[not set]', 'MemoryAvailable': '11617685504', 'CPUUsageNSec': '7825000', 'TasksCurrent': '[not set]', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmctld.service', 'Names': 'slurmctld.service', 'Requires': 'system.slice sysinit.target -.mount', 'Wants': 'munge.service tmp.mount slurmdbd.service', 'WantedBy': 'multi-user.target', 'Conflicts': 'shutdown.target', 'Before': 'shutdown.target multi-user.target', 'After': 'slurmdbd.service systemd-journald.socket basic.target -.mount sysinit.target network.target systemd-tmpfiles-setup.service system.slice tmp.mount munge.service', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm controller daemon', 'LoadState': 'loaded', 'ActiveState': 'activating', 'FreezerState': 'running', 'SubState': 'auto-restart', 'FragmentPath': '/etc/systemd/system/slurmctld.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 07:47:09 MSK', 'StateChangeTimestampMonotonic': '73660225387', 'InactiveExitTimestamp': 'Thu 2025-07-24 07:47:09 MSK', 'InactiveExitTimestampMonotonic': '73660225387', 'ActiveEnterTimestamp': 'Thu 2025-07-24 07:47:09 MSK', 'ActiveEnterTimestampMonotonic': '73660215366', 'ActiveExitTimestamp': 'Thu 2025-07-24 07:47:09 MSK', 'ActiveExitTimestampMonotonic': '73660224862', 'InactiveEnterTimestamp': 'Thu 2025-07-24 07:47:09 MSK', 'InactiveEnterTimestampMonotonic': '73660224862', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 07:34:39 MSK', 'ConditionTimestampMonotonic': '72910064638', 'AssertTimestamp': 'Thu 2025-07-24 07:34:39 MSK', 'AssertTimestampMonotonic': '72910064646', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': '21ff6483747a4f30a4b874c1eb0bd649', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmctld', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmctld', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmctld: activating"
2025-07-24 04:47:13,740 p=69418 u=master n=ansible | TASK [[TEST] Тестовая команда scontrol] ***********************************************************************************************************************************************
2025-07-24 04:47:13,740 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:13 +0000 (0:00:00.098)       0:00:15.751 ********* 
2025-07-24 04:47:14,002 p=69418 u=master n=ansible | ok: [sm01]
2025-07-24 04:47:14,007 p=69418 u=master n=ansible | TASK [[TEST] Результат scontrol ping] *************************************************************************************************************************************************
2025-07-24 04:47:14,007 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:14 +0000 (0:00:00.266)       0:00:16.018 ********* 
2025-07-24 04:47:14,032 p=69418 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 scontrol ping:\n❌ ОШИБКА:"
2025-07-24 04:47:14,041 p=69418 u=master n=ansible | RUNNING HANDLER [slurm_master : restart slurmdbd] *************************************************************************************************************************************
2025-07-24 04:47:14,041 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:14 +0000 (0:00:00.034)       0:00:16.052 ********* 
2025-07-24 04:47:14,900 p=69418 u=master n=ansible | changed: [sm01]
2025-07-24 04:47:14,907 p=69418 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-24 04:47:14,907 p=69418 u=master n=ansible | sm01                       : ok=36   changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-24 04:47:14,907 p=69418 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 16 seconds
2025-07-24 04:47:14,908 p=69418 u=master n=ansible | Thursday 24 July 2025  04:47:14 +0000 (0:00:00.866)       0:00:16.918 ********* 
2025-07-24 04:47:14,908 p=69418 u=master n=ansible | =============================================================================== 
2025-07-24 04:47:14,908 p=69418 u=master n=ansible | slurm_master : [SERVICES] Пауза после запуска slurmdbd ------------------------------------------------------------------------------------------------------------------------- 3.06s
2025-07-24 04:47:14,908 p=69418 u=master n=ansible | [TEST] Проверка созданных файлов ----------------------------------------------------------------------------------------------------------------------------------------------- 1.30s
2025-07-24 04:47:14,908 p=69418 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.14s
2025-07-24 04:47:14,908 p=69418 u=master n=ansible | slurm_master : [SERVICES] Перезагрузка systemd daemon -------------------------------------------------------------------------------------------------------------------------- 1.10s
2025-07-24 04:47:14,908 p=69418 u=master n=ansible | slurm_master : [CONFIG] Копирование конфигов на NFS для распространения -------------------------------------------------------------------------------------------------------- 1.02s
2025-07-24 04:47:14,908 p=69418 u=master n=ansible | [TEST] Проверка сервисов ------------------------------------------------------------------------------------------------------------------------------------------------------- 0.89s
2025-07-24 04:47:14,908 p=69418 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.87s
2025-07-24 04:47:14,908 p=69418 u=master n=ansible | slurm_master : restart slurmdbd ------------------------------------------------------------------------------------------------------------------------------------------------ 0.87s
2025-07-24 04:47:14,909 p=69418 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmdbd ------------------------------------------------------------------------------------------------------------------- 0.62s
2025-07-24 04:47:14,909 p=69418 u=master n=ansible | slurm_master : [CONFIG] Создание gres.conf для GPU ----------------------------------------------------------------------------------------------------------------------------- 0.62s
2025-07-24 04:47:14,909 p=69418 u=master n=ansible | slurm_master : [CONFIG] Создание cgroup.conf ----------------------------------------------------------------------------------------------------------------------------------- 0.61s
2025-07-24 04:47:14,909 p=69418 u=master n=ansible | slurm_master : [CONFIG] Создание конфига slurmdbd.conf ------------------------------------------------------------------------------------------------------------------------- 0.60s
2025-07-24 04:47:14,909 p=69418 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmctld ------------------------------------------------------------------------------------------------------------------ 0.58s
2025-07-24 04:47:14,909 p=69418 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmdbd (сначала база) ----------------------------------------------------------------------------------------------------------------------- 0.51s
2025-07-24 04:47:14,909 p=69418 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmctld (после базы) ------------------------------------------------------------------------------------------------------------------------ 0.50s
2025-07-24 04:47:14,909 p=69418 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.41s
2025-07-24 04:47:14,909 p=69418 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-24 04:47:14,909 p=69418 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-24 04:47:14,909 p=69418 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.29s
2025-07-24 04:47:14,909 p=69418 u=master n=ansible | slurm_master : [CONFIG] Создание директории для конфигов на NFS ---------------------------------------------------------------------------------------------------------------- 0.27s
2025-07-24 04:48:20,360 p=69642 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:48:20,360 p=69642 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:48:21,784 p=69642 u=master n=ansible | sm01 | FAILED | rc=3 >>
● slurmctld.service - Slurm controller daemon
     Loaded: loaded (/etc/systemd/system/slurmctld.service; enabled; preset: enabled)
     Active: activating (auto-restart) (Result: exit-code) since Thu 2025-07-24 07:48:17 MSK; 4s ago
    Process: 94387 ExecStart=/usr/sbin/slurmctld -D (code=exited, status=1/FAILURE)
   Main PID: 94387 (code=exited, status=1/FAILURE)
        CPU: 6msnon-zero return code

2025-07-24 04:49:13,773 p=69696 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:49:13,773 p=69696 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:49:14,413 p=69696 u=master n=ansible | sm01 | FAILED | rc=1 >>
[2025-07-24T07:49:14.383] error: _parse_next_key: Parsing error at unrecognized key: CgroupMountpoint
[2025-07-24T07:49:14.383] error: _parse_next_key: Parsing error at unrecognized key: CgroupAutomount
[2025-07-24T07:49:14.384] error: SlurmdLogFile 1 specified more than once, latest value used
[2025-07-24T07:49:14.384] error: SlurmctldLogFile 1 specified more than once, latest value used
[2025-07-24T07:49:14.384] error: SlurmctldDebug 1 specified more than once, latest value used
[2025-07-24T07:49:14.384] error: SlurmdDebug 1 specified more than once, latest value used
[2025-07-24T07:49:14.384] error: JobAcctGatherType 1 specified more than once, latest value used
[2025-07-24T07:49:14.384] error: JobAcctGatherFrequency 1 specified more than once, latest value used
[2025-07-24T07:49:14.384] fatal: Unable to process configuration filenon-zero return code

2025-07-24 04:49:51,599 p=69753 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:49:51,599 p=69753 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:49:52,269 p=69753 u=master n=ansible | sm01 | CHANGED | rc=0 >>
LISTEN 0      4096         0.0.0.0:6819       0.0.0.0:*          

2025-07-24 04:51:57,833 p=69841 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:51:57,833 p=69841 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:51:58,245 p=69841 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-24 04:51:58,259 p=69841 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-24 04:51:58,259 p=69841 u=master n=ansible | Thursday 24 July 2025  04:51:58 +0000 (0:00:00.016)       0:00:00.016 ********* 
2025-07-24 04:51:58,282 p=69841 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-24 04:51:58,286 p=69841 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-24 04:51:58,286 p=69841 u=master n=ansible | Thursday 24 July 2025  04:51:58 +0000 (0:00:00.026)       0:00:00.043 ********* 
2025-07-24 04:51:59,428 p=69841 u=master n=ansible | ok: [sm01]
2025-07-24 04:51:59,432 p=69841 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-24 04:51:59,432 p=69841 u=master n=ansible | Thursday 24 July 2025  04:51:59 +0000 (0:00:01.146)       0:00:01.189 ********* 
2025-07-24 04:51:59,480 p=69841 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-24 04:51:59,484 p=69841 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-24 04:51:59,484 p=69841 u=master n=ansible | Thursday 24 July 2025  04:51:59 +0000 (0:00:00.052)       0:00:01.241 ********* 
2025-07-24 04:51:59,517 p=69841 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-24 04:51:59,517 p=69841 u=master n=ansible | Thursday 24 July 2025  04:51:59 +0000 (0:00:00.032)       0:00:01.274 ********* 
2025-07-24 04:51:59,567 p=69841 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-24 04:51:59,571 p=69841 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-24 04:51:59,571 p=69841 u=master n=ansible | Thursday 24 July 2025  04:51:59 +0000 (0:00:00.053)       0:00:01.328 ********* 
2025-07-24 04:51:59,625 p=69841 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-24 04:51:59,633 p=69841 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-24 04:51:59,633 p=69841 u=master n=ansible | Thursday 24 July 2025  04:51:59 +0000 (0:00:00.062)       0:00:01.390 ********* 
2025-07-24 04:51:59,923 p=69841 u=master n=ansible | ok: [sm01]
2025-07-24 04:51:59,927 p=69841 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-24 04:51:59,927 p=69841 u=master n=ansible | Thursday 24 July 2025  04:51:59 +0000 (0:00:00.294)       0:00:01.684 ********* 
2025-07-24 04:51:59,976 p=69841 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-24 04:51:59,980 p=69841 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-24 04:51:59,980 p=69841 u=master n=ansible | Thursday 24 July 2025  04:51:59 +0000 (0:00:00.053)       0:00:01.737 ********* 
2025-07-24 04:52:00,420 p=69841 u=master n=ansible | changed: [sm01]
2025-07-24 04:52:00,424 p=69841 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-24 04:52:00,424 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:00 +0000 (0:00:00.443)       0:00:02.181 ********* 
2025-07-24 04:52:00,473 p=69841 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-24 04:52:00,477 p=69841 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-24 04:52:00,478 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:00 +0000 (0:00:00.053)       0:00:02.234 ********* 
2025-07-24 04:52:00,779 p=69841 u=master n=ansible | ok: [sm01]
2025-07-24 04:52:00,784 p=69841 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-24 04:52:00,784 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:00 +0000 (0:00:00.306)       0:00:02.541 ********* 
2025-07-24 04:52:01,093 p=69841 u=master n=ansible | ok: [sm01]
2025-07-24 04:52:01,097 p=69841 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-24 04:52:01,098 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:01 +0000 (0:00:00.313)       0:00:02.854 ********* 
2025-07-24 04:52:01,148 p=69841 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-24 04:52:01,152 p=69841 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-24 04:52:01,153 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:01 +0000 (0:00:00.055)       0:00:02.910 ********* 
2025-07-24 04:52:01,175 p=69841 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-24 04:52:01,185 p=69841 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-24 04:52:01,186 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:01 +0000 (0:00:00.032)       0:00:02.942 ********* 
2025-07-24 04:52:02,104 p=69841 u=master n=ansible | changed: [sm01]
2025-07-24 04:52:02,108 p=69841 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание конфига slurmdbd.conf] *************************************************************************************************************************
2025-07-24 04:52:02,109 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:02 +0000 (0:00:00.923)       0:00:03.866 ********* 
2025-07-24 04:52:02,991 p=69841 u=master n=ansible | ok: [sm01]
2025-07-24 04:52:02,996 p=69841 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание gres.conf для GPU] *****************************************************************************************************************************
2025-07-24 04:52:02,996 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:02 +0000 (0:00:00.887)       0:00:04.753 ********* 
2025-07-24 04:52:03,619 p=69841 u=master n=ansible | ok: [sm01]
2025-07-24 04:52:03,624 p=69841 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание cgroup.conf] ***********************************************************************************************************************************
2025-07-24 04:52:03,624 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:03 +0000 (0:00:00.628)       0:00:05.381 ********* 
2025-07-24 04:52:04,235 p=69841 u=master n=ansible | ok: [sm01]
2025-07-24 04:52:04,240 p=69841 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание директории для конфигов на NFS] ****************************************************************************************************************
2025-07-24 04:52:04,240 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:04 +0000 (0:00:00.615)       0:00:05.997 ********* 
2025-07-24 04:52:04,567 p=69841 u=master n=ansible | ok: [sm01]
2025-07-24 04:52:04,572 p=69841 u=master n=ansible | TASK [slurm_master : [CONFIG] Копирование конфигов на NFS для распространения] ********************************************************************************************************
2025-07-24 04:52:04,573 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:04 +0000 (0:00:00.332)       0:00:06.329 ********* 
2025-07-24 04:52:04,889 p=69841 u=master n=ansible | changed: [sm01] => (item=slurm.conf)
2025-07-24 04:52:05,184 p=69841 u=master n=ansible | ok: [sm01] => (item=cgroup.conf)
2025-07-24 04:52:05,479 p=69841 u=master n=ansible | ok: [sm01] => (item=gres.conf)
2025-07-24 04:52:05,485 p=69841 u=master n=ansible | TASK [slurm_master : [CONFIG] Конфигурация создана] ***********************************************************************************************************************************
2025-07-24 04:52:05,485 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:05 +0000 (0:00:00.912)       0:00:07.242 ********* 
2025-07-24 04:52:05,504 p=69841 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Конфигурация Slurm:\n✅ slurm.conf создан\n✅ gres.conf создан (AutoDetect=nvml)\n✅ cgroup.conf создан\n✅ slurmdbd.conf создан\n\U0001F4E4 Файлы скопированы в /sw/config/ для распространения"
2025-07-24 04:52:05,508 p=69841 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка systemd сервисов] ***********************************************************************************************************************
2025-07-24 04:52:05,508 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:05 +0000 (0:00:00.023)       0:00:07.265 ********* 
2025-07-24 04:52:05,531 p=69841 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/services.yml for sm01
2025-07-24 04:52:05,543 p=69841 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmctld] ******************************************************************************************************************
2025-07-24 04:52:05,543 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:05 +0000 (0:00:00.035)       0:00:07.300 ********* 
2025-07-24 04:52:06,232 p=69841 u=master n=ansible | ok: [sm01]
2025-07-24 04:52:06,236 p=69841 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmdbd] *******************************************************************************************************************
2025-07-24 04:52:06,237 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:06 +0000 (0:00:00.693)       0:00:07.993 ********* 
2025-07-24 04:52:06,850 p=69841 u=master n=ansible | ok: [sm01]
2025-07-24 04:52:06,854 p=69841 u=master n=ansible | TASK [slurm_master : [SERVICES] Перезагрузка systemd daemon] **************************************************************************************************************************
2025-07-24 04:52:06,854 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:06 +0000 (0:00:00.617)       0:00:08.611 ********* 
2025-07-24 04:52:08,088 p=69841 u=master n=ansible | ok: [sm01]
2025-07-24 04:52:08,092 p=69841 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmdbd (сначала база)] ***********************************************************************************************************************
2025-07-24 04:52:08,093 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:08 +0000 (0:00:01.238)       0:00:09.850 ********* 
2025-07-24 04:52:08,611 p=69841 u=master n=ansible | ok: [sm01]
2025-07-24 04:52:08,616 p=69841 u=master n=ansible | TASK [slurm_master : [SERVICES] Пауза после запуска slurmdbd] *************************************************************************************************************************
2025-07-24 04:52:08,616 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:08 +0000 (0:00:00.523)       0:00:10.373 ********* 
2025-07-24 04:52:08,664 p=69841 u=master n=ansible | Pausing for 3 seconds
2025-07-24 04:52:08,664 p=69841 u=master n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-24 04:52:11,670 p=69841 u=master n=ansible | ok: [sm01]
2025-07-24 04:52:11,675 p=69841 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmctld (после базы)] ************************************************************************************************************************
2025-07-24 04:52:11,675 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:11 +0000 (0:00:03.058)       0:00:13.432 ********* 
2025-07-24 04:52:12,165 p=69841 u=master n=ansible | ok: [sm01]
2025-07-24 04:52:12,170 p=69841 u=master n=ansible | TASK [slurm_master : [SERVICES] Сервисы запущены] *************************************************************************************************************************************
2025-07-24 04:52:12,170 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:12 +0000 (0:00:00.494)       0:00:13.927 ********* 
2025-07-24 04:52:12,189 p=69841 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F39B️ Slurm сервисы:\n✅ slurmdbd запущен\n✅ slurmctld запущен\n\U0001F527 Проверьте: systemctl status slurmctld slurmdbd"
2025-07-24 04:52:12,193 p=69841 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Завершение настройки] *****************************************************************************************************************************
2025-07-24 04:52:12,193 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:12 +0000 (0:00:00.023)       0:00:13.950 ********* 
2025-07-24 04:52:12,242 p=69841 u=master n=ansible | ok: [sm01] => 
  msg: "✅ Slurm Master настроен!\n\U0001F527 Кластер: hpc-cluster\n\U0001F39B️ Controller: sm01:6817\n\U0001F4BE Database: включена"
2025-07-24 04:52:12,249 p=69841 u=master n=ansible | TASK [[TEST] Проверка созданных файлов] ***********************************************************************************************************************************************
2025-07-24 04:52:12,249 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:12 +0000 (0:00:00.055)       0:00:14.006 ********* 
2025-07-24 04:52:12,531 p=69841 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurm.conf)
2025-07-24 04:52:12,800 p=69841 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurmdbd.conf)
2025-07-24 04:52:13,089 p=69841 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/gres.conf)
2025-07-24 04:52:13,343 p=69841 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmctld.service)
2025-07-24 04:52:13,599 p=69841 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmdbd.service)
2025-07-24 04:52:13,605 p=69841 u=master n=ansible | TASK [[TEST] Результаты проверки файлов] **********************************************************************************************************************************************
2025-07-24 04:52:13,605 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:13 +0000 (0:00:01.356)       0:00:15.362 ********* 
2025-07-24 04:52:13,668 p=69841 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurm.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 5824, 'inode': 1835034, 'dev': 2050, 'nlink': 1, 'atime': 1753332723.2045302, 'mtime': 1753332721.6935523, 'ctime': 1753332722.062547, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 16, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': 'dc5ced2ce31776e9719e7a1f7443b966fdc67a5f', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '672602275', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurm.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurm.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurm.conf: ✅ создан"
2025-07-24 04:52:13,673 p=69841 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurmdbd.conf', 'mode': '0600', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2318, 'inode': 1835035, 'dev': 2050, 'nlink': 1, 'atime': 1753332094.6684244, 'mtime': 1753332084.9605834, 'ctime': 1753332085.3325772, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': False, 'xgrp': False, 'woth': False, 'roth': False, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '379c00da27c17c640f268d909eb3fcca82934d56', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '3854950354', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurmdbd.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurmdbd.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurmdbd.conf: ✅ создан"
2025-07-24 04:52:13,679 p=69841 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/gres.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2225, 'inode': 1835031, 'dev': 2050, 'nlink': 1, 'atime': 1753331668.4423857, 'mtime': 1753331666.2524214, 'ctime': 1753331666.4904175, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '9c4de4a563fafe257ea173d75e4b265f37f70c7e', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '1956799153', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/gres.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/gres.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/gres.conf: ✅ создан"
2025-07-24 04:52:13,685 p=69841 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmctld.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 587, 'inode': 1835033, 'dev': 2050, 'nlink': 1, 'atime': 1753331674.9132805, 'mtime': 1753331668.8643787, 'ctime': 1753331669.0903752, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': '46eb21197027702db250059307749d445a8cbfc1', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '968271735', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmctld.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmctld.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmctld.service: ✅ создан"
2025-07-24 04:52:13,691 p=69841 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmdbd.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 690, 'inode': 1835036, 'dev': 2050, 'nlink': 1, 'atime': 1753332426.971969, 'mtime': 1753332425.8459873, 'ctime': 1753332426.0779836, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': '33d45fae188dc48fbaa9cc10e6db19a4d355f02b', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '3262396044', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmdbd.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmdbd.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmdbd.service: ✅ создан"
2025-07-24 04:52:13,699 p=69841 u=master n=ansible | TASK [[TEST] Проверка сервисов] *******************************************************************************************************************************************************
2025-07-24 04:52:13,699 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:13 +0000 (0:00:00.093)       0:00:15.456 ********* 
2025-07-24 04:52:14,163 p=69841 u=master n=ansible | ok: [sm01] => (item=slurmdbd)
2025-07-24 04:52:14,605 p=69841 u=master n=ansible | ok: [sm01] => (item=slurmctld)
2025-07-24 04:52:14,614 p=69841 u=master n=ansible | TASK [[TEST] Статус сервисов] *********************************************************************************************************************************************************
2025-07-24 04:52:14,614 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:14 +0000 (0:00:00.914)       0:00:16.371 ********* 
2025-07-24 04:52:14,693 p=69841 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmdbd', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '94321', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '1001', 'GID': '988', 'NRestarts': '0', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ExecMainStartTimestampMonotonic': '73665875213', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '94321', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmdbd.service', 'ControlGroupId': '186372', 'MemoryCurrent': '6811648', 'MemoryPeak': '7593984', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11593142272', 'CPUUsageNSec': '140393000', 'TasksCurrent': '40', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmdbd.service', 'Names': 'slurmdbd.service', 'Requires': 'sysinit.target system.slice -.mount', 'Wants': 'mariadb.service munge.service tmp.mount', 'WantedBy': 'multi-user.target slurmctld.service', 'Conflicts': 'shutdown.target', 'Before': 'multi-user.target shutdown.target slurmctld.service', 'After': 'systemd-journald.socket munge.service basic.target -.mount systemd-tmpfiles-setup.service mariadb.service system.slice tmp.mount network.target sysinit.target', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm DBD accounting daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmdbd.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'StateChangeTimestampMonotonic': '73665875484', 'InactiveExitTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'InactiveExitTimestampMonotonic': '73665875484', 'ActiveEnterTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ActiveEnterTimestampMonotonic': '73665875484', 'ActiveExitTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ActiveExitTimestampMonotonic': '73665855390', 'InactiveEnterTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'InactiveEnterTimestampMonotonic': '73665859078', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ConditionTimestampMonotonic': '73665860881', 'AssertTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'AssertTimestampMonotonic': '73665860890', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': '11fb6819a8bb4f6c946abffcec6a6a8c', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmdbd', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmdbd', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmdbd: active"
2025-07-24 04:52:14,704 p=69841 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmctld', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '0', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'exit-code', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '[not set]', 'GID': '[not set]', 'NRestarts': '201', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 07:52:13 MSK', 'ExecMainStartTimestampMonotonic': '73964721090', 'ExecMainExitTimestamp': 'Thu 2025-07-24 07:52:13 MSK', 'ExecMainExitTimestampMonotonic': '73964737702', 'ExecMainPID': '95111', 'ExecMainCode': '1', 'ExecMainStatus': '1', 'ExecStart': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D ; ignore_errors=no ; start_time=[Thu 2025-07-24 07:52:13 MSK] ; stop_time=[Thu 2025-07-24 07:52:13 MSK] ; pid=95111 ; code=exited ; status=1 }', 'ExecStartEx': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D ; flags= ; start_time=[Thu 2025-07-24 07:52:13 MSK] ; stop_time=[Thu 2025-07-24 07:52:13 MSK] ; pid=95111 ; code=exited ; status=1 }', 'Slice': 'system.slice', 'ControlGroupId': '195535', 'MemoryCurrent': '[not set]', 'MemoryPeak': '3026944', 'MemorySwapCurrent': '[not set]', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '[not set]', 'MemoryAvailable': '11592884224', 'CPUUsageNSec': '19428000', 'TasksCurrent': '[not set]', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmctld.service', 'Names': 'slurmctld.service', 'Requires': 'system.slice -.mount sysinit.target', 'Wants': 'slurmdbd.service tmp.mount munge.service', 'WantedBy': 'multi-user.target', 'Conflicts': 'shutdown.target', 'Before': 'shutdown.target multi-user.target', 'After': 'systemd-tmpfiles-setup.service sysinit.target systemd-journald.socket munge.service tmp.mount network.target basic.target -.mount slurmdbd.service system.slice', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm controller daemon', 'LoadState': 'loaded', 'ActiveState': 'activating', 'FreezerState': 'running', 'SubState': 'auto-restart', 'FragmentPath': '/etc/systemd/system/slurmctld.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 07:52:13 MSK', 'StateChangeTimestampMonotonic': '73964738124', 'InactiveExitTimestamp': 'Thu 2025-07-24 07:52:13 MSK', 'InactiveExitTimestampMonotonic': '73964738124', 'ActiveEnterTimestamp': 'Thu 2025-07-24 07:52:13 MSK', 'ActiveEnterTimestampMonotonic': '73964721241', 'ActiveExitTimestamp': 'Thu 2025-07-24 07:52:13 MSK', 'ActiveExitTimestampMonotonic': '73964737784', 'InactiveEnterTimestamp': 'Thu 2025-07-24 07:52:13 MSK', 'InactiveEnterTimestampMonotonic': '73964737784', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 07:34:39 MSK', 'ConditionTimestampMonotonic': '72910064638', 'AssertTimestamp': 'Thu 2025-07-24 07:34:39 MSK', 'AssertTimestampMonotonic': '72910064646', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': '2f2b2180dc7f47e89ea4d9333769330d', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmctld', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmctld', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmctld: activating"
2025-07-24 04:52:14,717 p=69841 u=master n=ansible | TASK [[TEST] Тестовая команда scontrol] ***********************************************************************************************************************************************
2025-07-24 04:52:14,717 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:14 +0000 (0:00:00.103)       0:00:16.474 ********* 
2025-07-24 04:52:14,984 p=69841 u=master n=ansible | ok: [sm01]
2025-07-24 04:52:14,988 p=69841 u=master n=ansible | TASK [[TEST] Результат scontrol ping] *************************************************************************************************************************************************
2025-07-24 04:52:14,988 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:14 +0000 (0:00:00.270)       0:00:16.745 ********* 
2025-07-24 04:52:15,012 p=69841 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 scontrol ping:\n❌ ОШИБКА:"
2025-07-24 04:52:15,021 p=69841 u=master n=ansible | RUNNING HANDLER [slurm_master : restart slurmctld] ************************************************************************************************************************************
2025-07-24 04:52:15,021 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:15 +0000 (0:00:00.032)       0:00:16.778 ********* 
2025-07-24 04:52:15,833 p=69841 u=master n=ansible | changed: [sm01]
2025-07-24 04:52:15,910 p=69841 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-24 04:52:15,910 p=69841 u=master n=ansible | sm01                       : ok=36   changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-24 04:52:15,910 p=69841 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 17 seconds
2025-07-24 04:52:15,911 p=69841 u=master n=ansible | Thursday 24 July 2025  04:52:15 +0000 (0:00:00.889)       0:00:17.668 ********* 
2025-07-24 04:52:15,911 p=69841 u=master n=ansible | =============================================================================== 
2025-07-24 04:52:15,911 p=69841 u=master n=ansible | slurm_master : [SERVICES] Пауза после запуска slurmdbd ------------------------------------------------------------------------------------------------------------------------- 3.06s
2025-07-24 04:52:15,911 p=69841 u=master n=ansible | [TEST] Проверка созданных файлов ----------------------------------------------------------------------------------------------------------------------------------------------- 1.36s
2025-07-24 04:52:15,912 p=69841 u=master n=ansible | slurm_master : [SERVICES] Перезагрузка systemd daemon -------------------------------------------------------------------------------------------------------------------------- 1.24s
2025-07-24 04:52:15,912 p=69841 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.15s
2025-07-24 04:52:15,912 p=69841 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.92s
2025-07-24 04:52:15,912 p=69841 u=master n=ansible | [TEST] Проверка сервисов ------------------------------------------------------------------------------------------------------------------------------------------------------- 0.91s
2025-07-24 04:52:15,912 p=69841 u=master n=ansible | slurm_master : [CONFIG] Копирование конфигов на NFS для распространения -------------------------------------------------------------------------------------------------------- 0.91s
2025-07-24 04:52:15,912 p=69841 u=master n=ansible | slurm_master : restart slurmctld ----------------------------------------------------------------------------------------------------------------------------------------------- 0.89s
2025-07-24 04:52:15,913 p=69841 u=master n=ansible | slurm_master : [CONFIG] Создание конфига slurmdbd.conf ------------------------------------------------------------------------------------------------------------------------- 0.89s
2025-07-24 04:52:15,913 p=69841 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmctld ------------------------------------------------------------------------------------------------------------------ 0.69s
2025-07-24 04:52:15,913 p=69841 u=master n=ansible | slurm_master : [CONFIG] Создание gres.conf для GPU ----------------------------------------------------------------------------------------------------------------------------- 0.63s
2025-07-24 04:52:15,913 p=69841 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmdbd ------------------------------------------------------------------------------------------------------------------- 0.62s
2025-07-24 04:52:15,913 p=69841 u=master n=ansible | slurm_master : [CONFIG] Создание cgroup.conf ----------------------------------------------------------------------------------------------------------------------------------- 0.62s
2025-07-24 04:52:15,913 p=69841 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmdbd (сначала база) ----------------------------------------------------------------------------------------------------------------------- 0.52s
2025-07-24 04:52:15,913 p=69841 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmctld (после базы) ------------------------------------------------------------------------------------------------------------------------ 0.49s
2025-07-24 04:52:15,914 p=69841 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.44s
2025-07-24 04:52:15,914 p=69841 u=master n=ansible | slurm_master : [CONFIG] Создание директории для конфигов на NFS ---------------------------------------------------------------------------------------------------------------- 0.33s
2025-07-24 04:52:15,914 p=69841 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-24 04:52:15,914 p=69841 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-24 04:52:15,914 p=69841 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.29s
2025-07-24 04:53:18,816 p=70082 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:53:18,817 p=70082 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:53:20,175 p=70082 u=master n=ansible | sm01 | FAILED | rc=1 >>
Usage: slurmctld [OPTIONS]
  -c            Do not recover state from last checkpoint.
  -D            Run daemon in foreground, with logging copied to stdout.
  -f file       Use specified file for slurmctld configuration.
  -h            Print this help message.
  -i            Ignore errors found while reading in state files on startup.
  -L logfile    Log messages to the specified file.
  -n value      Run the daemon at the specified nice value.
  -R            Recover full state from last checkpoint.
  -s            Change working directory to SlurmctldLogFile/StateSaveLocation.
  --systemd     Started from a systemd unit file.
  -v            Verbose mode. Multiple -v's increase verbosity.
  -V            Print version information and exit.non-zero return code

2025-07-24 04:57:18,171 p=70170 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:57:18,171 p=70170 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 04:57:18,565 p=70170 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-24 04:57:18,578 p=70170 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-24 04:57:18,578 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:18 +0000 (0:00:00.015)       0:00:00.015 ********* 
2025-07-24 04:57:18,601 p=70170 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-24 04:57:18,604 p=70170 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-24 04:57:18,605 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:18 +0000 (0:00:00.026)       0:00:00.041 ********* 
2025-07-24 04:57:19,702 p=70170 u=master n=ansible | ok: [sm01]
2025-07-24 04:57:19,705 p=70170 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-24 04:57:19,706 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:19 +0000 (0:00:01.100)       0:00:01.142 ********* 
2025-07-24 04:57:19,752 p=70170 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-24 04:57:19,756 p=70170 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-24 04:57:19,756 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:19 +0000 (0:00:00.050)       0:00:01.193 ********* 
2025-07-24 04:57:19,791 p=70170 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-24 04:57:19,791 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:19 +0000 (0:00:00.035)       0:00:01.228 ********* 
2025-07-24 04:57:19,842 p=70170 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-24 04:57:19,846 p=70170 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-24 04:57:19,846 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:19 +0000 (0:00:00.054)       0:00:01.283 ********* 
2025-07-24 04:57:19,898 p=70170 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-24 04:57:19,906 p=70170 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-24 04:57:19,906 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:19 +0000 (0:00:00.059)       0:00:01.343 ********* 
2025-07-24 04:57:20,185 p=70170 u=master n=ansible | ok: [sm01]
2025-07-24 04:57:20,189 p=70170 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-24 04:57:20,190 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:20 +0000 (0:00:00.283)       0:00:01.626 ********* 
2025-07-24 04:57:20,239 p=70170 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-24 04:57:20,243 p=70170 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-24 04:57:20,243 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:20 +0000 (0:00:00.053)       0:00:01.680 ********* 
2025-07-24 04:57:20,642 p=70170 u=master n=ansible | changed: [sm01]
2025-07-24 04:57:20,646 p=70170 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-24 04:57:20,646 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:20 +0000 (0:00:00.403)       0:00:02.083 ********* 
2025-07-24 04:57:20,695 p=70170 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-24 04:57:20,698 p=70170 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-24 04:57:20,699 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:20 +0000 (0:00:00.052)       0:00:02.135 ********* 
2025-07-24 04:57:20,999 p=70170 u=master n=ansible | ok: [sm01]
2025-07-24 04:57:21,003 p=70170 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-24 04:57:21,003 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:21 +0000 (0:00:00.304)       0:00:02.440 ********* 
2025-07-24 04:57:21,303 p=70170 u=master n=ansible | ok: [sm01]
2025-07-24 04:57:21,307 p=70170 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-24 04:57:21,307 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:21 +0000 (0:00:00.304)       0:00:02.744 ********* 
2025-07-24 04:57:21,358 p=70170 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-24 04:57:21,362 p=70170 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-24 04:57:21,362 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:21 +0000 (0:00:00.054)       0:00:02.799 ********* 
2025-07-24 04:57:21,383 p=70170 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-24 04:57:21,392 p=70170 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-24 04:57:21,392 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:21 +0000 (0:00:00.030)       0:00:02.829 ********* 
2025-07-24 04:57:22,305 p=70170 u=master n=ansible | changed: [sm01]
2025-07-24 04:57:22,309 p=70170 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание конфига slurmdbd.conf] *************************************************************************************************************************
2025-07-24 04:57:22,309 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:22 +0000 (0:00:00.916)       0:00:03.746 ********* 
2025-07-24 04:57:23,069 p=70170 u=master n=ansible | ok: [sm01]
2025-07-24 04:57:23,074 p=70170 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание gres.conf для GPU] *****************************************************************************************************************************
2025-07-24 04:57:23,074 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:23 +0000 (0:00:00.765)       0:00:04.511 ********* 
2025-07-24 04:57:23,693 p=70170 u=master n=ansible | ok: [sm01]
2025-07-24 04:57:23,697 p=70170 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание cgroup.conf] ***********************************************************************************************************************************
2025-07-24 04:57:23,698 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:23 +0000 (0:00:00.623)       0:00:05.134 ********* 
2025-07-24 04:57:24,294 p=70170 u=master n=ansible | ok: [sm01]
2025-07-24 04:57:24,299 p=70170 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание директории для конфигов на NFS] ****************************************************************************************************************
2025-07-24 04:57:24,300 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:24 +0000 (0:00:00.601)       0:00:05.736 ********* 
2025-07-24 04:57:24,559 p=70170 u=master n=ansible | ok: [sm01]
2025-07-24 04:57:24,564 p=70170 u=master n=ansible | TASK [slurm_master : [CONFIG] Копирование конфигов на NFS для распространения] ********************************************************************************************************
2025-07-24 04:57:24,565 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:24 +0000 (0:00:00.264)       0:00:06.001 ********* 
2025-07-24 04:57:24,872 p=70170 u=master n=ansible | changed: [sm01] => (item=slurm.conf)
2025-07-24 04:57:25,154 p=70170 u=master n=ansible | ok: [sm01] => (item=cgroup.conf)
2025-07-24 04:57:25,444 p=70170 u=master n=ansible | ok: [sm01] => (item=gres.conf)
2025-07-24 04:57:25,449 p=70170 u=master n=ansible | TASK [slurm_master : [CONFIG] Конфигурация создана] ***********************************************************************************************************************************
2025-07-24 04:57:25,450 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:25 +0000 (0:00:00.885)       0:00:06.886 ********* 
2025-07-24 04:57:25,470 p=70170 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Конфигурация Slurm:\n✅ slurm.conf создан\n✅ gres.conf создан (AutoDetect=nvml)\n✅ cgroup.conf создан\n✅ slurmdbd.conf создан\n\U0001F4E4 Файлы скопированы в /sw/config/ для распространения"
2025-07-24 04:57:25,474 p=70170 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка systemd сервисов] ***********************************************************************************************************************
2025-07-24 04:57:25,474 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:25 +0000 (0:00:00.024)       0:00:06.911 ********* 
2025-07-24 04:57:25,498 p=70170 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/services.yml for sm01
2025-07-24 04:57:25,510 p=70170 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmctld] ******************************************************************************************************************
2025-07-24 04:57:25,510 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:25 +0000 (0:00:00.035)       0:00:06.947 ********* 
2025-07-24 04:57:26,068 p=70170 u=master n=ansible | ok: [sm01]
2025-07-24 04:57:26,072 p=70170 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmdbd] *******************************************************************************************************************
2025-07-24 04:57:26,073 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:26 +0000 (0:00:00.562)       0:00:07.509 ********* 
2025-07-24 04:57:26,666 p=70170 u=master n=ansible | ok: [sm01]
2025-07-24 04:57:26,670 p=70170 u=master n=ansible | TASK [slurm_master : [SERVICES] Перезагрузка systemd daemon] **************************************************************************************************************************
2025-07-24 04:57:26,670 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:26 +0000 (0:00:00.597)       0:00:08.107 ********* 
2025-07-24 04:57:27,764 p=70170 u=master n=ansible | ok: [sm01]
2025-07-24 04:57:27,768 p=70170 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmdbd (сначала база)] ***********************************************************************************************************************
2025-07-24 04:57:27,769 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:27 +0000 (0:00:01.098)       0:00:09.205 ********* 
2025-07-24 04:57:28,274 p=70170 u=master n=ansible | ok: [sm01]
2025-07-24 04:57:28,285 p=70170 u=master n=ansible | TASK [slurm_master : [SERVICES] Пауза после запуска slurmdbd] *************************************************************************************************************************
2025-07-24 04:57:28,285 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:28 +0000 (0:00:00.516)       0:00:09.722 ********* 
2025-07-24 04:57:28,332 p=70170 u=master n=ansible | Pausing for 3 seconds
2025-07-24 04:57:28,333 p=70170 u=master n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-24 04:57:31,337 p=70170 u=master n=ansible | ok: [sm01]
2025-07-24 04:57:31,342 p=70170 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmctld (после базы)] ************************************************************************************************************************
2025-07-24 04:57:31,342 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:31 +0000 (0:00:03.056)       0:00:12.778 ********* 
2025-07-24 04:57:31,814 p=70170 u=master n=ansible | ok: [sm01]
2025-07-24 04:57:31,819 p=70170 u=master n=ansible | TASK [slurm_master : [SERVICES] Сервисы запущены] *************************************************************************************************************************************
2025-07-24 04:57:31,819 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:31 +0000 (0:00:00.477)       0:00:13.256 ********* 
2025-07-24 04:57:31,838 p=70170 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F39B️ Slurm сервисы:\n✅ slurmdbd запущен\n✅ slurmctld запущен\n\U0001F527 Проверьте: systemctl status slurmctld slurmdbd"
2025-07-24 04:57:31,842 p=70170 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Завершение настройки] *****************************************************************************************************************************
2025-07-24 04:57:31,842 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:31 +0000 (0:00:00.022)       0:00:13.279 ********* 
2025-07-24 04:57:31,891 p=70170 u=master n=ansible | ok: [sm01] => 
  msg: "✅ Slurm Master настроен!\n\U0001F527 Кластер: hpc-cluster\n\U0001F39B️ Controller: sm01:6817\n\U0001F4BE Database: включена"
2025-07-24 04:57:31,897 p=70170 u=master n=ansible | TASK [[TEST] Проверка созданных файлов] ***********************************************************************************************************************************************
2025-07-24 04:57:31,897 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:31 +0000 (0:00:00.054)       0:00:13.334 ********* 
2025-07-24 04:57:32,172 p=70170 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurm.conf)
2025-07-24 04:57:32,423 p=70170 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurmdbd.conf)
2025-07-24 04:57:32,678 p=70170 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/gres.conf)
2025-07-24 04:57:32,928 p=70170 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmctld.service)
2025-07-24 04:57:33,193 p=70170 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmdbd.service)
2025-07-24 04:57:33,199 p=70170 u=master n=ansible | TASK [[TEST] Результаты проверки файлов] **********************************************************************************************************************************************
2025-07-24 04:57:33,200 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:33 +0000 (0:00:01.302)       0:00:14.636 ********* 
2025-07-24 04:57:33,262 p=70170 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurm.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 5994, 'inode': 1835037, 'dev': 2050, 'nlink': 1, 'atime': 1753333044.8347137, 'mtime': 1753333041.8907588, 'ctime': 1753333042.261753, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 16, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '68f7c1cf52d05870f8d29312061da39d5b16ed5a', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '149981309', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurm.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurm.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurm.conf: ✅ создан"
2025-07-24 04:57:33,268 p=70170 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurmdbd.conf', 'mode': '0600', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2318, 'inode': 1835035, 'dev': 2050, 'nlink': 1, 'atime': 1753332094.6684244, 'mtime': 1753332084.9605834, 'ctime': 1753332085.3325772, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': False, 'xgrp': False, 'woth': False, 'roth': False, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '379c00da27c17c640f268d909eb3fcca82934d56', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '3854950354', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurmdbd.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurmdbd.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurmdbd.conf: ✅ создан"
2025-07-24 04:57:33,274 p=70170 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/gres.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2225, 'inode': 1835031, 'dev': 2050, 'nlink': 1, 'atime': 1753331668.4423857, 'mtime': 1753331666.2524214, 'ctime': 1753331666.4904175, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '9c4de4a563fafe257ea173d75e4b265f37f70c7e', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '1956799153', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/gres.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/gres.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/gres.conf: ✅ создан"
2025-07-24 04:57:33,281 p=70170 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmctld.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 587, 'inode': 1835033, 'dev': 2050, 'nlink': 1, 'atime': 1753331674.9132805, 'mtime': 1753331668.8643787, 'ctime': 1753331669.0903752, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': '46eb21197027702db250059307749d445a8cbfc1', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '968271735', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmctld.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmctld.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmctld.service: ✅ создан"
2025-07-24 04:57:33,288 p=70170 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmdbd.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 690, 'inode': 1835036, 'dev': 2050, 'nlink': 1, 'atime': 1753332426.971969, 'mtime': 1753332425.8459873, 'ctime': 1753332426.0779836, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': '33d45fae188dc48fbaa9cc10e6db19a4d355f02b', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '3262396044', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmdbd.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmdbd.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmdbd.service: ✅ создан"
2025-07-24 04:57:33,296 p=70170 u=master n=ansible | TASK [[TEST] Проверка сервисов] *******************************************************************************************************************************************************
2025-07-24 04:57:33,296 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:33 +0000 (0:00:00.096)       0:00:14.732 ********* 
2025-07-24 04:57:33,752 p=70170 u=master n=ansible | ok: [sm01] => (item=slurmdbd)
2025-07-24 04:57:34,187 p=70170 u=master n=ansible | ok: [sm01] => (item=slurmctld)
2025-07-24 04:57:34,195 p=70170 u=master n=ansible | TASK [[TEST] Статус сервисов] *********************************************************************************************************************************************************
2025-07-24 04:57:34,196 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:34 +0000 (0:00:00.899)       0:00:15.632 ********* 
2025-07-24 04:57:34,270 p=70170 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmdbd', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '94321', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '1001', 'GID': '988', 'NRestarts': '0', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ExecMainStartTimestampMonotonic': '73665875213', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '94321', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmdbd.service', 'ControlGroupId': '186372', 'MemoryCurrent': '6873088', 'MemoryPeak': '7905280', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11589046272', 'CPUUsageNSec': '272938000', 'TasksCurrent': '40', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmdbd.service', 'Names': 'slurmdbd.service', 'Requires': 'sysinit.target system.slice -.mount', 'Wants': 'munge.service tmp.mount mariadb.service', 'WantedBy': 'multi-user.target slurmctld.service', 'Conflicts': 'shutdown.target', 'Before': 'slurmctld.service shutdown.target multi-user.target', 'After': 'basic.target systemd-journald.socket sysinit.target system.slice tmp.mount -.mount systemd-tmpfiles-setup.service mariadb.service munge.service network.target', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm DBD accounting daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmdbd.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'StateChangeTimestampMonotonic': '73665875484', 'InactiveExitTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'InactiveExitTimestampMonotonic': '73665875484', 'ActiveEnterTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ActiveEnterTimestampMonotonic': '73665875484', 'ActiveExitTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ActiveExitTimestampMonotonic': '73665855390', 'InactiveEnterTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'InactiveEnterTimestampMonotonic': '73665859078', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ConditionTimestampMonotonic': '73665860881', 'AssertTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'AssertTimestampMonotonic': '73665860890', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': '11fb6819a8bb4f6c946abffcec6a6a8c', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmdbd', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmdbd', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmdbd: active"
2025-07-24 04:57:34,281 p=70170 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmctld', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '0', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'exit-code', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '[not set]', 'GID': '[not set]', 'NRestarts': '261', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 07:57:30 MSK', 'ExecMainStartTimestampMonotonic': '74281463131', 'ExecMainExitTimestamp': 'Thu 2025-07-24 07:57:30 MSK', 'ExecMainExitTimestampMonotonic': '74281483688', 'ExecMainPID': '97127', 'ExecMainCode': '1', 'ExecMainStatus': '1', 'ExecStart': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D ; ignore_errors=no ; start_time=[Thu 2025-07-24 07:57:30 MSK] ; stop_time=[Thu 2025-07-24 07:57:30 MSK] ; pid=97127 ; code=exited ; status=1 }', 'ExecStartEx': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D ; flags= ; start_time=[Thu 2025-07-24 07:57:30 MSK] ; stop_time=[Thu 2025-07-24 07:57:30 MSK] ; pid=97127 ; code=exited ; status=1 }', 'Slice': 'system.slice', 'ControlGroupId': '198195', 'MemoryCurrent': '[not set]', 'MemoryPeak': '[not set]', 'MemorySwapCurrent': '[not set]', 'MemorySwapPeak': '[not set]', 'MemoryZSwapCurrent': '[not set]', 'MemoryAvailable': '11580190720', 'CPUUsageNSec': '23687000', 'TasksCurrent': '[not set]', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmctld.service', 'Names': 'slurmctld.service', 'Requires': 'sysinit.target system.slice -.mount', 'Wants': 'slurmdbd.service munge.service tmp.mount', 'WantedBy': 'multi-user.target', 'Conflicts': 'shutdown.target', 'Before': 'multi-user.target shutdown.target', 'After': 'system.slice sysinit.target network.target systemd-tmpfiles-setup.service systemd-journald.socket basic.target slurmdbd.service tmp.mount munge.service -.mount', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm controller daemon', 'LoadState': 'loaded', 'ActiveState': 'activating', 'FreezerState': 'running', 'SubState': 'auto-restart', 'FragmentPath': '/etc/systemd/system/slurmctld.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 07:57:30 MSK', 'StateChangeTimestampMonotonic': '74281484385', 'InactiveExitTimestamp': 'Thu 2025-07-24 07:57:30 MSK', 'InactiveExitTimestampMonotonic': '74281484385', 'ActiveEnterTimestamp': 'Thu 2025-07-24 07:57:30 MSK', 'ActiveEnterTimestampMonotonic': '74281463333', 'ActiveExitTimestamp': 'Thu 2025-07-24 07:57:30 MSK', 'ActiveExitTimestampMonotonic': '74281483846', 'InactiveEnterTimestamp': 'Thu 2025-07-24 07:57:30 MSK', 'InactiveEnterTimestampMonotonic': '74281483846', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 07:52:15 MSK', 'ConditionTimestampMonotonic': '73966797669', 'AssertTimestamp': 'Thu 2025-07-24 07:52:15 MSK', 'AssertTimestampMonotonic': '73966797677', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': '6b5fbcac35604e41a55d81e77ca97d3b', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmctld', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmctld', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmctld: activating"
2025-07-24 04:57:34,293 p=70170 u=master n=ansible | TASK [[TEST] Тестовая команда scontrol] ***********************************************************************************************************************************************
2025-07-24 04:57:34,294 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:34 +0000 (0:00:00.098)       0:00:15.730 ********* 
2025-07-24 04:57:34,548 p=70170 u=master n=ansible | ok: [sm01]
2025-07-24 04:57:34,553 p=70170 u=master n=ansible | TASK [[TEST] Результат scontrol ping] *************************************************************************************************************************************************
2025-07-24 04:57:34,553 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:34 +0000 (0:00:00.258)       0:00:15.989 ********* 
2025-07-24 04:57:34,576 p=70170 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 scontrol ping:\n❌ ОШИБКА:"
2025-07-24 04:57:34,585 p=70170 u=master n=ansible | RUNNING HANDLER [slurm_master : restart slurmctld] ************************************************************************************************************************************
2025-07-24 04:57:34,585 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:34 +0000 (0:00:00.032)       0:00:16.022 ********* 
2025-07-24 04:57:35,406 p=70170 u=master n=ansible | changed: [sm01]
2025-07-24 04:57:35,413 p=70170 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-24 04:57:35,413 p=70170 u=master n=ansible | sm01                       : ok=36   changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-24 04:57:35,413 p=70170 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 16 seconds
2025-07-24 04:57:35,413 p=70170 u=master n=ansible | Thursday 24 July 2025  04:57:35 +0000 (0:00:00.828)       0:00:16.850 ********* 
2025-07-24 04:57:35,413 p=70170 u=master n=ansible | =============================================================================== 
2025-07-24 04:57:35,413 p=70170 u=master n=ansible | slurm_master : [SERVICES] Пауза после запуска slurmdbd ------------------------------------------------------------------------------------------------------------------------- 3.06s
2025-07-24 04:57:35,414 p=70170 u=master n=ansible | [TEST] Проверка созданных файлов ----------------------------------------------------------------------------------------------------------------------------------------------- 1.30s
2025-07-24 04:57:35,414 p=70170 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.10s
2025-07-24 04:57:35,414 p=70170 u=master n=ansible | slurm_master : [SERVICES] Перезагрузка systemd daemon -------------------------------------------------------------------------------------------------------------------------- 1.10s
2025-07-24 04:57:35,414 p=70170 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.92s
2025-07-24 04:57:35,414 p=70170 u=master n=ansible | [TEST] Проверка сервисов ------------------------------------------------------------------------------------------------------------------------------------------------------- 0.90s
2025-07-24 04:57:35,414 p=70170 u=master n=ansible | slurm_master : [CONFIG] Копирование конфигов на NFS для распространения -------------------------------------------------------------------------------------------------------- 0.89s
2025-07-24 04:57:35,414 p=70170 u=master n=ansible | slurm_master : restart slurmctld ----------------------------------------------------------------------------------------------------------------------------------------------- 0.83s
2025-07-24 04:57:35,414 p=70170 u=master n=ansible | slurm_master : [CONFIG] Создание конфига slurmdbd.conf ------------------------------------------------------------------------------------------------------------------------- 0.77s
2025-07-24 04:57:35,414 p=70170 u=master n=ansible | slurm_master : [CONFIG] Создание gres.conf для GPU ----------------------------------------------------------------------------------------------------------------------------- 0.62s
2025-07-24 04:57:35,414 p=70170 u=master n=ansible | slurm_master : [CONFIG] Создание cgroup.conf ----------------------------------------------------------------------------------------------------------------------------------- 0.60s
2025-07-24 04:57:35,414 p=70170 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmdbd ------------------------------------------------------------------------------------------------------------------- 0.60s
2025-07-24 04:57:35,415 p=70170 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmctld ------------------------------------------------------------------------------------------------------------------ 0.56s
2025-07-24 04:57:35,415 p=70170 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmdbd (сначала база) ----------------------------------------------------------------------------------------------------------------------- 0.52s
2025-07-24 04:57:35,415 p=70170 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmctld (после базы) ------------------------------------------------------------------------------------------------------------------------ 0.48s
2025-07-24 04:57:35,415 p=70170 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.40s
2025-07-24 04:57:35,415 p=70170 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-24 04:57:35,415 p=70170 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-24 04:57:35,415 p=70170 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.28s
2025-07-24 04:57:35,415 p=70170 u=master n=ansible | slurm_master : [CONFIG] Создание директории для конфигов на NFS ---------------------------------------------------------------------------------------------------------------- 0.27s
2025-07-24 05:03:17,587 p=70442 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 05:03:17,587 p=70442 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 05:03:17,981 p=70442 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-24 05:03:17,994 p=70442 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-24 05:03:17,995 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:17 +0000 (0:00:00.015)       0:00:00.015 ********* 
2025-07-24 05:03:18,017 p=70442 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-24 05:03:18,021 p=70442 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-24 05:03:18,021 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:18 +0000 (0:00:00.026)       0:00:00.041 ********* 
2025-07-24 05:03:19,118 p=70442 u=master n=ansible | ok: [sm01]
2025-07-24 05:03:19,122 p=70442 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-24 05:03:19,122 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:19 +0000 (0:00:01.100)       0:00:01.142 ********* 
2025-07-24 05:03:19,167 p=70442 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-24 05:03:19,170 p=70442 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-24 05:03:19,170 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:19 +0000 (0:00:00.048)       0:00:01.191 ********* 
2025-07-24 05:03:19,202 p=70442 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-24 05:03:19,203 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:19 +0000 (0:00:00.032)       0:00:01.223 ********* 
2025-07-24 05:03:19,251 p=70442 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-24 05:03:19,256 p=70442 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-24 05:03:19,256 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:19 +0000 (0:00:00.053)       0:00:01.276 ********* 
2025-07-24 05:03:19,307 p=70442 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-24 05:03:19,314 p=70442 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-24 05:03:19,315 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:19 +0000 (0:00:00.058)       0:00:01.335 ********* 
2025-07-24 05:03:19,591 p=70442 u=master n=ansible | ok: [sm01]
2025-07-24 05:03:19,595 p=70442 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-24 05:03:19,595 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:19 +0000 (0:00:00.280)       0:00:01.616 ********* 
2025-07-24 05:03:19,642 p=70442 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-24 05:03:19,646 p=70442 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-24 05:03:19,646 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:19 +0000 (0:00:00.051)       0:00:01.667 ********* 
2025-07-24 05:03:20,424 p=70442 u=master n=ansible | changed: [sm01]
2025-07-24 05:03:20,428 p=70442 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-24 05:03:20,429 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:20 +0000 (0:00:00.782)       0:00:02.449 ********* 
2025-07-24 05:03:20,478 p=70442 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-24 05:03:20,482 p=70442 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-24 05:03:20,482 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:20 +0000 (0:00:00.053)       0:00:02.502 ********* 
2025-07-24 05:03:20,776 p=70442 u=master n=ansible | ok: [sm01]
2025-07-24 05:03:20,780 p=70442 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-24 05:03:20,780 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:20 +0000 (0:00:00.298)       0:00:02.801 ********* 
2025-07-24 05:03:21,073 p=70442 u=master n=ansible | ok: [sm01]
2025-07-24 05:03:21,078 p=70442 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-24 05:03:21,078 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:21 +0000 (0:00:00.297)       0:00:03.098 ********* 
2025-07-24 05:03:21,127 p=70442 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-24 05:03:21,132 p=70442 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-24 05:03:21,132 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:21 +0000 (0:00:00.053)       0:00:03.152 ********* 
2025-07-24 05:03:21,153 p=70442 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-24 05:03:21,163 p=70442 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-24 05:03:21,163 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:21 +0000 (0:00:00.031)       0:00:03.183 ********* 
2025-07-24 05:03:22,048 p=70442 u=master n=ansible | changed: [sm01]
2025-07-24 05:03:22,053 p=70442 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание конфига slurmdbd.conf] *************************************************************************************************************************
2025-07-24 05:03:22,053 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:22 +0000 (0:00:00.889)       0:00:04.073 ********* 
2025-07-24 05:03:22,777 p=70442 u=master n=ansible | ok: [sm01]
2025-07-24 05:03:22,782 p=70442 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание gres.conf для GPU] *****************************************************************************************************************************
2025-07-24 05:03:22,782 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:22 +0000 (0:00:00.728)       0:00:04.802 ********* 
2025-07-24 05:03:23,391 p=70442 u=master n=ansible | ok: [sm01]
2025-07-24 05:03:23,395 p=70442 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание cgroup.conf] ***********************************************************************************************************************************
2025-07-24 05:03:23,396 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:23 +0000 (0:00:00.613)       0:00:05.416 ********* 
2025-07-24 05:03:23,986 p=70442 u=master n=ansible | ok: [sm01]
2025-07-24 05:03:23,991 p=70442 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание директории для конфигов на NFS] ****************************************************************************************************************
2025-07-24 05:03:23,991 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:23 +0000 (0:00:00.595)       0:00:06.012 ********* 
2025-07-24 05:03:24,251 p=70442 u=master n=ansible | ok: [sm01]
2025-07-24 05:03:24,256 p=70442 u=master n=ansible | TASK [slurm_master : [CONFIG] Копирование конфигов на NFS для распространения] ********************************************************************************************************
2025-07-24 05:03:24,256 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:24 +0000 (0:00:00.264)       0:00:06.277 ********* 
2025-07-24 05:03:24,559 p=70442 u=master n=ansible | changed: [sm01] => (item=slurm.conf)
2025-07-24 05:03:24,835 p=70442 u=master n=ansible | ok: [sm01] => (item=cgroup.conf)
2025-07-24 05:03:25,111 p=70442 u=master n=ansible | ok: [sm01] => (item=gres.conf)
2025-07-24 05:03:25,116 p=70442 u=master n=ansible | TASK [slurm_master : [CONFIG] Конфигурация создана] ***********************************************************************************************************************************
2025-07-24 05:03:25,116 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:25 +0000 (0:00:00.860)       0:00:07.137 ********* 
2025-07-24 05:03:25,135 p=70442 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Конфигурация Slurm:\n✅ slurm.conf создан\n✅ gres.conf создан (AutoDetect=nvml)\n✅ cgroup.conf создан\n✅ slurmdbd.conf создан\n\U0001F4E4 Файлы скопированы в /sw/config/ для распространения"
2025-07-24 05:03:25,138 p=70442 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка systemd сервисов] ***********************************************************************************************************************
2025-07-24 05:03:25,139 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:25 +0000 (0:00:00.022)       0:00:07.159 ********* 
2025-07-24 05:03:25,161 p=70442 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/services.yml for sm01
2025-07-24 05:03:25,173 p=70442 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmctld] ******************************************************************************************************************
2025-07-24 05:03:25,173 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:25 +0000 (0:00:00.034)       0:00:07.193 ********* 
2025-07-24 05:03:25,726 p=70442 u=master n=ansible | ok: [sm01]
2025-07-24 05:03:25,731 p=70442 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmdbd] *******************************************************************************************************************
2025-07-24 05:03:25,731 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:25 +0000 (0:00:00.557)       0:00:07.751 ********* 
2025-07-24 05:03:26,311 p=70442 u=master n=ansible | ok: [sm01]
2025-07-24 05:03:26,316 p=70442 u=master n=ansible | TASK [slurm_master : [SERVICES] Перезагрузка systemd daemon] **************************************************************************************************************************
2025-07-24 05:03:26,316 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:26 +0000 (0:00:00.584)       0:00:08.336 ********* 
2025-07-24 05:03:27,396 p=70442 u=master n=ansible | ok: [sm01]
2025-07-24 05:03:27,400 p=70442 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmdbd (сначала база)] ***********************************************************************************************************************
2025-07-24 05:03:27,400 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:27 +0000 (0:00:01.084)       0:00:09.421 ********* 
2025-07-24 05:03:27,933 p=70442 u=master n=ansible | ok: [sm01]
2025-07-24 05:03:27,938 p=70442 u=master n=ansible | TASK [slurm_master : [SERVICES] Пауза после запуска slurmdbd] *************************************************************************************************************************
2025-07-24 05:03:27,938 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:27 +0000 (0:00:00.537)       0:00:09.958 ********* 
2025-07-24 05:03:27,986 p=70442 u=master n=ansible | Pausing for 3 seconds
2025-07-24 05:03:27,987 p=70442 u=master n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-24 05:03:30,993 p=70442 u=master n=ansible | ok: [sm01]
2025-07-24 05:03:30,999 p=70442 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmctld (после базы)] ************************************************************************************************************************
2025-07-24 05:03:30,999 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:30 +0000 (0:00:03.060)       0:00:13.019 ********* 
2025-07-24 05:03:31,735 p=70442 u=master n=ansible | ok: [sm01]
2025-07-24 05:03:31,739 p=70442 u=master n=ansible | TASK [slurm_master : [SERVICES] Сервисы запущены] *************************************************************************************************************************************
2025-07-24 05:03:31,740 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:31 +0000 (0:00:00.740)       0:00:13.760 ********* 
2025-07-24 05:03:31,760 p=70442 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F39B️ Slurm сервисы:\n✅ slurmdbd запущен\n✅ slurmctld запущен\n\U0001F527 Проверьте: systemctl status slurmctld slurmdbd"
2025-07-24 05:03:31,764 p=70442 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Завершение настройки] *****************************************************************************************************************************
2025-07-24 05:03:31,764 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:31 +0000 (0:00:00.024)       0:00:13.784 ********* 
2025-07-24 05:03:31,814 p=70442 u=master n=ansible | ok: [sm01] => 
  msg: "✅ Slurm Master настроен!\n\U0001F527 Кластер: hpc-cluster\n\U0001F39B️ Controller: sm01:6817\n\U0001F4BE Database: включена"
2025-07-24 05:03:31,820 p=70442 u=master n=ansible | TASK [[TEST] Проверка созданных файлов] ***********************************************************************************************************************************************
2025-07-24 05:03:31,820 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:31 +0000 (0:00:00.056)       0:00:13.841 ********* 
2025-07-24 05:03:32,111 p=70442 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurm.conf)
2025-07-24 05:03:32,413 p=70442 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurmdbd.conf)
2025-07-24 05:03:32,664 p=70442 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/gres.conf)
2025-07-24 05:03:32,914 p=70442 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmctld.service)
2025-07-24 05:03:33,609 p=70442 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmdbd.service)
2025-07-24 05:03:33,615 p=70442 u=master n=ansible | TASK [[TEST] Результаты проверки файлов] **********************************************************************************************************************************************
2025-07-24 05:03:33,615 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:33 +0000 (0:00:01.795)       0:00:15.636 ********* 
2025-07-24 05:03:33,676 p=70442 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurm.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 4013, 'inode': 1835034, 'dev': 2050, 'nlink': 1, 'atime': 1753333404.5241346, 'mtime': 1753333401.6501796, 'ctime': 1753333402.010174, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '00eaf6b8e5f17b5a4a168be27da529412001b47e', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '3453814798', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurm.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurm.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurm.conf: ✅ создан"
2025-07-24 05:03:33,681 p=70442 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurmdbd.conf', 'mode': '0600', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2318, 'inode': 1835035, 'dev': 2050, 'nlink': 1, 'atime': 1753332094.6684244, 'mtime': 1753332084.9605834, 'ctime': 1753332085.3325772, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': False, 'xgrp': False, 'woth': False, 'roth': False, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '379c00da27c17c640f268d909eb3fcca82934d56', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '3854950354', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurmdbd.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurmdbd.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurmdbd.conf: ✅ создан"
2025-07-24 05:03:33,687 p=70442 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/gres.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2225, 'inode': 1835031, 'dev': 2050, 'nlink': 1, 'atime': 1753331668.4423857, 'mtime': 1753331666.2524214, 'ctime': 1753331666.4904175, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '9c4de4a563fafe257ea173d75e4b265f37f70c7e', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '1956799153', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/gres.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/gres.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/gres.conf: ✅ создан"
2025-07-24 05:03:33,693 p=70442 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmctld.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 587, 'inode': 1835033, 'dev': 2050, 'nlink': 1, 'atime': 1753331674.9132805, 'mtime': 1753331668.8643787, 'ctime': 1753331669.0903752, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': '46eb21197027702db250059307749d445a8cbfc1', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '968271735', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmctld.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmctld.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmctld.service: ✅ создан"
2025-07-24 05:03:33,700 p=70442 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmdbd.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 690, 'inode': 1835036, 'dev': 2050, 'nlink': 1, 'atime': 1753332426.971969, 'mtime': 1753332425.8459873, 'ctime': 1753332426.0779836, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': '33d45fae188dc48fbaa9cc10e6db19a4d355f02b', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '3262396044', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmdbd.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmdbd.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmdbd.service: ✅ создан"
2025-07-24 05:03:33,707 p=70442 u=master n=ansible | TASK [[TEST] Проверка сервисов] *******************************************************************************************************************************************************
2025-07-24 05:03:33,707 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:33 +0000 (0:00:00.091)       0:00:15.728 ********* 
2025-07-24 05:03:34,221 p=70442 u=master n=ansible | ok: [sm01] => (item=slurmdbd)
2025-07-24 05:03:34,774 p=70442 u=master n=ansible | ok: [sm01] => (item=slurmctld)
2025-07-24 05:03:34,782 p=70442 u=master n=ansible | TASK [[TEST] Статус сервисов] *********************************************************************************************************************************************************
2025-07-24 05:03:34,782 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:34 +0000 (0:00:01.074)       0:00:16.802 ********* 
2025-07-24 05:03:34,859 p=70442 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmdbd', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '94321', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '1001', 'GID': '988', 'NRestarts': '0', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ExecMainStartTimestampMonotonic': '73665875213', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '94321', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmdbd.service', 'ControlGroupId': '186372', 'MemoryCurrent': '7184384', 'MemoryPeak': '7946240', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11591159808', 'CPUUsageNSec': '409273000', 'TasksCurrent': '41', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmdbd.service', 'Names': 'slurmdbd.service', 'Requires': 'system.slice -.mount sysinit.target', 'Wants': 'munge.service mariadb.service tmp.mount', 'WantedBy': 'multi-user.target slurmctld.service', 'Conflicts': 'shutdown.target', 'Before': 'slurmctld.service multi-user.target shutdown.target', 'After': 'basic.target munge.service mariadb.service tmp.mount sysinit.target system.slice systemd-journald.socket -.mount systemd-tmpfiles-setup.service network.target', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm DBD accounting daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmdbd.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'StateChangeTimestampMonotonic': '73665875484', 'InactiveExitTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'InactiveExitTimestampMonotonic': '73665875484', 'ActiveEnterTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ActiveEnterTimestampMonotonic': '73665875484', 'ActiveExitTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ActiveExitTimestampMonotonic': '73665855390', 'InactiveEnterTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'InactiveEnterTimestampMonotonic': '73665859078', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ConditionTimestampMonotonic': '73665860881', 'AssertTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'AssertTimestampMonotonic': '73665860890', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': '11fb6819a8bb4f6c946abffcec6a6a8c', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmdbd', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmdbd', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmdbd: active"
2025-07-24 05:03:34,869 p=70442 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmctld', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '99220', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '1001', 'GID': '988', 'NRestarts': '328', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 08:03:26 MSK', 'ExecMainStartTimestampMonotonic': '74637962078', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '99220', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmctld.service', 'ControlGroupId': '201142', 'MemoryCurrent': '3211264', 'MemoryPeak': '3710976', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11585998848', 'CPUUsageNSec': '18814000', 'TasksCurrent': '25', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmctld.service', 'Names': 'slurmctld.service', 'Requires': 'system.slice -.mount sysinit.target', 'Wants': 'munge.service tmp.mount slurmdbd.service', 'WantedBy': 'multi-user.target', 'Conflicts': 'shutdown.target', 'Before': 'shutdown.target multi-user.target', 'After': 'network.target system.slice -.mount basic.target slurmdbd.service systemd-journald.socket munge.service sysinit.target tmp.mount systemd-tmpfiles-setup.service', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm controller daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmctld.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 08:03:26 MSK', 'StateChangeTimestampMonotonic': '74637962242', 'InactiveExitTimestamp': 'Thu 2025-07-24 08:03:21 MSK', 'InactiveExitTimestampMonotonic': '74632729868', 'ActiveEnterTimestamp': 'Thu 2025-07-24 08:03:26 MSK', 'ActiveEnterTimestampMonotonic': '74637962242', 'ActiveExitTimestamp': 'Thu 2025-07-24 08:03:21 MSK', 'ActiveExitTimestampMonotonic': '74632729474', 'InactiveEnterTimestamp': 'Thu 2025-07-24 08:03:21 MSK', 'InactiveEnterTimestampMonotonic': '74632729474', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 07:57:35 MSK', 'ConditionTimestampMonotonic': '74286369671', 'AssertTimestamp': 'Thu 2025-07-24 07:57:35 MSK', 'AssertTimestampMonotonic': '74286369679', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': '192304a6516f47b08833f2aceb50e142', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmctld', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmctld', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmctld: active"
2025-07-24 05:03:34,881 p=70442 u=master n=ansible | TASK [[TEST] Тестовая команда scontrol] ***********************************************************************************************************************************************
2025-07-24 05:03:34,881 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:34 +0000 (0:00:00.099)       0:00:16.902 ********* 
2025-07-24 05:03:35,152 p=70442 u=master n=ansible | ok: [sm01]
2025-07-24 05:03:35,157 p=70442 u=master n=ansible | TASK [[TEST] Результат scontrol ping] *************************************************************************************************************************************************
2025-07-24 05:03:35,157 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:35 +0000 (0:00:00.275)       0:00:17.177 ********* 
2025-07-24 05:03:35,181 p=70442 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 scontrol ping:\n❌ ОШИБКА:"
2025-07-24 05:03:35,190 p=70442 u=master n=ansible | RUNNING HANDLER [slurm_master : restart slurmctld] ************************************************************************************************************************************
2025-07-24 05:03:35,190 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:35 +0000 (0:00:00.033)       0:00:17.211 ********* 
2025-07-24 05:03:46,887 p=70442 u=master n=ansible | changed: [sm01]
2025-07-24 05:03:46,895 p=70442 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-24 05:03:46,895 p=70442 u=master n=ansible | sm01                       : ok=36   changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-24 05:03:46,895 p=70442 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 28 seconds
2025-07-24 05:03:46,895 p=70442 u=master n=ansible | Thursday 24 July 2025  05:03:46 +0000 (0:00:11.705)       0:00:28.916 ********* 
2025-07-24 05:03:46,896 p=70442 u=master n=ansible | =============================================================================== 
2025-07-24 05:03:46,896 p=70442 u=master n=ansible | slurm_master : restart slurmctld ---------------------------------------------------------------------------------------------------------------------------------------------- 11.71s
2025-07-24 05:03:46,896 p=70442 u=master n=ansible | slurm_master : [SERVICES] Пауза после запуска slurmdbd ------------------------------------------------------------------------------------------------------------------------- 3.06s
2025-07-24 05:03:46,896 p=70442 u=master n=ansible | [TEST] Проверка созданных файлов ----------------------------------------------------------------------------------------------------------------------------------------------- 1.80s
2025-07-24 05:03:46,896 p=70442 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.10s
2025-07-24 05:03:46,896 p=70442 u=master n=ansible | slurm_master : [SERVICES] Перезагрузка systemd daemon -------------------------------------------------------------------------------------------------------------------------- 1.08s
2025-07-24 05:03:46,896 p=70442 u=master n=ansible | [TEST] Проверка сервисов ------------------------------------------------------------------------------------------------------------------------------------------------------- 1.07s
2025-07-24 05:03:46,896 p=70442 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.89s
2025-07-24 05:03:46,897 p=70442 u=master n=ansible | slurm_master : [CONFIG] Копирование конфигов на NFS для распространения -------------------------------------------------------------------------------------------------------- 0.86s
2025-07-24 05:03:46,897 p=70442 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.78s
2025-07-24 05:03:46,897 p=70442 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmctld (после базы) ------------------------------------------------------------------------------------------------------------------------ 0.74s
2025-07-24 05:03:46,897 p=70442 u=master n=ansible | slurm_master : [CONFIG] Создание конфига slurmdbd.conf ------------------------------------------------------------------------------------------------------------------------- 0.73s
2025-07-24 05:03:46,897 p=70442 u=master n=ansible | slurm_master : [CONFIG] Создание gres.conf для GPU ----------------------------------------------------------------------------------------------------------------------------- 0.61s
2025-07-24 05:03:46,897 p=70442 u=master n=ansible | slurm_master : [CONFIG] Создание cgroup.conf ----------------------------------------------------------------------------------------------------------------------------------- 0.60s
2025-07-24 05:03:46,897 p=70442 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmdbd ------------------------------------------------------------------------------------------------------------------- 0.58s
2025-07-24 05:03:46,897 p=70442 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmctld ------------------------------------------------------------------------------------------------------------------ 0.56s
2025-07-24 05:03:46,897 p=70442 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmdbd (сначала база) ----------------------------------------------------------------------------------------------------------------------- 0.54s
2025-07-24 05:03:46,897 p=70442 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-24 05:03:46,898 p=70442 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-24 05:03:46,898 p=70442 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.28s
2025-07-24 05:03:46,898 p=70442 u=master n=ansible | [TEST] Тестовая команда scontrol ----------------------------------------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-24 08:13:08,133 p=71572 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 08:13:08,133 p=71572 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 08:13:08,533 p=71572 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-24 08:13:08,541 p=71572 u=master n=ansible | TASK [Gathering Facts] ****************************************************************************************************************************************************************
2025-07-24 08:13:08,541 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:08 +0000 (0:00:00.010)       0:00:00.010 ********* 
2025-07-24 08:13:10,064 p=71572 u=master n=ansible | ok: [sm01]
2025-07-24 08:13:10,071 p=71572 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-24 08:13:10,071 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:10 +0000 (0:00:01.529)       0:00:01.540 ********* 
2025-07-24 08:13:10,095 p=71572 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-24 08:13:10,098 p=71572 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-24 08:13:10,098 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:10 +0000 (0:00:00.027)       0:00:01.567 ********* 
2025-07-24 08:13:10,489 p=71572 u=master n=ansible | ok: [sm01]
2025-07-24 08:13:10,492 p=71572 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-24 08:13:10,492 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:10 +0000 (0:00:00.394)       0:00:01.961 ********* 
2025-07-24 08:13:10,538 p=71572 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-24 08:13:10,541 p=71572 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-24 08:13:10,541 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:10 +0000 (0:00:00.048)       0:00:02.010 ********* 
2025-07-24 08:13:10,572 p=71572 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-24 08:13:10,573 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:10 +0000 (0:00:00.031)       0:00:02.042 ********* 
2025-07-24 08:13:10,620 p=71572 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-24 08:13:10,623 p=71572 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-24 08:13:10,623 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:10 +0000 (0:00:00.050)       0:00:02.092 ********* 
2025-07-24 08:13:10,673 p=71572 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-24 08:13:10,679 p=71572 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-24 08:13:10,679 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:10 +0000 (0:00:00.055)       0:00:02.148 ********* 
2025-07-24 08:13:11,007 p=71572 u=master n=ansible | ok: [sm01]
2025-07-24 08:13:11,011 p=71572 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-24 08:13:11,011 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:11 +0000 (0:00:00.331)       0:00:02.480 ********* 
2025-07-24 08:13:11,063 p=71572 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-24 08:13:11,066 p=71572 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-24 08:13:11,066 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:11 +0000 (0:00:00.055)       0:00:02.535 ********* 
2025-07-24 08:13:11,481 p=71572 u=master n=ansible | changed: [sm01]
2025-07-24 08:13:11,484 p=71572 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-24 08:13:11,485 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:11 +0000 (0:00:00.418)       0:00:02.954 ********* 
2025-07-24 08:13:11,534 p=71572 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-24 08:13:11,538 p=71572 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-24 08:13:11,538 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:11 +0000 (0:00:00.053)       0:00:03.007 ********* 
2025-07-24 08:13:11,832 p=71572 u=master n=ansible | ok: [sm01]
2025-07-24 08:13:11,836 p=71572 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-24 08:13:11,836 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:11 +0000 (0:00:00.297)       0:00:03.305 ********* 
2025-07-24 08:13:12,144 p=71572 u=master n=ansible | ok: [sm01]
2025-07-24 08:13:12,148 p=71572 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-24 08:13:12,149 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:12 +0000 (0:00:00.312)       0:00:03.617 ********* 
2025-07-24 08:13:12,202 p=71572 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-24 08:13:12,206 p=71572 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-24 08:13:12,206 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:12 +0000 (0:00:00.057)       0:00:03.675 ********* 
2025-07-24 08:13:12,232 p=71572 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-24 08:13:12,241 p=71572 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-24 08:13:12,241 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:12 +0000 (0:00:00.035)       0:00:03.710 ********* 
2025-07-24 08:13:13,147 p=71572 u=master n=ansible | changed: [sm01]
2025-07-24 08:13:13,151 p=71572 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание конфига slurmdbd.conf] *************************************************************************************************************************
2025-07-24 08:13:13,151 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:13 +0000 (0:00:00.909)       0:00:04.620 ********* 
2025-07-24 08:13:13,790 p=71572 u=master n=ansible | changed: [sm01]
2025-07-24 08:13:13,794 p=71572 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание gres.conf для GPU] *****************************************************************************************************************************
2025-07-24 08:13:13,794 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:13 +0000 (0:00:00.642)       0:00:05.263 ********* 
2025-07-24 08:13:14,473 p=71572 u=master n=ansible | changed: [sm01]
2025-07-24 08:13:14,477 p=71572 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание cgroup.conf] ***********************************************************************************************************************************
2025-07-24 08:13:14,477 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:14 +0000 (0:00:00.683)       0:00:05.946 ********* 
2025-07-24 08:13:15,125 p=71572 u=master n=ansible | changed: [sm01]
2025-07-24 08:13:15,129 p=71572 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание директории для конфигов на NFS] ****************************************************************************************************************
2025-07-24 08:13:15,130 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:15 +0000 (0:00:00.652)       0:00:06.598 ********* 
2025-07-24 08:13:15,527 p=71572 u=master n=ansible | ok: [sm01]
2025-07-24 08:13:15,532 p=71572 u=master n=ansible | TASK [slurm_master : [CONFIG] Копирование конфигов на NFS для распространения] ********************************************************************************************************
2025-07-24 08:13:15,532 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:15 +0000 (0:00:00.402)       0:00:07.001 ********* 
2025-07-24 08:13:15,838 p=71572 u=master n=ansible | changed: [sm01] => (item=slurm.conf)
2025-07-24 08:13:16,116 p=71572 u=master n=ansible | changed: [sm01] => (item=cgroup.conf)
2025-07-24 08:13:16,398 p=71572 u=master n=ansible | changed: [sm01] => (item=gres.conf)
2025-07-24 08:13:16,403 p=71572 u=master n=ansible | TASK [slurm_master : [CONFIG] Конфигурация создана] ***********************************************************************************************************************************
2025-07-24 08:13:16,403 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:16 +0000 (0:00:00.871)       0:00:07.872 ********* 
2025-07-24 08:13:16,423 p=71572 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Конфигурация Slurm:\n✅ slurm.conf создан\n✅ gres.conf создан (AutoDetect=nvml)\n✅ cgroup.conf создан\n✅ slurmdbd.conf создан\n\U0001F4E4 Файлы скопированы в /sw/config/ для распространения"
2025-07-24 08:13:16,427 p=71572 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка systemd сервисов] ***********************************************************************************************************************
2025-07-24 08:13:16,427 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:16 +0000 (0:00:00.023)       0:00:07.896 ********* 
2025-07-24 08:13:16,448 p=71572 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/services.yml for sm01
2025-07-24 08:13:16,460 p=71572 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmctld] ******************************************************************************************************************
2025-07-24 08:13:16,460 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:16 +0000 (0:00:00.032)       0:00:07.929 ********* 
2025-07-24 08:13:17,046 p=71572 u=master n=ansible | changed: [sm01]
2025-07-24 08:13:17,050 p=71572 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmdbd] *******************************************************************************************************************
2025-07-24 08:13:17,051 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:17 +0000 (0:00:00.590)       0:00:08.520 ********* 
2025-07-24 08:13:17,631 p=71572 u=master n=ansible | ok: [sm01]
2025-07-24 08:13:17,635 p=71572 u=master n=ansible | TASK [slurm_master : [SERVICES] Перезагрузка systemd daemon] **************************************************************************************************************************
2025-07-24 08:13:17,635 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:17 +0000 (0:00:00.584)       0:00:09.104 ********* 
2025-07-24 08:13:18,687 p=71572 u=master n=ansible | ok: [sm01]
2025-07-24 08:13:18,691 p=71572 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmdbd (сначала база)] ***********************************************************************************************************************
2025-07-24 08:13:18,691 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:18 +0000 (0:00:01.055)       0:00:10.160 ********* 
2025-07-24 08:13:19,263 p=71572 u=master n=ansible | ok: [sm01]
2025-07-24 08:13:19,269 p=71572 u=master n=ansible | TASK [slurm_master : [SERVICES] Пауза после запуска slurmdbd] *************************************************************************************************************************
2025-07-24 08:13:19,269 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:19 +0000 (0:00:00.577)       0:00:10.738 ********* 
2025-07-24 08:13:19,319 p=71572 u=master n=ansible | Pausing for 3 seconds
2025-07-24 08:13:19,320 p=71572 u=master n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-24 08:13:22,326 p=71572 u=master n=ansible | ok: [sm01]
2025-07-24 08:13:22,331 p=71572 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmctld (после базы)] ************************************************************************************************************************
2025-07-24 08:13:22,331 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:22 +0000 (0:00:03.062)       0:00:13.800 ********* 
2025-07-24 08:13:22,813 p=71572 u=master n=ansible | ok: [sm01]
2025-07-24 08:13:22,817 p=71572 u=master n=ansible | TASK [slurm_master : [SERVICES] Сервисы запущены] *************************************************************************************************************************************
2025-07-24 08:13:22,817 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:22 +0000 (0:00:00.486)       0:00:14.286 ********* 
2025-07-24 08:13:22,836 p=71572 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F39B️ Slurm сервисы:\n✅ slurmdbd запущен\n✅ slurmctld запущен\n\U0001F527 Проверьте: systemctl status slurmctld slurmdbd"
2025-07-24 08:13:22,840 p=71572 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Завершение настройки] *****************************************************************************************************************************
2025-07-24 08:13:22,840 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:22 +0000 (0:00:00.022)       0:00:14.309 ********* 
2025-07-24 08:13:22,889 p=71572 u=master n=ansible | ok: [sm01] => 
  msg: "✅ Slurm Master настроен!\n\U0001F527 Кластер: hpc-cluster\n\U0001F39B️ Controller: sm01:6817\n\U0001F4BE Database: включена"
2025-07-24 08:13:22,895 p=71572 u=master n=ansible | TASK [[TEST] Проверка созданных файлов] ***********************************************************************************************************************************************
2025-07-24 08:13:22,895 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:22 +0000 (0:00:00.055)       0:00:14.364 ********* 
2025-07-24 08:13:23,173 p=71572 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurm.conf)
2025-07-24 08:13:23,422 p=71572 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurmdbd.conf)
2025-07-24 08:13:23,675 p=71572 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/gres.conf)
2025-07-24 08:13:23,923 p=71572 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmctld.service)
2025-07-24 08:13:24,172 p=71572 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmdbd.service)
2025-07-24 08:13:24,178 p=71572 u=master n=ansible | TASK [[TEST] Результаты проверки файлов] **********************************************************************************************************************************************
2025-07-24 08:13:24,179 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:24 +0000 (0:00:01.283)       0:00:15.648 ********* 
2025-07-24 08:13:24,240 p=71572 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurm.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 4013, 'inode': 1835037, 'dev': 2050, 'nlink': 1, 'atime': 1753344794.2065117, 'mtime': 1753344792.7205365, 'ctime': 1753344793.0995302, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': 'cafbd9a39a8ba6397c3001b07fff4b53c5dc9945', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '3725569482', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurm.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurm.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurm.conf: ✅ создан"
2025-07-24 08:13:24,244 p=71572 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurmdbd.conf', 'mode': '0600', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2318, 'inode': 1835034, 'dev': 2050, 'nlink': 1, 'atime': 1753344793.7345197, 'mtime': 1753344793.4955235, 'ctime': 1753344793.7435195, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': False, 'xgrp': False, 'woth': False, 'roth': False, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': 'a657639f1caa4c7e202faa0bd7d3484757b9bd7f', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '3324141192', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurmdbd.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurmdbd.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurmdbd.conf: ✅ создан"
2025-07-24 08:13:24,250 p=71572 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/gres.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2225, 'inode': 1835035, 'dev': 2050, 'nlink': 1, 'atime': 1753344796.3584762, 'mtime': 1753344794.1715124, 'ctime': 1753344794.4255083, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': 'bb93ccf0cabdbc7eb7df382a3b05d9dd81e7e416', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '1961642942', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/gres.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/gres.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/gres.conf: ✅ создан"
2025-07-24 08:13:24,257 p=71572 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmctld.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 590, 'inode': 1835032, 'dev': 2050, 'nlink': 1, 'atime': 1753344798.4444416, 'mtime': 1753344796.7704694, 'ctime': 1753344797.0064654, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': 'b5cc6f04c214721e839e1775ed109736cfb6bcc7', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '832008793', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmctld.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmctld.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmctld.service: ✅ создан"
2025-07-24 08:13:24,263 p=71572 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmdbd.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 690, 'inode': 1835036, 'dev': 2050, 'nlink': 1, 'atime': 1753332426.971969, 'mtime': 1753332425.8459873, 'ctime': 1753332426.0779836, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': '33d45fae188dc48fbaa9cc10e6db19a4d355f02b', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '3262396044', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmdbd.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmdbd.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmdbd.service: ✅ создан"
2025-07-24 08:13:24,272 p=71572 u=master n=ansible | TASK [[TEST] Проверка сервисов] *******************************************************************************************************************************************************
2025-07-24 08:13:24,272 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:24 +0000 (0:00:00.093)       0:00:15.741 ********* 
2025-07-24 08:13:24,768 p=71572 u=master n=ansible | ok: [sm01] => (item=slurmdbd)
2025-07-24 08:13:25,194 p=71572 u=master n=ansible | ok: [sm01] => (item=slurmctld)
2025-07-24 08:13:25,202 p=71572 u=master n=ansible | TASK [[TEST] Статус сервисов] *********************************************************************************************************************************************************
2025-07-24 08:13:25,203 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:25 +0000 (0:00:00.930)       0:00:16.672 ********* 
2025-07-24 08:13:25,282 p=71572 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmdbd', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '94321', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '1001', 'GID': '988', 'NRestarts': '0', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ExecMainStartTimestampMonotonic': '73665875213', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '94321', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmdbd.service', 'ControlGroupId': '186372', 'MemoryCurrent': '8749056', 'MemoryPeak': '9601024', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11561512960', 'CPUUsageNSec': '12799712000', 'TasksCurrent': '40', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmdbd.service', 'Names': 'slurmdbd.service', 'Requires': 'system.slice -.mount sysinit.target', 'Wants': 'mariadb.service tmp.mount munge.service', 'WantedBy': 'multi-user.target slurmctld.service', 'Conflicts': 'shutdown.target', 'Before': 'multi-user.target slurmctld.service shutdown.target', 'After': 'network.target tmp.mount systemd-journald.socket systemd-tmpfiles-setup.service sysinit.target system.slice -.mount basic.target mariadb.service munge.service', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm DBD accounting daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmdbd.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'StateChangeTimestampMonotonic': '73665875484', 'InactiveExitTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'InactiveExitTimestampMonotonic': '73665875484', 'ActiveEnterTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ActiveEnterTimestampMonotonic': '73665875484', 'ActiveExitTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ActiveExitTimestampMonotonic': '73665855390', 'InactiveEnterTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'InactiveEnterTimestampMonotonic': '73665859078', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'ConditionTimestampMonotonic': '73665860881', 'AssertTimestamp': 'Thu 2025-07-24 07:47:14 MSK', 'AssertTimestampMonotonic': '73665860890', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': '11fb6819a8bb4f6c946abffcec6a6a8c', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmdbd', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmdbd', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmdbd: active"
2025-07-24 08:13:25,295 p=71572 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmctld', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '0', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'exit-code', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '[not set]', 'GID': '[not set]', 'NRestarts': '2154', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 11:13:24 MSK', 'ExecMainStartTimestampMonotonic': '86035712161', 'ExecMainExitTimestamp': 'Thu 2025-07-24 11:13:24 MSK', 'ExecMainExitTimestampMonotonic': '86035776272', 'ExecMainPID': '162872', 'ExecMainCode': '1', 'ExecMainStatus': '1', 'ExecStart': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D -i ; ignore_errors=no ; start_time=[Thu 2025-07-24 11:13:24 MSK] ; stop_time=[Thu 2025-07-24 11:13:24 MSK] ; pid=162872 ; code=exited ; status=1 }', 'ExecStartEx': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D -i ; flags= ; start_time=[Thu 2025-07-24 11:13:24 MSK] ; stop_time=[Thu 2025-07-24 11:13:24 MSK] ; pid=162872 ; code=exited ; status=1 }', 'Slice': 'system.slice', 'ControlGroupId': '291827', 'MemoryCurrent': '[not set]', 'MemoryPeak': '[not set]', 'MemorySwapCurrent': '[not set]', 'MemorySwapPeak': '[not set]', 'MemoryZSwapCurrent': '[not set]', 'MemoryAvailable': '11561582592', 'CPUUsageNSec': '20815000', 'TasksCurrent': '[not set]', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmctld.service', 'Names': 'slurmctld.service', 'Requires': '-.mount system.slice sysinit.target', 'Wants': 'slurmdbd.service munge.service tmp.mount', 'WantedBy': 'multi-user.target', 'Conflicts': 'shutdown.target', 'Before': 'multi-user.target shutdown.target', 'After': 'system.slice network.target systemd-journald.socket -.mount tmp.mount slurmdbd.service sysinit.target munge.service basic.target systemd-tmpfiles-setup.service', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm controller daemon', 'LoadState': 'loaded', 'ActiveState': 'activating', 'FreezerState': 'running', 'SubState': 'auto-restart', 'FragmentPath': '/etc/systemd/system/slurmctld.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 11:13:24 MSK', 'StateChangeTimestampMonotonic': '86035776987', 'InactiveExitTimestamp': 'Thu 2025-07-24 11:13:24 MSK', 'InactiveExitTimestampMonotonic': '86035776987', 'ActiveEnterTimestamp': 'Thu 2025-07-24 11:13:24 MSK', 'ActiveEnterTimestampMonotonic': '86035712416', 'ActiveExitTimestamp': 'Thu 2025-07-24 11:13:24 MSK', 'ActiveExitTimestampMonotonic': '86035776420', 'InactiveEnterTimestamp': 'Thu 2025-07-24 11:13:24 MSK', 'InactiveEnterTimestampMonotonic': '86035776420', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 08:03:46 MSK', 'ConditionTimestampMonotonic': '74657849425', 'AssertTimestamp': 'Thu 2025-07-24 08:03:46 MSK', 'AssertTimestampMonotonic': '74657849437', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': 'c66f426b757346c6ba34b191de49b6ae', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmctld', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmctld', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmctld: activating"
2025-07-24 08:13:25,306 p=71572 u=master n=ansible | TASK [[TEST] Тестовая команда scontrol] ***********************************************************************************************************************************************
2025-07-24 08:13:25,307 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:25 +0000 (0:00:00.103)       0:00:16.775 ********* 
2025-07-24 08:13:25,564 p=71572 u=master n=ansible | ok: [sm01]
2025-07-24 08:13:25,568 p=71572 u=master n=ansible | TASK [[TEST] Результат scontrol ping] *************************************************************************************************************************************************
2025-07-24 08:13:25,569 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:25 +0000 (0:00:00.261)       0:00:17.038 ********* 
2025-07-24 08:13:25,593 p=71572 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 scontrol ping:\n❌ ОШИБКА:"
2025-07-24 08:13:25,600 p=71572 u=master n=ansible | RUNNING HANDLER [slurm_master : restart slurmctld] ************************************************************************************************************************************
2025-07-24 08:13:25,600 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:25 +0000 (0:00:00.031)       0:00:17.069 ********* 
2025-07-24 08:13:26,424 p=71572 u=master n=ansible | changed: [sm01]
2025-07-24 08:13:26,429 p=71572 u=master n=ansible | RUNNING HANDLER [slurm_master : restart slurmdbd] *************************************************************************************************************************************
2025-07-24 08:13:26,429 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:26 +0000 (0:00:00.828)       0:00:17.898 ********* 
2025-07-24 08:13:27,290 p=71572 u=master n=ansible | changed: [sm01]
2025-07-24 08:13:27,297 p=71572 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-24 08:13:27,297 p=71572 u=master n=ansible | sm01                       : ok=38   changed=9    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-24 08:13:27,298 p=71572 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 18 seconds
2025-07-24 08:13:27,298 p=71572 u=master n=ansible | Thursday 24 July 2025  08:13:27 +0000 (0:00:00.868)       0:00:18.767 ********* 
2025-07-24 08:13:27,298 p=71572 u=master n=ansible | =============================================================================== 
2025-07-24 08:13:27,298 p=71572 u=master n=ansible | slurm_master : [SERVICES] Пауза после запуска slurmdbd ------------------------------------------------------------------------------------------------------------------------- 3.06s
2025-07-24 08:13:27,298 p=71572 u=master n=ansible | Gathering Facts ---------------------------------------------------------------------------------------------------------------------------------------------------------------- 1.53s
2025-07-24 08:13:27,298 p=71572 u=master n=ansible | [TEST] Проверка созданных файлов ----------------------------------------------------------------------------------------------------------------------------------------------- 1.28s
2025-07-24 08:13:27,298 p=71572 u=master n=ansible | slurm_master : [SERVICES] Перезагрузка systemd daemon -------------------------------------------------------------------------------------------------------------------------- 1.06s
2025-07-24 08:13:27,298 p=71572 u=master n=ansible | [TEST] Проверка сервисов ------------------------------------------------------------------------------------------------------------------------------------------------------- 0.93s
2025-07-24 08:13:27,298 p=71572 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.91s
2025-07-24 08:13:27,299 p=71572 u=master n=ansible | slurm_master : [CONFIG] Копирование конфигов на NFS для распространения -------------------------------------------------------------------------------------------------------- 0.87s
2025-07-24 08:13:27,299 p=71572 u=master n=ansible | slurm_master : restart slurmdbd ------------------------------------------------------------------------------------------------------------------------------------------------ 0.87s
2025-07-24 08:13:27,299 p=71572 u=master n=ansible | slurm_master : restart slurmctld ----------------------------------------------------------------------------------------------------------------------------------------------- 0.83s
2025-07-24 08:13:27,299 p=71572 u=master n=ansible | slurm_master : [CONFIG] Создание gres.conf для GPU ----------------------------------------------------------------------------------------------------------------------------- 0.68s
2025-07-24 08:13:27,299 p=71572 u=master n=ansible | slurm_master : [CONFIG] Создание cgroup.conf ----------------------------------------------------------------------------------------------------------------------------------- 0.65s
2025-07-24 08:13:27,299 p=71572 u=master n=ansible | slurm_master : [CONFIG] Создание конфига slurmdbd.conf ------------------------------------------------------------------------------------------------------------------------- 0.64s
2025-07-24 08:13:27,299 p=71572 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmctld ------------------------------------------------------------------------------------------------------------------ 0.59s
2025-07-24 08:13:27,299 p=71572 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmdbd ------------------------------------------------------------------------------------------------------------------- 0.58s
2025-07-24 08:13:27,299 p=71572 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmdbd (сначала база) ----------------------------------------------------------------------------------------------------------------------- 0.58s
2025-07-24 08:13:27,299 p=71572 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmctld (после базы) ------------------------------------------------------------------------------------------------------------------------ 0.49s
2025-07-24 08:13:27,299 p=71572 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.42s
2025-07-24 08:13:27,299 p=71572 u=master n=ansible | slurm_master : [CONFIG] Создание директории для конфигов на NFS ---------------------------------------------------------------------------------------------------------------- 0.40s
2025-07-24 08:13:27,300 p=71572 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 0.39s
2025-07-24 08:13:27,300 p=71572 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.33s
2025-07-24 09:56:57,364 p=71994 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 09:56:57,364 p=71994 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 09:56:57,776 p=71994 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-24 09:56:57,785 p=71994 u=master n=ansible | TASK [Gathering Facts] ****************************************************************************************************************************************************************
2025-07-24 09:56:57,785 p=71994 u=master n=ansible | Thursday 24 July 2025  09:56:57 +0000 (0:00:00.011)       0:00:00.011 ********* 
2025-07-24 09:56:59,759 p=71994 u=master n=ansible | ok: [sm01]
2025-07-24 09:56:59,767 p=71994 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-24 09:56:59,767 p=71994 u=master n=ansible | Thursday 24 July 2025  09:56:59 +0000 (0:00:01.981)       0:00:01.992 ********* 
2025-07-24 09:56:59,790 p=71994 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-24 09:56:59,793 p=71994 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-24 09:56:59,793 p=71994 u=master n=ansible | Thursday 24 July 2025  09:56:59 +0000 (0:00:00.026)       0:00:02.018 ********* 
2025-07-24 09:57:00,213 p=71994 u=master n=ansible | ok: [sm01]
2025-07-24 09:57:00,216 p=71994 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-24 09:57:00,217 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:00 +0000 (0:00:00.423)       0:00:02.442 ********* 
2025-07-24 09:57:00,268 p=71994 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-24 09:57:00,271 p=71994 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-24 09:57:00,271 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:00 +0000 (0:00:00.054)       0:00:02.496 ********* 
2025-07-24 09:57:00,304 p=71994 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-24 09:57:00,304 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:00 +0000 (0:00:00.032)       0:00:02.529 ********* 
2025-07-24 09:57:00,352 p=71994 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-24 09:57:00,355 p=71994 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-24 09:57:00,356 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:00 +0000 (0:00:00.051)       0:00:02.581 ********* 
2025-07-24 09:57:00,406 p=71994 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-24 09:57:00,411 p=71994 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-24 09:57:00,411 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:00 +0000 (0:00:00.055)       0:00:02.636 ********* 
2025-07-24 09:57:00,694 p=71994 u=master n=ansible | ok: [sm01]
2025-07-24 09:57:00,699 p=71994 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-24 09:57:00,699 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:00 +0000 (0:00:00.287)       0:00:02.924 ********* 
2025-07-24 09:57:00,759 p=71994 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-24 09:57:00,762 p=71994 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-24 09:57:00,763 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:00 +0000 (0:00:00.063)       0:00:02.988 ********* 
2025-07-24 09:57:01,233 p=71994 u=master n=ansible | changed: [sm01]
2025-07-24 09:57:01,237 p=71994 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-24 09:57:01,237 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:01 +0000 (0:00:00.474)       0:00:03.462 ********* 
2025-07-24 09:57:01,286 p=71994 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-24 09:57:01,290 p=71994 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-24 09:57:01,290 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:01 +0000 (0:00:00.052)       0:00:03.515 ********* 
2025-07-24 09:57:01,587 p=71994 u=master n=ansible | ok: [sm01]
2025-07-24 09:57:01,591 p=71994 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-24 09:57:01,591 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:01 +0000 (0:00:00.300)       0:00:03.816 ********* 
2025-07-24 09:57:01,892 p=71994 u=master n=ansible | ok: [sm01]
2025-07-24 09:57:01,896 p=71994 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-24 09:57:01,896 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:01 +0000 (0:00:00.304)       0:00:04.121 ********* 
2025-07-24 09:57:01,950 p=71994 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-24 09:57:01,954 p=71994 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-24 09:57:01,954 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:01 +0000 (0:00:00.057)       0:00:04.179 ********* 
2025-07-24 09:57:01,980 p=71994 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-24 09:57:01,989 p=71994 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-24 09:57:01,990 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:01 +0000 (0:00:00.035)       0:00:04.215 ********* 
2025-07-24 09:57:02,997 p=71994 u=master n=ansible | changed: [sm01]
2025-07-24 09:57:03,001 p=71994 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание конфига slurmdbd.conf] *************************************************************************************************************************
2025-07-24 09:57:03,001 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:03 +0000 (0:00:01.011)       0:00:05.226 ********* 
2025-07-24 09:57:03,640 p=71994 u=master n=ansible | changed: [sm01]
2025-07-24 09:57:03,644 p=71994 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание gres.conf для GPU] *****************************************************************************************************************************
2025-07-24 09:57:03,644 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:03 +0000 (0:00:00.642)       0:00:05.869 ********* 
2025-07-24 09:57:04,290 p=71994 u=master n=ansible | changed: [sm01]
2025-07-24 09:57:04,294 p=71994 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание cgroup.conf] ***********************************************************************************************************************************
2025-07-24 09:57:04,294 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:04 +0000 (0:00:00.650)       0:00:06.519 ********* 
2025-07-24 09:57:04,914 p=71994 u=master n=ansible | changed: [sm01]
2025-07-24 09:57:04,918 p=71994 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание директории для конфигов на NFS] ****************************************************************************************************************
2025-07-24 09:57:04,919 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:04 +0000 (0:00:00.624)       0:00:07.144 ********* 
2025-07-24 09:57:05,314 p=71994 u=master n=ansible | ok: [sm01]
2025-07-24 09:57:05,319 p=71994 u=master n=ansible | TASK [slurm_master : [CONFIG] Копирование конфигов на NFS для распространения] ********************************************************************************************************
2025-07-24 09:57:05,319 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:05 +0000 (0:00:00.400)       0:00:07.544 ********* 
2025-07-24 09:57:05,625 p=71994 u=master n=ansible | changed: [sm01] => (item=slurm.conf)
2025-07-24 09:57:05,907 p=71994 u=master n=ansible | changed: [sm01] => (item=cgroup.conf)
2025-07-24 09:57:06,188 p=71994 u=master n=ansible | changed: [sm01] => (item=gres.conf)
2025-07-24 09:57:06,193 p=71994 u=master n=ansible | TASK [slurm_master : [CONFIG] Конфигурация создана] ***********************************************************************************************************************************
2025-07-24 09:57:06,193 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:06 +0000 (0:00:00.874)       0:00:08.418 ********* 
2025-07-24 09:57:06,214 p=71994 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Конфигурация Slurm:\n✅ slurm.conf создан\n✅ gres.conf создан (AutoDetect=nvml)\n✅ cgroup.conf создан\n✅ slurmdbd.conf создан\n\U0001F4E4 Файлы скопированы в /sw/config/ для распространения"
2025-07-24 09:57:06,218 p=71994 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка systemd сервисов] ***********************************************************************************************************************
2025-07-24 09:57:06,218 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:06 +0000 (0:00:00.024)       0:00:08.443 ********* 
2025-07-24 09:57:06,240 p=71994 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/services.yml for sm01
2025-07-24 09:57:06,253 p=71994 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmctld] ******************************************************************************************************************
2025-07-24 09:57:06,253 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:06 +0000 (0:00:00.034)       0:00:08.478 ********* 
2025-07-24 09:57:06,824 p=71994 u=master n=ansible | ok: [sm01]
2025-07-24 09:57:06,829 p=71994 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmdbd] *******************************************************************************************************************
2025-07-24 09:57:06,829 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:06 +0000 (0:00:00.576)       0:00:09.054 ********* 
2025-07-24 09:57:07,436 p=71994 u=master n=ansible | ok: [sm01]
2025-07-24 09:57:07,440 p=71994 u=master n=ansible | TASK [slurm_master : [SERVICES] Перезагрузка systemd daemon] **************************************************************************************************************************
2025-07-24 09:57:07,440 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:07 +0000 (0:00:00.610)       0:00:09.665 ********* 
2025-07-24 09:57:08,521 p=71994 u=master n=ansible | ok: [sm01]
2025-07-24 09:57:08,525 p=71994 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmdbd (сначала база)] ***********************************************************************************************************************
2025-07-24 09:57:08,525 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:08 +0000 (0:00:01.085)       0:00:10.750 ********* 
2025-07-24 09:57:09,041 p=71994 u=master n=ansible | ok: [sm01]
2025-07-24 09:57:09,046 p=71994 u=master n=ansible | TASK [slurm_master : [SERVICES] Пауза после запуска slurmdbd] *************************************************************************************************************************
2025-07-24 09:57:09,047 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:09 +0000 (0:00:00.521)       0:00:11.272 ********* 
2025-07-24 09:57:09,094 p=71994 u=master n=ansible | Pausing for 3 seconds
2025-07-24 09:57:09,095 p=71994 u=master n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-24 09:57:12,100 p=71994 u=master n=ansible | ok: [sm01]
2025-07-24 09:57:12,105 p=71994 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmctld (после базы)] ************************************************************************************************************************
2025-07-24 09:57:12,106 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:12 +0000 (0:00:03.059)       0:00:14.331 ********* 
2025-07-24 09:57:12,653 p=71994 u=master n=ansible | ok: [sm01]
2025-07-24 09:57:12,657 p=71994 u=master n=ansible | TASK [slurm_master : [SERVICES] Сервисы запущены] *************************************************************************************************************************************
2025-07-24 09:57:12,657 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:12 +0000 (0:00:00.551)       0:00:14.882 ********* 
2025-07-24 09:57:12,677 p=71994 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F39B️ Slurm сервисы:\n✅ slurmdbd запущен\n✅ slurmctld запущен\n\U0001F527 Проверьте: systemctl status slurmctld slurmdbd"
2025-07-24 09:57:12,680 p=71994 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Завершение настройки] *****************************************************************************************************************************
2025-07-24 09:57:12,680 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:12 +0000 (0:00:00.023)       0:00:14.905 ********* 
2025-07-24 09:57:12,730 p=71994 u=master n=ansible | ok: [sm01] => 
  msg: "✅ Slurm Master настроен!\n\U0001F527 Кластер: hpc-cluster\n\U0001F39B️ Controller: sm01:6817\n\U0001F4BE Database: включена"
2025-07-24 09:57:12,736 p=71994 u=master n=ansible | TASK [[TEST] Проверка созданных файлов] ***********************************************************************************************************************************************
2025-07-24 09:57:12,736 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:12 +0000 (0:00:00.055)       0:00:14.961 ********* 
2025-07-24 09:57:13,024 p=71994 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurm.conf)
2025-07-24 09:57:13,286 p=71994 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurmdbd.conf)
2025-07-24 09:57:13,539 p=71994 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/gres.conf)
2025-07-24 09:57:13,801 p=71994 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmctld.service)
2025-07-24 09:57:14,050 p=71994 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmdbd.service)
2025-07-24 09:57:14,057 p=71994 u=master n=ansible | TASK [[TEST] Результаты проверки файлов] **********************************************************************************************************************************************
2025-07-24 09:57:14,057 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:14 +0000 (0:00:01.321)       0:00:16.282 ********* 
2025-07-24 09:57:14,119 p=71994 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurm.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 4013, 'inode': 1835033, 'dev': 2050, 'nlink': 1, 'atime': 1753351025.5859132, 'mtime': 1753351022.4859645, 'ctime': 1753351022.9529567, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': 'cb7b7208ea5423c8a8b4f0a0a03912d5a1dc0b24', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '482638238', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurm.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurm.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurm.conf: ✅ создан"
2025-07-24 09:57:14,123 p=71994 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurmdbd.conf', 'mode': '0600', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2318, 'inode': 1835037, 'dev': 2050, 'nlink': 1, 'atime': 1753351023.5899463, 'mtime': 1753351023.35895, 'ctime': 1753351023.597946, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': False, 'xgrp': False, 'woth': False, 'roth': False, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': 'a3ce7cd469ae3b36e629545e366a78a05518568a', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '436598599', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurmdbd.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurmdbd.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurmdbd.conf: ✅ создан"
2025-07-24 09:57:14,129 p=71994 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/gres.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2225, 'inode': 1835034, 'dev': 2050, 'nlink': 1, 'atime': 1753351026.1529038, 'mtime': 1753351024.0079393, 'ctime': 1753351024.2479353, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '178aa0b034a3237229fb0553abc5961a0981a35b', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '2551209221', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/gres.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/gres.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/gres.conf: ✅ создан"
2025-07-24 09:57:14,136 p=71994 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmctld.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 590, 'inode': 1835032, 'dev': 2050, 'nlink': 1, 'atime': 1753344798.4444416, 'mtime': 1753344796.7704694, 'ctime': 1753344797.0064654, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': 'b5cc6f04c214721e839e1775ed109736cfb6bcc7', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '832008793', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmctld.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmctld.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmctld.service: ✅ создан"
2025-07-24 09:57:14,142 p=71994 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmdbd.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 690, 'inode': 1835036, 'dev': 2050, 'nlink': 1, 'atime': 1753332426.971969, 'mtime': 1753332425.8459873, 'ctime': 1753332426.0779836, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': '33d45fae188dc48fbaa9cc10e6db19a4d355f02b', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '3262396044', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmdbd.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmdbd.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmdbd.service: ✅ создан"
2025-07-24 09:57:14,151 p=71994 u=master n=ansible | TASK [[TEST] Проверка сервисов] *******************************************************************************************************************************************************
2025-07-24 09:57:14,151 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:14 +0000 (0:00:00.093)       0:00:16.376 ********* 
2025-07-24 09:57:14,603 p=71994 u=master n=ansible | ok: [sm01] => (item=slurmdbd)
2025-07-24 09:57:15,032 p=71994 u=master n=ansible | ok: [sm01] => (item=slurmctld)
2025-07-24 09:57:15,040 p=71994 u=master n=ansible | TASK [[TEST] Статус сервисов] *********************************************************************************************************************************************************
2025-07-24 09:57:15,040 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:15 +0000 (0:00:00.888)       0:00:17.265 ********* 
2025-07-24 09:57:15,114 p=71994 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmdbd', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '163055', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '1001', 'GID': '988', 'NRestarts': '0', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 11:13:27 MSK', 'ExecMainStartTimestampMonotonic': '86038263094', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '163055', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmdbd.service', 'ControlGroupId': '186372', 'MemoryCurrent': '10440704', 'MemoryPeak': '11239424', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11555614720', 'CPUUsageNSec': '7107945000', 'TasksCurrent': '41', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmdbd.service', 'Names': 'slurmdbd.service', 'Requires': 'system.slice -.mount sysinit.target', 'Wants': 'tmp.mount munge.service mariadb.service', 'WantedBy': 'multi-user.target slurmctld.service', 'Conflicts': 'shutdown.target', 'Before': 'slurmctld.service shutdown.target multi-user.target', 'After': '-.mount systemd-journald.socket mariadb.service tmp.mount munge.service systemd-tmpfiles-setup.service basic.target network.target system.slice sysinit.target', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm DBD accounting daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmdbd.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 11:13:27 MSK', 'StateChangeTimestampMonotonic': '86038263320', 'InactiveExitTimestamp': 'Thu 2025-07-24 11:13:27 MSK', 'InactiveExitTimestampMonotonic': '86038263320', 'ActiveEnterTimestamp': 'Thu 2025-07-24 11:13:27 MSK', 'ActiveEnterTimestampMonotonic': '86038263320', 'ActiveExitTimestamp': 'Thu 2025-07-24 11:13:27 MSK', 'ActiveExitTimestampMonotonic': '86038254532', 'InactiveEnterTimestamp': 'Thu 2025-07-24 11:13:27 MSK', 'InactiveEnterTimestampMonotonic': '86038258038', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 11:13:27 MSK', 'ConditionTimestampMonotonic': '86038259852', 'AssertTimestamp': 'Thu 2025-07-24 11:13:27 MSK', 'AssertTimestampMonotonic': '86038259865', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': 'ed01a6883dbe447792df4c811270e97b', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmdbd', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmdbd', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmdbd: active"
2025-07-24 09:57:15,125 p=71994 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmctld', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '197825', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '1001', 'GID': '988', 'NRestarts': '3331', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 12:57:07 MSK', 'ExecMainStartTimestampMonotonic': '92258463082', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '197825', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D -i ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D -i ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmctld.service', 'ControlGroupId': '341814', 'MemoryCurrent': '4009984', 'MemoryPeak': '4780032', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11555102720', 'CPUUsageNSec': '45706000', 'TasksCurrent': '41', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmctld.service', 'Names': 'slurmctld.service', 'Requires': '-.mount system.slice sysinit.target', 'Wants': 'tmp.mount slurmdbd.service munge.service', 'WantedBy': 'multi-user.target', 'Conflicts': 'shutdown.target', 'Before': 'multi-user.target shutdown.target', 'After': 'slurmdbd.service network.target sysinit.target systemd-journald.socket -.mount systemd-tmpfiles-setup.service system.slice tmp.mount munge.service basic.target', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm controller daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmctld.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 12:57:07 MSK', 'StateChangeTimestampMonotonic': '92258463257', 'InactiveExitTimestamp': 'Thu 2025-07-24 12:57:02 MSK', 'InactiveExitTimestampMonotonic': '92253249941', 'ActiveEnterTimestamp': 'Thu 2025-07-24 12:57:07 MSK', 'ActiveEnterTimestampMonotonic': '92258463257', 'ActiveExitTimestamp': 'Thu 2025-07-24 12:57:02 MSK', 'ActiveExitTimestampMonotonic': '92253249392', 'InactiveEnterTimestamp': 'Thu 2025-07-24 12:57:02 MSK', 'InactiveEnterTimestampMonotonic': '92253249392', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 11:13:26 MSK', 'ConditionTimestampMonotonic': '86037386387', 'AssertTimestamp': 'Thu 2025-07-24 11:13:26 MSK', 'AssertTimestampMonotonic': '86037386394', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': '286ac0684d7c4936a8e36167e9250542', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmctld', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmctld', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmctld: active"
2025-07-24 09:57:15,135 p=71994 u=master n=ansible | TASK [[TEST] Тестовая команда scontrol] ***********************************************************************************************************************************************
2025-07-24 09:57:15,136 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:15 +0000 (0:00:00.095)       0:00:17.361 ********* 
2025-07-24 09:57:15,393 p=71994 u=master n=ansible | ok: [sm01]
2025-07-24 09:57:15,397 p=71994 u=master n=ansible | TASK [[TEST] Результат scontrol ping] *************************************************************************************************************************************************
2025-07-24 09:57:15,397 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:15 +0000 (0:00:00.261)       0:00:17.622 ********* 
2025-07-24 09:57:15,421 p=71994 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 scontrol ping:\n❌ ОШИБКА:"
2025-07-24 09:57:15,428 p=71994 u=master n=ansible | RUNNING HANDLER [slurm_master : restart slurmctld] ************************************************************************************************************************************
2025-07-24 09:57:15,428 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:15 +0000 (0:00:00.030)       0:00:17.653 ********* 
2025-07-24 09:57:19,062 p=71994 u=master n=ansible | changed: [sm01]
2025-07-24 09:57:19,066 p=71994 u=master n=ansible | RUNNING HANDLER [slurm_master : restart slurmdbd] *************************************************************************************************************************************
2025-07-24 09:57:19,066 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:19 +0000 (0:00:03.638)       0:00:21.291 ********* 
2025-07-24 09:57:19,915 p=71994 u=master n=ansible | changed: [sm01]
2025-07-24 09:57:19,924 p=71994 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-24 09:57:19,924 p=71994 u=master n=ansible | sm01                       : ok=38   changed=8    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-24 09:57:19,924 p=71994 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 22 seconds
2025-07-24 09:57:19,925 p=71994 u=master n=ansible | Thursday 24 July 2025  09:57:19 +0000 (0:00:00.858)       0:00:22.150 ********* 
2025-07-24 09:57:19,925 p=71994 u=master n=ansible | =============================================================================== 
2025-07-24 09:57:19,925 p=71994 u=master n=ansible | slurm_master : restart slurmctld ----------------------------------------------------------------------------------------------------------------------------------------------- 3.64s
2025-07-24 09:57:19,925 p=71994 u=master n=ansible | slurm_master : [SERVICES] Пауза после запуска slurmdbd ------------------------------------------------------------------------------------------------------------------------- 3.06s
2025-07-24 09:57:19,925 p=71994 u=master n=ansible | Gathering Facts ---------------------------------------------------------------------------------------------------------------------------------------------------------------- 1.98s
2025-07-24 09:57:19,925 p=71994 u=master n=ansible | [TEST] Проверка созданных файлов ----------------------------------------------------------------------------------------------------------------------------------------------- 1.32s
2025-07-24 09:57:19,925 p=71994 u=master n=ansible | slurm_master : [SERVICES] Перезагрузка systemd daemon -------------------------------------------------------------------------------------------------------------------------- 1.09s
2025-07-24 09:57:19,926 p=71994 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 1.01s
2025-07-24 09:57:19,926 p=71994 u=master n=ansible | [TEST] Проверка сервисов ------------------------------------------------------------------------------------------------------------------------------------------------------- 0.89s
2025-07-24 09:57:19,926 p=71994 u=master n=ansible | slurm_master : [CONFIG] Копирование конфигов на NFS для распространения -------------------------------------------------------------------------------------------------------- 0.87s
2025-07-24 09:57:19,926 p=71994 u=master n=ansible | slurm_master : restart slurmdbd ------------------------------------------------------------------------------------------------------------------------------------------------ 0.86s
2025-07-24 09:57:19,926 p=71994 u=master n=ansible | slurm_master : [CONFIG] Создание gres.conf для GPU ----------------------------------------------------------------------------------------------------------------------------- 0.65s
2025-07-24 09:57:19,926 p=71994 u=master n=ansible | slurm_master : [CONFIG] Создание конфига slurmdbd.conf ------------------------------------------------------------------------------------------------------------------------- 0.64s
2025-07-24 09:57:19,926 p=71994 u=master n=ansible | slurm_master : [CONFIG] Создание cgroup.conf ----------------------------------------------------------------------------------------------------------------------------------- 0.62s
2025-07-24 09:57:19,926 p=71994 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmdbd ------------------------------------------------------------------------------------------------------------------- 0.61s
2025-07-24 09:57:19,927 p=71994 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmctld ------------------------------------------------------------------------------------------------------------------ 0.58s
2025-07-24 09:57:19,927 p=71994 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmctld (после базы) ------------------------------------------------------------------------------------------------------------------------ 0.55s
2025-07-24 09:57:19,927 p=71994 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmdbd (сначала база) ----------------------------------------------------------------------------------------------------------------------- 0.52s
2025-07-24 09:57:19,927 p=71994 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.47s
2025-07-24 09:57:19,927 p=71994 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 0.42s
2025-07-24 09:57:19,927 p=71994 u=master n=ansible | slurm_master : [CONFIG] Создание директории для конфигов на NFS ---------------------------------------------------------------------------------------------------------------- 0.40s
2025-07-24 09:57:19,927 p=71994 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-24 10:00:57,485 p=72297 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 10:00:57,485 p=72297 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 10:00:59,074 p=72297 u=master n=ansible | cn01 | FAILED | rc=4 >>
Unit slurmd.service could not be found.non-zero return code

2025-07-24 10:00:59,169 p=72297 u=master n=ansible | cn02 | FAILED | rc=4 >>
Unit slurmd.service could not be found.non-zero return code

2025-07-24 10:09:52,648 p=72395 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 10:09:52,648 p=72395 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 10:09:54,172 p=72395 u=master n=ansible | cn02 | FAILED | rc=4 >>
Unit slurmd.service could not be found.non-zero return code

2025-07-24 10:09:54,220 p=72395 u=master n=ansible | cn01 | FAILED | rc=4 >>
Unit slurmd.service could not be found.non-zero return code

2025-07-24 10:10:01,371 p=72458 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 10:10:01,371 p=72458 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 10:10:01,774 p=72458 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-24 10:10:01,788 p=72458 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-24 10:10:01,788 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:01 +0000 (0:00:00.016)       0:00:00.016 ********* 
2025-07-24 10:10:01,813 p=72458 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-24 10:10:01,817 p=72458 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-24 10:10:01,817 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:01 +0000 (0:00:00.029)       0:00:00.045 ********* 
2025-07-24 10:10:02,920 p=72458 u=master n=ansible | ok: [sm01]
2025-07-24 10:10:02,924 p=72458 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-24 10:10:02,924 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:02 +0000 (0:00:01.106)       0:00:01.152 ********* 
2025-07-24 10:10:02,971 p=72458 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-24 10:10:02,974 p=72458 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-24 10:10:02,975 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:02 +0000 (0:00:00.050)       0:00:01.203 ********* 
2025-07-24 10:10:03,008 p=72458 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-24 10:10:03,009 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:03 +0000 (0:00:00.034)       0:00:01.237 ********* 
2025-07-24 10:10:03,058 p=72458 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-24 10:10:03,063 p=72458 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-24 10:10:03,063 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:03 +0000 (0:00:00.054)       0:00:01.291 ********* 
2025-07-24 10:10:03,117 p=72458 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-24 10:10:03,124 p=72458 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-24 10:10:03,125 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:03 +0000 (0:00:00.061)       0:00:01.353 ********* 
2025-07-24 10:10:03,398 p=72458 u=master n=ansible | ok: [sm01]
2025-07-24 10:10:03,402 p=72458 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-24 10:10:03,402 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:03 +0000 (0:00:00.277)       0:00:01.630 ********* 
2025-07-24 10:10:03,452 p=72458 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-24 10:10:03,456 p=72458 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-24 10:10:03,456 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:03 +0000 (0:00:00.054)       0:00:01.684 ********* 
2025-07-24 10:10:03,864 p=72458 u=master n=ansible | changed: [sm01]
2025-07-24 10:10:03,869 p=72458 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-24 10:10:03,869 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:03 +0000 (0:00:00.412)       0:00:02.097 ********* 
2025-07-24 10:10:03,919 p=72458 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-24 10:10:03,923 p=72458 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-24 10:10:03,923 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:03 +0000 (0:00:00.053)       0:00:02.151 ********* 
2025-07-24 10:10:04,218 p=72458 u=master n=ansible | ok: [sm01]
2025-07-24 10:10:04,222 p=72458 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-24 10:10:04,223 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:04 +0000 (0:00:00.299)       0:00:02.450 ********* 
2025-07-24 10:10:04,529 p=72458 u=master n=ansible | ok: [sm01]
2025-07-24 10:10:04,534 p=72458 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-24 10:10:04,534 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:04 +0000 (0:00:00.311)       0:00:02.762 ********* 
2025-07-24 10:10:04,587 p=72458 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-24 10:10:04,592 p=72458 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-24 10:10:04,592 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:04 +0000 (0:00:00.058)       0:00:02.820 ********* 
2025-07-24 10:10:04,614 p=72458 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-24 10:10:04,624 p=72458 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-24 10:10:04,624 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:04 +0000 (0:00:00.032)       0:00:02.852 ********* 
2025-07-24 10:10:05,494 p=72458 u=master n=ansible | ok: [sm01]
2025-07-24 10:10:05,499 p=72458 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание конфига slurmdbd.conf] *************************************************************************************************************************
2025-07-24 10:10:05,499 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:05 +0000 (0:00:00.874)       0:00:03.727 ********* 
2025-07-24 10:10:06,101 p=72458 u=master n=ansible | ok: [sm01]
2025-07-24 10:10:06,105 p=72458 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание gres.conf для GPU] *****************************************************************************************************************************
2025-07-24 10:10:06,106 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:06 +0000 (0:00:00.606)       0:00:04.334 ********* 
2025-07-24 10:10:06,735 p=72458 u=master n=ansible | ok: [sm01]
2025-07-24 10:10:06,739 p=72458 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание cgroup.conf] ***********************************************************************************************************************************
2025-07-24 10:10:06,740 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:06 +0000 (0:00:00.633)       0:00:04.968 ********* 
2025-07-24 10:10:07,309 p=72458 u=master n=ansible | ok: [sm01]
2025-07-24 10:10:07,476 p=72458 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание директории для конфигов на NFS] ****************************************************************************************************************
2025-07-24 10:10:07,476 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:07 +0000 (0:00:00.736)       0:00:05.704 ********* 
2025-07-24 10:10:07,756 p=72458 u=master n=ansible | ok: [sm01]
2025-07-24 10:10:07,761 p=72458 u=master n=ansible | TASK [slurm_master : [CONFIG] Копирование конфигов на NFS для распространения] ********************************************************************************************************
2025-07-24 10:10:07,761 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:07 +0000 (0:00:00.284)       0:00:05.989 ********* 
2025-07-24 10:10:08,216 p=72458 u=master n=ansible | ok: [sm01] => (item=slurm.conf)
2025-07-24 10:10:08,507 p=72458 u=master n=ansible | ok: [sm01] => (item=cgroup.conf)
2025-07-24 10:10:08,791 p=72458 u=master n=ansible | ok: [sm01] => (item=gres.conf)
2025-07-24 10:10:08,797 p=72458 u=master n=ansible | TASK [slurm_master : [CONFIG] Конфигурация создана] ***********************************************************************************************************************************
2025-07-24 10:10:08,798 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:08 +0000 (0:00:01.036)       0:00:07.026 ********* 
2025-07-24 10:10:08,817 p=72458 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Конфигурация Slurm:\n✅ slurm.conf создан\n✅ gres.conf создан (AutoDetect=nvml)\n✅ cgroup.conf создан\n✅ slurmdbd.conf создан\n\U0001F4E4 Файлы скопированы в /sw/config/ для распространения"
2025-07-24 10:10:08,821 p=72458 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка systemd сервисов] ***********************************************************************************************************************
2025-07-24 10:10:08,821 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:08 +0000 (0:00:00.023)       0:00:07.049 ********* 
2025-07-24 10:10:08,846 p=72458 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/services.yml for sm01
2025-07-24 10:10:08,859 p=72458 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmctld] ******************************************************************************************************************
2025-07-24 10:10:08,859 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:08 +0000 (0:00:00.038)       0:00:07.087 ********* 
2025-07-24 10:10:09,423 p=72458 u=master n=ansible | ok: [sm01]
2025-07-24 10:10:09,427 p=72458 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmdbd] *******************************************************************************************************************
2025-07-24 10:10:09,427 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:09 +0000 (0:00:00.568)       0:00:07.655 ********* 
2025-07-24 10:10:10,044 p=72458 u=master n=ansible | changed: [sm01]
2025-07-24 10:10:10,048 p=72458 u=master n=ansible | TASK [slurm_master : [SERVICES] Перезагрузка systemd daemon] **************************************************************************************************************************
2025-07-24 10:10:10,048 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:10 +0000 (0:00:00.620)       0:00:08.276 ********* 
2025-07-24 10:10:11,141 p=72458 u=master n=ansible | ok: [sm01]
2025-07-24 10:10:11,145 p=72458 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmdbd (сначала база)] ***********************************************************************************************************************
2025-07-24 10:10:11,145 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:11 +0000 (0:00:01.097)       0:00:09.373 ********* 
2025-07-24 10:10:11,656 p=72458 u=master n=ansible | ok: [sm01]
2025-07-24 10:10:11,661 p=72458 u=master n=ansible | TASK [slurm_master : [SERVICES] Пауза после запуска slurmdbd] *************************************************************************************************************************
2025-07-24 10:10:11,661 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:11 +0000 (0:00:00.515)       0:00:09.889 ********* 
2025-07-24 10:10:11,709 p=72458 u=master n=ansible | Pausing for 3 seconds
2025-07-24 10:10:11,709 p=72458 u=master n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-24 10:10:14,714 p=72458 u=master n=ansible | ok: [sm01]
2025-07-24 10:10:14,720 p=72458 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmctld (после базы)] ************************************************************************************************************************
2025-07-24 10:10:14,720 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:14 +0000 (0:00:03.058)       0:00:12.948 ********* 
2025-07-24 10:10:15,212 p=72458 u=master n=ansible | ok: [sm01]
2025-07-24 10:10:15,217 p=72458 u=master n=ansible | TASK [slurm_master : [SERVICES] Сервисы запущены] *************************************************************************************************************************************
2025-07-24 10:10:15,217 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:15 +0000 (0:00:00.497)       0:00:13.445 ********* 
2025-07-24 10:10:15,238 p=72458 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F39B️ Slurm сервисы:\n✅ slurmdbd запущен\n✅ slurmctld запущен\n\U0001F527 Проверьте: systemctl status slurmctld slurmdbd"
2025-07-24 10:10:15,242 p=72458 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Завершение настройки] *****************************************************************************************************************************
2025-07-24 10:10:15,242 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:15 +0000 (0:00:00.024)       0:00:13.470 ********* 
2025-07-24 10:10:15,292 p=72458 u=master n=ansible | ok: [sm01] => 
  msg: "✅ Slurm Master настроен!\n\U0001F527 Кластер: hpc-cluster\n\U0001F39B️ Controller: sm01:6817\n\U0001F4BE Database: включена"
2025-07-24 10:10:15,299 p=72458 u=master n=ansible | TASK [[TEST] Проверка созданных файлов] ***********************************************************************************************************************************************
2025-07-24 10:10:15,299 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:15 +0000 (0:00:00.057)       0:00:13.527 ********* 
2025-07-24 10:10:15,581 p=72458 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurm.conf)
2025-07-24 10:10:15,840 p=72458 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurmdbd.conf)
2025-07-24 10:10:16,102 p=72458 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/gres.conf)
2025-07-24 10:10:16,362 p=72458 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmctld.service)
2025-07-24 10:10:16,616 p=72458 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmdbd.service)
2025-07-24 10:10:16,623 p=72458 u=master n=ansible | TASK [[TEST] Результаты проверки файлов] **********************************************************************************************************************************************
2025-07-24 10:10:16,623 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:16 +0000 (0:00:01.323)       0:00:14.851 ********* 
2025-07-24 10:10:16,687 p=72458 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurm.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 4013, 'inode': 1835033, 'dev': 2050, 'nlink': 1, 'atime': 1753351025.5859132, 'mtime': 1753351022.4859645, 'ctime': 1753351022.9529567, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': 'cb7b7208ea5423c8a8b4f0a0a03912d5a1dc0b24', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '482638238', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurm.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurm.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurm.conf: ✅ создан"
2025-07-24 10:10:16,692 p=72458 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurmdbd.conf', 'mode': '0600', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2318, 'inode': 1835037, 'dev': 2050, 'nlink': 1, 'atime': 1753351033.2417865, 'mtime': 1753351023.35895, 'ctime': 1753351023.597946, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': False, 'xgrp': False, 'woth': False, 'roth': False, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': 'a3ce7cd469ae3b36e629545e366a78a05518568a', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '436598599', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurmdbd.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurmdbd.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurmdbd.conf: ✅ создан"
2025-07-24 10:10:16,698 p=72458 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/gres.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2225, 'inode': 1835034, 'dev': 2050, 'nlink': 1, 'atime': 1753351026.1529038, 'mtime': 1753351024.0079393, 'ctime': 1753351024.2479353, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '178aa0b034a3237229fb0553abc5961a0981a35b', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '2551209221', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/gres.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/gres.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/gres.conf: ✅ создан"
2025-07-24 10:10:16,704 p=72458 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmctld.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 590, 'inode': 1835032, 'dev': 2050, 'nlink': 1, 'atime': 1753344798.4444416, 'mtime': 1753344796.7704694, 'ctime': 1753344797.0064654, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': 'b5cc6f04c214721e839e1775ed109736cfb6bcc7', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '832008793', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmctld.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmctld.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmctld.service: ✅ создан"
2025-07-24 10:10:16,710 p=72458 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmdbd.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 721, 'inode': 1835031, 'dev': 2050, 'nlink': 1, 'atime': 1753351810.9089837, 'mtime': 1753351809.7690024, 'ctime': 1753351810.0039988, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': 'c11a46375987d44401bfd407475adcbce4bd2212', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '1227475877', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmdbd.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmdbd.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmdbd.service: ✅ создан"
2025-07-24 10:10:16,718 p=72458 u=master n=ansible | TASK [[TEST] Проверка сервисов] *******************************************************************************************************************************************************
2025-07-24 10:10:16,718 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:16 +0000 (0:00:00.095)       0:00:14.946 ********* 
2025-07-24 10:10:17,184 p=72458 u=master n=ansible | ok: [sm01] => (item=slurmdbd)
2025-07-24 10:10:17,624 p=72458 u=master n=ansible | ok: [sm01] => (item=slurmctld)
2025-07-24 10:10:17,632 p=72458 u=master n=ansible | TASK [[TEST] Статус сервисов] *********************************************************************************************************************************************************
2025-07-24 10:10:17,632 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:17 +0000 (0:00:00.913)       0:00:15.860 ********* 
2025-07-24 10:10:17,709 p=72458 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmdbd', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '198148', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '1001', 'GID': '988', 'NRestarts': '0', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'ExecMainStartTimestampMonotonic': '92270891156', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '198148', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmdbd.service', 'ControlGroupId': '186372', 'MemoryCurrent': '9928704', 'MemoryPeak': '11239424', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11539787776', 'CPUUsageNSec': '376012000', 'TasksCurrent': '41', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'root', 'Group': 'root', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmdbd.service', 'Names': 'slurmdbd.service', 'Requires': 'sysinit.target system.slice -.mount', 'Wants': 'mariadb.service munge.service tmp.mount', 'WantedBy': 'slurmctld.service multi-user.target', 'Conflicts': 'shutdown.target', 'Before': 'slurmctld.service multi-user.target shutdown.target', 'After': 'munge.service systemd-tmpfiles-setup.service systemd-journald.socket tmp.mount system.slice network.target sysinit.target -.mount basic.target mariadb.service', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm DBD accounting daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmdbd.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'StateChangeTimestampMonotonic': '92270891575', 'InactiveExitTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'InactiveExitTimestampMonotonic': '92270891575', 'ActiveEnterTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'ActiveEnterTimestampMonotonic': '92270891575', 'ActiveExitTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'ActiveExitTimestampMonotonic': '92270878882', 'InactiveEnterTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'InactiveEnterTimestampMonotonic': '92270882979', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'ConditionTimestampMonotonic': '92270884820', 'AssertTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'AssertTimestampMonotonic': '92270884832', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': '4daf9957cba24cd7bec9f785874402b7', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmdbd', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmdbd', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmdbd: active"
2025-07-24 10:10:17,719 p=72458 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmctld', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '198051', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '1001', 'GID': '988', 'NRestarts': '0', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'ExecMainStartTimestampMonotonic': '92270033118', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '198051', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D -i ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D -i ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmctld.service', 'ControlGroupId': '341856', 'MemoryCurrent': '6656000', 'MemoryPeak': '7725056', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11538857984', 'CPUUsageNSec': '1360092000', 'TasksCurrent': '36', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmctld.service', 'Names': 'slurmctld.service', 'Requires': 'system.slice sysinit.target -.mount', 'Wants': 'munge.service slurmdbd.service tmp.mount', 'WantedBy': 'multi-user.target', 'Conflicts': 'shutdown.target', 'Before': 'shutdown.target multi-user.target', 'After': 'systemd-tmpfiles-setup.service network.target slurmdbd.service sysinit.target systemd-journald.socket basic.target system.slice -.mount munge.service tmp.mount', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm controller daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmctld.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'StateChangeTimestampMonotonic': '92270033353', 'InactiveExitTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'InactiveExitTimestampMonotonic': '92270033353', 'ActiveEnterTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'ActiveEnterTimestampMonotonic': '92270033353', 'ActiveExitTimestamp': 'Thu 2025-07-24 12:57:16 MSK', 'ActiveExitTimestampMonotonic': '92267226224', 'InactiveEnterTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'InactiveEnterTimestampMonotonic': '92270026083', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'ConditionTimestampMonotonic': '92270027983', 'AssertTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'AssertTimestampMonotonic': '92270027993', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': '845ed5d7f9d34e4a97c2523d0cea3cad', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmctld', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmctld', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmctld: active"
2025-07-24 10:10:17,730 p=72458 u=master n=ansible | TASK [[TEST] Тестовая команда scontrol] ***********************************************************************************************************************************************
2025-07-24 10:10:17,731 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:17 +0000 (0:00:00.098)       0:00:15.959 ********* 
2025-07-24 10:10:17,997 p=72458 u=master n=ansible | ok: [sm01]
2025-07-24 10:10:18,002 p=72458 u=master n=ansible | TASK [[TEST] Результат scontrol ping] *************************************************************************************************************************************************
2025-07-24 10:10:18,002 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:18 +0000 (0:00:00.271)       0:00:16.230 ********* 
2025-07-24 10:10:18,027 p=72458 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 scontrol ping:\n❌ ОШИБКА:"
2025-07-24 10:10:18,037 p=72458 u=master n=ansible | RUNNING HANDLER [slurm_master : restart slurmdbd] *************************************************************************************************************************************
2025-07-24 10:10:18,037 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:18 +0000 (0:00:00.034)       0:00:16.265 ********* 
2025-07-24 10:10:18,889 p=72458 u=master n=ansible | changed: [sm01]
2025-07-24 10:10:18,897 p=72458 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-24 10:10:18,897 p=72458 u=master n=ansible | sm01                       : ok=36   changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-24 10:10:18,897 p=72458 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 17 seconds
2025-07-24 10:10:18,897 p=72458 u=master n=ansible | Thursday 24 July 2025  10:10:18 +0000 (0:00:00.860)       0:00:17.125 ********* 
2025-07-24 10:10:18,897 p=72458 u=master n=ansible | =============================================================================== 
2025-07-24 10:10:18,898 p=72458 u=master n=ansible | slurm_master : [SERVICES] Пауза после запуска slurmdbd ------------------------------------------------------------------------------------------------------------------------- 3.06s
2025-07-24 10:10:18,898 p=72458 u=master n=ansible | [TEST] Проверка созданных файлов ----------------------------------------------------------------------------------------------------------------------------------------------- 1.32s
2025-07-24 10:10:18,898 p=72458 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.11s
2025-07-24 10:10:18,898 p=72458 u=master n=ansible | slurm_master : [SERVICES] Перезагрузка systemd daemon -------------------------------------------------------------------------------------------------------------------------- 1.10s
2025-07-24 10:10:18,898 p=72458 u=master n=ansible | slurm_master : [CONFIG] Копирование конфигов на NFS для распространения -------------------------------------------------------------------------------------------------------- 1.04s
2025-07-24 10:10:18,898 p=72458 u=master n=ansible | [TEST] Проверка сервисов ------------------------------------------------------------------------------------------------------------------------------------------------------- 0.91s
2025-07-24 10:10:18,898 p=72458 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.87s
2025-07-24 10:10:18,898 p=72458 u=master n=ansible | slurm_master : restart slurmdbd ------------------------------------------------------------------------------------------------------------------------------------------------ 0.86s
2025-07-24 10:10:18,898 p=72458 u=master n=ansible | slurm_master : [CONFIG] Создание cgroup.conf ----------------------------------------------------------------------------------------------------------------------------------- 0.74s
2025-07-24 10:10:18,898 p=72458 u=master n=ansible | slurm_master : [CONFIG] Создание gres.conf для GPU ----------------------------------------------------------------------------------------------------------------------------- 0.63s
2025-07-24 10:10:18,899 p=72458 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmdbd ------------------------------------------------------------------------------------------------------------------- 0.62s
2025-07-24 10:10:18,899 p=72458 u=master n=ansible | slurm_master : [CONFIG] Создание конфига slurmdbd.conf ------------------------------------------------------------------------------------------------------------------------- 0.61s
2025-07-24 10:10:18,899 p=72458 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmctld ------------------------------------------------------------------------------------------------------------------ 0.57s
2025-07-24 10:10:18,899 p=72458 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmdbd (сначала база) ----------------------------------------------------------------------------------------------------------------------- 0.52s
2025-07-24 10:10:18,899 p=72458 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmctld (после базы) ------------------------------------------------------------------------------------------------------------------------ 0.50s
2025-07-24 10:10:18,899 p=72458 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.41s
2025-07-24 10:10:18,899 p=72458 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-24 10:10:18,899 p=72458 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.30s
2025-07-24 10:10:18,899 p=72458 u=master n=ansible | slurm_master : [CONFIG] Создание директории для конфигов на NFS ---------------------------------------------------------------------------------------------------------------- 0.28s
2025-07-24 10:10:18,899 p=72458 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.28s
2025-07-24 10:13:08,065 p=72700 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 10:13:08,065 p=72700 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 10:13:08,490 p=72700 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-24 10:13:08,504 p=72700 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-24 10:13:08,504 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:08 +0000 (0:00:00.016)       0:00:00.016 ********* 
2025-07-24 10:13:08,528 p=72700 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-24 10:13:08,532 p=72700 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-24 10:13:08,532 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:08 +0000 (0:00:00.027)       0:00:00.044 ********* 
2025-07-24 10:13:09,651 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:09,655 p=72700 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-24 10:13:09,655 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:09 +0000 (0:00:01.123)       0:00:01.167 ********* 
2025-07-24 10:13:09,701 p=72700 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-24 10:13:09,705 p=72700 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-24 10:13:09,705 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:09 +0000 (0:00:00.049)       0:00:01.216 ********* 
2025-07-24 10:13:09,739 p=72700 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-24 10:13:09,739 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:09 +0000 (0:00:00.034)       0:00:01.251 ********* 
2025-07-24 10:13:09,788 p=72700 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-24 10:13:09,792 p=72700 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-24 10:13:09,792 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:09 +0000 (0:00:00.053)       0:00:01.304 ********* 
2025-07-24 10:13:09,846 p=72700 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-24 10:13:09,853 p=72700 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-24 10:13:09,854 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:09 +0000 (0:00:00.061)       0:00:01.365 ********* 
2025-07-24 10:13:10,133 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:10,137 p=72700 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-24 10:13:10,137 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:10 +0000 (0:00:00.283)       0:00:01.649 ********* 
2025-07-24 10:13:10,191 p=72700 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-24 10:13:10,195 p=72700 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-24 10:13:10,195 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:10 +0000 (0:00:00.058)       0:00:01.707 ********* 
2025-07-24 10:13:10,607 p=72700 u=master n=ansible | changed: [sm01]
2025-07-24 10:13:10,611 p=72700 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-24 10:13:10,611 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:10 +0000 (0:00:00.416)       0:00:02.123 ********* 
2025-07-24 10:13:10,661 p=72700 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-24 10:13:10,665 p=72700 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-24 10:13:10,665 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:10 +0000 (0:00:00.053)       0:00:02.177 ********* 
2025-07-24 10:13:10,975 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:10,980 p=72700 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-24 10:13:10,980 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:10 +0000 (0:00:00.314)       0:00:02.491 ********* 
2025-07-24 10:13:11,283 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:11,287 p=72700 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-24 10:13:11,287 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:11 +0000 (0:00:00.307)       0:00:02.799 ********* 
2025-07-24 10:13:11,342 p=72700 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-24 10:13:11,346 p=72700 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-24 10:13:11,346 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:11 +0000 (0:00:00.059)       0:00:02.858 ********* 
2025-07-24 10:13:11,368 p=72700 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-24 10:13:11,378 p=72700 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-24 10:13:11,379 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:11 +0000 (0:00:00.032)       0:00:02.890 ********* 
2025-07-24 10:13:12,257 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:12,262 p=72700 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание конфига slurmdbd.conf] *************************************************************************************************************************
2025-07-24 10:13:12,262 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:12 +0000 (0:00:00.883)       0:00:03.774 ********* 
2025-07-24 10:13:12,866 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:12,871 p=72700 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание gres.conf для GPU] *****************************************************************************************************************************
2025-07-24 10:13:12,871 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:12 +0000 (0:00:00.609)       0:00:04.383 ********* 
2025-07-24 10:13:13,486 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:13,490 p=72700 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание cgroup.conf] ***********************************************************************************************************************************
2025-07-24 10:13:13,490 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:13 +0000 (0:00:00.619)       0:00:05.002 ********* 
2025-07-24 10:13:14,129 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:14,134 p=72700 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание директории для конфигов на NFS] ****************************************************************************************************************
2025-07-24 10:13:14,134 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:14 +0000 (0:00:00.643)       0:00:05.646 ********* 
2025-07-24 10:13:14,402 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:14,407 p=72700 u=master n=ansible | TASK [slurm_master : [CONFIG] Копирование конфигов на NFS для распространения] ********************************************************************************************************
2025-07-24 10:13:14,408 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:14 +0000 (0:00:00.273)       0:00:05.919 ********* 
2025-07-24 10:13:14,852 p=72700 u=master n=ansible | ok: [sm01] => (item=slurm.conf)
2025-07-24 10:13:15,133 p=72700 u=master n=ansible | ok: [sm01] => (item=cgroup.conf)
2025-07-24 10:13:15,417 p=72700 u=master n=ansible | ok: [sm01] => (item=gres.conf)
2025-07-24 10:13:15,424 p=72700 u=master n=ansible | TASK [slurm_master : [CONFIG] Конфигурация создана] ***********************************************************************************************************************************
2025-07-24 10:13:15,424 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:15 +0000 (0:00:01.016)       0:00:06.936 ********* 
2025-07-24 10:13:15,444 p=72700 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Конфигурация Slurm:\n✅ slurm.conf создан\n✅ gres.conf создан (AutoDetect=nvml)\n✅ cgroup.conf создан\n✅ slurmdbd.conf создан\n\U0001F4E4 Файлы скопированы в /sw/config/ для распространения"
2025-07-24 10:13:15,448 p=72700 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка systemd сервисов] ***********************************************************************************************************************
2025-07-24 10:13:15,448 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:15 +0000 (0:00:00.023)       0:00:06.960 ********* 
2025-07-24 10:13:15,471 p=72700 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/services.yml for sm01
2025-07-24 10:13:15,483 p=72700 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmctld] ******************************************************************************************************************
2025-07-24 10:13:15,484 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:15 +0000 (0:00:00.035)       0:00:06.995 ********* 
2025-07-24 10:13:16,044 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:16,048 p=72700 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmdbd] *******************************************************************************************************************
2025-07-24 10:13:16,048 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:16 +0000 (0:00:00.564)       0:00:07.560 ********* 
2025-07-24 10:13:16,639 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:16,644 p=72700 u=master n=ansible | TASK [slurm_master : [SERVICES] Перезагрузка systemd daemon] **************************************************************************************************************************
2025-07-24 10:13:16,644 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:16 +0000 (0:00:00.595)       0:00:08.156 ********* 
2025-07-24 10:13:17,733 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:17,738 p=72700 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmdbd (сначала база)] ***********************************************************************************************************************
2025-07-24 10:13:17,738 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:17 +0000 (0:00:01.094)       0:00:09.250 ********* 
2025-07-24 10:13:18,239 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:18,245 p=72700 u=master n=ansible | TASK [slurm_master : [SERVICES] Пауза после запуска slurmdbd] *************************************************************************************************************************
2025-07-24 10:13:18,245 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:18 +0000 (0:00:00.506)       0:00:09.757 ********* 
2025-07-24 10:13:18,293 p=72700 u=master n=ansible | Pausing for 3 seconds
2025-07-24 10:13:18,294 p=72700 u=master n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-24 10:13:21,299 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:21,305 p=72700 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmctld (после базы)] ************************************************************************************************************************
2025-07-24 10:13:21,305 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:21 +0000 (0:00:03.059)       0:00:12.816 ********* 
2025-07-24 10:13:21,800 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:21,805 p=72700 u=master n=ansible | TASK [slurm_master : [SERVICES] Сервисы запущены] *************************************************************************************************************************************
2025-07-24 10:13:21,805 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:21 +0000 (0:00:00.500)       0:00:13.317 ********* 
2025-07-24 10:13:21,825 p=72700 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F39B️ Slurm сервисы:\n✅ slurmdbd запущен\n✅ slurmctld запущен\n\U0001F527 Проверьте: systemctl status slurmctld slurmdbd"
2025-07-24 10:13:21,829 p=72700 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Завершение настройки] *****************************************************************************************************************************
2025-07-24 10:13:21,829 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:21 +0000 (0:00:00.024)       0:00:13.341 ********* 
2025-07-24 10:13:21,880 p=72700 u=master n=ansible | ok: [sm01] => 
  msg: "✅ Slurm Master настроен!\n\U0001F527 Кластер: hpc-cluster\n\U0001F39B️ Controller: sm01:6817\n\U0001F4BE Database: включена"
2025-07-24 10:13:21,887 p=72700 u=master n=ansible | TASK [[TEST] Проверка созданных файлов] ***********************************************************************************************************************************************
2025-07-24 10:13:21,887 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:21 +0000 (0:00:00.057)       0:00:13.399 ********* 
2025-07-24 10:13:22,167 p=72700 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurm.conf)
2025-07-24 10:13:22,419 p=72700 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurmdbd.conf)
2025-07-24 10:13:22,669 p=72700 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/gres.conf)
2025-07-24 10:13:22,925 p=72700 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmctld.service)
2025-07-24 10:13:23,176 p=72700 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmdbd.service)
2025-07-24 10:13:23,183 p=72700 u=master n=ansible | TASK [[TEST] Результаты проверки файлов] **********************************************************************************************************************************************
2025-07-24 10:13:23,183 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:23 +0000 (0:00:01.296)       0:00:14.695 ********* 
2025-07-24 10:13:23,246 p=72700 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurm.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 4013, 'inode': 1835033, 'dev': 2050, 'nlink': 1, 'atime': 1753351025.5859132, 'mtime': 1753351022.4859645, 'ctime': 1753351022.9529567, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': 'cb7b7208ea5423c8a8b4f0a0a03912d5a1dc0b24', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '482638238', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurm.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurm.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurm.conf: ✅ создан"
2025-07-24 10:13:23,250 p=72700 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurmdbd.conf', 'mode': '0600', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2318, 'inode': 1835037, 'dev': 2050, 'nlink': 1, 'atime': 1753351033.2417865, 'mtime': 1753351023.35895, 'ctime': 1753351023.597946, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': False, 'xgrp': False, 'woth': False, 'roth': False, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': 'a3ce7cd469ae3b36e629545e366a78a05518568a', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '436598599', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurmdbd.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurmdbd.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurmdbd.conf: ✅ создан"
2025-07-24 10:13:23,256 p=72700 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/gres.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2225, 'inode': 1835034, 'dev': 2050, 'nlink': 1, 'atime': 1753351026.1529038, 'mtime': 1753351024.0079393, 'ctime': 1753351024.2479353, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '178aa0b034a3237229fb0553abc5961a0981a35b', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '2551209221', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/gres.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/gres.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/gres.conf: ✅ создан"
2025-07-24 10:13:23,262 p=72700 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmctld.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 590, 'inode': 1835032, 'dev': 2050, 'nlink': 1, 'atime': 1753344798.4444416, 'mtime': 1753344796.7704694, 'ctime': 1753344797.0064654, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': 'b5cc6f04c214721e839e1775ed109736cfb6bcc7', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '832008793', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmctld.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmctld.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmctld.service: ✅ создан"
2025-07-24 10:13:23,269 p=72700 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmdbd.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 721, 'inode': 1835031, 'dev': 2050, 'nlink': 1, 'atime': 1753351810.9089837, 'mtime': 1753351809.7690024, 'ctime': 1753351810.0039988, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': 'c11a46375987d44401bfd407475adcbce4bd2212', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '1227475877', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmdbd.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmdbd.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmdbd.service: ✅ создан"
2025-07-24 10:13:23,276 p=72700 u=master n=ansible | TASK [[TEST] Проверка сервисов] *******************************************************************************************************************************************************
2025-07-24 10:13:23,277 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:23 +0000 (0:00:00.093)       0:00:14.788 ********* 
2025-07-24 10:13:23,732 p=72700 u=master n=ansible | ok: [sm01] => (item=slurmdbd)
2025-07-24 10:13:24,173 p=72700 u=master n=ansible | ok: [sm01] => (item=slurmctld)
2025-07-24 10:13:24,181 p=72700 u=master n=ansible | TASK [[TEST] Статус сервисов] *********************************************************************************************************************************************************
2025-07-24 10:13:24,182 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:24 +0000 (0:00:00.905)       0:00:15.693 ********* 
2025-07-24 10:13:24,257 p=72700 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmdbd', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '198808', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '0', 'GID': '0', 'NRestarts': '0', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'ExecMainStartTimestampMonotonic': '93049865192', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '198808', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmdbd.service', 'ControlGroupId': '186372', 'MemoryCurrent': '10153984', 'MemoryPeak': '11239424', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11539812352', 'CPUUsageNSec': '89806000', 'TasksCurrent': '41', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'root', 'Group': 'root', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmdbd.service', 'Names': 'slurmdbd.service', 'Requires': 'system.slice sysinit.target -.mount', 'Wants': 'mariadb.service tmp.mount munge.service', 'WantedBy': 'multi-user.target slurmctld.service', 'Conflicts': 'shutdown.target', 'Before': 'shutdown.target multi-user.target slurmctld.service', 'After': 'system.slice systemd-journald.socket munge.service -.mount network.target basic.target sysinit.target tmp.mount systemd-tmpfiles-setup.service mariadb.service', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm DBD accounting daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmdbd.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'StateChangeTimestampMonotonic': '93049865492', 'InactiveExitTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'InactiveExitTimestampMonotonic': '93049865492', 'ActiveEnterTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'ActiveEnterTimestampMonotonic': '93049865492', 'ActiveExitTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'ActiveExitTimestampMonotonic': '93049854437', 'InactiveEnterTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'InactiveEnterTimestampMonotonic': '93049858196', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'ConditionTimestampMonotonic': '93049860598', 'AssertTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'AssertTimestampMonotonic': '93049860626', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': 'f6f792194d1d4b0088f197c67a8a7cb0', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmdbd', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmdbd', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmdbd: active"
2025-07-24 10:13:24,267 p=72700 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmctld', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '198051', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '1001', 'GID': '988', 'NRestarts': '0', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'ExecMainStartTimestampMonotonic': '92270033118', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '198051', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D -i ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D -i ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmctld.service', 'ControlGroupId': '341856', 'MemoryCurrent': '6807552', 'MemoryPeak': '7725056', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11555692544', 'CPUUsageNSec': '1675885000', 'TasksCurrent': '41', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmctld.service', 'Names': 'slurmctld.service', 'Requires': 'system.slice sysinit.target -.mount', 'Wants': 'tmp.mount slurmdbd.service munge.service', 'WantedBy': 'multi-user.target', 'Conflicts': 'shutdown.target', 'Before': 'shutdown.target multi-user.target', 'After': 'network.target -.mount slurmdbd.service systemd-tmpfiles-setup.service sysinit.target systemd-journald.socket tmp.mount basic.target system.slice munge.service', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm controller daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmctld.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'StateChangeTimestampMonotonic': '92270033353', 'InactiveExitTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'InactiveExitTimestampMonotonic': '92270033353', 'ActiveEnterTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'ActiveEnterTimestampMonotonic': '92270033353', 'ActiveExitTimestamp': 'Thu 2025-07-24 12:57:16 MSK', 'ActiveExitTimestampMonotonic': '92267226224', 'InactiveEnterTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'InactiveEnterTimestampMonotonic': '92270026083', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'ConditionTimestampMonotonic': '92270027983', 'AssertTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'AssertTimestampMonotonic': '92270027993', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': '845ed5d7f9d34e4a97c2523d0cea3cad', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmctld', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmctld', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmctld: active"
2025-07-24 10:13:24,279 p=72700 u=master n=ansible | TASK [[TEST] Тест scontrol ping] ******************************************************************************************************************************************************
2025-07-24 10:13:24,280 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:24 +0000 (0:00:00.097)       0:00:15.791 ********* 
2025-07-24 10:13:24,545 p=72700 u=master n=ansible | ok: [sm01]
2025-07-24 10:13:24,549 p=72700 u=master n=ansible | TASK [[TEST] Результат scontrol ping] *************************************************************************************************************************************************
2025-07-24 10:13:24,550 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:24 +0000 (0:00:00.270)       0:00:16.061 ********* 
2025-07-24 10:13:24,602 p=72700 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 scontrol ping:\n✅ УСПЕХ: Slurmctld(primary) at sm01 is UP"
2025-07-24 10:13:24,614 p=72700 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-24 10:13:24,614 p=72700 u=master n=ansible | sm01                       : ok=35   changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-24 10:13:24,615 p=72700 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 16 seconds
2025-07-24 10:13:24,615 p=72700 u=master n=ansible | Thursday 24 July 2025  10:13:24 +0000 (0:00:00.065)       0:00:16.126 ********* 
2025-07-24 10:13:24,615 p=72700 u=master n=ansible | =============================================================================== 
2025-07-24 10:13:24,615 p=72700 u=master n=ansible | slurm_master : [SERVICES] Пауза после запуска slurmdbd ------------------------------------------------------------------------------------------------------------------------- 3.06s
2025-07-24 10:13:24,615 p=72700 u=master n=ansible | [TEST] Проверка созданных файлов ----------------------------------------------------------------------------------------------------------------------------------------------- 1.30s
2025-07-24 10:13:24,615 p=72700 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.12s
2025-07-24 10:13:24,615 p=72700 u=master n=ansible | slurm_master : [SERVICES] Перезагрузка systemd daemon -------------------------------------------------------------------------------------------------------------------------- 1.09s
2025-07-24 10:13:24,616 p=72700 u=master n=ansible | slurm_master : [CONFIG] Копирование конфигов на NFS для распространения -------------------------------------------------------------------------------------------------------- 1.02s
2025-07-24 10:13:24,616 p=72700 u=master n=ansible | [TEST] Проверка сервисов ------------------------------------------------------------------------------------------------------------------------------------------------------- 0.91s
2025-07-24 10:13:24,616 p=72700 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.88s
2025-07-24 10:13:24,616 p=72700 u=master n=ansible | slurm_master : [CONFIG] Создание cgroup.conf ----------------------------------------------------------------------------------------------------------------------------------- 0.64s
2025-07-24 10:13:24,616 p=72700 u=master n=ansible | slurm_master : [CONFIG] Создание gres.conf для GPU ----------------------------------------------------------------------------------------------------------------------------- 0.62s
2025-07-24 10:13:24,616 p=72700 u=master n=ansible | slurm_master : [CONFIG] Создание конфига slurmdbd.conf ------------------------------------------------------------------------------------------------------------------------- 0.61s
2025-07-24 10:13:24,616 p=72700 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmdbd ------------------------------------------------------------------------------------------------------------------- 0.60s
2025-07-24 10:13:24,616 p=72700 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmctld ------------------------------------------------------------------------------------------------------------------ 0.56s
2025-07-24 10:13:24,616 p=72700 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmdbd (сначала база) ----------------------------------------------------------------------------------------------------------------------- 0.51s
2025-07-24 10:13:24,617 p=72700 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmctld (после базы) ------------------------------------------------------------------------------------------------------------------------ 0.50s
2025-07-24 10:13:24,617 p=72700 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.42s
2025-07-24 10:13:24,617 p=72700 u=master n=ansible | slurm_master : [MARIADB] Тест подключения пользователя Slurm ------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-24 10:13:24,617 p=72700 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.31s
2025-07-24 10:13:24,617 p=72700 u=master n=ansible | slurm_master : [MARIADB] Проверка работы свежей MariaDB ------------------------------------------------------------------------------------------------------------------------ 0.28s
2025-07-24 10:13:24,617 p=72700 u=master n=ansible | slurm_master : [CONFIG] Создание директории для конфигов на NFS ---------------------------------------------------------------------------------------------------------------- 0.27s
2025-07-24 10:13:24,617 p=72700 u=master n=ansible | [TEST] Тест scontrol ping ------------------------------------------------------------------------------------------------------------------------------------------------------ 0.27s
2025-07-24 16:40:10,333 p=73761 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 16:40:10,333 p=73761 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 16:40:10,733 p=73761 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-24 16:40:10,742 p=73761 u=master n=ansible | TASK [Gathering Facts] ****************************************************************************************************************************************************************
2025-07-24 16:40:10,742 p=73761 u=master n=ansible | Thursday 24 July 2025  16:40:10 +0000 (0:00:00.010)       0:00:00.010 ********* 
2025-07-24 16:40:12,466 p=73761 u=master n=ansible | ok: [sm01]
2025-07-24 16:40:12,473 p=73761 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-24 16:40:12,474 p=73761 u=master n=ansible | Thursday 24 July 2025  16:40:12 +0000 (0:00:01.731)       0:00:01.742 ********* 
2025-07-24 16:40:12,498 p=73761 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-24 16:40:12,501 p=73761 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-24 16:40:12,501 p=73761 u=master n=ansible | Thursday 24 July 2025  16:40:12 +0000 (0:00:00.027)       0:00:01.770 ********* 
2025-07-24 16:40:12,890 p=73761 u=master n=ansible | ok: [sm01]
2025-07-24 16:40:12,893 p=73761 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-24 16:40:12,894 p=73761 u=master n=ansible | Thursday 24 July 2025  16:40:12 +0000 (0:00:00.392)       0:00:02.162 ********* 
2025-07-24 16:40:12,941 p=73761 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-24 16:40:12,945 p=73761 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-24 16:40:12,945 p=73761 u=master n=ansible | Thursday 24 July 2025  16:40:12 +0000 (0:00:00.051)       0:00:02.213 ********* 
2025-07-24 16:40:12,977 p=73761 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-24 16:40:12,977 p=73761 u=master n=ansible | Thursday 24 July 2025  16:40:12 +0000 (0:00:00.032)       0:00:02.245 ********* 
2025-07-24 16:40:13,024 p=73761 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-24 16:40:13,028 p=73761 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-24 16:40:13,028 p=73761 u=master n=ansible | Thursday 24 July 2025  16:40:13 +0000 (0:00:00.050)       0:00:02.296 ********* 
2025-07-24 16:40:13,080 p=73761 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-24 16:40:13,086 p=73761 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-24 16:40:13,086 p=73761 u=master n=ansible | Thursday 24 July 2025  16:40:13 +0000 (0:00:00.058)       0:00:02.354 ********* 
2025-07-24 16:40:13,359 p=73761 u=master n=ansible | ok: [sm01]
2025-07-24 16:40:13,363 p=73761 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-24 16:40:13,363 p=73761 u=master n=ansible | Thursday 24 July 2025  16:40:13 +0000 (0:00:00.276)       0:00:02.631 ********* 
2025-07-24 16:40:13,413 p=73761 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-24 16:40:13,416 p=73761 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-24 16:40:13,416 p=73761 u=master n=ansible | Thursday 24 July 2025  16:40:13 +0000 (0:00:00.053)       0:00:02.685 ********* 
2025-07-24 16:40:13,810 p=73761 u=master n=ansible | changed: [sm01]
2025-07-24 16:40:13,815 p=73761 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-24 16:40:13,815 p=73761 u=master n=ansible | Thursday 24 July 2025  16:40:13 +0000 (0:00:00.398)       0:00:03.083 ********* 
2025-07-24 16:40:13,865 p=73761 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-24 16:40:13,868 p=73761 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-24 16:40:13,869 p=73761 u=master n=ansible | Thursday 24 July 2025  16:40:13 +0000 (0:00:00.053)       0:00:03.137 ********* 
2025-07-24 16:40:14,169 p=73761 u=master n=ansible | ok: [sm01]
2025-07-24 16:40:14,173 p=73761 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-24 16:40:14,173 p=73761 u=master n=ansible | Thursday 24 July 2025  16:40:14 +0000 (0:00:00.304)       0:00:03.442 ********* 
2025-07-24 16:40:14,476 p=73761 u=master n=ansible | ok: [sm01]
2025-07-24 16:40:14,481 p=73761 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание конфига оптимизации для Slurm] ****************************************************************************************************************
2025-07-24 16:40:14,481 p=73761 u=master n=ansible | Thursday 24 July 2025  16:40:14 +0000 (0:00:00.308)       0:00:03.750 ********* 
2025-07-24 16:40:15,294 p=73761 u=master n=ansible | ERROR! The requested handler 'restart mariadb' was not found in either the main handlers list nor in the listening handlers list
2025-07-24 16:43:34,614 p=73889 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_SUBSET option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 16:43:34,614 p=73889 u=master n=ansible | [DEPRECATION WARNING]: DEFAULT_GATHER_TIMEOUT option, the module_defaults keyword is a more generic version and can apply to all calls to the M(ansible.builtin.gather_facts) or 
M(ansible.builtin.setup) actions, use module_defaults instead. This feature will be removed from ansible-core in version 2.18. Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
2025-07-24 16:43:35,034 p=73889 u=master n=ansible | PLAY [🧪 Тестирование роли slurm_master (простая версия)] *****************************************************************************************************************************
2025-07-24 16:43:35,049 p=73889 u=master n=ansible | TASK [[TEST] Информация о тестировании] ***********************************************************************************************************************************************
2025-07-24 16:43:35,050 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:35 +0000 (0:00:00.017)       0:00:00.017 ********* 
2025-07-24 16:43:35,077 p=73889 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Тестируем упрощенную роль slurm_master на sm01\n\U0001F4E6 Slurm собран: /usr/local/slurm\n\U0001F42C MariaDB работает: проверим подключение"
2025-07-24 16:43:35,080 p=73889 u=master n=ansible | TASK [[TEST] Проверка MariaDB перед настройкой] ***************************************************************************************************************************************
2025-07-24 16:43:35,080 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:35 +0000 (0:00:00.030)       0:00:00.048 ********* 
2025-07-24 16:43:36,413 p=73889 u=master n=ansible | ok: [sm01]
2025-07-24 16:43:36,417 p=73889 u=master n=ansible | TASK [[TEST] Статус MariaDB] **********************************************************************************************************************************************************
2025-07-24 16:43:36,417 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:36 +0000 (0:00:01.336)       0:00:01.385 ********* 
2025-07-24 16:43:36,463 p=73889 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB: False"
2025-07-24 16:43:36,467 p=73889 u=master n=ansible | TASK [[TEST] Выполнение роли slurm_master] ********************************************************************************************************************************************
2025-07-24 16:43:36,467 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:36 +0000 (0:00:00.049)       0:00:01.435 ********* 
2025-07-24 16:43:36,500 p=73889 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Начало настройки Slurm Master] ********************************************************************************************************************
2025-07-24 16:43:36,500 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:36 +0000 (0:00:00.032)       0:00:01.468 ********* 
2025-07-24 16:43:36,556 p=73889 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F3AF Настройка Slurm Master узла: sm01\n\U0001F4CD Роль: primary\n\U0001F310 IP: определяется..."
2025-07-24 16:43:36,560 p=73889 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка MariaDB для Slurm] **********************************************************************************************************************
2025-07-24 16:43:36,560 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:36 +0000 (0:00:00.060)       0:00:01.528 ********* 
2025-07-24 16:43:36,614 p=73889 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/mariadb.yml for sm01
2025-07-24 16:43:36,621 p=73889 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка работы свежей MariaDB] ************************************************************************************************************************
2025-07-24 16:43:36,621 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:36 +0000 (0:00:00.060)       0:00:01.589 ********* 
2025-07-24 16:43:36,898 p=73889 u=master n=ansible | ok: [sm01]
2025-07-24 16:43:36,903 p=73889 u=master n=ansible | TASK [slurm_master : [MARIADB] Показать версию MariaDB] *******************************************************************************************************************************
2025-07-24 16:43:36,903 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:36 +0000 (0:00:00.282)       0:00:01.871 ********* 
2025-07-24 16:43:36,954 p=73889 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB версия: 10.11.13-MariaDB-0ubuntu0.24.04.1"
2025-07-24 16:43:36,958 p=73889 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия)] **********************************************************************************************
2025-07-24 16:43:36,958 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:36 +0000 (0:00:00.054)       0:00:01.925 ********* 
2025-07-24 16:43:37,366 p=73889 u=master n=ansible | changed: [sm01]
2025-07-24 16:43:37,370 p=73889 u=master n=ansible | TASK [slurm_master : [MARIADB] Результат создания пользователя] ***********************************************************************************************************************
2025-07-24 16:43:37,371 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:37 +0000 (0:00:00.412)       0:00:02.338 ********* 
2025-07-24 16:43:37,418 p=73889 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Создание пользователя: False"
2025-07-24 16:43:37,422 p=73889 u=master n=ansible | TASK [slurm_master : [MARIADB] Тест подключения пользователя Slurm] *******************************************************************************************************************
2025-07-24 16:43:37,422 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:37 +0000 (0:00:00.051)       0:00:02.390 ********* 
2025-07-24 16:43:37,718 p=73889 u=master n=ansible | ok: [sm01]
2025-07-24 16:43:37,722 p=73889 u=master n=ansible | TASK [slurm_master : [MARIADB] Проверка списка баз данных] ****************************************************************************************************************************
2025-07-24 16:43:37,723 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:37 +0000 (0:00:00.300)       0:00:02.690 ********* 
2025-07-24 16:43:38,020 p=73889 u=master n=ansible | ok: [sm01]
2025-07-24 16:43:38,026 p=73889 u=master n=ansible | TASK [slurm_master : [MARIADB] Создание конфига оптимизации для Slurm] ****************************************************************************************************************
2025-07-24 16:43:38,026 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:38 +0000 (0:00:00.303)       0:00:02.993 ********* 
2025-07-24 16:43:38,860 p=73889 u=master n=ansible | ok: [sm01]
2025-07-24 16:43:38,870 p=73889 u=master n=ansible | TASK [slurm_master : [MARIADB] Перезапуск MariaDB для применения настроек] ************************************************************************************************************
2025-07-24 16:43:38,871 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:38 +0000 (0:00:00.844)       0:00:03.838 ********* 
2025-07-24 16:43:43,005 p=73889 u=master n=ansible | changed: [sm01]
2025-07-24 16:43:43,011 p=73889 u=master n=ansible | TASK [slurm_master : [MARIADB] Финальный результат] ***********************************************************************************************************************************
2025-07-24 16:43:43,011 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:43 +0000 (0:00:04.140)       0:00:07.978 ********* 
2025-07-24 16:43:43,068 p=73889 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F42C MariaDB настройка завершена:\n\U0001F464 Пользователь: slurm\n\U0001F4CA База: slurm_acct_db\n✅ Подключение: False\n\n\U0001F4CB Доступные базы:\nDatabase\ninformation_schema\nslurm_acct_db\n\n\U0001F389 ГОТОВ ДЛЯ SLURM!"
2025-07-24 16:43:43,072 p=73889 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Создание конфигурации Slurm] **********************************************************************************************************************
2025-07-24 16:43:43,072 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:43 +0000 (0:00:00.061)       0:00:08.040 ********* 
2025-07-24 16:43:43,094 p=73889 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/config.yml for sm01
2025-07-24 16:43:43,104 p=73889 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание основного конфига slurm.conf] ******************************************************************************************************************
2025-07-24 16:43:43,105 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:43 +0000 (0:00:00.032)       0:00:08.072 ********* 
2025-07-24 16:43:43,910 p=73889 u=master n=ansible | changed: [sm01]
2025-07-24 16:43:43,914 p=73889 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание конфига slurmdbd.conf] *************************************************************************************************************************
2025-07-24 16:43:43,914 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:43 +0000 (0:00:00.809)       0:00:08.882 ********* 
2025-07-24 16:43:44,548 p=73889 u=master n=ansible | changed: [sm01]
2025-07-24 16:43:44,552 p=73889 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание gres.conf для GPU] *****************************************************************************************************************************
2025-07-24 16:43:44,552 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:44 +0000 (0:00:00.637)       0:00:09.520 ********* 
2025-07-24 16:43:45,204 p=73889 u=master n=ansible | changed: [sm01]
2025-07-24 16:43:45,209 p=73889 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание cgroup.conf] ***********************************************************************************************************************************
2025-07-24 16:43:45,209 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:45 +0000 (0:00:00.656)       0:00:10.176 ********* 
2025-07-24 16:43:45,800 p=73889 u=master n=ansible | changed: [sm01]
2025-07-24 16:43:45,804 p=73889 u=master n=ansible | TASK [slurm_master : [CONFIG] Создание директории для конфигов на NFS] ****************************************************************************************************************
2025-07-24 16:43:45,805 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:45 +0000 (0:00:00.595)       0:00:10.772 ********* 
2025-07-24 16:43:46,066 p=73889 u=master n=ansible | ok: [sm01]
2025-07-24 16:43:46,073 p=73889 u=master n=ansible | TASK [slurm_master : [CONFIG] Копирование конфигов на NFS для распространения] ********************************************************************************************************
2025-07-24 16:43:46,073 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:46 +0000 (0:00:00.268)       0:00:11.040 ********* 
2025-07-24 16:43:46,375 p=73889 u=master n=ansible | changed: [sm01] => (item=slurm.conf)
2025-07-24 16:43:46,655 p=73889 u=master n=ansible | changed: [sm01] => (item=cgroup.conf)
2025-07-24 16:43:47,018 p=73889 u=master n=ansible | changed: [sm01] => (item=gres.conf)
2025-07-24 16:43:47,024 p=73889 u=master n=ansible | TASK [slurm_master : [CONFIG] Конфигурация создана] ***********************************************************************************************************************************
2025-07-24 16:43:47,024 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:47 +0000 (0:00:00.951)       0:00:11.992 ********* 
2025-07-24 16:43:47,046 p=73889 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F4DD Конфигурация Slurm:\n✅ slurm.conf создан\n✅ gres.conf создан (AutoDetect=nvml)\n✅ cgroup.conf создан\n✅ slurmdbd.conf создан\n\U0001F4E4 Файлы скопированы в /sw/config/ для распространения"
2025-07-24 16:43:47,051 p=73889 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Настройка systemd сервисов] ***********************************************************************************************************************
2025-07-24 16:43:47,051 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:47 +0000 (0:00:00.026)       0:00:12.018 ********* 
2025-07-24 16:43:47,071 p=73889 u=master n=ansible | included: /home/master/22Jul/slurm-hpc-cluster/roles/slurm_master/tasks/services.yml for sm01
2025-07-24 16:43:47,085 p=73889 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmctld] ******************************************************************************************************************
2025-07-24 16:43:47,085 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:47 +0000 (0:00:00.034)       0:00:12.053 ********* 
2025-07-24 16:43:47,639 p=73889 u=master n=ansible | ok: [sm01]
2025-07-24 16:43:47,643 p=73889 u=master n=ansible | TASK [slurm_master : [SERVICES] Создание systemd unit для slurmdbd] *******************************************************************************************************************
2025-07-24 16:43:47,643 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:47 +0000 (0:00:00.558)       0:00:12.611 ********* 
2025-07-24 16:43:48,254 p=73889 u=master n=ansible | ok: [sm01]
2025-07-24 16:43:48,258 p=73889 u=master n=ansible | TASK [slurm_master : [SERVICES] Перезагрузка systemd daemon] **************************************************************************************************************************
2025-07-24 16:43:48,259 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:48 +0000 (0:00:00.615)       0:00:13.226 ********* 
2025-07-24 16:43:49,049 p=73889 u=master n=ansible | ok: [sm01]
2025-07-24 16:43:49,053 p=73889 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmdbd (сначала база)] ***********************************************************************************************************************
2025-07-24 16:43:49,053 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:49 +0000 (0:00:00.794)       0:00:14.021 ********* 
2025-07-24 16:43:49,577 p=73889 u=master n=ansible | ok: [sm01]
2025-07-24 16:43:49,582 p=73889 u=master n=ansible | TASK [slurm_master : [SERVICES] Пауза после запуска slurmdbd] *************************************************************************************************************************
2025-07-24 16:43:49,582 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:49 +0000 (0:00:00.528)       0:00:14.550 ********* 
2025-07-24 16:43:49,634 p=73889 u=master n=ansible | Pausing for 3 seconds
2025-07-24 16:43:49,635 p=73889 u=master n=ansible | (ctrl+C then 'C' = continue early, ctrl+C then 'A' = abort)
2025-07-24 16:43:52,640 p=73889 u=master n=ansible | ok: [sm01]
2025-07-24 16:43:52,646 p=73889 u=master n=ansible | TASK [slurm_master : [SERVICES] Запуск slurmctld (после базы)] ************************************************************************************************************************
2025-07-24 16:43:52,646 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:52 +0000 (0:00:03.063)       0:00:17.613 ********* 
2025-07-24 16:43:53,130 p=73889 u=master n=ansible | ok: [sm01]
2025-07-24 16:43:53,135 p=73889 u=master n=ansible | TASK [slurm_master : [SERVICES] Сервисы запущены] *************************************************************************************************************************************
2025-07-24 16:43:53,135 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:53 +0000 (0:00:00.489)       0:00:18.103 ********* 
2025-07-24 16:43:53,157 p=73889 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F39B️ Slurm сервисы:\n✅ slurmdbd запущен\n✅ slurmctld запущен\n\U0001F527 Проверьте: systemctl status slurmctld slurmdbd"
2025-07-24 16:43:53,161 p=73889 u=master n=ansible | TASK [slurm_master : [SLURM-MASTER] Завершение настройки] *****************************************************************************************************************************
2025-07-24 16:43:53,161 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:53 +0000 (0:00:00.025)       0:00:18.129 ********* 
2025-07-24 16:43:53,214 p=73889 u=master n=ansible | ok: [sm01] => 
  msg: "✅ Slurm Master настроен!\n\U0001F527 Кластер: hpc-cluster\n\U0001F39B️ Controller: sm01:6817\n\U0001F4BE Database: включена"
2025-07-24 16:43:53,221 p=73889 u=master n=ansible | TASK [[TEST] Проверка созданных файлов] ***********************************************************************************************************************************************
2025-07-24 16:43:53,221 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:53 +0000 (0:00:00.059)       0:00:18.189 ********* 
2025-07-24 16:43:53,498 p=73889 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurm.conf)
2025-07-24 16:43:53,751 p=73889 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/slurmdbd.conf)
2025-07-24 16:43:54,004 p=73889 u=master n=ansible | ok: [sm01] => (item=/etc/slurm/gres.conf)
2025-07-24 16:43:54,257 p=73889 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmctld.service)
2025-07-24 16:43:54,510 p=73889 u=master n=ansible | ok: [sm01] => (item=/etc/systemd/system/slurmdbd.service)
2025-07-24 16:43:54,516 p=73889 u=master n=ansible | TASK [[TEST] Результаты проверки файлов] **********************************************************************************************************************************************
2025-07-24 16:43:54,516 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:54 +0000 (0:00:01.295)       0:00:19.484 ********* 
2025-07-24 16:43:54,582 p=73889 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurm.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 4013, 'inode': 1835038, 'dev': 2050, 'nlink': 1, 'atime': 1753375426.3382046, 'mtime': 1753375423.4842515, 'ctime': 1753375423.8682451, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '1284efa68c65e73c03e76b5b53162a280ad388d2', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '1944077186', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurm.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurm.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurm.conf: ✅ создан"
2025-07-24 16:43:54,587 p=73889 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/slurmdbd.conf', 'mode': '0600', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2318, 'inode': 1835033, 'dev': 2050, 'nlink': 1, 'atime': 1753375424.5002348, 'mtime': 1753375424.2692385, 'ctime': 1753375424.5072346, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': False, 'xgrp': False, 'woth': False, 'roth': False, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '142c637022515a839ab198161b04b41880b824e0', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '28587080', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/slurmdbd.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/slurmdbd.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/slurmdbd.conf: ✅ создан"
2025-07-24 16:43:54,593 p=73889 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/slurm/gres.conf', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 1001, 'gid': 988, 'size': 2225, 'inode': 1835037, 'dev': 2050, 'nlink': 1, 'atime': 1753375426.9051955, 'mtime': 1753375424.9252279, 'ctime': 1753375425.163224, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'slurm', 'gr_name': 'slurm', 'checksum': '9a906b4ca83f13fc0d7a918d3301f668ea5c460a', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '3458324234', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/slurm/gres.conf', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/slurm/gres.conf', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/slurm/gres.conf: ✅ создан"
2025-07-24 16:43:54,600 p=73889 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmctld.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 590, 'inode': 1835032, 'dev': 2050, 'nlink': 1, 'atime': 1753344798.4444416, 'mtime': 1753344796.7704694, 'ctime': 1753344797.0064654, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': 'b5cc6f04c214721e839e1775ed109736cfb6bcc7', 'mimetype': 'text/plain', 'charset': 'us-ascii', 'version': '832008793', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmctld.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmctld.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmctld.service: ✅ создан"
2025-07-24 16:43:54,607 p=73889 u=master n=ansible | ok: [sm01] => (item={'changed': False, 'stat': {'exists': True, 'path': '/etc/systemd/system/slurmdbd.service', 'mode': '0644', 'isdir': False, 'ischr': False, 'isblk': False, 'isreg': True, 'isfifo': False, 'islnk': False, 'issock': False, 'uid': 0, 'gid': 0, 'size': 721, 'inode': 1835031, 'dev': 2050, 'nlink': 1, 'atime': 1753351810.9089837, 'mtime': 1753351809.7690024, 'ctime': 1753351810.0039988, 'wusr': True, 'rusr': True, 'xusr': False, 'wgrp': False, 'rgrp': True, 'xgrp': False, 'woth': False, 'roth': True, 'xoth': False, 'isuid': False, 'isgid': False, 'blocks': 8, 'block_size': 4096, 'device_type': 0, 'readable': True, 'writeable': True, 'executable': False, 'pw_name': 'root', 'gr_name': 'root', 'checksum': 'c11a46375987d44401bfd407475adcbce4bd2212', 'mimetype': 'text/plain', 'charset': 'utf-8', 'version': '1227475877', 'attributes': ['extents'], 'attr_flags': 'e'}, 'invocation': {'module_args': {'path': '/etc/systemd/system/slurmdbd.service', 'follow': False, 'get_checksum': True, 'get_mime': True, 'get_attributes': True, 'checksum_algorithm': 'sha1'}}, 'failed': False, 'item': '/etc/systemd/system/slurmdbd.service', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F4C1 /etc/systemd/system/slurmdbd.service: ✅ создан"
2025-07-24 16:43:54,616 p=73889 u=master n=ansible | TASK [[TEST] Проверка сервисов] *******************************************************************************************************************************************************
2025-07-24 16:43:54,616 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:54 +0000 (0:00:00.100)       0:00:19.584 ********* 
2025-07-24 16:43:55,071 p=73889 u=master n=ansible | ok: [sm01] => (item=slurmdbd)
2025-07-24 16:43:55,500 p=73889 u=master n=ansible | ok: [sm01] => (item=slurmctld)
2025-07-24 16:43:55,509 p=73889 u=master n=ansible | TASK [[TEST] Статус сервисов] *********************************************************************************************************************************************************
2025-07-24 16:43:55,509 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:55 +0000 (0:00:00.892)       0:00:20.476 ********* 
2025-07-24 16:43:55,590 p=73889 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmdbd', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '198808', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '0', 'GID': '0', 'NRestarts': '0', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'ExecMainStartTimestampMonotonic': '93049865192', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '198808', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmdbd ; argv[]=/usr/sbin/slurmdbd -D ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmdbd.service', 'ControlGroupId': '186372', 'MemoryCurrent': '13238272', 'MemoryPeak': '13799424', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11527606272', 'CPUUsageNSec': '9758864000', 'TasksCurrent': '41', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'root', 'Group': 'root', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmdbd.service', 'Names': 'slurmdbd.service', 'Requires': 'sysinit.target -.mount system.slice', 'Wants': 'tmp.mount munge.service mariadb.service', 'WantedBy': 'multi-user.target slurmctld.service', 'Conflicts': 'shutdown.target', 'Before': 'slurmctld.service multi-user.target shutdown.target', 'After': 'systemd-journald.socket tmp.mount mariadb.service -.mount network.target munge.service systemd-tmpfiles-setup.service sysinit.target system.slice basic.target', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm DBD accounting daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmdbd.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'StateChangeTimestampMonotonic': '93049865492', 'InactiveExitTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'InactiveExitTimestampMonotonic': '93049865492', 'ActiveEnterTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'ActiveEnterTimestampMonotonic': '93049865492', 'ActiveExitTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'ActiveExitTimestampMonotonic': '93049854437', 'InactiveEnterTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'InactiveEnterTimestampMonotonic': '93049858196', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'ConditionTimestampMonotonic': '93049860598', 'AssertTimestamp': 'Thu 2025-07-24 13:10:18 MSK', 'AssertTimestampMonotonic': '93049860626', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': 'f6f792194d1d4b0088f197c67a8a7cb0', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmdbd', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmdbd', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmdbd: active"
2025-07-24 16:43:55,601 p=73889 u=master n=ansible | ok: [sm01] => (item={'name': 'slurmctld', 'changed': False, 'status': {'Type': 'simple', 'ExitType': 'main', 'Restart': 'on-failure', 'RestartMode': 'normal', 'NotifyAccess': 'none', 'RestartUSec': '5s', 'RestartSteps': '0', 'RestartMaxDelayUSec': 'infinity', 'RestartUSecNext': '5s', 'TimeoutStartUSec': '1min 30s', 'TimeoutStopUSec': '1min 30s', 'TimeoutAbortUSec': '1min 30s', 'TimeoutStartFailureMode': 'terminate', 'TimeoutStopFailureMode': 'terminate', 'RuntimeMaxUSec': 'infinity', 'RuntimeRandomizedExtraUSec': '0', 'WatchdogUSec': '0', 'WatchdogTimestampMonotonic': '0', 'RootDirectoryStartOnly': 'no', 'RemainAfterExit': 'no', 'GuessMainPID': 'yes', 'MainPID': '198051', 'ControlPID': '0', 'FileDescriptorStoreMax': '0', 'NFileDescriptorStore': '0', 'FileDescriptorStorePreserve': 'restart', 'StatusErrno': '0', 'Result': 'success', 'ReloadResult': 'success', 'CleanResult': 'success', 'UID': '1001', 'GID': '988', 'NRestarts': '0', 'OOMPolicy': 'stop', 'ReloadSignal': '1', 'ExecMainStartTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'ExecMainStartTimestampMonotonic': '92270033118', 'ExecMainExitTimestampMonotonic': '0', 'ExecMainPID': '198051', 'ExecMainCode': '0', 'ExecMainStatus': '0', 'ExecStart': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D -i ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'ExecStartEx': '{ path=/usr/sbin/slurmctld ; argv[]=/usr/sbin/slurmctld -D -i ; flags= ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }', 'Slice': 'system.slice', 'ControlGroup': '/system.slice/slurmctld.service', 'ControlGroupId': '341856', 'MemoryCurrent': '6848512', 'MemoryPeak': '7995392', 'MemorySwapCurrent': '0', 'MemorySwapPeak': '0', 'MemoryZSwapCurrent': '0', 'MemoryAvailable': '11525541888', 'CPUUsageNSec': '41001292000', 'TasksCurrent': '36', 'IPIngressBytes': '[no data]', 'IPIngressPackets': '[no data]', 'IPEgressBytes': '[no data]', 'IPEgressPackets': '[no data]', 'IOReadBytes': '[not set]', 'IOReadOperations': '[not set]', 'IOWriteBytes': '[not set]', 'IOWriteOperations': '[not set]', 'Delegate': 'no', 'CPUAccounting': 'yes', 'CPUWeight': '[not set]', 'StartupCPUWeight': '[not set]', 'CPUShares': '[not set]', 'StartupCPUShares': '[not set]', 'CPUQuotaPerSecUSec': 'infinity', 'CPUQuotaPeriodUSec': 'infinity', 'IOAccounting': 'no', 'IOWeight': '[not set]', 'StartupIOWeight': '[not set]', 'BlockIOAccounting': 'no', 'BlockIOWeight': '[not set]', 'StartupBlockIOWeight': '[not set]', 'MemoryAccounting': 'yes', 'DefaultMemoryLow': '0', 'DefaultStartupMemoryLow': '0', 'DefaultMemoryMin': '0', 'MemoryMin': '0', 'MemoryLow': '0', 'StartupMemoryLow': '0', 'MemoryHigh': 'infinity', 'StartupMemoryHigh': 'infinity', 'MemoryMax': 'infinity', 'StartupMemoryMax': 'infinity', 'MemorySwapMax': 'infinity', 'StartupMemorySwapMax': 'infinity', 'MemoryZSwapMax': 'infinity', 'StartupMemoryZSwapMax': 'infinity', 'MemoryLimit': 'infinity', 'DevicePolicy': 'auto', 'TasksAccounting': 'yes', 'TasksMax': '13974', 'IPAccounting': 'no', 'ManagedOOMSwap': 'auto', 'ManagedOOMMemoryPressure': 'auto', 'ManagedOOMMemoryPressureLimit': '0', 'ManagedOOMPreference': 'none', 'MemoryPressureWatch': 'auto', 'MemoryPressureThresholdUSec': '200ms', 'CoredumpReceive': 'no', 'UMask': '0022', 'LimitCPU': 'infinity', 'LimitCPUSoft': 'infinity', 'LimitFSIZE': 'infinity', 'LimitFSIZESoft': 'infinity', 'LimitDATA': 'infinity', 'LimitDATASoft': 'infinity', 'LimitSTACK': 'infinity', 'LimitSTACKSoft': 'infinity', 'LimitCORE': 'infinity', 'LimitCORESoft': '0', 'LimitRSS': 'infinity', 'LimitRSSSoft': 'infinity', 'LimitNOFILE': '65536', 'LimitNOFILESoft': '65536', 'LimitAS': 'infinity', 'LimitASSoft': 'infinity', 'LimitNPROC': '46581', 'LimitNPROCSoft': '46581', 'LimitMEMLOCK': 'infinity', 'LimitMEMLOCKSoft': 'infinity', 'LimitLOCKS': 'infinity', 'LimitLOCKSSoft': 'infinity', 'LimitSIGPENDING': '46581', 'LimitSIGPENDINGSoft': '46581', 'LimitMSGQUEUE': '819200', 'LimitMSGQUEUESoft': '819200', 'LimitNICE': '0', 'LimitNICESoft': '0', 'LimitRTPRIO': '0', 'LimitRTPRIOSoft': '0', 'LimitRTTIME': 'infinity', 'LimitRTTIMESoft': 'infinity', 'RootEphemeral': 'no', 'OOMScoreAdjust': '0', 'CoredumpFilter': '0x33', 'Nice': '0', 'IOSchedulingClass': '2', 'IOSchedulingPriority': '4', 'CPUSchedulingPolicy': '0', 'CPUSchedulingPriority': '0', 'CPUAffinityFromNUMA': 'no', 'NUMAPolicy': 'n/a', 'TimerSlackNSec': '50000', 'CPUSchedulingResetOnFork': 'no', 'NonBlocking': 'no', 'StandardInput': 'null', 'StandardOutput': 'journal', 'StandardError': 'inherit', 'TTYReset': 'no', 'TTYVHangup': 'no', 'TTYVTDisallocate': 'no', 'SyslogPriority': '30', 'SyslogLevelPrefix': 'yes', 'SyslogLevel': '6', 'SyslogFacility': '3', 'LogLevelMax': '-1', 'LogRateLimitIntervalUSec': '0', 'LogRateLimitBurst': '0', 'SecureBits': '0', 'CapabilityBoundingSet': 'cap_chown cap_dac_override cap_dac_read_search cap_fowner cap_fsetid cap_kill cap_setgid cap_setuid cap_setpcap cap_linux_immutable cap_net_bind_service cap_net_broadcast cap_net_admin cap_net_raw cap_ipc_lock cap_ipc_owner cap_sys_module cap_sys_rawio cap_sys_chroot cap_sys_ptrace cap_sys_pacct cap_sys_admin cap_sys_boot cap_sys_nice cap_sys_resource cap_sys_time cap_sys_tty_config cap_mknod cap_lease cap_audit_write cap_audit_control cap_setfcap cap_mac_override cap_mac_admin cap_syslog cap_wake_alarm cap_block_suspend cap_audit_read cap_perfmon cap_bpf cap_checkpoint_restore', 'User': 'slurm', 'Group': 'slurm', 'DynamicUser': 'no', 'SetLoginEnvironment': 'no', 'RemoveIPC': 'no', 'PrivateTmp': 'yes', 'PrivateDevices': 'no', 'ProtectClock': 'no', 'ProtectKernelTunables': 'no', 'ProtectKernelModules': 'no', 'ProtectKernelLogs': 'no', 'ProtectControlGroups': 'no', 'PrivateNetwork': 'no', 'PrivateUsers': 'no', 'PrivateMounts': 'no', 'PrivateIPC': 'no', 'ProtectHome': 'no', 'ProtectSystem': 'no', 'SameProcessGroup': 'no', 'UtmpMode': 'init', 'IgnoreSIGPIPE': 'yes', 'NoNewPrivileges': 'yes', 'SystemCallErrorNumber': '2147483646', 'LockPersonality': 'no', 'RuntimeDirectoryPreserve': 'no', 'RuntimeDirectoryMode': '0755', 'StateDirectoryMode': '0755', 'CacheDirectoryMode': '0755', 'LogsDirectoryMode': '0755', 'ConfigurationDirectoryMode': '0755', 'TimeoutCleanUSec': 'infinity', 'MemoryDenyWriteExecute': 'no', 'RestrictRealtime': 'no', 'RestrictSUIDSGID': 'no', 'RestrictNamespaces': 'no', 'MountAPIVFS': 'no', 'KeyringMode': 'private', 'ProtectProc': 'default', 'ProcSubset': 'all', 'ProtectHostname': 'no', 'MemoryKSM': 'no', 'RootImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'MountImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'ExtensionImagePolicy': 'root=verity+signed+encrypted+unprotected+absent:usr=verity+signed+encrypted+unprotected+absent:home=encrypted+unprotected+absent:srv=encrypted+unprotected+absent:tmp=encrypted+unprotected+absent:var=encrypted+unprotected+absent', 'KillMode': 'process', 'KillSignal': '15', 'RestartKillSignal': '15', 'FinalKillSignal': '9', 'SendSIGKILL': 'yes', 'SendSIGHUP': 'no', 'WatchdogSignal': '6', 'Id': 'slurmctld.service', 'Names': 'slurmctld.service', 'Requires': 'sysinit.target -.mount system.slice', 'Wants': 'tmp.mount slurmdbd.service munge.service', 'WantedBy': 'multi-user.target', 'Conflicts': 'shutdown.target', 'Before': 'shutdown.target multi-user.target', 'After': 'network.target sysinit.target -.mount slurmdbd.service tmp.mount systemd-tmpfiles-setup.service munge.service system.slice systemd-journald.socket basic.target', 'RequiresMountsFor': '/var/tmp', 'Description': 'Slurm controller daemon', 'LoadState': 'loaded', 'ActiveState': 'active', 'FreezerState': 'running', 'SubState': 'running', 'FragmentPath': '/etc/systemd/system/slurmctld.service', 'UnitFileState': 'enabled', 'UnitFilePreset': 'enabled', 'StateChangeTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'StateChangeTimestampMonotonic': '92270033353', 'InactiveExitTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'InactiveExitTimestampMonotonic': '92270033353', 'ActiveEnterTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'ActiveEnterTimestampMonotonic': '92270033353', 'ActiveExitTimestamp': 'Thu 2025-07-24 12:57:16 MSK', 'ActiveExitTimestampMonotonic': '92267226224', 'InactiveEnterTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'InactiveEnterTimestampMonotonic': '92270026083', 'CanStart': 'yes', 'CanStop': 'yes', 'CanReload': 'no', 'CanIsolate': 'no', 'CanFreeze': 'yes', 'StopWhenUnneeded': 'no', 'RefuseManualStart': 'no', 'RefuseManualStop': 'no', 'AllowIsolate': 'no', 'DefaultDependencies': 'yes', 'SurviveFinalKillSignal': 'no', 'OnSuccessJobMode': 'fail', 'OnFailureJobMode': 'replace', 'IgnoreOnIsolate': 'no', 'NeedDaemonReload': 'no', 'JobTimeoutUSec': 'infinity', 'JobRunningTimeoutUSec': 'infinity', 'JobTimeoutAction': 'none', 'ConditionResult': 'yes', 'AssertResult': 'yes', 'ConditionTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'ConditionTimestampMonotonic': '92270027983', 'AssertTimestamp': 'Thu 2025-07-24 12:57:19 MSK', 'AssertTimestampMonotonic': '92270027993', 'Transient': 'no', 'Perpetual': 'no', 'StartLimitIntervalUSec': '0', 'StartLimitBurst': '5', 'StartLimitAction': 'none', 'FailureAction': 'none', 'SuccessAction': 'none', 'InvocationID': '845ed5d7f9d34e4a97c2523d0cea3cad', 'CollectMode': 'inactive'}, 'invocation': {'module_args': {'name': 'slurmctld', 'daemon_reload': False, 'daemon_reexec': False, 'scope': 'system', 'no_block': False, 'state': None, 'enabled': None, 'force': None, 'masked': None}}, 'failed': False, 'failed_when_result': False, 'item': 'slurmctld', 'ansible_loop_var': 'item'}) => 
  msg: "\U0001F39B️ slurmctld: active"
2025-07-24 16:43:55,611 p=73889 u=master n=ansible | TASK [[TEST] Тест scontrol ping] ******************************************************************************************************************************************************
2025-07-24 16:43:55,612 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:55 +0000 (0:00:00.102)       0:00:20.579 ********* 
2025-07-24 16:43:55,875 p=73889 u=master n=ansible | ok: [sm01]
2025-07-24 16:43:55,879 p=73889 u=master n=ansible | TASK [[TEST] Результат scontrol ping] *************************************************************************************************************************************************
2025-07-24 16:43:55,880 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:55 +0000 (0:00:00.267)       0:00:20.847 ********* 
2025-07-24 16:43:55,932 p=73889 u=master n=ansible | ok: [sm01] => 
  msg: "\U0001F527 scontrol ping:\n✅ УСПЕХ: Slurmctld(primary) at sm01 is UP"
2025-07-24 16:43:55,941 p=73889 u=master n=ansible | RUNNING HANDLER [slurm_master : restart slurmctld] ************************************************************************************************************************************
2025-07-24 16:43:55,941 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:55 +0000 (0:00:00.061)       0:00:20.909 ********* 
2025-07-24 16:43:56,875 p=73889 u=master n=ansible | changed: [sm01]
2025-07-24 16:43:56,880 p=73889 u=master n=ansible | RUNNING HANDLER [slurm_master : restart slurmdbd] *************************************************************************************************************************************
2025-07-24 16:43:56,881 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:56 +0000 (0:00:00.939)       0:00:21.848 ********* 
2025-07-24 16:43:57,727 p=73889 u=master n=ansible | changed: [sm01]
2025-07-24 16:43:57,735 p=73889 u=master n=ansible | PLAY RECAP ****************************************************************************************************************************************************************************
2025-07-24 16:43:57,735 p=73889 u=master n=ansible | sm01                       : ok=39   changed=9    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
2025-07-24 16:43:57,735 p=73889 u=master n=ansible | Playbook run took 0 days, 0 hours, 0 minutes, 22 seconds
2025-07-24 16:43:57,735 p=73889 u=master n=ansible | Thursday 24 July 2025  16:43:57 +0000 (0:00:00.854)       0:00:22.703 ********* 
2025-07-24 16:43:57,735 p=73889 u=master n=ansible | =============================================================================== 
2025-07-24 16:43:57,736 p=73889 u=master n=ansible | slurm_master : [MARIADB] Перезапуск MariaDB для применения настроек ------------------------------------------------------------------------------------------------------------ 4.14s
2025-07-24 16:43:57,736 p=73889 u=master n=ansible | slurm_master : [SERVICES] Пауза после запуска slurmdbd ------------------------------------------------------------------------------------------------------------------------- 3.06s
2025-07-24 16:43:57,736 p=73889 u=master n=ansible | [TEST] Проверка MariaDB перед настройкой --------------------------------------------------------------------------------------------------------------------------------------- 1.34s
2025-07-24 16:43:57,736 p=73889 u=master n=ansible | [TEST] Проверка созданных файлов ----------------------------------------------------------------------------------------------------------------------------------------------- 1.30s
2025-07-24 16:43:57,736 p=73889 u=master n=ansible | slurm_master : [CONFIG] Копирование конфигов на NFS для распространения -------------------------------------------------------------------------------------------------------- 0.95s
2025-07-24 16:43:57,736 p=73889 u=master n=ansible | slurm_master : restart slurmctld ----------------------------------------------------------------------------------------------------------------------------------------------- 0.94s
2025-07-24 16:43:57,736 p=73889 u=master n=ansible | [TEST] Проверка сервисов ------------------------------------------------------------------------------------------------------------------------------------------------------- 0.89s
2025-07-24 16:43:57,736 p=73889 u=master n=ansible | slurm_master : restart slurmdbd ------------------------------------------------------------------------------------------------------------------------------------------------ 0.85s
2025-07-24 16:43:57,737 p=73889 u=master n=ansible | slurm_master : [MARIADB] Создание конфига оптимизации для Slurm ---------------------------------------------------------------------------------------------------------------- 0.84s
2025-07-24 16:43:57,737 p=73889 u=master n=ansible | slurm_master : [CONFIG] Создание основного конфига slurm.conf ------------------------------------------------------------------------------------------------------------------ 0.81s
2025-07-24 16:43:57,737 p=73889 u=master n=ansible | slurm_master : [SERVICES] Перезагрузка systemd daemon -------------------------------------------------------------------------------------------------------------------------- 0.79s
2025-07-24 16:43:57,737 p=73889 u=master n=ansible | slurm_master : [CONFIG] Создание gres.conf для GPU ----------------------------------------------------------------------------------------------------------------------------- 0.66s
2025-07-24 16:43:57,737 p=73889 u=master n=ansible | slurm_master : [CONFIG] Создание конфига slurmdbd.conf ------------------------------------------------------------------------------------------------------------------------- 0.64s
2025-07-24 16:43:57,737 p=73889 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmdbd ------------------------------------------------------------------------------------------------------------------- 0.62s
2025-07-24 16:43:57,737 p=73889 u=master n=ansible | slurm_master : [CONFIG] Создание cgroup.conf ----------------------------------------------------------------------------------------------------------------------------------- 0.60s
2025-07-24 16:43:57,737 p=73889 u=master n=ansible | slurm_master : [SERVICES] Создание systemd unit для slurmctld ------------------------------------------------------------------------------------------------------------------ 0.56s
2025-07-24 16:43:57,737 p=73889 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmdbd (сначала база) ----------------------------------------------------------------------------------------------------------------------- 0.53s
2025-07-24 16:43:57,737 p=73889 u=master n=ansible | slurm_master : [SERVICES] Запуск slurmctld (после базы) ------------------------------------------------------------------------------------------------------------------------ 0.49s
2025-07-24 16:43:57,738 p=73889 u=master n=ansible | slurm_master : [MARIADB] Создание пользователя и базы Slurm (исправленная версия) ---------------------------------------------------------------------------------------------- 0.41s
2025-07-24 16:43:57,738 p=73889 u=master n=ansible | slurm_master : [MARIADB] Проверка списка баз данных ---------------------------------------------------------------------------------------------------------------------------- 0.30s
