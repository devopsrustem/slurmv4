# roles/slurm_compute/tasks/main.yml
---
# =============================================================================
# SLURM COMPUTE NODE CONFIGURATION
# =============================================================================

- name: "[SLURM-COMPUTE] –ù–∞—á–∞–ª–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ Slurm Compute —É–∑–ª–∞"
  debug:
    msg: |
      üéØ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Slurm Compute —É–∑–ª–∞: {{ inventory_hostname }}
      üîó Master: {{ slurm_master_host }} ({{ slurm_master_addr }})
      üñ•Ô∏è  GPU: {{ gpu_count }}x {{ gpu_type }}

# =============================================================================
# –£–°–¢–ê–ù–û–í–ö–ê SLURM BINARIES
# =============================================================================

- name: "[SLURM-COMPUTE] –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Slurm binaries"
  stat:
    path: "/opt/slurm/sbin/slurmd"
  register: slurmd_binary
  tags: verify

- name: "[SLURM-COMPUTE] –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ Slurm binaries –∏–∑ NFS"
  shell: |
    cp -r /sw/slurm-final/* /opt/slurm/
    chown -R root:root /opt/slurm
    chmod -R 755 /opt/slurm/bin /opt/slurm/sbin
    echo "‚úÖ Slurm —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω –Ω–∞ {{ inventory_hostname }}"
  when: not slurmd_binary.stat.exists
  tags: install

- name: "[SLURM-COMPUTE] –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–∞—Å—Ç–µ—Ä —É–∑–ª–∞"
  wait_for:
    host: "{{ slurm_master_addr }}"
    port: 6817
    timeout: 10
  ignore_errors: true
  register: master_connectivity
  tags: verify

- name: "[SLURM-COMPUTE] –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –º–∞—Å—Ç–µ—Ä —É–∑–ª–µ"
  debug:
    msg: |
      ‚ö†Ô∏è  –ú–∞—Å—Ç–µ—Ä —É–∑–µ–ª {{ slurm_master_host }}:6817 –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
      üîß –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫—É, –Ω–æ slurmd –º–æ–∂–µ—Ç –Ω–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è
  when: master_connectivity.failed | default(false)
  tags: verify

# =============================================================================
# –ö–û–ü–ò–†–û–í–ê–ù–ò–ï –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–û–ù–ù–´–• –§–ê–ô–õ–û–í
# =============================================================================

- name: "[SLURM-COMPUTE] –û–∂–∏–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –Ω–∞ NFS"
  wait_for:
    path: "{{ nfs_config_path }}/{{ item }}"
    timeout: 30
  loop: "{{ slurm_config_files }}"
  tags: config

- name: "[SLURM-COMPUTE] –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ NFS"
  copy:
    src: "{{ nfs_config_path }}/{{ item }}"
    dest: "{{ slurm_config_dir }}/{{ item }}"
    remote_src: yes
    owner: slurm
    group: slurm
    mode: '0644'
    backup: yes
  loop: "{{ slurm_config_files }}"
  notify: restart slurmd
  tags: config

# =============================================================================
# –ö–û–ü–ò–†–û–í–ê–ù–ò–ï PROLOG/EPILOG –°–ö–†–ò–ü–¢–û–í
# =============================================================================

- name: "[SLURM-COMPUTE] –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è prolog/epilog"
  file:
    path: "{{ item }}"
    state: directory
    owner: root
    group: root
    mode: '0755'
  loop:
    - /etc/slurm/prolog.d
    - /etc/slurm/epilog.d

- name: "[SLURM-COMPUTE] –û–∂–∏–¥–∞–Ω–∏–µ prolog/epilog —Å–∫—Ä–∏–ø—Ç–æ–≤ –Ω–∞ NFS"
  wait_for:
    path: "{{ nfs_config_path }}/{{ item }}"
    timeout: 30
  loop:
    - prolog.sh
    - epilog.sh

- name: "[SLURM-COMPUTE] –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ prolog/epilog —Å–∫—Ä–∏–ø—Ç–æ–≤ –∏–∑ NFS"
  copy:
    src: "{{ nfs_config_path }}/{{ item.src }}"
    dest: "{{ item.dest }}"
    remote_src: yes
    owner: root
    group: root
    mode: '0755'
    backup: yes
  loop:
    - { src: "prolog.sh", dest: "/etc/slurm/prolog.d/prolog.sh" }
    - { src: "epilog.sh", dest: "/etc/slurm/epilog.d/epilog.sh" }
  notify: restart slurmd

- name: "[SLURM-COMPUTE] –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∏—Ö —Å—Å—ã–ª–æ–∫ –Ω–∞ –∫–æ–º–∞–Ω–¥—ã"
  file:
    src: "/opt/slurm/bin/{{ item }}"
    dest: "/usr/bin/{{ item }}"
    state: link
    force: yes
  loop:
    - sinfo
    - squeue
    - sbatch
    - srun
    - scancel
    - scontrol
  tags: links

- name: "[SLURM-COMPUTE] –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–º–≤–æ–ª–∏—á–µ—Å–∫–∏—Ö —Å—Å—ã–ª–æ–∫ –Ω–∞ –¥–µ–º–æ–Ω—ã"
  file:
    src: "/opt/slurm/sbin/{{ item }}"
    dest: "/usr/sbin/{{ item }}"
    state: link
    force: yes
  loop:
    - slurmd
  tags: links

# =============================================================================
# GPU DETECTION (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
# =============================================================================

- name: "[SLURM-COMPUTE] –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è NVIDIA GPU"
  command: nvidia-smi -L
  register: nvidia_check
  failed_when: false
  changed_when: false
  when: gpu_detection_enabled
  tags: gpu

- name: "[SLURM-COMPUTE] –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è GPU"
  debug:
    msg: |
      {% if nvidia_check.rc == 0 %}
      üéÆ GPU –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã:
      {{ nvidia_check.stdout_lines | join('\n') }}
      {% else %}
      ‚ö†Ô∏è  GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–ª–∏ nvidia-smi –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
      üìù –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
      {% endif %}
  when: gpu_detection_enabled
  tags: gpu

# =============================================================================
# SYSTEMD SERVICE CONFIGURATION
# =============================================================================

- name: "[SLURM-COMPUTE] –°–æ–∑–¥–∞–Ω–∏–µ systemd unit –¥–ª—è slurmd"
  template:
    src: slurmd.service.j2
    dest: /etc/systemd/system/slurmd.service
    owner: root
    group: root
    mode: '0644'
  notify: restart slurmd
  tags: service

- name: "[SLURM-COMPUTE] –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ systemd daemon"
  systemd:
    daemon_reload: yes
  tags: service

# =============================================================================
# CGROUP CONFIGURATION
# =============================================================================

- name: "[SLURM-COMPUTE] –ü—Ä–æ–≤–µ—Ä–∫–∞ cgroup v1/v2"
  shell: |
    if [ -d /sys/fs/cgroup/systemd ]; then
      echo "cgroup_v1"
    elif [ -f /sys/fs/cgroup/cgroup.controllers ]; then
      echo "cgroup_v2"
    else
      echo "unknown"
    fi
  register: cgroup_version
  changed_when: false
  when: cgroup_enabled
  tags: cgroup

- name: "[SLURM-COMPUTE] –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ cgroup"
  debug:
    msg: |
      üóÇÔ∏è  Cgroup –≤–µ—Ä—Å–∏—è: {{ cgroup_version.stdout | default('–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞') }}
      üìÅ –¢–æ—á–∫–∞ –º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: /sys/fs/cgroup
  when: cgroup_enabled
  tags: cgroup

# =============================================================================
# NODE HEALTH CHECK
# =============================================================================

- name: "[SLURM-COMPUTE] –°–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–¥–æ—Ä–æ–≤—å—è —É–∑–ª–∞"
  copy:
    dest: /usr/local/bin/slurm_health_check.sh
    mode: '0755'
    content: |
      #!/bin/bash
      # Slurm Node Health Check Script
      # Generated by Ansible
      
      # Check disk space
      DISK_USAGE=$(df / | tail -1 | awk '{print $5}' | sed 's/%//')
      if [ $DISK_USAGE -gt 90 ]; then
        echo "ERROR: Disk usage is ${DISK_USAGE}%"
        exit 1
      fi
      
      # Check memory
      MEM_AVAILABLE=$(free | awk '/^Mem:/{print int($7/$2*100)}')
      if [ $MEM_AVAILABLE -lt 5 ]; then
        echo "ERROR: Memory usage too high, only ${MEM_AVAILABLE}% available"
        exit 1
      fi
      
      # Check GPU (if present)
      if command -v nvidia-smi >/dev/null 2>&1; then
        if ! nvidia-smi -q >/dev/null 2>&1; then
          echo "ERROR: GPU check failed"
          exit 1
        fi
      fi
      
      echo "Node {{ inventory_hostname }} is healthy"
      exit 0
  tags: health

# =============================================================================
# SERVICE STARTUP
# =============================================================================

- name: "[SLURM-COMPUTE] –ó–∞–ø—É—Å–∫ –∏ –≤–∫–ª—é—á–µ–Ω–∏–µ slurmd"
  systemd:
    name: slurmd
    enabled: "{{ slurmd_service_enabled }}"
    state: "{{ slurmd_auto_start | ternary('started', 'stopped') }}"
  tags: service

# =============================================================================
# VERIFICATION
# =============================================================================

- name: "[SLURM-COMPUTE] –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ –ø—Ä–æ–≤–µ—Ä–∫–æ–π"
  pause:
    seconds: 5
  tags: verify

- name: "[SLURM-COMPUTE] –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ slurmd"
  systemd:
    name: slurmd
  register: slurmd_status
  tags: verify

- name: "[SLURM-COMPUTE] –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤ slurmd"
  shell: |
    if systemctl is-active slurmd >/dev/null 2>&1; then
      echo "‚úÖ slurmd –∞–∫—Ç–∏–≤–µ–Ω"
      tail -3 {{ slurmd_log_file }} 2>/dev/null || echo "–õ–æ–≥–∏ –ø–æ–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"
    else
      echo "‚ùå slurmd –Ω–µ–∞–∫—Ç–∏–≤–µ–Ω"
      journalctl -u slurmd -n 5 --no-pager
    fi
  register: slurmd_check
  changed_when: false
  tags: verify

- name: "[SLURM-COMPUTE] –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –º–∞—Å—Ç–µ—Ä—É"
  shell: |
    # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ slurmctld
    timeout 10 telnet {{ slurm_master_addr }} 6817 </dev/null >/dev/null 2>&1
    if [ $? -eq 0 ]; then
      echo "‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –º–∞—Å—Ç–µ—Ä—É —Ä–∞–±–æ—Ç–∞–µ—Ç"
    else
      echo "‚ö†Ô∏è  –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –º–∞—Å—Ç–µ—Ä—É –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ"
    fi
  register: master_connection_test
  failed_when: false
  changed_when: false
  tags: verify
